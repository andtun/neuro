{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import imageio\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.layers import Dense, Input, Dropout\n",
    "from tensorflow.keras.models import Sequential, Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Misc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# todo: apply to classes\n",
    "def make_trainable(net, val, lr=0.001):\n",
    "    net.model.trainable = val\n",
    "    for l in net.model.layers:\n",
    "        l.trainable = val\n",
    "    net.cmpile(lr)\n",
    "    \n",
    "def define_gan(generator, discriminator):\n",
    "    # make weights in the discriminator not trainable\n",
    "    discriminator.trainable = False\n",
    "    # connect them\n",
    "    model = Sequential()\n",
    "    # add generator\n",
    "    model.add(generator)\n",
    "    # add the discriminator\n",
    "    model.add(discriminator)\n",
    "    # при замене оптимизатора всё слетает ???\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam')\n",
    "    return model\n",
    "\n",
    "def fit_discriminator(discriminator, Data, epochs, lr=0.001):\n",
    "    make_trainable(discriminator, True, lr=lr)\n",
    "    #discriminator.trainable = True\n",
    "    discriminator.fit(Data.x, Data.y, epochs=epochs, plot=True)\n",
    "    \n",
    "# Training GAN\n",
    "def fit_gan(gan, Data, epochs):\n",
    "    p = Plot('GAN_results')\n",
    "\n",
    "    for i in range(epochs):\n",
    "        V = Data.load_random(n_samples=64)\n",
    "        print(\"Epoch %d\" % i)\n",
    "        generated = generator.predict(V)\n",
    "        if i % 10 == 0:\n",
    "            p.add_to_gif(generated, np.ones(V.shape[0]), title='Epoch %d' % i, alpha=1)\n",
    "        #make_trainable(discriminator, False)\n",
    "        print(\"Fitting GAN\")\n",
    "        gan.fit(V, np.ones(V.shape[0]), epochs=2)\n",
    "        #make_trainable(discriminator, True)\n",
    "        print(\"Fitting discriminator\")\n",
    "        discriminator.fit(generated, np.zeros(V.shape[0]), validation_split=None)\n",
    "        discriminator.fit(Data.x, Data.y, validation_split=0.2)\n",
    "    p.save_gif()\n",
    "    gan.save('gan.h5')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data generation class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To generate data\n",
    "class Dataset():\n",
    "    x = None\n",
    "    y = None\n",
    "    W = None\n",
    "    \n",
    "    def __init__(self):\n",
    "        return\n",
    "    \n",
    "    def load_data(self, data_range=10):\n",
    "        dots_x = []\n",
    "        for i in range(data_range):\n",
    "            x = random.gauss(0, data_range)\n",
    "            dots_x.append((x, x**2)) # square\n",
    "            for j in range(4):\n",
    "                dots_x.append((x, random.gauss(x**2, data_range**2))) # less than square\n",
    "                #dots_x.append((x**r, x**(2*r*(1+random.gauss(0.5, 0.25)/20)))) # more than square\n",
    "        dots_x = np.array(dots_x)\n",
    "        #dots_y = np.array([random.uniform(0.75, 1.2) if x[0]**2 == x[1] else random.uniform(0, 0.3) for x in dots_x])\n",
    "        dots_y = np.array([1 if x[0]**2 == x[1] else 0 for x in dots_x])\n",
    "        self.x, self.y = dots_x, dots_y\n",
    "        return dots_x, dots_y\n",
    "    \n",
    "    def load_weights(self, default_weight=0.12):\n",
    "        W = self.y.copy().astype(float)\n",
    "        W[W == 0] = 0.12\n",
    "        self.W = W\n",
    "        return W\n",
    "        \n",
    "    @staticmethod\n",
    "    def load_random(n_dim=5, n_samples=16):\n",
    "        V = np.random.normal(size=(n_samples, n_dim))\n",
    "        return V\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image plotting class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To plot images\n",
    "class Plot:\n",
    "    name = \"\"\n",
    "    images = []\n",
    "    threshold = 0.0\n",
    "    \n",
    "    def __init__(self, name, threshold=0.6):\n",
    "        self.name = name\n",
    "        self.threshold = threshold\n",
    "        self.images = []\n",
    "    \n",
    "    @staticmethod\n",
    "    def parabola_plot(ax, xrange):\n",
    "        x = np.linspace(xrange, 1)\n",
    "        y = x*x\n",
    "        plt.plot(x, y)\n",
    "    \n",
    "    @staticmethod\n",
    "    def dots_plot(ax, dots_x, dots_y, color):\n",
    "        ax.scatter(dots_x, dots_y, color=color, alpha=0.15)\n",
    "        plt.plot()\n",
    "    \n",
    "    def picture(self, dots, predictions, title='', alpha=0.3):\n",
    "        predictions = predictions.reshape(predictions.shape[0])\n",
    "        dots_x = dots.T[0]\n",
    "        fig = plt.figure()\n",
    "        ax1 = fig.add_subplot(111)\n",
    "        ax1.set(title=title)\n",
    "        #ax2 = ax1.twinx()\n",
    "        plt.grid(axis='both')\n",
    "        xrange = (dots_x.min(), dots_x.max())\n",
    "        self.parabola_plot(ax1, xrange)\n",
    "        ax1.scatter(dots.T[0], dots.T[1], c=predictions, cmap='YlOrRd', alpha=alpha)\n",
    "        \n",
    "    def add_to_gif(self, dots_x, predictions, title='', alpha=0.3):\n",
    "        self.picture(dots_x, predictions, title=title, alpha=alpha)\n",
    "        plt.savefig(self.name+'.png')\n",
    "        plt.close()\n",
    "        image = Image.open(self.name+'.png')\n",
    "        ar = np.asarray(image)\n",
    "        self.images.append(ar)\n",
    "        \n",
    "    def save_gif(self):\n",
    "        kargs = { 'duration': 0.2 }\n",
    "        imageio.mimsave(self.name+'.gif', self.images, None, **kargs)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural networks classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classes for neural networks\n",
    "\n",
    "# Generator\n",
    "class Gen:\n",
    "    model = None\n",
    "    \n",
    "    def __init__(self):\n",
    "        model = Sequential([tf.keras.layers.LeakyReLU(),\n",
    "                            Dense(15, input_dim=5, kernel_initializer='he_uniform'),\n",
    "                            Dense(2, activation='linear')\n",
    "        ])\n",
    "        self.model = model\n",
    "        \n",
    "    def predict(self, dots_x):\n",
    "        return self.model.predict(dots_x)\n",
    "    \n",
    "    def cmpile(self):\n",
    "        return\n",
    "    \n",
    "# Discriminator\n",
    "class Dsc:\n",
    "    model = None\n",
    "    \n",
    "    def __init__(self):\n",
    "        model = Sequential([tf.keras.layers.LeakyReLU(),\n",
    "                            Dense(25, input_dim=2, kernel_initializer='he_uniform'),\n",
    "                            Dense(1, activation='sigmoid')\n",
    "        ])\n",
    "        self.model = model\n",
    "    \n",
    "    def cmpile(self, lr=0.0001):\n",
    "        self.model.compile(loss='binary_crossentropy',\n",
    "                           optimizer=tf.keras.optimizers.Adam(lr),\n",
    "                           metrics=['accuracy'])\n",
    "        \n",
    "    def fit(self, dots_x, dots_y, weights=None, epochs=1, validation_split=0.15, plot=False):\n",
    "        if plot:\n",
    "            img = Plot('discriminator_fit')\n",
    "            for i in range(epochs):\n",
    "                print(\"Epoch %d out of %d\" % (i, epochs))\n",
    "                self.model.fit(dots_x, \n",
    "                               dots_y, \n",
    "                               epochs=10, \n",
    "                               sample_weight=weights,\n",
    "                               validation_split=validation_split)\n",
    "                img.add_to_gif(dots_x, self.model.predict(dots_x), title='Epoch %d' % i)\n",
    "            img.save_gif()                        \n",
    "        else:\n",
    "            self.model.fit(dots_x, \n",
    "                           dots_y, \n",
    "                           epochs=epochs, \n",
    "                           sample_weight=weights, \n",
    "                           validation_split=validation_split)\n",
    "    \n",
    "    def save(self, name='discriminator'):\n",
    "        self.model.save(name+'.h5')\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# # Raw classes, don't work \n",
    "\n",
    "```python\n",
    "class Gan:\n",
    "    gen = None\n",
    "    dsc = None\n",
    "    model = None\n",
    "    \n",
    "    def __init__(self, gen, dsc, n_dim=5):\n",
    "        make_trainable(dsc, False)\n",
    "        self.gen = gen\n",
    "        self.dsc = dsc\n",
    "        # connect them\n",
    "        model = Sequential()\n",
    "        # add generator\n",
    "        model.add(gen.model)\n",
    "        # add the discriminator\n",
    "        model.add(dsc.model)\n",
    "        self.model = model\n",
    "    \n",
    "    # This method doesn't work\n",
    "    # Presumably because of some optimizer issue\n",
    "    def cmpile(self, lr=0.001):\n",
    "        self.model.compile(loss='binary_crossentropy',\n",
    "                           optimizer=tf.keras.optimizers.Adam(lr),\n",
    "                           metrics = ['accuracy'])\n",
    "        \n",
    "    def fit(self, dots_x, dots_y, epochs=1):\n",
    "        self.model.fit(dots_x, dots_y, epochs=epochs)\n",
    "        \n",
    "class Dummy:\n",
    "    model = None\n",
    "    \n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "        \n",
    "    def cmpile(self, lr=0.0001):\n",
    "        self.model.compile(loss='binary_crossentropy',\n",
    "                           optimizer=tf.keras.optimizers.Adam(lr),\n",
    "                           metrics=['accuracy'])\n",
    "    \n",
    "    # todo: remove hardcode\n",
    "    def fit(self, dots_x, dots_y, weights=None, epochs=1, validation_split=0.15, plot=False):\n",
    "        if plot:\n",
    "            img = Plot('discriminator_fit')\n",
    "            for i in range(epochs//25):\n",
    "                print(\"Epoch %d out of %d\" % (i, epochs))\n",
    "                self.model.fit(dots_x, \n",
    "                               dots_y, \n",
    "                               epochs=25, \n",
    "                               sample_weight=weights)\n",
    "                img.add_to_gif(dots_x, self.model.predict(dots_x), title='Epoch %d' % i*25)\n",
    "            img.save_gif()                        \n",
    "        else:\n",
    "            self.model.fit(dots_x, \n",
    "                           dots_y, \n",
    "                           epochs=epochs, \n",
    "                           sample_weight=weights, \n",
    "                           validation_split=validation_split)\n",
    "    \n",
    "    def save(self, name='discriminator'):\n",
    "        self.model.save(name+'.h5')\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#discriminator = tf.keras.models.load_model('discriminator.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start Here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating data\n",
    "Data = Dataset()\n",
    "Data.load_data(data_range=1000)\n",
    "weights = Data.load_weights()\n",
    "\n",
    "# Defining neural networks\n",
    "generator = Gen()\n",
    "discriminator = Dsc()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 out of 200\n",
      "Train on 4250 samples, validate on 750 samples\n",
      "Epoch 1/10\n",
      "4250/4250 [==============================] - 1s 333us/sample - loss: 49297.5242 - acc: 0.5487 - val_loss: 1766.5903 - val_acc: 0.5707\n",
      "Epoch 2/10\n",
      "4250/4250 [==============================] - 1s 218us/sample - loss: 18906.2685 - acc: 0.5534 - val_loss: 7796.1712 - val_acc: 0.5547\n",
      "Epoch 3/10\n",
      "4250/4250 [==============================] - 1s 271us/sample - loss: 13515.6579 - acc: 0.5532 - val_loss: 14203.4100 - val_acc: 0.5413\n",
      "Epoch 4/10\n",
      "4250/4250 [==============================] - 1s 232us/sample - loss: 14431.4179 - acc: 0.5546 - val_loss: 4631.5997 - val_acc: 0.5587\n",
      "Epoch 5/10\n",
      "4250/4250 [==============================] - 1s 243us/sample - loss: 12511.5800 - acc: 0.5536 - val_loss: 9831.5083 - val_acc: 0.5493\n",
      "Epoch 6/10\n",
      "4250/4250 [==============================] - 1s 255us/sample - loss: 18878.4384 - acc: 0.5513 - val_loss: 8548.2822 - val_acc: 0.5560\n",
      "Epoch 7/10\n",
      "4250/4250 [==============================] - 1s 223us/sample - loss: 15988.3196 - acc: 0.5609 - val_loss: 15044.2141 - val_acc: 0.5413\n",
      "Epoch 8/10\n",
      "4250/4250 [==============================] - 1s 258us/sample - loss: 13220.5270 - acc: 0.5522 - val_loss: 8924.7463 - val_acc: 0.5560\n",
      "Epoch 9/10\n",
      "4250/4250 [==============================] - 1s 242us/sample - loss: 14908.0491 - acc: 0.5591 - val_loss: 8780.3703 - val_acc: 0.5560\n",
      "Epoch 10/10\n",
      "4250/4250 [==============================] - 1s 245us/sample - loss: 12243.7643 - acc: 0.5515 - val_loss: 2817.5647 - val_acc: 0.4093\n",
      "Epoch 1 out of 200\n",
      "Train on 4250 samples, validate on 750 samples\n",
      "Epoch 1/10\n",
      "4250/4250 [==============================] - 1s 251us/sample - loss: 13193.3197 - acc: 0.5572 - val_loss: 1337.7800 - val_acc: 0.5867\n",
      "Epoch 2/10\n",
      "4250/4250 [==============================] - 1s 237us/sample - loss: 27563.8634 - acc: 0.5454 - val_loss: 1771.3617 - val_acc: 0.5760\n",
      "Epoch 3/10\n",
      "4250/4250 [==============================] - 1s 252us/sample - loss: 16543.2090 - acc: 0.5633 - val_loss: 686.2117 - val_acc: 0.4720\n",
      "Epoch 4/10\n",
      "4250/4250 [==============================] - 1s 248us/sample - loss: 10289.1014 - acc: 0.5619 - val_loss: 481.0179 - val_acc: 0.4760\n",
      "Epoch 5/10\n",
      "4250/4250 [==============================] - 1s 246us/sample - loss: 11919.6463 - acc: 0.5433 - val_loss: 14016.5572 - val_acc: 0.5400\n",
      "Epoch 6/10\n",
      "4250/4250 [==============================] - 1s 240us/sample - loss: 20628.8913 - acc: 0.5414 - val_loss: 7050.9608 - val_acc: 0.5533\n",
      "Epoch 7/10\n",
      "4250/4250 [==============================] - 1s 245us/sample - loss: 16593.8914 - acc: 0.5445 - val_loss: 11672.9677 - val_acc: 0.5427\n",
      "Epoch 8/10\n",
      "4250/4250 [==============================] - 1s 245us/sample - loss: 15073.2816 - acc: 0.5473 - val_loss: 17184.6785 - val_acc: 0.5400\n",
      "Epoch 9/10\n",
      "4250/4250 [==============================] - 1s 246us/sample - loss: 15076.6372 - acc: 0.5536 - val_loss: 8798.8339 - val_acc: 0.5467\n",
      "Epoch 10/10\n",
      "4250/4250 [==============================] - 1s 237us/sample - loss: 13893.1589 - acc: 0.5539 - val_loss: 12239.4918 - val_acc: 0.4507\n",
      "Epoch 2 out of 200\n",
      "Train on 4250 samples, validate on 750 samples\n",
      "Epoch 1/10\n",
      "4250/4250 [==============================] - 1s 264us/sample - loss: 12978.8706 - acc: 0.5565 - val_loss: 11127.8146 - val_acc: 0.5427\n",
      "Epoch 2/10\n",
      "4250/4250 [==============================] - 1s 253us/sample - loss: 13012.5631 - acc: 0.5555 - val_loss: 8186.4728 - val_acc: 0.5467\n",
      "Epoch 3/10\n",
      "4250/4250 [==============================] - 1s 258us/sample - loss: 10877.5175 - acc: 0.5536 - val_loss: 2675.5650 - val_acc: 0.5627\n",
      "Epoch 4/10\n",
      "4250/4250 [==============================] - 1s 235us/sample - loss: 10801.3820 - acc: 0.5591 - val_loss: 4862.0339 - val_acc: 0.5573\n",
      "Epoch 5/10\n",
      "4250/4250 [==============================] - 1s 247us/sample - loss: 12954.7737 - acc: 0.5560 - val_loss: 2035.3084 - val_acc: 0.5707\n",
      "Epoch 6/10\n",
      "4250/4250 [==============================] - 1s 229us/sample - loss: 9922.8139 - acc: 0.5565 - val_loss: 14309.6920 - val_acc: 0.5400\n",
      "Epoch 7/10\n",
      "4250/4250 [==============================] - 1s 257us/sample - loss: 10580.8358 - acc: 0.5487 - val_loss: 4699.3940 - val_acc: 0.5573\n",
      "Epoch 8/10\n",
      "4250/4250 [==============================] - 1s 234us/sample - loss: 11267.2486 - acc: 0.5452 - val_loss: 10919.9355 - val_acc: 0.5400\n",
      "Epoch 9/10\n",
      "4250/4250 [==============================] - 1s 232us/sample - loss: 8182.2147 - acc: 0.5529 - val_loss: 7638.2637 - val_acc: 0.4507\n",
      "Epoch 10/10\n",
      "4250/4250 [==============================] - 1s 252us/sample - loss: 7126.1440 - acc: 0.5482 - val_loss: 5865.0348 - val_acc: 0.5453\n",
      "Epoch 3 out of 200\n",
      "Train on 4250 samples, validate on 750 samples\n",
      "Epoch 1/10\n",
      "4250/4250 [==============================] - 1s 246us/sample - loss: 10123.4331 - acc: 0.5647 - val_loss: 2519.2210 - val_acc: 0.5587\n",
      "Epoch 2/10\n",
      "4250/4250 [==============================] - 1s 240us/sample - loss: 11878.0348 - acc: 0.5515 - val_loss: 2677.1809 - val_acc: 0.5600\n",
      "Epoch 3/10\n",
      "4250/4250 [==============================] - 1s 236us/sample - loss: 10045.5597 - acc: 0.5506 - val_loss: 4814.8767 - val_acc: 0.4373\n",
      "Epoch 4/10\n",
      "4250/4250 [==============================] - 1s 244us/sample - loss: 6703.7395 - acc: 0.5558 - val_loss: 2888.6074 - val_acc: 0.5600\n",
      "Epoch 5/10\n",
      "4250/4250 [==============================] - 1s 230us/sample - loss: 6805.5294 - acc: 0.5548 - val_loss: 1801.8883 - val_acc: 0.5707\n",
      "Epoch 6/10\n",
      "4250/4250 [==============================] - 1s 248us/sample - loss: 7423.2458 - acc: 0.5548 - val_loss: 12135.5350 - val_acc: 0.5400\n",
      "Epoch 7/10\n",
      "4250/4250 [==============================] - 1s 250us/sample - loss: 10099.2743 - acc: 0.5544 - val_loss: 8855.1634 - val_acc: 0.4493\n",
      "Epoch 8/10\n",
      "4250/4250 [==============================] - 1s 246us/sample - loss: 8866.9474 - acc: 0.5445 - val_loss: 9351.2141 - val_acc: 0.4520\n",
      "Epoch 9/10\n",
      "4250/4250 [==============================] - 1s 248us/sample - loss: 7119.7733 - acc: 0.5456 - val_loss: 6460.8377 - val_acc: 0.5440\n",
      "Epoch 10/10\n",
      "4250/4250 [==============================] - 1s 251us/sample - loss: 6133.0070 - acc: 0.5532 - val_loss: 2945.9892 - val_acc: 0.5587\n",
      "Epoch 4 out of 200\n",
      "Train on 4250 samples, validate on 750 samples\n",
      "Epoch 1/10\n",
      "4250/4250 [==============================] - 1s 251us/sample - loss: 11280.3122 - acc: 0.5464 - val_loss: 12262.3199 - val_acc: 0.5400\n",
      "Epoch 2/10\n",
      "4250/4250 [==============================] - 1s 235us/sample - loss: 6490.5365 - acc: 0.5598 - val_loss: 10017.4962 - val_acc: 0.5400\n",
      "Epoch 3/10\n",
      "4250/4250 [==============================] - 1s 262us/sample - loss: 5902.7841 - acc: 0.5609 - val_loss: 3331.6797 - val_acc: 0.5573\n",
      "Epoch 4/10\n",
      "4250/4250 [==============================] - 1s 252us/sample - loss: 6756.8044 - acc: 0.5560 - val_loss: 303.1742 - val_acc: 0.6160\n",
      "Epoch 5/10\n",
      "4250/4250 [==============================] - 1s 240us/sample - loss: 7987.2669 - acc: 0.5574 - val_loss: 9287.7213 - val_acc: 0.5413\n",
      "Epoch 6/10\n",
      "4250/4250 [==============================] - 1s 233us/sample - loss: 6052.9066 - acc: 0.5558 - val_loss: 9000.7606 - val_acc: 0.5427\n",
      "Epoch 7/10\n",
      "4250/4250 [==============================] - 1s 242us/sample - loss: 6730.2667 - acc: 0.5471 - val_loss: 7759.8175 - val_acc: 0.5427\n",
      "Epoch 8/10\n",
      "4250/4250 [==============================] - 1s 241us/sample - loss: 5855.0550 - acc: 0.5553 - val_loss: 1905.6448 - val_acc: 0.5640\n",
      "Epoch 9/10\n",
      "4250/4250 [==============================] - 1s 246us/sample - loss: 6756.0594 - acc: 0.5520 - val_loss: 3140.1738 - val_acc: 0.4320\n",
      "Epoch 10/10\n",
      "4250/4250 [==============================] - 1s 234us/sample - loss: 5350.6723 - acc: 0.5588 - val_loss: 5658.5989 - val_acc: 0.5440\n",
      "Epoch 5 out of 200\n",
      "Train on 4250 samples, validate on 750 samples\n",
      "Epoch 1/10\n",
      "4250/4250 [==============================] - 1s 262us/sample - loss: 5931.5786 - acc: 0.5416 - val_loss: 8793.1151 - val_acc: 0.5400\n",
      "Epoch 2/10\n",
      "4250/4250 [==============================] - 1s 229us/sample - loss: 4025.5806 - acc: 0.5609 - val_loss: 7183.8169 - val_acc: 0.5427\n",
      "Epoch 3/10\n",
      "4250/4250 [==============================] - 1s 237us/sample - loss: 7582.6807 - acc: 0.5461 - val_loss: 11677.4417 - val_acc: 0.5413\n",
      "Epoch 4/10\n",
      "4250/4250 [==============================] - 1s 238us/sample - loss: 8013.6855 - acc: 0.5471 - val_loss: 938.7319 - val_acc: 0.5800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/10\n",
      "4250/4250 [==============================] - 1s 236us/sample - loss: 4076.7743 - acc: 0.5522 - val_loss: 7286.0675 - val_acc: 0.5413\n",
      "Epoch 6/10\n",
      "4250/4250 [==============================] - 1s 245us/sample - loss: 4224.5184 - acc: 0.5694 - val_loss: 3662.3309 - val_acc: 0.5493\n",
      "Epoch 7/10\n",
      "4250/4250 [==============================] - 1s 246us/sample - loss: 7079.5943 - acc: 0.5369 - val_loss: 2793.9086 - val_acc: 0.5573\n",
      "Epoch 8/10\n",
      "4250/4250 [==============================] - 1s 254us/sample - loss: 6134.4598 - acc: 0.5459 - val_loss: 6054.4639 - val_acc: 0.5427\n",
      "Epoch 9/10\n",
      "4250/4250 [==============================] - 1s 241us/sample - loss: 5255.3775 - acc: 0.5595 - val_loss: 2655.9925 - val_acc: 0.4333\n",
      "Epoch 10/10\n",
      "4250/4250 [==============================] - 1s 231us/sample - loss: 4652.4903 - acc: 0.5536 - val_loss: 4419.4575 - val_acc: 0.5427\n",
      "Epoch 6 out of 200\n",
      "Train on 4250 samples, validate on 750 samples\n",
      "Epoch 1/10\n",
      "4250/4250 [==============================] - 1s 251us/sample - loss: 6831.3302 - acc: 0.5624 - val_loss: 6894.9167 - val_acc: 0.5400\n",
      "Epoch 2/10\n",
      "4250/4250 [==============================] - 1s 242us/sample - loss: 6531.7948 - acc: 0.5567 - val_loss: 1556.5407 - val_acc: 0.4360\n",
      "Epoch 3/10\n",
      "4250/4250 [==============================] - 1s 240us/sample - loss: 7754.1831 - acc: 0.5541 - val_loss: 1852.1515 - val_acc: 0.4320\n",
      "Epoch 4/10\n",
      "4250/4250 [==============================] - 1s 245us/sample - loss: 8173.5073 - acc: 0.5454 - val_loss: 5061.6437 - val_acc: 0.5467\n",
      "Epoch 5/10\n",
      "4250/4250 [==============================] - 1s 246us/sample - loss: 6931.8826 - acc: 0.5562 - val_loss: 4537.4816 - val_acc: 0.5507\n",
      "Epoch 6/10\n",
      "4250/4250 [==============================] - 1s 237us/sample - loss: 3171.8985 - acc: 0.5704 - val_loss: 861.1906 - val_acc: 0.5800\n",
      "Epoch 7/10\n",
      "4250/4250 [==============================] - 1s 241us/sample - loss: 6079.4061 - acc: 0.5584 - val_loss: 12994.4501 - val_acc: 0.5400\n",
      "Epoch 8/10\n",
      "4250/4250 [==============================] - 1s 223us/sample - loss: 4603.3486 - acc: 0.5591 - val_loss: 1342.9488 - val_acc: 0.5693\n",
      "Epoch 9/10\n",
      "4250/4250 [==============================] - 1s 211us/sample - loss: 5512.5329 - acc: 0.5621 - val_loss: 7457.6330 - val_acc: 0.4493\n",
      "Epoch 10/10\n",
      "4250/4250 [==============================] - 1s 261us/sample - loss: 6451.8775 - acc: 0.5435 - val_loss: 1995.6222 - val_acc: 0.4333\n",
      "Epoch 7 out of 200\n",
      "Train on 4250 samples, validate on 750 samples\n",
      "Epoch 1/10\n",
      "4250/4250 [==============================] - 1s 246us/sample - loss: 4050.6139 - acc: 0.5508 - val_loss: 2403.3068 - val_acc: 0.5573\n",
      "Epoch 2/10\n",
      "4250/4250 [==============================] - 1s 209us/sample - loss: 4798.1468 - acc: 0.5619 - val_loss: 5481.2252 - val_acc: 0.4453\n",
      "Epoch 3/10\n",
      "4250/4250 [==============================] - 1s 205us/sample - loss: 5177.4085 - acc: 0.5485 - val_loss: 1986.7818 - val_acc: 0.5587\n",
      "Epoch 4/10\n",
      "4250/4250 [==============================] - 1s 239us/sample - loss: 3383.9155 - acc: 0.5515 - val_loss: 1041.1737 - val_acc: 0.5720\n",
      "Epoch 5/10\n",
      "4250/4250 [==============================] - 1s 252us/sample - loss: 4436.9886 - acc: 0.5551 - val_loss: 3323.9132 - val_acc: 0.5467\n",
      "Epoch 6/10\n",
      "4250/4250 [==============================] - 1s 234us/sample - loss: 5584.4830 - acc: 0.5518 - val_loss: 3727.2613 - val_acc: 0.5440\n",
      "Epoch 7/10\n",
      "4250/4250 [==============================] - 1s 246us/sample - loss: 4678.8253 - acc: 0.5551 - val_loss: 1967.9858 - val_acc: 0.5587\n",
      "Epoch 8/10\n",
      "4250/4250 [==============================] - 1s 251us/sample - loss: 3599.2936 - acc: 0.5520 - val_loss: 3041.1508 - val_acc: 0.5493\n",
      "Epoch 9/10\n",
      "4250/4250 [==============================] - 1s 262us/sample - loss: 4583.4008 - acc: 0.5473 - val_loss: 9482.2126 - val_acc: 0.5400\n",
      "Epoch 10/10\n",
      "4250/4250 [==============================] - 1s 241us/sample - loss: 3154.4190 - acc: 0.5682 - val_loss: 444.5679 - val_acc: 0.5973\n",
      "Epoch 8 out of 200\n",
      "Train on 4250 samples, validate on 750 samples\n",
      "Epoch 1/10\n",
      "4250/4250 [==============================] - 1s 245us/sample - loss: 6271.7365 - acc: 0.5461 - val_loss: 3285.7107 - val_acc: 0.5480\n",
      "Epoch 2/10\n",
      "4250/4250 [==============================] - 1s 251us/sample - loss: 5388.3849 - acc: 0.5494 - val_loss: 5737.8931 - val_acc: 0.5440\n",
      "Epoch 3/10\n",
      "4250/4250 [==============================] - 1s 246us/sample - loss: 3842.2480 - acc: 0.5499 - val_loss: 6661.5529 - val_acc: 0.5413\n",
      "Epoch 4/10\n",
      "4250/4250 [==============================] - 1s 234us/sample - loss: 2643.4864 - acc: 0.5511 - val_loss: 2810.1596 - val_acc: 0.5507\n",
      "Epoch 5/10\n",
      "4250/4250 [==============================] - 1s 241us/sample - loss: 3437.5948 - acc: 0.5680 - val_loss: 895.8487 - val_acc: 0.4387\n",
      "Epoch 6/10\n",
      "4250/4250 [==============================] - 1s 247us/sample - loss: 2264.2229 - acc: 0.5701 - val_loss: 916.0233 - val_acc: 0.5680\n",
      "Epoch 7/10\n",
      "4250/4250 [==============================] - 1s 244us/sample - loss: 3431.9651 - acc: 0.5607 - val_loss: 1949.4920 - val_acc: 0.5587\n",
      "Epoch 8/10\n",
      "4250/4250 [==============================] - 1s 252us/sample - loss: 7204.8475 - acc: 0.5536 - val_loss: 8264.8794 - val_acc: 0.5400\n",
      "Epoch 9/10\n",
      "4250/4250 [==============================] - 1s 222us/sample - loss: 5241.4321 - acc: 0.5501 - val_loss: 6878.4464 - val_acc: 0.4493\n",
      "Epoch 10/10\n",
      "4250/4250 [==============================] - 1s 235us/sample - loss: 4395.8162 - acc: 0.5638 - val_loss: 544.1873 - val_acc: 0.5893\n",
      "Epoch 9 out of 200\n",
      "Train on 4250 samples, validate on 750 samples\n",
      "Epoch 1/10\n",
      "4250/4250 [==============================] - 1s 243us/sample - loss: 2459.3086 - acc: 0.5551 - val_loss: 1547.8896 - val_acc: 0.4320\n",
      "Epoch 2/10\n",
      "4250/4250 [==============================] - 1s 251us/sample - loss: 2342.6921 - acc: 0.5642 - val_loss: 449.8145 - val_acc: 0.5907\n",
      "Epoch 3/10\n",
      "4250/4250 [==============================] - 1s 245us/sample - loss: 2969.3213 - acc: 0.5600 - val_loss: 2570.7436 - val_acc: 0.5507\n",
      "Epoch 4/10\n",
      "4250/4250 [==============================] - 1s 244us/sample - loss: 5067.5161 - acc: 0.5440 - val_loss: 5823.9611 - val_acc: 0.5413\n",
      "Epoch 5/10\n",
      "4250/4250 [==============================] - 1s 254us/sample - loss: 5407.0691 - acc: 0.5548 - val_loss: 3067.1050 - val_acc: 0.5493\n",
      "Epoch 6/10\n",
      "4250/4250 [==============================] - 1s 244us/sample - loss: 4741.9255 - acc: 0.5513 - val_loss: 3304.7258 - val_acc: 0.5480\n",
      "Epoch 7/10\n",
      "4250/4250 [==============================] - 1s 264us/sample - loss: 2950.6077 - acc: 0.5694 - val_loss: 738.5812 - val_acc: 0.5800\n",
      "Epoch 8/10\n",
      "4250/4250 [==============================] - 1s 228us/sample - loss: 3062.2167 - acc: 0.5586 - val_loss: 5069.1738 - val_acc: 0.5440\n",
      "Epoch 9/10\n",
      "4250/4250 [==============================] - 1s 235us/sample - loss: 3108.2430 - acc: 0.5548 - val_loss: 1992.3529 - val_acc: 0.5587\n",
      "Epoch 10/10\n",
      "4250/4250 [==============================] - 1s 226us/sample - loss: 1987.5019 - acc: 0.5649 - val_loss: 1352.5686 - val_acc: 0.4347\n",
      "Epoch 10 out of 200\n",
      "Train on 4250 samples, validate on 750 samples\n",
      "Epoch 1/10\n",
      "4250/4250 [==============================] - 1s 236us/sample - loss: 3447.1850 - acc: 0.5607 - val_loss: 394.3594 - val_acc: 0.4720\n",
      "Epoch 2/10\n",
      "4250/4250 [==============================] - 1s 235us/sample - loss: 2960.2580 - acc: 0.5631 - val_loss: 4039.3036 - val_acc: 0.5440\n",
      "Epoch 3/10\n",
      "4250/4250 [==============================] - 1s 254us/sample - loss: 6049.5836 - acc: 0.5471 - val_loss: 281.6902 - val_acc: 0.6240\n",
      "Epoch 4/10\n",
      "4250/4250 [==============================] - 1s 241us/sample - loss: 3450.7253 - acc: 0.5511 - val_loss: 698.1569 - val_acc: 0.5800\n",
      "Epoch 5/10\n",
      "4250/4250 [==============================] - 1s 271us/sample - loss: 3930.3306 - acc: 0.5581 - val_loss: 1847.0025 - val_acc: 0.5600\n",
      "Epoch 6/10\n",
      "4250/4250 [==============================] - 1s 262us/sample - loss: 2980.3161 - acc: 0.5661 - val_loss: 1810.6028 - val_acc: 0.5600\n",
      "Epoch 7/10\n",
      "4250/4250 [==============================] - 1s 331us/sample - loss: 3604.4251 - acc: 0.5565 - val_loss: 5191.1915 - val_acc: 0.5413\n",
      "Epoch 8/10\n",
      "4250/4250 [==============================] - 1s 327us/sample - loss: 2627.7419 - acc: 0.5788 - val_loss: 611.2179 - val_acc: 0.5773\n",
      "Epoch 9/10\n",
      "4250/4250 [==============================] - 1s 253us/sample - loss: 1633.4157 - acc: 0.5722 - val_loss: 2839.0290 - val_acc: 0.5440\n",
      "Epoch 10/10\n",
      "4250/4250 [==============================] - 1s 301us/sample - loss: 1931.4734 - acc: 0.5614 - val_loss: 1360.6026 - val_acc: 0.5600\n",
      "Epoch 11 out of 200\n",
      "Train on 4250 samples, validate on 750 samples\n",
      "Epoch 1/10\n",
      "4250/4250 [==============================] - 1s 235us/sample - loss: 1929.8927 - acc: 0.5661 - val_loss: 720.0768 - val_acc: 0.5680\n",
      "Epoch 2/10\n",
      "4250/4250 [==============================] - 1s 252us/sample - loss: 4780.3979 - acc: 0.5607 - val_loss: 1956.9388 - val_acc: 0.5507\n",
      "Epoch 3/10\n",
      "4250/4250 [==============================] - 1s 258us/sample - loss: 2764.5320 - acc: 0.5567 - val_loss: 1601.5152 - val_acc: 0.5600\n",
      "Epoch 4/10\n",
      "4250/4250 [==============================] - 1s 227us/sample - loss: 1859.6302 - acc: 0.5704 - val_loss: 1937.4609 - val_acc: 0.5560\n",
      "Epoch 5/10\n",
      "4250/4250 [==============================] - 1s 249us/sample - loss: 2085.2301 - acc: 0.5685 - val_loss: 2208.5754 - val_acc: 0.5493\n",
      "Epoch 6/10\n",
      "4250/4250 [==============================] - 1s 255us/sample - loss: 1452.5129 - acc: 0.5786 - val_loss: 2150.7213 - val_acc: 0.4373\n",
      "Epoch 7/10\n",
      "4250/4250 [==============================] - 1s 240us/sample - loss: 1654.3490 - acc: 0.5708 - val_loss: 652.1929 - val_acc: 0.5707\n",
      "Epoch 8/10\n",
      "4250/4250 [==============================] - 1s 262us/sample - loss: 1836.6979 - acc: 0.5633 - val_loss: 3183.3389 - val_acc: 0.5440\n",
      "Epoch 9/10\n",
      "4250/4250 [==============================] - 1s 238us/sample - loss: 3707.4780 - acc: 0.5532 - val_loss: 7049.3034 - val_acc: 0.5387\n",
      "Epoch 10/10\n",
      "4250/4250 [==============================] - 1s 225us/sample - loss: 1659.5986 - acc: 0.5821 - val_loss: 651.1165 - val_acc: 0.5720\n",
      "Epoch 12 out of 200\n",
      "Train on 4250 samples, validate on 750 samples\n",
      "Epoch 1/10\n",
      "4250/4250 [==============================] - 1s 285us/sample - loss: 1898.5037 - acc: 0.5762 - val_loss: 86.3229 - val_acc: 0.7080\n",
      "Epoch 2/10\n",
      "4250/4250 [==============================] - 1s 270us/sample - loss: 3131.6819 - acc: 0.5551 - val_loss: 2344.6266 - val_acc: 0.5453\n",
      "Epoch 3/10\n",
      "4250/4250 [==============================] - 1s 254us/sample - loss: 1371.6245 - acc: 0.5842 - val_loss: 2379.7524 - val_acc: 0.5467\n",
      "Epoch 4/10\n",
      "4250/4250 [==============================] - 1s 258us/sample - loss: 1493.7563 - acc: 0.5701 - val_loss: 1756.9158 - val_acc: 0.4360\n",
      "Epoch 5/10\n",
      "4250/4250 [==============================] - 1s 261us/sample - loss: 2652.7166 - acc: 0.5529 - val_loss: 2565.3001 - val_acc: 0.5440\n",
      "Epoch 6/10\n",
      "4250/4250 [==============================] - 1s 223us/sample - loss: 2297.4887 - acc: 0.5631 - val_loss: 127.1974 - val_acc: 0.6733\n",
      "Epoch 7/10\n",
      "4250/4250 [==============================] - 1s 263us/sample - loss: 1198.5342 - acc: 0.5725 - val_loss: 1338.8576 - val_acc: 0.4333\n",
      "Epoch 8/10\n",
      "4250/4250 [==============================] - 1s 258us/sample - loss: 1245.5892 - acc: 0.5845 - val_loss: 2370.4243 - val_acc: 0.4413\n",
      "Epoch 9/10\n",
      "4250/4250 [==============================] - 1s 242us/sample - loss: 1214.0666 - acc: 0.5739 - val_loss: 360.9964 - val_acc: 0.4467\n",
      "Epoch 10/10\n",
      "4250/4250 [==============================] - 1s 250us/sample - loss: 1535.0476 - acc: 0.5708 - val_loss: 500.6524 - val_acc: 0.5773\n",
      "Epoch 13 out of 200\n",
      "Train on 4250 samples, validate on 750 samples\n",
      "Epoch 1/10\n",
      "4250/4250 [==============================] - 1s 323us/sample - loss: 1023.6165 - acc: 0.5713 - val_loss: 1022.3083 - val_acc: 0.5600\n",
      "Epoch 2/10\n",
      "4250/4250 [==============================] - 1s 215us/sample - loss: 1621.0800 - acc: 0.5654 - val_loss: 1615.1754 - val_acc: 0.5493\n",
      "Epoch 3/10\n",
      "4250/4250 [==============================] - 1s 253us/sample - loss: 3259.0979 - acc: 0.5442 - val_loss: 1521.3013 - val_acc: 0.5507\n",
      "Epoch 4/10\n",
      "4250/4250 [==============================] - 1s 185us/sample - loss: 990.7772 - acc: 0.5704 - val_loss: 82.7346 - val_acc: 0.7307\n",
      "Epoch 5/10\n",
      "4250/4250 [==============================] - 1s 217us/sample - loss: 1216.5348 - acc: 0.5793 - val_loss: 414.1832 - val_acc: 0.5853\n",
      "Epoch 6/10\n",
      "4250/4250 [==============================] - 1s 221us/sample - loss: 1312.0904 - acc: 0.5727 - val_loss: 962.6131 - val_acc: 0.5600\n",
      "Epoch 7/10\n",
      "4250/4250 [==============================] - 1s 214us/sample - loss: 1103.6186 - acc: 0.5828 - val_loss: 41.8594 - val_acc: 0.6453\n",
      "Epoch 8/10\n",
      "4250/4250 [==============================] - 1s 235us/sample - loss: 842.5474 - acc: 0.5755 - val_loss: 253.3365 - val_acc: 0.6107\n",
      "Epoch 9/10\n",
      "4250/4250 [==============================] - 1s 197us/sample - loss: 2133.6676 - acc: 0.5548 - val_loss: 1620.7537 - val_acc: 0.5493\n",
      "Epoch 10/10\n",
      "4250/4250 [==============================] - 1s 275us/sample - loss: 827.9015 - acc: 0.5828 - val_loss: 413.4368 - val_acc: 0.5800\n",
      "Epoch 14 out of 200\n",
      "Train on 4250 samples, validate on 750 samples\n",
      "Epoch 1/10\n",
      "4250/4250 [==============================] - 1s 261us/sample - loss: 1292.1277 - acc: 0.5612 - val_loss: 1035.9593 - val_acc: 0.5560\n",
      "Epoch 2/10\n",
      "4250/4250 [==============================] - 1s 223us/sample - loss: 706.6913 - acc: 0.5894 - val_loss: 573.6222 - val_acc: 0.5693\n",
      "Epoch 3/10\n",
      "4250/4250 [==============================] - 1s 235us/sample - loss: 781.7470 - acc: 0.5955 - val_loss: 487.2346 - val_acc: 0.5733\n",
      "Epoch 4/10\n",
      "4250/4250 [==============================] - 1s 279us/sample - loss: 1267.9216 - acc: 0.5791 - val_loss: 680.6409 - val_acc: 0.5640\n",
      "Epoch 5/10\n",
      "4250/4250 [==============================] - 1s 235us/sample - loss: 514.0648 - acc: 0.5948 - val_loss: 29.2366 - val_acc: 0.8000\n",
      "Epoch 6/10\n",
      "4250/4250 [==============================] - 1s 256us/sample - loss: 850.4857 - acc: 0.5929 - val_loss: 1106.0347 - val_acc: 0.4307\n",
      "Epoch 7/10\n",
      "4250/4250 [==============================] - 1s 241us/sample - loss: 366.0023 - acc: 0.6226 - val_loss: 707.1312 - val_acc: 0.5613\n",
      "Epoch 8/10\n",
      "4250/4250 [==============================] - 1s 221us/sample - loss: 800.9528 - acc: 0.5812 - val_loss: 661.3216 - val_acc: 0.5640\n",
      "Epoch 9/10\n",
      "4250/4250 [==============================] - 1s 207us/sample - loss: 509.1692 - acc: 0.5953 - val_loss: 204.4539 - val_acc: 0.6160\n",
      "Epoch 10/10\n",
      "4250/4250 [==============================] - 1s 258us/sample - loss: 382.8091 - acc: 0.6259 - val_loss: 263.8645 - val_acc: 0.5947\n",
      "Epoch 15 out of 200\n",
      "Train on 4250 samples, validate on 750 samples\n",
      "Epoch 1/10\n",
      "4250/4250 [==============================] - 1s 278us/sample - loss: 427.8890 - acc: 0.6068 - val_loss: 65.2596 - val_acc: 0.7520\n",
      "Epoch 2/10\n",
      "4250/4250 [==============================] - 1s 238us/sample - loss: 349.2556 - acc: 0.6089 - val_loss: 281.3663 - val_acc: 0.4227\n",
      "Epoch 3/10\n",
      "4250/4250 [==============================] - 1s 214us/sample - loss: 486.9117 - acc: 0.5988 - val_loss: 312.8622 - val_acc: 0.5813\n",
      "Epoch 4/10\n",
      "4250/4250 [==============================] - 1s 216us/sample - loss: 1125.7884 - acc: 0.5831 - val_loss: 188.3044 - val_acc: 0.6227\n",
      "Epoch 5/10\n",
      "4250/4250 [==============================] - 1s 251us/sample - loss: 505.6651 - acc: 0.6007 - val_loss: 380.0007 - val_acc: 0.4280\n",
      "Epoch 6/10\n",
      "4250/4250 [==============================] - 1s 253us/sample - loss: 419.0526 - acc: 0.6118 - val_loss: 151.3164 - val_acc: 0.6453\n",
      "Epoch 7/10\n",
      "4250/4250 [==============================] - 1s 248us/sample - loss: 231.4449 - acc: 0.6386 - val_loss: 459.4812 - val_acc: 0.5667\n",
      "Epoch 8/10\n",
      "4250/4250 [==============================] - 1s 248us/sample - loss: 197.8909 - acc: 0.6645 - val_loss: 243.6489 - val_acc: 0.5960\n",
      "Epoch 9/10\n",
      "4250/4250 [==============================] - ETA: 0s - loss: 1462.9974 - acc: 0.56 - 1s 244us/sample - loss: 1450.0005 - acc: 0.5689 - val_loss: 369.3762 - val_acc: 0.5707\n",
      "Epoch 10/10\n",
      "4250/4250 [==============================] - 1s 234us/sample - loss: 298.1971 - acc: 0.6259 - val_loss: 293.8980 - val_acc: 0.5880\n",
      "Epoch 16 out of 200\n",
      "Train on 4250 samples, validate on 750 samples\n",
      "Epoch 1/10\n",
      "4250/4250 [==============================] - 1s 252us/sample - loss: 113.0433 - acc: 0.6812 - val_loss: 103.7734 - val_acc: 0.6853\n",
      "Epoch 2/10\n",
      "4250/4250 [==============================] - 1s 232us/sample - loss: 146.1598 - acc: 0.6532 - val_loss: 85.9048 - val_acc: 0.7080\n",
      "Epoch 3/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4250/4250 [==============================] - 1s 235us/sample - loss: 102.7632 - acc: 0.6805 - val_loss: 52.8886 - val_acc: 0.7693\n",
      "Epoch 4/10\n",
      "4250/4250 [==============================] - 1s 261us/sample - loss: 293.3401 - acc: 0.6089 - val_loss: 293.5663 - val_acc: 0.5840\n",
      "Epoch 5/10\n",
      "4250/4250 [==============================] - 1s 211us/sample - loss: 151.8435 - acc: 0.6894 - val_loss: 61.2081 - val_acc: 0.7440\n",
      "Epoch 6/10\n",
      "4250/4250 [==============================] - 1s 247us/sample - loss: 52.9930 - acc: 0.7285 - val_loss: 26.4287 - val_acc: 0.5960\n",
      "Epoch 7/10\n",
      "4250/4250 [==============================] - 1s 228us/sample - loss: 64.2289 - acc: 0.7125 - val_loss: 38.7175 - val_acc: 0.7933\n",
      "Epoch 8/10\n",
      "4250/4250 [==============================] - 1s 223us/sample - loss: 48.1903 - acc: 0.7346 - val_loss: 13.6841 - val_acc: 0.7960\n",
      "Epoch 9/10\n",
      "4250/4250 [==============================] - 1s 257us/sample - loss: 87.6519 - acc: 0.6868 - val_loss: 24.2969 - val_acc: 0.8000\n",
      "Epoch 10/10\n",
      "4250/4250 [==============================] - 1s 250us/sample - loss: 33.7693 - acc: 0.7428 - val_loss: 23.2155 - val_acc: 0.8000\n",
      "Epoch 17 out of 200\n",
      "Train on 4250 samples, validate on 750 samples\n",
      "Epoch 1/10\n",
      "4250/4250 [==============================] - 1s 272us/sample - loss: 36.0499 - acc: 0.7464 - val_loss: 17.1920 - val_acc: 0.6707\n",
      "Epoch 2/10\n",
      "4250/4250 [==============================] - 1s 248us/sample - loss: 17.5565 - acc: 0.7638 - val_loss: 13.2823 - val_acc: 0.7733\n",
      "Epoch 3/10\n",
      "4250/4250 [==============================] - 1s 291us/sample - loss: 19.4303 - acc: 0.7642 - val_loss: 15.4108 - val_acc: 0.8000\n",
      "Epoch 4/10\n",
      "4250/4250 [==============================] - 1s 298us/sample - loss: 23.8192 - acc: 0.7548 - val_loss: 20.4733 - val_acc: 0.8000\n",
      "Epoch 5/10\n",
      "4250/4250 [==============================] - 1s 254us/sample - loss: 30.2946 - acc: 0.7508 - val_loss: 16.5772 - val_acc: 0.8000\n",
      "Epoch 6/10\n",
      "4250/4250 [==============================] - 1s 215us/sample - loss: 17.2339 - acc: 0.7654 - val_loss: 12.1471 - val_acc: 0.7693\n",
      "Epoch 7/10\n",
      "4250/4250 [==============================] - 1s 213us/sample - loss: 14.0829 - acc: 0.7767 - val_loss: 12.7030 - val_acc: 0.7773\n",
      "Epoch 8/10\n",
      "4250/4250 [==============================] - 1s 219us/sample - loss: 14.3928 - acc: 0.7635 - val_loss: 14.4349 - val_acc: 0.8000\n",
      "Epoch 9/10\n",
      "4250/4250 [==============================] - 1s 220us/sample - loss: 263.5583 - acc: 0.6473 - val_loss: 27.1992 - val_acc: 0.5720\n",
      "Epoch 10/10\n",
      "4250/4250 [==============================] - 1s 218us/sample - loss: 1209.6969 - acc: 0.5534 - val_loss: 257.8046 - val_acc: 0.4253\n",
      "Epoch 18 out of 200\n",
      "Train on 4250 samples, validate on 750 samples\n",
      "Epoch 1/10\n",
      "4250/4250 [==============================] - 1s 261us/sample - loss: 128.1351 - acc: 0.6913 - val_loss: 14.2296 - val_acc: 0.6827\n",
      "Epoch 2/10\n",
      "4250/4250 [==============================] - 1s 220us/sample - loss: 13.3025 - acc: 0.7739 - val_loss: 13.0944 - val_acc: 0.8000\n",
      "Epoch 3/10\n",
      "4250/4250 [==============================] - 1s 260us/sample - loss: 13.3843 - acc: 0.7722 - val_loss: 12.4368 - val_acc: 0.8000\n",
      "Epoch 4/10\n",
      "4250/4250 [==============================] - 1s 275us/sample - loss: 13.4953 - acc: 0.7725 - val_loss: 17.6149 - val_acc: 0.8000\n",
      "Epoch 5/10\n",
      "4250/4250 [==============================] - 1s 219us/sample - loss: 15.2164 - acc: 0.7652 - val_loss: 17.4873 - val_acc: 0.8000\n",
      "Epoch 6/10\n",
      "4250/4250 [==============================] - 1s 240us/sample - loss: 16.9070 - acc: 0.7685 - val_loss: 11.8080 - val_acc: 0.8000\n",
      "Epoch 7/10\n",
      "4250/4250 [==============================] - 1s 271us/sample - loss: 12.4301 - acc: 0.7779 - val_loss: 11.0286 - val_acc: 0.7947\n",
      "Epoch 8/10\n",
      "4250/4250 [==============================] - 1s 263us/sample - loss: 11.8128 - acc: 0.7751 - val_loss: 11.3361 - val_acc: 0.8000\n",
      "Epoch 9/10\n",
      "4250/4250 [==============================] - 1s 207us/sample - loss: 13.0411 - acc: 0.7696 - val_loss: 13.8718 - val_acc: 0.8000\n",
      "Epoch 10/10\n",
      "4250/4250 [==============================] - 1s 222us/sample - loss: 13.4958 - acc: 0.7642 - val_loss: 14.4390 - val_acc: 0.8000\n",
      "Epoch 19 out of 200\n",
      "Train on 4250 samples, validate on 750 samples\n",
      "Epoch 1/10\n",
      "4250/4250 [==============================] - 1s 204us/sample - loss: 16.3322 - acc: 0.7584 - val_loss: 33.4930 - val_acc: 0.7653\n",
      "Epoch 2/10\n",
      "4250/4250 [==============================] - 1s 229us/sample - loss: 25.2827 - acc: 0.7489 - val_loss: 20.4036 - val_acc: 0.8000\n",
      "Epoch 3/10\n",
      "4250/4250 [==============================] - 1s 235us/sample - loss: 20.2260 - acc: 0.7487 - val_loss: 10.4133 - val_acc: 0.8000\n",
      "Epoch 4/10\n",
      "4250/4250 [==============================] - 1s 247us/sample - loss: 12.5092 - acc: 0.7715 - val_loss: 11.2392 - val_acc: 0.8000\n",
      "Epoch 5/10\n",
      "4250/4250 [==============================] - 1s 232us/sample - loss: 22.0216 - acc: 0.7504 - val_loss: 198.5719 - val_acc: 0.5827\n",
      "Epoch 6/10\n",
      "4250/4250 [==============================] - 1s 230us/sample - loss: 900.4627 - acc: 0.5581 - val_loss: 1755.7371 - val_acc: 0.5413\n",
      "Epoch 7/10\n",
      "4250/4250 [==============================] - 1s 234us/sample - loss: 309.5951 - acc: 0.6772 - val_loss: 11.6239 - val_acc: 0.8000\n",
      "Epoch 8/10\n",
      "4250/4250 [==============================] - 1s 236us/sample - loss: 11.1956 - acc: 0.7755 - val_loss: 10.6211 - val_acc: 0.8000\n",
      "Epoch 9/10\n",
      "4250/4250 [==============================] - 1s 254us/sample - loss: 10.6904 - acc: 0.7736 - val_loss: 11.0415 - val_acc: 0.8000\n",
      "Epoch 10/10\n",
      "4250/4250 [==============================] - 1s 233us/sample - loss: 10.7105 - acc: 0.7706 - val_loss: 9.3549 - val_acc: 0.7933\n",
      "Epoch 20 out of 200\n",
      "Train on 4250 samples, validate on 750 samples\n",
      "Epoch 1/10\n",
      "4250/4250 [==============================] - 1s 269us/sample - loss: 11.4949 - acc: 0.7765 - val_loss: 9.3500 - val_acc: 0.7960\n",
      "Epoch 2/10\n",
      "4250/4250 [==============================] - 1s 240us/sample - loss: 19.4027 - acc: 0.7449 - val_loss: 44.3183 - val_acc: 0.7280\n",
      "Epoch 3/10\n",
      "4250/4250 [==============================] - 1s 227us/sample - loss: 35.2491 - acc: 0.7188 - val_loss: 10.3415 - val_acc: 0.8000\n",
      "Epoch 4/10\n",
      "4250/4250 [==============================] - 1s 219us/sample - loss: 12.5974 - acc: 0.7605 - val_loss: 13.1898 - val_acc: 0.8000\n",
      "Epoch 5/10\n",
      "4250/4250 [==============================] - 1s 238us/sample - loss: 15.9593 - acc: 0.7569 - val_loss: 8.9804 - val_acc: 0.8000\n",
      "Epoch 6/10\n",
      "4250/4250 [==============================] - 1s 206us/sample - loss: 9.4742 - acc: 0.7736 - val_loss: 8.6941 - val_acc: 0.7667\n",
      "Epoch 7/10\n",
      "4250/4250 [==============================] - 1s 251us/sample - loss: 9.5676 - acc: 0.7744 - val_loss: 14.0607 - val_acc: 0.8000\n",
      "Epoch 8/10\n",
      "4250/4250 [==============================] - 1s 224us/sample - loss: 104.7636 - acc: 0.6784 - val_loss: 10.0069 - val_acc: 0.6813\n",
      "Epoch 9/10\n",
      "4250/4250 [==============================] - 1s 252us/sample - loss: 10.5090 - acc: 0.7678 - val_loss: 9.4882 - val_acc: 0.8000\n",
      "Epoch 10/10\n",
      "4250/4250 [==============================] - 1s 247us/sample - loss: 9.1545 - acc: 0.7699 - val_loss: 9.9007 - val_acc: 0.8000\n",
      "Epoch 21 out of 200\n",
      "Train on 4250 samples, validate on 750 samples\n",
      "Epoch 1/10\n",
      "4250/4250 [==============================] - 1s 250us/sample - loss: 8.5925 - acc: 0.7791 - val_loss: 7.6965 - val_acc: 0.7920\n",
      "Epoch 2/10\n",
      "4250/4250 [==============================] - 1s 259us/sample - loss: 9.0542 - acc: 0.7696 - val_loss: 7.4012 - val_acc: 0.7640\n",
      "Epoch 3/10\n",
      "4250/4250 [==============================] - 1s 257us/sample - loss: 2193.2087 - acc: 0.5976 - val_loss: 26359.5070 - val_acc: 0.5360\n",
      "Epoch 4/10\n",
      "4250/4250 [==============================] - 1s 220us/sample - loss: 2734.3024 - acc: 0.5739 - val_loss: 65.0235 - val_acc: 0.6627\n",
      "Epoch 5/10\n",
      "4250/4250 [==============================] - 1s 277us/sample - loss: 13.4345 - acc: 0.7642 - val_loss: 8.7871 - val_acc: 0.8000\n",
      "Epoch 6/10\n",
      "4250/4250 [==============================] - 1s 245us/sample - loss: 7.9643 - acc: 0.7769 - val_loss: 8.4914 - val_acc: 0.8000\n",
      "Epoch 7/10\n",
      "4250/4250 [==============================] - 1s 243us/sample - loss: 7.9447 - acc: 0.7807 - val_loss: 7.5243 - val_acc: 0.8000\n",
      "Epoch 8/10\n",
      "4250/4250 [==============================] - 1s 248us/sample - loss: 7.7570 - acc: 0.7762 - val_loss: 7.3226 - val_acc: 0.7987\n",
      "Epoch 9/10\n",
      "4250/4250 [==============================] - 1s 234us/sample - loss: 7.5779 - acc: 0.7798 - val_loss: 7.3708 - val_acc: 0.8000\n",
      "Epoch 10/10\n",
      "4250/4250 [==============================] - 1s 224us/sample - loss: 7.5725 - acc: 0.7786 - val_loss: 7.1862 - val_acc: 0.8000\n",
      "Epoch 22 out of 200\n",
      "Train on 4250 samples, validate on 750 samples\n",
      "Epoch 1/10\n",
      "4250/4250 [==============================] - 1s 272us/sample - loss: 7.2974 - acc: 0.7762 - val_loss: 7.2601 - val_acc: 0.8000\n",
      "Epoch 2/10\n",
      "4250/4250 [==============================] - 1s 244us/sample - loss: 7.7805 - acc: 0.7748 - val_loss: 6.9042 - val_acc: 0.8000\n",
      "Epoch 3/10\n",
      "4250/4250 [==============================] - 1s 252us/sample - loss: 7.5432 - acc: 0.7661 - val_loss: 7.1179 - val_acc: 0.8000\n",
      "Epoch 4/10\n",
      "4250/4250 [==============================] - 1s 273us/sample - loss: 9.8049 - acc: 0.7642 - val_loss: 12.5204 - val_acc: 0.8000\n",
      "Epoch 5/10\n",
      "4250/4250 [==============================] - 1s 236us/sample - loss: 7.5299 - acc: 0.7687 - val_loss: 6.7129 - val_acc: 0.7040\n",
      "Epoch 6/10\n",
      "4250/4250 [==============================] - 1s 250us/sample - loss: 6.4337 - acc: 0.7751 - val_loss: 5.5758 - val_acc: 0.7800\n",
      "Epoch 7/10\n",
      "4250/4250 [==============================] - 1s 247us/sample - loss: 6.3265 - acc: 0.7762 - val_loss: 5.7179 - val_acc: 0.8000\n",
      "Epoch 8/10\n",
      "4250/4250 [==============================] - 1s 237us/sample - loss: 6.3626 - acc: 0.7694 - val_loss: 5.6675 - val_acc: 0.7267\n",
      "Epoch 9/10\n",
      "4250/4250 [==============================] - 1s 253us/sample - loss: 6.2161 - acc: 0.7727 - val_loss: 6.2906 - val_acc: 0.6773\n",
      "Epoch 10/10\n",
      "4250/4250 [==============================] - 1s 272us/sample - loss: 8.8659 - acc: 0.7508 - val_loss: 5.3869 - val_acc: 0.8000\n",
      "Epoch 23 out of 200\n",
      "Train on 4250 samples, validate on 750 samples\n",
      "Epoch 1/10\n",
      "4250/4250 [==============================] - 1s 242us/sample - loss: 5.7586 - acc: 0.7708 - val_loss: 12.2836 - val_acc: 0.5653\n",
      "Epoch 2/10\n",
      "4250/4250 [==============================] - 1s 224us/sample - loss: 13.1587 - acc: 0.7315 - val_loss: 5.9504 - val_acc: 0.8000\n",
      "Epoch 3/10\n",
      "4250/4250 [==============================] - 1s 208us/sample - loss: 6.2139 - acc: 0.7729 - val_loss: 12.8852 - val_acc: 0.7907\n",
      "Epoch 4/10\n",
      "4250/4250 [==============================] - 1s 227us/sample - loss: 8.1252 - acc: 0.7565 - val_loss: 4.2841 - val_acc: 0.7853\n",
      "Epoch 5/10\n",
      "4250/4250 [==============================] - 1s 195us/sample - loss: 6.2900 - acc: 0.7574 - val_loss: 5.0659 - val_acc: 0.8000\n",
      "Epoch 6/10\n",
      "4250/4250 [==============================] - 1s 227us/sample - loss: 458.1796 - acc: 0.6393 - val_loss: 305.8266 - val_acc: 0.5480\n",
      "Epoch 7/10\n",
      "4250/4250 [==============================] - 1s 245us/sample - loss: 962.0348 - acc: 0.5826 - val_loss: 13.3602 - val_acc: 0.7880\n",
      "Epoch 8/10\n",
      "4250/4250 [==============================] - 1s 276us/sample - loss: 5.4080 - acc: 0.7704 - val_loss: 4.3537 - val_acc: 0.8000\n",
      "Epoch 9/10\n",
      "4250/4250 [==============================] - 1s 216us/sample - loss: 4.5355 - acc: 0.7727 - val_loss: 4.3401 - val_acc: 0.8000\n",
      "Epoch 10/10\n",
      "4250/4250 [==============================] - 1s 206us/sample - loss: 4.3409 - acc: 0.7758 - val_loss: 4.2200 - val_acc: 0.8000\n",
      "Epoch 24 out of 200\n",
      "Train on 4250 samples, validate on 750 samples\n",
      "Epoch 1/10\n",
      "4250/4250 [==============================] - 1s 234us/sample - loss: 4.0485 - acc: 0.7795 - val_loss: 3.7549 - val_acc: 0.8000\n",
      "Epoch 2/10\n",
      "4250/4250 [==============================] - 1s 226us/sample - loss: 4.3887 - acc: 0.7713 - val_loss: 3.8663 - val_acc: 0.8000\n",
      "Epoch 3/10\n",
      "4250/4250 [==============================] - 1s 235us/sample - loss: 4.0413 - acc: 0.7713 - val_loss: 3.9624 - val_acc: 0.8000\n",
      "Epoch 4/10\n",
      "4250/4250 [==============================] - 1s 205us/sample - loss: 5.9347 - acc: 0.7598 - val_loss: 7.0697 - val_acc: 0.7987\n",
      "Epoch 5/10\n",
      "4250/4250 [==============================] - 1s 224us/sample - loss: 69.5893 - acc: 0.6174 - val_loss: 4.0021 - val_acc: 0.6640\n",
      "Epoch 6/10\n",
      "4250/4250 [==============================] - 1s 218us/sample - loss: 15.1293 - acc: 0.7198 - val_loss: 4.3795 - val_acc: 0.7053\n",
      "Epoch 7/10\n",
      "4250/4250 [==============================] - 1s 217us/sample - loss: 3391.7845 - acc: 0.5475 - val_loss: 529.5506 - val_acc: 0.5413\n",
      "Epoch 8/10\n",
      "4250/4250 [==============================] - 1s 220us/sample - loss: 545.6543 - acc: 0.5833 - val_loss: 5.1594 - val_acc: 0.8000\n",
      "Epoch 9/10\n",
      "4250/4250 [==============================] - 1s 213us/sample - loss: 12.0155 - acc: 0.7306 - val_loss: 3.1395 - val_acc: 0.7880\n",
      "Epoch 10/10\n",
      "4250/4250 [==============================] - 1s 221us/sample - loss: 3.4018 - acc: 0.7765 - val_loss: 3.3512 - val_acc: 0.8000\n",
      "Epoch 25 out of 200\n",
      "Train on 4250 samples, validate on 750 samples\n",
      "Epoch 1/10\n",
      "4250/4250 [==============================] - 1s 238us/sample - loss: 3.0802 - acc: 0.7774 - val_loss: 2.9842 - val_acc: 0.8000\n",
      "Epoch 2/10\n",
      "4250/4250 [==============================] - 1s 229us/sample - loss: 3.0104 - acc: 0.7772 - val_loss: 2.5918 - val_acc: 0.7680\n",
      "Epoch 3/10\n",
      "4250/4250 [==============================] - 1s 220us/sample - loss: 2.8355 - acc: 0.7751 - val_loss: 2.5303 - val_acc: 0.7813\n",
      "Epoch 4/10\n",
      "4250/4250 [==============================] - 1s 221us/sample - loss: 2.6898 - acc: 0.7758 - val_loss: 2.8572 - val_acc: 0.8000\n",
      "Epoch 5/10\n",
      "4250/4250 [==============================] - 1s 221us/sample - loss: 2.6958 - acc: 0.7732 - val_loss: 2.1993 - val_acc: 0.7453\n",
      "Epoch 6/10\n",
      "4250/4250 [==============================] - 1s 243us/sample - loss: 2.3537 - acc: 0.7744 - val_loss: 2.3810 - val_acc: 0.8000\n",
      "Epoch 7/10\n",
      "4250/4250 [==============================] - 1s 216us/sample - loss: 2.6015 - acc: 0.7685 - val_loss: 2.1070 - val_acc: 0.8000\n",
      "Epoch 8/10\n",
      "4250/4250 [==============================] - 1s 210us/sample - loss: 2.0024 - acc: 0.7758 - val_loss: 1.6899 - val_acc: 0.7440\n",
      "Epoch 9/10\n",
      "4250/4250 [==============================] - 1s 220us/sample - loss: 1.9490 - acc: 0.7704 - val_loss: 1.9590 - val_acc: 0.8000\n",
      "Epoch 10/10\n",
      "4250/4250 [==============================] - 1s 212us/sample - loss: 2.0585 - acc: 0.7616 - val_loss: 1.7360 - val_acc: 0.8000\n",
      "Epoch 26 out of 200\n",
      "Train on 4250 samples, validate on 750 samples\n",
      "Epoch 1/10\n",
      "4250/4250 [==============================] - 1s 227us/sample - loss: 1.5074 - acc: 0.7720 - val_loss: 1.5132 - val_acc: 0.8000\n",
      "Epoch 2/10\n",
      "4250/4250 [==============================] - 1s 216us/sample - loss: 1.2752 - acc: 0.7762 - val_loss: 1.1581 - val_acc: 0.8000\n",
      "Epoch 3/10\n",
      "4250/4250 [==============================] - 1s 228us/sample - loss: 1.0462 - acc: 0.7814 - val_loss: 0.9946 - val_acc: 0.8000\n",
      "Epoch 4/10\n",
      "4250/4250 [==============================] - 1s 223us/sample - loss: 0.9712 - acc: 0.7739 - val_loss: 0.8010 - val_acc: 0.8000\n",
      "Epoch 5/10\n",
      "4250/4250 [==============================] - 1s 222us/sample - loss: 0.7714 - acc: 0.7798 - val_loss: 0.6088 - val_acc: 0.7933\n",
      "Epoch 6/10\n",
      "4250/4250 [==============================] - 1s 215us/sample - loss: 1.1167 - acc: 0.7548 - val_loss: 0.5685 - val_acc: 0.8000\n",
      "Epoch 7/10\n",
      "4250/4250 [==============================] - 1s 222us/sample - loss: 0.8676 - acc: 0.7659 - val_loss: 0.7292 - val_acc: 0.6680\n",
      "Epoch 8/10\n",
      "4250/4250 [==============================] - 1s 222us/sample - loss: 0.6549 - acc: 0.7671 - val_loss: 0.8156 - val_acc: 0.8000\n",
      "Epoch 9/10\n",
      "4250/4250 [==============================] - 1s 226us/sample - loss: 0.7394 - acc: 0.7624 - val_loss: 0.7958 - val_acc: 0.7760\n",
      "Epoch 10/10\n",
      "4250/4250 [==============================] - 1s 218us/sample - loss: 3.6844 - acc: 0.7240 - val_loss: 41.7061 - val_acc: 0.5440\n",
      "Epoch 27 out of 200\n",
      "Train on 4250 samples, validate on 750 samples\n",
      "Epoch 1/10\n",
      "4250/4250 [==============================] - 1s 209us/sample - loss: 536.3212 - acc: 0.5405 - val_loss: 125.0197 - val_acc: 0.5400\n",
      "Epoch 2/10\n",
      "4250/4250 [==============================] - 1s 209us/sample - loss: 641.8480 - acc: 0.5492 - val_loss: 14.6295 - val_acc: 0.5640\n",
      "Epoch 3/10\n",
      "4250/4250 [==============================] - 1s 211us/sample - loss: 50.4130 - acc: 0.6200 - val_loss: 1.9710 - val_acc: 0.7920\n",
      "Epoch 4/10\n",
      "4250/4250 [==============================] - 1s 220us/sample - loss: 1.0661 - acc: 0.7696 - val_loss: 0.6980 - val_acc: 0.8000\n",
      "Epoch 5/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4250/4250 [==============================] - 1s 218us/sample - loss: 0.6199 - acc: 0.7911 - val_loss: 0.5884 - val_acc: 0.8000\n",
      "Epoch 6/10\n",
      "4250/4250 [==============================] - 1s 219us/sample - loss: 0.5561 - acc: 0.7934 - val_loss: 0.5412 - val_acc: 0.8000\n",
      "Epoch 7/10\n",
      "4250/4250 [==============================] - 1s 209us/sample - loss: 0.5184 - acc: 0.7988 - val_loss: 0.5090 - val_acc: 0.8000\n",
      "Epoch 8/10\n",
      "4250/4250 [==============================] - 1s 220us/sample - loss: 0.5301 - acc: 0.7918 - val_loss: 0.5174 - val_acc: 0.8000\n",
      "Epoch 9/10\n",
      "4250/4250 [==============================] - 1s 218us/sample - loss: 0.5040 - acc: 0.7995 - val_loss: 0.5032 - val_acc: 0.8000\n",
      "Epoch 10/10\n",
      "4250/4250 [==============================] - 1s 219us/sample - loss: 0.5078 - acc: 0.7991 - val_loss: 0.5001 - val_acc: 0.8000\n",
      "Epoch 28 out of 200\n",
      "Train on 4250 samples, validate on 750 samples\n",
      "Epoch 1/10\n",
      "4250/4250 [==============================] - 1s 198us/sample - loss: 0.5065 - acc: 0.7981 - val_loss: 0.5005 - val_acc: 0.8000\n",
      "Epoch 2/10\n",
      "4250/4250 [==============================] - 1s 210us/sample - loss: 0.5241 - acc: 0.7960 - val_loss: 0.5048 - val_acc: 0.8000\n",
      "Epoch 3/10\n",
      "4250/4250 [==============================] - 1s 214us/sample - loss: 0.5141 - acc: 0.7995 - val_loss: 0.5032 - val_acc: 0.8000\n",
      "Epoch 4/10\n",
      "4250/4250 [==============================] - 1s 213us/sample - loss: 0.7966 - acc: 0.7675 - val_loss: 0.6079 - val_acc: 0.7240\n",
      "Epoch 5/10\n",
      "4250/4250 [==============================] - 1s 221us/sample - loss: 1705.7082 - acc: 0.5555 - val_loss: 755.4194 - val_acc: 0.5400\n",
      "Epoch 6/10\n",
      "4250/4250 [==============================] - 1s 208us/sample - loss: 669.3620 - acc: 0.5435 - val_loss: 9.5020 - val_acc: 0.6413\n",
      "Epoch 7/10\n",
      "4250/4250 [==============================] - 1s 222us/sample - loss: 22.0967 - acc: 0.6391 - val_loss: 0.7883 - val_acc: 0.7240\n",
      "Epoch 8/10\n",
      "4250/4250 [==============================] - 1s 216us/sample - loss: 0.6862 - acc: 0.7831 - val_loss: 0.6075 - val_acc: 0.8000\n",
      "Epoch 9/10\n",
      "4250/4250 [==============================] - 1s 217us/sample - loss: 0.5733 - acc: 0.7934 - val_loss: 0.5258 - val_acc: 0.8000\n",
      "Epoch 10/10\n",
      "4250/4250 [==============================] - 1s 214us/sample - loss: 0.5430 - acc: 0.7894 - val_loss: 0.5298 - val_acc: 0.8000\n",
      "Epoch 29 out of 200\n",
      "Train on 4250 samples, validate on 750 samples\n",
      "Epoch 1/10\n",
      "4250/4250 [==============================] - 1s 219us/sample - loss: 0.5134 - acc: 0.7988 - val_loss: 0.5030 - val_acc: 0.8000\n",
      "Epoch 2/10\n",
      "4250/4250 [==============================] - 1s 213us/sample - loss: 0.5068 - acc: 0.7995 - val_loss: 0.5014 - val_acc: 0.8000\n",
      "Epoch 3/10\n",
      "4250/4250 [==============================] - 1s 205us/sample - loss: 0.5083 - acc: 0.7991 - val_loss: 0.5171 - val_acc: 0.7947\n",
      "Epoch 4/10\n",
      "4250/4250 [==============================] - 1s 217us/sample - loss: 0.5128 - acc: 0.7981 - val_loss: 0.5233 - val_acc: 0.7853\n",
      "Epoch 5/10\n",
      "4250/4250 [==============================] - 1s 212us/sample - loss: 0.5101 - acc: 0.7986 - val_loss: 0.5444 - val_acc: 0.8000\n",
      "Epoch 6/10\n",
      "4250/4250 [==============================] - 1s 220us/sample - loss: 0.5171 - acc: 0.7984 - val_loss: 0.5023 - val_acc: 0.8000\n",
      "Epoch 7/10\n",
      "4250/4250 [==============================] - 1s 208us/sample - loss: 0.5052 - acc: 0.7995 - val_loss: 0.5093 - val_acc: 0.8000\n",
      "Epoch 8/10\n",
      "4250/4250 [==============================] - 1s 222us/sample - loss: 0.5303 - acc: 0.7948 - val_loss: 0.5298 - val_acc: 0.7840\n",
      "Epoch 9/10\n",
      "4250/4250 [==============================] - 1s 225us/sample - loss: 0.5516 - acc: 0.7859 - val_loss: 0.4999 - val_acc: 0.8000\n",
      "Epoch 10/10\n",
      "4250/4250 [==============================] - 1s 226us/sample - loss: 0.5100 - acc: 0.7976 - val_loss: 0.5270 - val_acc: 0.7880\n",
      "Epoch 30 out of 200\n",
      "Train on 4250 samples, validate on 750 samples\n",
      "Epoch 1/10\n",
      "4250/4250 [==============================] - 1s 217us/sample - loss: 70.1118 - acc: 0.6812 - val_loss: 222.7658 - val_acc: 0.5400\n",
      "Epoch 2/10\n",
      "4250/4250 [==============================] - 1s 209us/sample - loss: 1746.7866 - acc: 0.5442 - val_loss: 165.7320 - val_acc: 0.4493\n",
      "Epoch 3/10\n",
      "4250/4250 [==============================] - 1s 233us/sample - loss: 51.0860 - acc: 0.6061 - val_loss: 1.0266 - val_acc: 0.6760\n",
      "Epoch 4/10\n",
      "4250/4250 [==============================] - 1s 214us/sample - loss: 0.7933 - acc: 0.7753 - val_loss: 0.6505 - val_acc: 0.8000\n",
      "Epoch 5/10\n",
      "4250/4250 [==============================] - 1s 220us/sample - loss: 0.5809 - acc: 0.7932 - val_loss: 0.5481 - val_acc: 0.8000\n",
      "Epoch 6/10\n",
      "4250/4250 [==============================] - 1s 202us/sample - loss: 0.5393 - acc: 0.7960 - val_loss: 0.5108 - val_acc: 0.8000\n",
      "Epoch 7/10\n",
      "4250/4250 [==============================] - 1s 244us/sample - loss: 0.5140 - acc: 0.7981 - val_loss: 0.5059 - val_acc: 0.8000\n",
      "Epoch 8/10\n",
      "4250/4250 [==============================] - 1s 267us/sample - loss: 0.5219 - acc: 0.7974 - val_loss: 0.5056 - val_acc: 0.8000\n",
      "Epoch 9/10\n",
      "4250/4250 [==============================] - 1s 205us/sample - loss: 0.5291 - acc: 0.7951 - val_loss: 0.5198 - val_acc: 0.8000\n",
      "Epoch 10/10\n",
      "4250/4250 [==============================] - 1s 267us/sample - loss: 0.5184 - acc: 0.7967 - val_loss: 0.5208 - val_acc: 0.7960\n",
      "Epoch 31 out of 200\n",
      "Train on 4250 samples, validate on 750 samples\n",
      "Epoch 1/10\n",
      "4250/4250 [==============================] - 1s 253us/sample - loss: 0.5107 - acc: 0.7981 - val_loss: 0.5055 - val_acc: 0.8000\n",
      "Epoch 2/10\n",
      "4250/4250 [==============================] - 1s 217us/sample - loss: 0.5223 - acc: 0.7953 - val_loss: 0.5054 - val_acc: 0.8000\n",
      "Epoch 3/10\n",
      "4250/4250 [==============================] - 1s 208us/sample - loss: 0.5192 - acc: 0.7960 - val_loss: 0.5007 - val_acc: 0.8000\n",
      "Epoch 4/10\n",
      "4250/4250 [==============================] - 1s 312us/sample - loss: 0.5295 - acc: 0.7915 - val_loss: 0.5713 - val_acc: 0.7227\n",
      "Epoch 5/10\n",
      "4250/4250 [==============================] - 1s 274us/sample - loss: 2.0499 - acc: 0.7249 - val_loss: 9.1734 - val_acc: 0.5667\n",
      "Epoch 6/10\n",
      "4250/4250 [==============================] - 1s 200us/sample - loss: 541.7189 - acc: 0.5306 - val_loss: 199.7649 - val_acc: 0.5413\n",
      "Epoch 7/10\n",
      "4250/4250 [==============================] - 1s 252us/sample - loss: 399.1795 - acc: 0.5499 - val_loss: 197.9864 - val_acc: 0.5440\n",
      "Epoch 8/10\n",
      "4250/4250 [==============================] - 1s 224us/sample - loss: 130.0750 - acc: 0.6344 - val_loss: 1.1674 - val_acc: 0.8000\n",
      "Epoch 9/10\n",
      "4250/4250 [==============================] - 2s 512us/sample - loss: 0.8101 - acc: 0.7809 - val_loss: 0.7805 - val_acc: 0.8000\n",
      "Epoch 10/10\n",
      "4250/4250 [==============================] - 1s 287us/sample - loss: 0.6566 - acc: 0.7868 - val_loss: 0.5859 - val_acc: 0.8000\n",
      "Epoch 32 out of 200\n",
      "Train on 4250 samples, validate on 750 samples\n",
      "Epoch 1/10\n",
      "4250/4250 [==============================] - 1s 248us/sample - loss: 0.7218 - acc: 0.7680 - val_loss: 0.6948 - val_acc: 0.7653\n",
      "Epoch 2/10\n",
      "4250/4250 [==============================] - 1s 206us/sample - loss: 0.6145 - acc: 0.7772 - val_loss: 0.5733 - val_acc: 0.7533\n",
      "Epoch 3/10\n",
      "4250/4250 [==============================] - 1s 233us/sample - loss: 0.5269 - acc: 0.7960 - val_loss: 0.5033 - val_acc: 0.8000\n",
      "Epoch 4/10\n",
      "4250/4250 [==============================] - 1s 229us/sample - loss: 0.5342 - acc: 0.7889 - val_loss: 0.5256 - val_acc: 0.8000\n",
      "Epoch 5/10\n",
      "4250/4250 [==============================] - 1s 194us/sample - loss: 0.5539 - acc: 0.7849 - val_loss: 0.6918 - val_acc: 0.7120\n",
      "Epoch 6/10\n",
      "4250/4250 [==============================] - 1s 214us/sample - loss: 0.5664 - acc: 0.7819 - val_loss: 0.5350 - val_acc: 0.7707\n",
      "Epoch 7/10\n",
      "4250/4250 [==============================] - 1s 227us/sample - loss: 0.5703 - acc: 0.7779 - val_loss: 0.5197 - val_acc: 0.7867\n",
      "Epoch 8/10\n",
      "4250/4250 [==============================] - 1s 215us/sample - loss: 0.5764 - acc: 0.7767 - val_loss: 0.5360 - val_acc: 0.8000\n",
      "Epoch 9/10\n",
      "4250/4250 [==============================] - 1s 220us/sample - loss: 0.6562 - acc: 0.7576 - val_loss: 0.6479 - val_acc: 0.7893\n",
      "Epoch 10/10\n",
      "4250/4250 [==============================] - 1s 227us/sample - loss: 467.5815 - acc: 0.5969 - val_loss: 2667.3238 - val_acc: 0.4627\n",
      "Epoch 33 out of 200\n",
      "Train on 4250 samples, validate on 750 samples\n",
      "Epoch 1/10\n",
      "4250/4250 [==============================] - 1s 235us/sample - loss: 2257.8211 - acc: 0.5388 - val_loss: 2660.6187 - val_acc: 0.5360\n",
      "Epoch 2/10\n",
      "4250/4250 [==============================] - 1s 264us/sample - loss: 417.9088 - acc: 0.5584 - val_loss: 109.7448 - val_acc: 0.5427\n",
      "Epoch 3/10\n",
      "4250/4250 [==============================] - 1s 244us/sample - loss: 10.3622 - acc: 0.7264 - val_loss: 0.7141 - val_acc: 0.8000\n",
      "Epoch 4/10\n",
      "4250/4250 [==============================] - 1s 239us/sample - loss: 0.6896 - acc: 0.7906 - val_loss: 0.6065 - val_acc: 0.8000\n",
      "Epoch 5/10\n",
      "4250/4250 [==============================] - ETA: 0s - loss: 0.6187 - acc: 0.784 - 1s 222us/sample - loss: 0.6115 - acc: 0.7868 - val_loss: 0.5580 - val_acc: 0.8000\n",
      "Epoch 6/10\n",
      "4250/4250 [==============================] - 1s 214us/sample - loss: 0.5380 - acc: 0.7962 - val_loss: 0.5230 - val_acc: 0.8000\n",
      "Epoch 7/10\n",
      "4250/4250 [==============================] - 1s 188us/sample - loss: 0.5318 - acc: 0.7932 - val_loss: 0.5161 - val_acc: 0.8000\n",
      "Epoch 8/10\n",
      "4250/4250 [==============================] - 1s 230us/sample - loss: 0.5121 - acc: 0.7984 - val_loss: 0.5004 - val_acc: 0.8000\n",
      "Epoch 9/10\n",
      "4250/4250 [==============================] - 1s 218us/sample - loss: 0.5056 - acc: 0.7998 - val_loss: 0.5000 - val_acc: 0.8000\n",
      "Epoch 10/10\n",
      "4250/4250 [==============================] - 1s 221us/sample - loss: 0.5061 - acc: 0.7995 - val_loss: 0.5079 - val_acc: 0.8000\n",
      "Epoch 34 out of 200\n",
      "Train on 4250 samples, validate on 750 samples\n",
      "Epoch 1/10\n",
      "4250/4250 [==============================] - 1s 216us/sample - loss: 0.5154 - acc: 0.7976 - val_loss: 0.5032 - val_acc: 0.8000\n",
      "Epoch 2/10\n",
      "4250/4250 [==============================] - 1s 200us/sample - loss: 0.5216 - acc: 0.7986 - val_loss: 0.5037 - val_acc: 0.8000\n",
      "Epoch 3/10\n",
      "4250/4250 [==============================] - 1s 216us/sample - loss: 0.5204 - acc: 0.7974 - val_loss: 0.5060 - val_acc: 0.8000\n",
      "Epoch 4/10\n",
      "4250/4250 [==============================] - 1s 230us/sample - loss: 0.5240 - acc: 0.7922 - val_loss: 0.5020 - val_acc: 0.8000\n",
      "Epoch 5/10\n",
      "4250/4250 [==============================] - 1s 209us/sample - loss: 0.5279 - acc: 0.7915 - val_loss: 0.5052 - val_acc: 0.8000\n",
      "Epoch 6/10\n",
      "4250/4250 [==============================] - 1s 242us/sample - loss: 0.5462 - acc: 0.7894 - val_loss: 0.5964 - val_acc: 0.8000\n",
      "Epoch 7/10\n",
      "4250/4250 [==============================] - 1s 215us/sample - loss: 0.5620 - acc: 0.7849 - val_loss: 0.7061 - val_acc: 0.7853\n",
      "Epoch 8/10\n",
      "4250/4250 [==============================] - 1s 217us/sample - loss: 0.7743 - acc: 0.7621 - val_loss: 0.5107 - val_acc: 0.8000\n",
      "Epoch 9/10\n",
      "4250/4250 [==============================] - 1s 235us/sample - loss: 0.5180 - acc: 0.7936 - val_loss: 0.5031 - val_acc: 0.8000\n",
      "Epoch 10/10\n",
      "4250/4250 [==============================] - 1s 194us/sample - loss: 5.8856 - acc: 0.7334 - val_loss: 53.5199 - val_acc: 0.5413\n",
      "Epoch 35 out of 200\n",
      "Train on 4250 samples, validate on 750 samples\n",
      "Epoch 1/10\n",
      "4250/4250 [==============================] - 1s 233us/sample - loss: 327.4476 - acc: 0.5428 - val_loss: 736.2367 - val_acc: 0.5373\n",
      "Epoch 2/10\n",
      "4250/4250 [==============================] - 1s 217us/sample - loss: 526.5074 - acc: 0.5405 - val_loss: 414.5523 - val_acc: 0.4560\n",
      "Epoch 3/10\n",
      "4250/4250 [==============================] - 1s 257us/sample - loss: 91.2688 - acc: 0.6031 - val_loss: 1.0497 - val_acc: 0.8000\n",
      "Epoch 4/10\n",
      "4250/4250 [==============================] - 1s 226us/sample - loss: 0.8642 - acc: 0.7781 - val_loss: 0.7086 - val_acc: 0.8000\n",
      "Epoch 5/10\n",
      "4250/4250 [==============================] - 1s 250us/sample - loss: 0.6977 - acc: 0.7847 - val_loss: 0.6248 - val_acc: 0.8000\n",
      "Epoch 6/10\n",
      "4250/4250 [==============================] - 1s 319us/sample - loss: 0.5900 - acc: 0.7904 - val_loss: 0.5385 - val_acc: 0.8000\n",
      "Epoch 7/10\n",
      "4250/4250 [==============================] - 1s 228us/sample - loss: 0.6372 - acc: 0.7704 - val_loss: 1.4940 - val_acc: 0.7053\n",
      "Epoch 8/10\n",
      "4250/4250 [==============================] - 1s 215us/sample - loss: 1.8919 - acc: 0.7129 - val_loss: 0.5429 - val_acc: 0.7800\n",
      "Epoch 9/10\n",
      "4250/4250 [==============================] - 1s 244us/sample - loss: 0.5284 - acc: 0.7962 - val_loss: 0.5074 - val_acc: 0.8000\n",
      "Epoch 10/10\n",
      "4250/4250 [==============================] - 1s 261us/sample - loss: 0.5213 - acc: 0.7944 - val_loss: 0.5034 - val_acc: 0.8000\n",
      "Epoch 36 out of 200\n",
      "Train on 4250 samples, validate on 750 samples\n",
      "Epoch 1/10\n",
      "4250/4250 [==============================] - 1s 249us/sample - loss: 0.5805 - acc: 0.7826 - val_loss: 0.6129 - val_acc: 0.8000\n",
      "Epoch 2/10\n",
      "4250/4250 [==============================] - 1s 263us/sample - loss: 4.2127 - acc: 0.6929 - val_loss: 41.0735 - val_acc: 0.4493\n",
      "Epoch 3/10\n",
      "4250/4250 [==============================] - 1s 211us/sample - loss: 2644.9093 - acc: 0.5332 - val_loss: 60.2432 - val_acc: 0.5600\n",
      "Epoch 4/10\n",
      "4250/4250 [==============================] - 1s 208us/sample - loss: 147.2116 - acc: 0.5675 - val_loss: 5.6642 - val_acc: 0.4720\n",
      "Epoch 5/10\n",
      "4250/4250 [==============================] - 1s 215us/sample - loss: 1.2939 - acc: 0.7638 - val_loss: 0.5763 - val_acc: 0.8000\n",
      "Epoch 6/10\n",
      "4250/4250 [==============================] - 1s 215us/sample - loss: 0.5774 - acc: 0.7922 - val_loss: 0.5393 - val_acc: 0.8000\n",
      "Epoch 7/10\n",
      "4250/4250 [==============================] - 1s 221us/sample - loss: 0.5301 - acc: 0.7960 - val_loss: 0.5080 - val_acc: 0.8000\n",
      "Epoch 8/10\n",
      "4250/4250 [==============================] - 1s 226us/sample - loss: 0.5144 - acc: 0.7972 - val_loss: 0.5100 - val_acc: 0.8000\n",
      "Epoch 9/10\n",
      "4250/4250 [==============================] - 1s 234us/sample - loss: 0.5113 - acc: 0.7998 - val_loss: 0.5012 - val_acc: 0.8000\n",
      "Epoch 10/10\n",
      "4250/4250 [==============================] - 1s 211us/sample - loss: 0.5059 - acc: 0.7995 - val_loss: 0.5024 - val_acc: 0.8000\n",
      "Epoch 37 out of 200\n",
      "Train on 4250 samples, validate on 750 samples\n",
      "Epoch 1/10\n",
      "4250/4250 [==============================] - 1s 302us/sample - loss: 0.5169 - acc: 0.7981 - val_loss: 0.5012 - val_acc: 0.8000\n",
      "Epoch 2/10\n",
      "4250/4250 [==============================] - 1s 313us/sample - loss: 0.5061 - acc: 0.8000 - val_loss: 0.5017 - val_acc: 0.8000\n",
      "Epoch 3/10\n",
      "4250/4250 [==============================] - 1s 223us/sample - loss: 0.5201 - acc: 0.7955 - val_loss: 0.5201 - val_acc: 0.7960\n",
      "Epoch 4/10\n",
      "4250/4250 [==============================] - 1s 217us/sample - loss: 0.5260 - acc: 0.7932 - val_loss: 0.5021 - val_acc: 0.8000\n",
      "Epoch 5/10\n",
      "4250/4250 [==============================] - 1s 264us/sample - loss: 0.5192 - acc: 0.7946 - val_loss: 0.5135 - val_acc: 0.8000\n",
      "Epoch 6/10\n",
      "4250/4250 [==============================] - 1s 260us/sample - loss: 0.5247 - acc: 0.7932 - val_loss: 0.5670 - val_acc: 0.7333\n",
      "Epoch 7/10\n",
      "4250/4250 [==============================] - 1s 246us/sample - loss: 840.6414 - acc: 0.5588 - val_loss: 477.6640 - val_acc: 0.5400\n",
      "Epoch 8/10\n",
      "4250/4250 [==============================] - 1s 196us/sample - loss: 3953.7218 - acc: 0.5461 - val_loss: 712.1380 - val_acc: 0.5413\n",
      "Epoch 9/10\n",
      "4250/4250 [==============================] - 1s 244us/sample - loss: 808.5596 - acc: 0.5496 - val_loss: 40.1197 - val_acc: 0.4307\n",
      "Epoch 10/10\n",
      "4250/4250 [==============================] - 1s 216us/sample - loss: 14.4211 - acc: 0.6402 - val_loss: 2.9681 - val_acc: 0.7707\n",
      "Epoch 38 out of 200\n",
      "Train on 4250 samples, validate on 750 samples\n",
      "Epoch 1/10\n",
      "4250/4250 [==============================] - 1s 260us/sample - loss: 1.7009 - acc: 0.7527 - val_loss: 0.7524 - val_acc: 0.8000\n",
      "Epoch 2/10\n",
      "4250/4250 [==============================] - 1s 230us/sample - loss: 0.7857 - acc: 0.7835 - val_loss: 0.6363 - val_acc: 0.7627\n",
      "Epoch 3/10\n",
      "4250/4250 [==============================] - 1s 204us/sample - loss: 0.6523 - acc: 0.7868 - val_loss: 0.5519 - val_acc: 0.8000\n",
      "Epoch 4/10\n",
      "4250/4250 [==============================] - 1s 240us/sample - loss: 0.5542 - acc: 0.7941 - val_loss: 0.5529 - val_acc: 0.8000\n",
      "Epoch 5/10\n",
      "4250/4250 [==============================] - 1s 230us/sample - loss: 0.5315 - acc: 0.7920 - val_loss: 0.5074 - val_acc: 0.8000\n",
      "Epoch 6/10\n",
      "4250/4250 [==============================] - 1s 254us/sample - loss: 0.5187 - acc: 0.7958 - val_loss: 0.5507 - val_acc: 0.8000\n",
      "Epoch 7/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4250/4250 [==============================] - 1s 215us/sample - loss: 0.5165 - acc: 0.7988 - val_loss: 0.5059 - val_acc: 0.8000\n",
      "Epoch 8/10\n",
      "4250/4250 [==============================] - 1s 200us/sample - loss: 0.5158 - acc: 0.7965 - val_loss: 0.5037 - val_acc: 0.8000\n",
      "Epoch 9/10\n",
      "4250/4250 [==============================] - 1s 210us/sample - loss: 0.5092 - acc: 0.7984 - val_loss: 0.5002 - val_acc: 0.8000\n",
      "Epoch 10/10\n",
      "4250/4250 [==============================] - 1s 222us/sample - loss: 0.5132 - acc: 0.7988 - val_loss: 0.5089 - val_acc: 0.8000\n",
      "Epoch 39 out of 200\n",
      "Train on 4250 samples, validate on 750 samples\n",
      "Epoch 1/10\n",
      "4250/4250 [==============================] - 1s 300us/sample - loss: 0.5097 - acc: 0.7988 - val_loss: 0.5033 - val_acc: 0.8000\n",
      "Epoch 2/10\n",
      "4250/4250 [==============================] - 1s 236us/sample - loss: 0.5289 - acc: 0.7901 - val_loss: 0.5249 - val_acc: 0.7987\n",
      "Epoch 3/10\n",
      "4250/4250 [==============================] - 1s 205us/sample - loss: 0.5551 - acc: 0.7852 - val_loss: 0.7845 - val_acc: 0.6587\n",
      "Epoch 4/10\n",
      "4250/4250 [==============================] - 1s 232us/sample - loss: 0.8034 - acc: 0.7391 - val_loss: 0.5013 - val_acc: 0.8000\n",
      "Epoch 5/10\n",
      "4250/4250 [==============================] - 1s 225us/sample - loss: 0.5385 - acc: 0.7944 - val_loss: 0.5652 - val_acc: 0.7320\n",
      "Epoch 6/10\n",
      "4250/4250 [==============================] - 1s 228us/sample - loss: 158.2730 - acc: 0.6247 - val_loss: 549.7912 - val_acc: 0.5373\n",
      "Epoch 7/10\n",
      "4250/4250 [==============================] - 1s 237us/sample - loss: 626.2373 - acc: 0.5449 - val_loss: 426.8984 - val_acc: 0.4573\n",
      "Epoch 8/10\n",
      "4250/4250 [==============================] - 1s 211us/sample - loss: 142.0494 - acc: 0.5536 - val_loss: 50.3237 - val_acc: 0.5533\n",
      "Epoch 9/10\n",
      "4250/4250 [==============================] - 1s 216us/sample - loss: 46.8536 - acc: 0.6431 - val_loss: 0.8869 - val_acc: 0.7360\n",
      "Epoch 10/10\n",
      "4250/4250 [==============================] - 1s 219us/sample - loss: 0.8107 - acc: 0.7842 - val_loss: 0.6859 - val_acc: 0.7960\n",
      "Epoch 40 out of 200\n",
      "Train on 4250 samples, validate on 750 samples\n",
      "Epoch 1/10\n",
      "4250/4250 [==============================] - 1s 219us/sample - loss: 0.6644 - acc: 0.7856 - val_loss: 0.6212 - val_acc: 0.7640\n",
      "Epoch 2/10\n",
      "4250/4250 [==============================] - 1s 219us/sample - loss: 0.5750 - acc: 0.7915 - val_loss: 0.5375 - val_acc: 0.8000\n",
      "Epoch 3/10\n",
      "4250/4250 [==============================] - 1s 218us/sample - loss: 0.5440 - acc: 0.7913 - val_loss: 0.6385 - val_acc: 0.7680\n",
      "Epoch 4/10\n",
      "4250/4250 [==============================] - 1s 229us/sample - loss: 0.5345 - acc: 0.7939 - val_loss: 0.5016 - val_acc: 0.8000\n",
      "Epoch 5/10\n",
      "4250/4250 [==============================] - 1s 210us/sample - loss: 0.5160 - acc: 0.7941 - val_loss: 0.5238 - val_acc: 0.7867\n",
      "Epoch 6/10\n",
      "4250/4250 [==============================] - 1s 330us/sample - loss: 0.5184 - acc: 0.7967 - val_loss: 0.5045 - val_acc: 0.8000\n",
      "Epoch 7/10\n",
      "4250/4250 [==============================] - 1s 295us/sample - loss: 0.5213 - acc: 0.7960 - val_loss: 0.5693 - val_acc: 0.7400\n",
      "Epoch 8/10\n",
      "4250/4250 [==============================] - 1s 243us/sample - loss: 0.5652 - acc: 0.7824 - val_loss: 0.5194 - val_acc: 0.7973\n",
      "Epoch 9/10\n",
      "4250/4250 [==============================] - 1s 209us/sample - loss: 0.5793 - acc: 0.7791 - val_loss: 0.5188 - val_acc: 0.8000\n",
      "Epoch 10/10\n",
      "4250/4250 [==============================] - 1s 231us/sample - loss: 22.0015 - acc: 0.6362 - val_loss: 75.1837 - val_acc: 0.5413\n",
      "Epoch 41 out of 200\n",
      "Train on 4250 samples, validate on 750 samples\n",
      "Epoch 1/10\n",
      "4250/4250 [==============================] - 1s 271us/sample - loss: 3210.0578 - acc: 0.5445 - val_loss: 1222.6805 - val_acc: 0.4640\n",
      "Epoch 2/10\n",
      "4250/4250 [==============================] - 1s 258us/sample - loss: 226.2913 - acc: 0.5633 - val_loss: 32.4529 - val_acc: 0.5653\n",
      "Epoch 3/10\n",
      "4250/4250 [==============================] - 1s 268us/sample - loss: 30.5245 - acc: 0.6301 - val_loss: 0.9482 - val_acc: 0.8000\n",
      "Epoch 4/10\n",
      "4250/4250 [==============================] - 1s 229us/sample - loss: 0.7683 - acc: 0.7859 - val_loss: 0.6840 - val_acc: 0.8000\n",
      "Epoch 5/10\n",
      "4250/4250 [==============================] - 1s 238us/sample - loss: 0.6364 - acc: 0.7896 - val_loss: 0.5717 - val_acc: 0.7867\n",
      "Epoch 6/10\n",
      "4250/4250 [==============================] - 1s 234us/sample - loss: 0.5693 - acc: 0.7899 - val_loss: 0.5272 - val_acc: 0.8000\n",
      "Epoch 7/10\n",
      "4250/4250 [==============================] - 1s 238us/sample - loss: 0.5265 - acc: 0.7955 - val_loss: 0.5166 - val_acc: 0.8000\n",
      "Epoch 8/10\n",
      "4250/4250 [==============================] - 2s 354us/sample - loss: 0.5138 - acc: 0.7974 - val_loss: 0.5038 - val_acc: 0.8000\n",
      "Epoch 9/10\n",
      "4250/4250 [==============================] - 1s 225us/sample - loss: 0.5130 - acc: 0.7991 - val_loss: 0.5018 - val_acc: 0.8000\n",
      "Epoch 10/10\n",
      "4250/4250 [==============================] - 1s 280us/sample - loss: 0.5090 - acc: 0.7998 - val_loss: 0.5001 - val_acc: 0.8000\n",
      "Epoch 42 out of 200\n",
      "Train on 4250 samples, validate on 750 samples\n",
      "Epoch 1/10\n",
      "4250/4250 [==============================] - 1s 234us/sample - loss: 0.5188 - acc: 0.7958 - val_loss: 0.5059 - val_acc: 0.8000\n",
      "Epoch 2/10\n",
      "4250/4250 [==============================] - 1s 212us/sample - loss: 0.5100 - acc: 0.7986 - val_loss: 0.4998 - val_acc: 0.8000\n",
      "Epoch 3/10\n",
      "4250/4250 [==============================] - 1s 240us/sample - loss: 0.5166 - acc: 0.7981 - val_loss: 0.5063 - val_acc: 0.8000\n",
      "Epoch 4/10\n",
      "4250/4250 [==============================] - 1s 229us/sample - loss: 0.5061 - acc: 0.8000 - val_loss: 0.5029 - val_acc: 0.8000\n",
      "Epoch 5/10\n",
      "4250/4250 [==============================] - 1s 237us/sample - loss: 0.5255 - acc: 0.7960 - val_loss: 0.5161 - val_acc: 0.8000\n",
      "Epoch 6/10\n",
      "4250/4250 [==============================] - 1s 218us/sample - loss: 0.5297 - acc: 0.7946 - val_loss: 0.5124 - val_acc: 0.8000\n",
      "Epoch 7/10\n",
      "4250/4250 [==============================] - 1s 224us/sample - loss: 0.5340 - acc: 0.7955 - val_loss: 0.5412 - val_acc: 0.7653\n",
      "Epoch 8/10\n",
      "4250/4250 [==============================] - 1s 238us/sample - loss: 17.2758 - acc: 0.6247 - val_loss: 25.8290 - val_acc: 0.5560\n",
      "Epoch 9/10\n",
      "4250/4250 [==============================] - 1s 233us/sample - loss: 1049.6436 - acc: 0.5473 - val_loss: 674.8371 - val_acc: 0.4560\n",
      "Epoch 10/10\n",
      "4250/4250 [==============================] - 1s 188us/sample - loss: 117.2876 - acc: 0.5574 - val_loss: 5.9306 - val_acc: 0.4200\n",
      "Epoch 43 out of 200\n",
      "Train on 4250 samples, validate on 750 samples\n",
      "Epoch 1/10\n",
      "4250/4250 [==============================] - 1s 214us/sample - loss: 3.2595 - acc: 0.7424 - val_loss: 0.6619 - val_acc: 0.7733\n",
      "Epoch 2/10\n",
      "4250/4250 [==============================] - 1s 203us/sample - loss: 0.6643 - acc: 0.7856 - val_loss: 0.6332 - val_acc: 0.8000\n",
      "Epoch 3/10\n",
      "4250/4250 [==============================] - 1s 213us/sample - loss: 0.6137 - acc: 0.7849 - val_loss: 0.5831 - val_acc: 0.7867\n",
      "Epoch 4/10\n",
      "4250/4250 [==============================] - 1s 207us/sample - loss: 0.5353 - acc: 0.7953 - val_loss: 0.5125 - val_acc: 0.8000\n",
      "Epoch 5/10\n",
      "4250/4250 [==============================] - 1s 212us/sample - loss: 0.5150 - acc: 0.7976 - val_loss: 0.5214 - val_acc: 0.7987\n",
      "Epoch 6/10\n",
      "4250/4250 [==============================] - 1s 222us/sample - loss: 0.5204 - acc: 0.7913 - val_loss: 0.5591 - val_acc: 0.8000\n",
      "Epoch 7/10\n",
      "4250/4250 [==============================] - 1s 214us/sample - loss: 0.5246 - acc: 0.7972 - val_loss: 0.5011 - val_acc: 0.8000\n",
      "Epoch 8/10\n",
      "4250/4250 [==============================] - 1s 212us/sample - loss: 0.5086 - acc: 0.7981 - val_loss: 0.5021 - val_acc: 0.8000\n",
      "Epoch 9/10\n",
      "4250/4250 [==============================] - 1s 206us/sample - loss: 0.5169 - acc: 0.7967 - val_loss: 0.5374 - val_acc: 0.7920\n",
      "Epoch 10/10\n",
      "4250/4250 [==============================] - 1s 205us/sample - loss: 0.5348 - acc: 0.7925 - val_loss: 0.6838 - val_acc: 0.8000\n",
      "Epoch 44 out of 200\n",
      "Train on 4250 samples, validate on 750 samples\n",
      "Epoch 1/10\n",
      "4250/4250 [==============================] - 1s 202us/sample - loss: 0.5807 - acc: 0.7748 - val_loss: 0.5000 - val_acc: 0.8000\n",
      "Epoch 2/10\n",
      "4250/4250 [==============================] - 1s 209us/sample - loss: 0.5102 - acc: 0.7991 - val_loss: 0.5141 - val_acc: 0.8000\n",
      "Epoch 3/10\n",
      "4250/4250 [==============================] - 1s 210us/sample - loss: 0.5310 - acc: 0.7962 - val_loss: 0.5041 - val_acc: 0.8000\n",
      "Epoch 4/10\n",
      "4250/4250 [==============================] - 1s 217us/sample - loss: 0.5208 - acc: 0.7953 - val_loss: 0.5955 - val_acc: 0.6947\n",
      "Epoch 5/10\n",
      "4250/4250 [==============================] - 1s 198us/sample - loss: 114.6049 - acc: 0.6694 - val_loss: 936.7466 - val_acc: 0.5387\n",
      "Epoch 6/10\n",
      "4250/4250 [==============================] - 1s 195us/sample - loss: 1177.2886 - acc: 0.5421 - val_loss: 349.3841 - val_acc: 0.4560\n",
      "Epoch 7/10\n",
      "4250/4250 [==============================] - 1s 201us/sample - loss: 46.2719 - acc: 0.6626 - val_loss: 0.8062 - val_acc: 0.8000\n",
      "Epoch 8/10\n",
      "4250/4250 [==============================] - 1s 211us/sample - loss: 0.7457 - acc: 0.7762 - val_loss: 0.7168 - val_acc: 0.8000\n",
      "Epoch 9/10\n",
      "4250/4250 [==============================] - 1s 251us/sample - loss: 0.5703 - acc: 0.7911 - val_loss: 0.5293 - val_acc: 0.8000\n",
      "Epoch 10/10\n",
      "4250/4250 [==============================] - 1s 220us/sample - loss: 0.5424 - acc: 0.7906 - val_loss: 0.5574 - val_acc: 0.8000\n",
      "Epoch 45 out of 200\n",
      "Train on 4250 samples, validate on 750 samples\n",
      "Epoch 1/10\n",
      "4250/4250 [==============================] - 1s 219us/sample - loss: 0.5384 - acc: 0.7911 - val_loss: 0.5053 - val_acc: 0.8000\n",
      "Epoch 2/10\n",
      "4250/4250 [==============================] - 1s 211us/sample - loss: 0.5228 - acc: 0.7944 - val_loss: 0.5005 - val_acc: 0.8000\n",
      "Epoch 3/10\n",
      "4250/4250 [==============================] - 1s 217us/sample - loss: 0.5326 - acc: 0.7892 - val_loss: 0.5327 - val_acc: 0.8000\n",
      "Epoch 4/10\n",
      "4250/4250 [==============================] - 1s 213us/sample - loss: 0.5063 - acc: 0.7995 - val_loss: 0.5084 - val_acc: 0.8000\n",
      "Epoch 5/10\n",
      "4250/4250 [==============================] - 1s 217us/sample - loss: 0.5356 - acc: 0.7901 - val_loss: 0.5384 - val_acc: 0.7867\n",
      "Epoch 6/10\n",
      "4250/4250 [==============================] - 1s 212us/sample - loss: 0.5570 - acc: 0.7894 - val_loss: 0.5158 - val_acc: 0.8000\n",
      "Epoch 7/10\n",
      "4250/4250 [==============================] - 1s 195us/sample - loss: 0.8635 - acc: 0.7369 - val_loss: 0.5792 - val_acc: 0.8000\n",
      "Epoch 8/10\n",
      "4250/4250 [==============================] - 1s 279us/sample - loss: 45.3709 - acc: 0.6104 - val_loss: 9.8611 - val_acc: 0.4453\n",
      "Epoch 9/10\n",
      "4250/4250 [==============================] - 1s 228us/sample - loss: 1446.3780 - acc: 0.5292 - val_loss: 1633.5986 - val_acc: 0.5373\n",
      "Epoch 10/10\n",
      "4250/4250 [==============================] - 1s 217us/sample - loss: 547.9878 - acc: 0.5522 - val_loss: 688.0127 - val_acc: 0.4587\n",
      "Epoch 46 out of 200\n",
      "Train on 4250 samples, validate on 750 samples\n",
      "Epoch 1/10\n",
      "4250/4250 [==============================] - 1s 248us/sample - loss: 217.0109 - acc: 0.5534 - val_loss: 56.4080 - val_acc: 0.5600\n",
      "Epoch 2/10\n",
      "4250/4250 [==============================] - 1s 203us/sample - loss: 3.1326 - acc: 0.7579 - val_loss: 0.8347 - val_acc: 0.8000\n",
      "Epoch 3/10\n",
      "4250/4250 [==============================] - 1s 212us/sample - loss: 0.7770 - acc: 0.7847 - val_loss: 0.7302 - val_acc: 0.8000\n",
      "Epoch 4/10\n",
      "4250/4250 [==============================] - 1s 237us/sample - loss: 0.6574 - acc: 0.7908 - val_loss: 0.5846 - val_acc: 0.8000\n",
      "Epoch 5/10\n",
      "4250/4250 [==============================] - 1s 281us/sample - loss: 0.5798 - acc: 0.7939 - val_loss: 0.5307 - val_acc: 0.8000\n",
      "Epoch 6/10\n",
      "4250/4250 [==============================] - 1s 226us/sample - loss: 0.5285 - acc: 0.7962 - val_loss: 0.5140 - val_acc: 0.8000\n",
      "Epoch 7/10\n",
      "4250/4250 [==============================] - ETA: 0s - loss: 0.5171 - acc: 0.7974- ETA: 0s - loss: 0.5167 - acc: 0.79 - 1s 272us/sample - loss: 0.5157 - acc: 0.7986 - val_loss: 0.5109 - val_acc: 0.8000\n",
      "Epoch 8/10\n",
      "4250/4250 [==============================] - 1s 216us/sample - loss: 0.5158 - acc: 0.7976 - val_loss: 0.5012 - val_acc: 0.8000\n",
      "Epoch 9/10\n",
      "4250/4250 [==============================] - 1s 214us/sample - loss: 0.5389 - acc: 0.7908 - val_loss: 0.6735 - val_acc: 0.7947\n",
      "Epoch 10/10\n",
      "4250/4250 [==============================] - 1s 230us/sample - loss: 0.5304 - acc: 0.7965 - val_loss: 0.5052 - val_acc: 0.8000\n",
      "Epoch 47 out of 200\n",
      "Train on 4250 samples, validate on 750 samples\n",
      "Epoch 1/10\n",
      "4250/4250 [==============================] - 1s 296us/sample - loss: 0.5210 - acc: 0.7955 - val_loss: 0.5059 - val_acc: 0.8000\n",
      "Epoch 2/10\n",
      "4250/4250 [==============================] - 1s 251us/sample - loss: 0.5197 - acc: 0.7941 - val_loss: 0.5055 - val_acc: 0.8000\n",
      "Epoch 3/10\n",
      "4250/4250 [==============================] - 1s 210us/sample - loss: 0.5561 - acc: 0.7904 - val_loss: 0.5148 - val_acc: 0.8000\n",
      "Epoch 4/10\n",
      "4250/4250 [==============================] - 1s 235us/sample - loss: 0.5131 - acc: 0.7998 - val_loss: 0.5163 - val_acc: 0.8000\n",
      "Epoch 5/10\n",
      "4250/4250 [==============================] - 1s 211us/sample - loss: 0.5082 - acc: 0.7981 - val_loss: 0.5020 - val_acc: 0.8000\n",
      "Epoch 6/10\n",
      "4250/4250 [==============================] - 1s 227us/sample - loss: 0.5176 - acc: 0.7944 - val_loss: 0.5350 - val_acc: 0.8000\n",
      "Epoch 7/10\n",
      "4250/4250 [==============================] - 1s 205us/sample - loss: 0.5221 - acc: 0.7965 - val_loss: 0.5063 - val_acc: 0.8000\n",
      "Epoch 8/10\n",
      "4250/4250 [==============================] - 1s 242us/sample - loss: 0.5484 - acc: 0.7896 - val_loss: 1.3169 - val_acc: 0.7293\n",
      "Epoch 9/10\n",
      "4250/4250 [==============================] - 1s 245us/sample - loss: 226.9958 - acc: 0.5574 - val_loss: 418.3903 - val_acc: 0.5373\n",
      "Epoch 10/10\n",
      "4250/4250 [==============================] - 1s 219us/sample - loss: 2611.4478 - acc: 0.5440 - val_loss: 571.4356 - val_acc: 0.5387\n",
      "Epoch 48 out of 200\n",
      "Train on 4250 samples, validate on 750 samples\n",
      "Epoch 1/10\n",
      "4250/4250 [==============================] - 1s 284us/sample - loss: 69.6564 - acc: 0.6372 - val_loss: 1.0041 - val_acc: 0.8000\n",
      "Epoch 2/10\n",
      "4250/4250 [==============================] - 1s 247us/sample - loss: 0.7414 - acc: 0.7849 - val_loss: 0.6757 - val_acc: 0.8000\n",
      "Epoch 3/10\n",
      "4250/4250 [==============================] - 1s 254us/sample - loss: 0.6145 - acc: 0.7918 - val_loss: 0.5554 - val_acc: 0.8000\n",
      "Epoch 4/10\n",
      "4250/4250 [==============================] - 1s 242us/sample - loss: 0.5477 - acc: 0.7908 - val_loss: 0.5213 - val_acc: 0.8000\n",
      "Epoch 5/10\n",
      "4250/4250 [==============================] - 1s 250us/sample - loss: 0.5172 - acc: 0.7979 - val_loss: 0.5156 - val_acc: 0.8000\n",
      "Epoch 6/10\n",
      "4250/4250 [==============================] - 1s 259us/sample - loss: 0.5188 - acc: 0.7962 - val_loss: 0.5022 - val_acc: 0.8000\n",
      "Epoch 7/10\n",
      "4250/4250 [==============================] - ETA: 0s - loss: 0.5069 - acc: 0.799 - 1s 274us/sample - loss: 0.5068 - acc: 0.7995 - val_loss: 0.5017 - val_acc: 0.8000\n",
      "Epoch 8/10\n",
      "4250/4250 [==============================] - 1s 253us/sample - loss: 0.5057 - acc: 0.8000 - val_loss: 0.5006 - val_acc: 0.8000\n",
      "Epoch 9/10\n",
      "4250/4250 [==============================] - 1s 296us/sample - loss: 0.5069 - acc: 0.7995 - val_loss: 0.5075 - val_acc: 0.8000\n",
      "Epoch 10/10\n",
      "4250/4250 [==============================] - 1s 261us/sample - loss: 0.5116 - acc: 0.7991 - val_loss: 0.5021 - val_acc: 0.8000\n",
      "Epoch 49 out of 200\n",
      "Train on 4250 samples, validate on 750 samples\n",
      "Epoch 1/10\n",
      "4250/4250 [==============================] - 1s 233us/sample - loss: 0.5087 - acc: 0.7991 - val_loss: 0.5006 - val_acc: 0.8000\n",
      "Epoch 2/10\n",
      "4250/4250 [==============================] - 1s 229us/sample - loss: 0.5315 - acc: 0.7936 - val_loss: 0.5126 - val_acc: 0.8000\n",
      "Epoch 3/10\n",
      "4250/4250 [==============================] - ETA: 0s - loss: 0.5094 - acc: 0.799 - 1s 223us/sample - loss: 0.5104 - acc: 0.7979 - val_loss: 0.5060 - val_acc: 0.8000\n",
      "Epoch 4/10\n",
      "4250/4250 [==============================] - 1s 214us/sample - loss: 0.6308 - acc: 0.7746 - val_loss: 0.5770 - val_acc: 0.8000\n",
      "Epoch 5/10\n",
      "4250/4250 [==============================] - 1s 208us/sample - loss: 0.6488 - acc: 0.7671 - val_loss: 0.5033 - val_acc: 0.8000\n",
      "Epoch 6/10\n",
      "4250/4250 [==============================] - 1s 212us/sample - loss: 0.5143 - acc: 0.7986 - val_loss: 0.5108 - val_acc: 0.8000\n",
      "Epoch 7/10\n",
      "4250/4250 [==============================] - 1s 238us/sample - loss: 0.5093 - acc: 0.7995 - val_loss: 0.5109 - val_acc: 0.8000\n",
      "Epoch 8/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4250/4250 [==============================] - 1s 255us/sample - loss: 0.5358 - acc: 0.7948 - val_loss: 0.5349 - val_acc: 0.7800\n",
      "Epoch 9/10\n",
      "4250/4250 [==============================] - 1s 231us/sample - loss: 0.5465 - acc: 0.7842 - val_loss: 0.5038 - val_acc: 0.8000\n",
      "Epoch 10/10\n",
      "4250/4250 [==============================] - 1s 236us/sample - loss: 0.7447 - acc: 0.7635 - val_loss: 0.7124 - val_acc: 0.8000\n",
      "Epoch 50 out of 200\n",
      "Train on 4250 samples, validate on 750 samples\n",
      "Epoch 1/10\n",
      "4250/4250 [==============================] - 1s 267us/sample - loss: 1.0049 - acc: 0.7466 - val_loss: 0.8969 - val_acc: 0.7773\n",
      "Epoch 2/10\n",
      "4250/4250 [==============================] - 1s 240us/sample - loss: 828.9977 - acc: 0.5496 - val_loss: 226.4494 - val_acc: 0.5400\n",
      "Epoch 3/10\n",
      "4250/4250 [==============================] - 1s 232us/sample - loss: 99.4635 - acc: 0.5826 - val_loss: 9.3948 - val_acc: 0.6093\n",
      "Epoch 4/10\n",
      "4250/4250 [==============================] - 1s 257us/sample - loss: 23.0554 - acc: 0.6005 - val_loss: 2.5365 - val_acc: 0.7867\n",
      "Epoch 5/10\n",
      "4250/4250 [==============================] - 1s 253us/sample - loss: 146.9645 - acc: 0.5511 - val_loss: 71.8589 - val_acc: 0.5440\n",
      "Epoch 6/10\n",
      "4250/4250 [==============================] - 1s 237us/sample - loss: 210.0751 - acc: 0.5628 - val_loss: 33.0624 - val_acc: 0.5627\n",
      "Epoch 7/10\n",
      "4250/4250 [==============================] - 1s 243us/sample - loss: 7.1802 - acc: 0.7141 - val_loss: 0.9501 - val_acc: 0.7680\n",
      "Epoch 8/10\n",
      "4250/4250 [==============================] - 1s 213us/sample - loss: 1.0466 - acc: 0.7741 - val_loss: 0.8228 - val_acc: 0.7867\n",
      "Epoch 9/10\n",
      "4250/4250 [==============================] - 1s 237us/sample - loss: 0.9640 - acc: 0.7741 - val_loss: 0.6894 - val_acc: 0.7987\n",
      "Epoch 10/10\n",
      "4250/4250 [==============================] - 1s 261us/sample - loss: 0.7058 - acc: 0.7852 - val_loss: 0.6441 - val_acc: 0.8000\n",
      "Epoch 51 out of 200\n",
      "Train on 4250 samples, validate on 750 samples\n",
      "Epoch 1/10\n",
      "4250/4250 [==============================] - 1s 217us/sample - loss: 0.6624 - acc: 0.7800 - val_loss: 0.5524 - val_acc: 0.8000\n",
      "Epoch 2/10\n",
      "4250/4250 [==============================] - 1s 232us/sample - loss: 0.5469 - acc: 0.7955 - val_loss: 0.5243 - val_acc: 0.8000\n",
      "Epoch 3/10\n",
      "4250/4250 [==============================] - 1s 225us/sample - loss: 0.5262 - acc: 0.7953 - val_loss: 0.5136 - val_acc: 0.8000\n",
      "Epoch 4/10\n",
      "4250/4250 [==============================] - 1s 252us/sample - loss: 0.7671 - acc: 0.7649 - val_loss: 2.0867 - val_acc: 0.6413\n",
      "Epoch 5/10\n",
      "4250/4250 [==============================] - 1s 227us/sample - loss: 3211.4665 - acc: 0.5480 - val_loss: 13839.8874 - val_acc: 0.5360\n",
      "Epoch 6/10\n",
      "4250/4250 [==============================] - 1s 207us/sample - loss: 4441.0025 - acc: 0.5506 - val_loss: 158.3163 - val_acc: 0.5533\n",
      "Epoch 7/10\n",
      "4250/4250 [==============================] - 1s 240us/sample - loss: 57.5631 - acc: 0.5816 - val_loss: 10.4463 - val_acc: 0.6253\n",
      "Epoch 8/10\n",
      "4250/4250 [==============================] - ETA: 0s - loss: 9.9294 - acc: 0.6370 - 1s 250us/sample - loss: 9.4644 - acc: 0.6445 - val_loss: 0.8393 - val_acc: 0.8000\n",
      "Epoch 9/10\n",
      "4250/4250 [==============================] - 1s 218us/sample - loss: 11.4665 - acc: 0.6402 - val_loss: 3.6916 - val_acc: 0.7253\n",
      "Epoch 10/10\n",
      "4250/4250 [==============================] - 1s 238us/sample - loss: 1.1667 - acc: 0.7741 - val_loss: 0.6273 - val_acc: 0.8000\n",
      "Epoch 52 out of 200\n",
      "Train on 4250 samples, validate on 750 samples\n",
      "Epoch 1/10\n",
      "4250/4250 [==============================] - 1s 265us/sample - loss: 0.6116 - acc: 0.7936 - val_loss: 0.5885 - val_acc: 0.7640\n",
      "Epoch 2/10\n",
      "4250/4250 [==============================] - 1s 216us/sample - loss: 0.5681 - acc: 0.7889 - val_loss: 0.5448 - val_acc: 0.8000\n",
      "Epoch 3/10\n",
      "4250/4250 [==============================] - 1s 253us/sample - loss: 0.5193 - acc: 0.7981 - val_loss: 0.5086 - val_acc: 0.8000\n",
      "Epoch 4/10\n",
      "4250/4250 [==============================] - 1s 229us/sample - loss: 0.5088 - acc: 0.7988 - val_loss: 0.5052 - val_acc: 0.8000\n",
      "Epoch 5/10\n",
      "4250/4250 [==============================] - 1s 224us/sample - loss: 0.5050 - acc: 0.7995 - val_loss: 0.5117 - val_acc: 0.8000\n",
      "Epoch 6/10\n",
      "4250/4250 [==============================] - 1s 237us/sample - loss: 0.5050 - acc: 0.8000 - val_loss: 0.5020 - val_acc: 0.8000\n",
      "Epoch 7/10\n",
      "4250/4250 [==============================] - 1s 224us/sample - loss: 0.5042 - acc: 0.8000 - val_loss: 0.5001 - val_acc: 0.8000\n",
      "Epoch 8/10\n",
      "4250/4250 [==============================] - 1s 270us/sample - loss: 0.5061 - acc: 0.7986 - val_loss: 0.4999 - val_acc: 0.8000\n",
      "Epoch 9/10\n",
      "4250/4250 [==============================] - 1s 223us/sample - loss: 0.5047 - acc: 0.8000 - val_loss: 0.5005 - val_acc: 0.8000\n",
      "Epoch 10/10\n",
      "4250/4250 [==============================] - 1s 198us/sample - loss: 0.5051 - acc: 0.7998 - val_loss: 0.5073 - val_acc: 0.8000\n",
      "Epoch 53 out of 200\n",
      "Train on 4250 samples, validate on 750 samples\n",
      "Epoch 1/10\n",
      "4250/4250 [==============================] - 1s 219us/sample - loss: 0.5072 - acc: 0.8000 - val_loss: 0.5003 - val_acc: 0.8000\n",
      "Epoch 2/10\n",
      "4250/4250 [==============================] - 1s 217us/sample - loss: 0.5308 - acc: 0.7929 - val_loss: 0.5006 - val_acc: 0.8000\n",
      "Epoch 3/10\n",
      "4250/4250 [==============================] - 1s 231us/sample - loss: 0.5097 - acc: 0.7986 - val_loss: 0.5347 - val_acc: 0.7787\n",
      "Epoch 4/10\n",
      "4250/4250 [==============================] - 1s 231us/sample - loss: 0.5119 - acc: 0.7981 - val_loss: 0.5062 - val_acc: 0.8000\n",
      "Epoch 5/10\n",
      "4250/4250 [==============================] - 1s 212us/sample - loss: 0.5375 - acc: 0.7948 - val_loss: 0.7156 - val_acc: 0.7987\n",
      "Epoch 6/10\n",
      "4250/4250 [==============================] - 1s 226us/sample - loss: 0.5521 - acc: 0.7878 - val_loss: 0.5110 - val_acc: 0.8000\n",
      "Epoch 7/10\n",
      "4250/4250 [==============================] - 1s 249us/sample - loss: 0.5297 - acc: 0.7925 - val_loss: 0.5044 - val_acc: 0.8000\n",
      "Epoch 8/10\n",
      "4250/4250 [==============================] - 1s 219us/sample - loss: 0.5232 - acc: 0.7962 - val_loss: 0.5022 - val_acc: 0.8000\n",
      "Epoch 9/10\n",
      "4250/4250 [==============================] - 1s 254us/sample - loss: 0.6623 - acc: 0.7732 - val_loss: 0.5005 - val_acc: 0.8000\n",
      "Epoch 10/10\n",
      "4250/4250 [==============================] - 1s 246us/sample - loss: 488.8256 - acc: 0.5607 - val_loss: 59.9346 - val_acc: 0.5413\n",
      "Epoch 54 out of 200\n",
      "Train on 4250 samples, validate on 750 samples\n",
      "Epoch 1/10\n",
      "4250/4250 [==============================] - 1s 209us/sample - loss: 2477.7418 - acc: 0.5355 - val_loss: 1035.6822 - val_acc: 0.4507\n",
      "Epoch 2/10\n",
      "4250/4250 [==============================] - 1s 259us/sample - loss: 715.3006 - acc: 0.5602 - val_loss: 266.5973 - val_acc: 0.4400\n",
      "Epoch 3/10\n",
      "4250/4250 [==============================] - 1s 195us/sample - loss: 297.2596 - acc: 0.5605 - val_loss: 254.1663 - val_acc: 0.5453\n",
      "Epoch 4/10\n",
      "4250/4250 [==============================] - 1s 217us/sample - loss: 122.6570 - acc: 0.5833 - val_loss: 7.1209 - val_acc: 0.7133\n",
      "Epoch 5/10\n",
      "4250/4250 [==============================] - 1s 189us/sample - loss: 25.4873 - acc: 0.6136 - val_loss: 3.9956 - val_acc: 0.5240\n",
      "Epoch 6/10\n",
      "4250/4250 [==============================] - 1s 239us/sample - loss: 6.8983 - acc: 0.7056 - val_loss: 1.7117 - val_acc: 0.8000\n",
      "Epoch 7/10\n",
      "4250/4250 [==============================] - 1s 197us/sample - loss: 6.9821 - acc: 0.6896 - val_loss: 2.5839 - val_acc: 0.5560\n",
      "Epoch 8/10\n",
      "4250/4250 [==============================] - 1s 204us/sample - loss: 1.9122 - acc: 0.7518 - val_loss: 0.8601 - val_acc: 0.8000\n",
      "Epoch 9/10\n",
      "4250/4250 [==============================] - 1s 266us/sample - loss: 0.8677 - acc: 0.7788 - val_loss: 0.7247 - val_acc: 0.7867\n",
      "Epoch 10/10\n",
      "4250/4250 [==============================] - 1s 240us/sample - loss: 0.7843 - acc: 0.7784 - val_loss: 0.6229 - val_acc: 0.7853\n",
      "Epoch 55 out of 200\n",
      "Train on 4250 samples, validate on 750 samples\n",
      "Epoch 1/10\n",
      "4250/4250 [==============================] - 1s 216us/sample - loss: 0.6074 - acc: 0.7873 - val_loss: 0.5666 - val_acc: 0.8000\n",
      "Epoch 2/10\n",
      "4250/4250 [==============================] - 1s 187us/sample - loss: 0.5455 - acc: 0.7929 - val_loss: 0.5616 - val_acc: 0.7520\n",
      "Epoch 3/10\n",
      "4250/4250 [==============================] - 1s 187us/sample - loss: 0.5384 - acc: 0.7892 - val_loss: 0.5056 - val_acc: 0.8000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/10\n",
      "4250/4250 [==============================] - 1s 213us/sample - loss: 0.5131 - acc: 0.7972 - val_loss: 0.5033 - val_acc: 0.8000\n",
      "Epoch 5/10\n",
      "4250/4250 [==============================] - 1s 208us/sample - loss: 0.5065 - acc: 0.7998 - val_loss: 0.5042 - val_acc: 0.8000\n",
      "Epoch 6/10\n",
      "4250/4250 [==============================] - 1s 215us/sample - loss: 0.5114 - acc: 0.7986 - val_loss: 0.4998 - val_acc: 0.8000\n",
      "Epoch 7/10\n",
      "4250/4250 [==============================] - 1s 217us/sample - loss: 0.5198 - acc: 0.7944 - val_loss: 0.5188 - val_acc: 0.8000\n",
      "Epoch 8/10\n",
      "4250/4250 [==============================] - 1s 240us/sample - loss: 0.5085 - acc: 0.7998 - val_loss: 0.5001 - val_acc: 0.8000\n",
      "Epoch 9/10\n",
      "4250/4250 [==============================] - 1s 252us/sample - loss: 0.5598 - acc: 0.7854 - val_loss: 0.6747 - val_acc: 0.6947\n",
      "Epoch 10/10\n",
      "4250/4250 [==============================] - 1s 231us/sample - loss: 31.6797 - acc: 0.6718 - val_loss: 76.0491 - val_acc: 0.5560\n",
      "Epoch 56 out of 200\n",
      "Train on 4250 samples, validate on 750 samples\n",
      "Epoch 1/10\n",
      "4250/4250 [==============================] - 1s 303us/sample - loss: 1547.3764 - acc: 0.5325 - val_loss: 3191.5426 - val_acc: 0.5400\n",
      "Epoch 2/10\n",
      "4250/4250 [==============================] - 1s 241us/sample - loss: 853.3804 - acc: 0.5616 - val_loss: 152.5140 - val_acc: 0.5453\n",
      "Epoch 3/10\n",
      "4250/4250 [==============================] - 1s 233us/sample - loss: 16.0338 - acc: 0.7014 - val_loss: 0.6934 - val_acc: 0.8000\n",
      "Epoch 4/10\n",
      "4250/4250 [==============================] - 1s 237us/sample - loss: 0.6755 - acc: 0.7864 - val_loss: 0.5862 - val_acc: 0.8000\n",
      "Epoch 5/10\n",
      "4250/4250 [==============================] - 1s 259us/sample - loss: 0.5792 - acc: 0.7934 - val_loss: 0.5288 - val_acc: 0.8000\n",
      "Epoch 6/10\n",
      "4250/4250 [==============================] - 1s 246us/sample - loss: 0.5327 - acc: 0.7958 - val_loss: 0.5128 - val_acc: 0.8000\n",
      "Epoch 7/10\n",
      "4250/4250 [==============================] - 1s 245us/sample - loss: 0.5158 - acc: 0.7979 - val_loss: 0.5292 - val_acc: 0.7987\n",
      "Epoch 8/10\n",
      "4250/4250 [==============================] - 1s 261us/sample - loss: 0.5084 - acc: 0.8002 - val_loss: 0.5005 - val_acc: 0.8000\n",
      "Epoch 9/10\n",
      "4250/4250 [==============================] - 1s 246us/sample - loss: 0.5053 - acc: 0.7998 - val_loss: 0.5005 - val_acc: 0.8000\n",
      "Epoch 10/10\n",
      "4250/4250 [==============================] - 1s 299us/sample - loss: 0.5065 - acc: 0.7995 - val_loss: 0.5008 - val_acc: 0.8000\n",
      "Epoch 57 out of 200\n",
      "Train on 4250 samples, validate on 750 samples\n",
      "Epoch 1/10\n",
      "4250/4250 [==============================] - 1s 223us/sample - loss: 0.5131 - acc: 0.7972 - val_loss: 0.5311 - val_acc: 0.8000\n",
      "Epoch 2/10\n",
      "4250/4250 [==============================] - 1s 274us/sample - loss: 0.5097 - acc: 0.7995 - val_loss: 0.5074 - val_acc: 0.8000\n",
      "Epoch 3/10\n",
      "4250/4250 [==============================] - 1s 206us/sample - loss: 0.5110 - acc: 0.7991 - val_loss: 0.5011 - val_acc: 0.8000\n",
      "Epoch 4/10\n",
      "4250/4250 [==============================] - 1s 206us/sample - loss: 0.5072 - acc: 0.7991 - val_loss: 0.5002 - val_acc: 0.8000\n",
      "Epoch 5/10\n",
      "4250/4250 [==============================] - 1s 200us/sample - loss: 0.5121 - acc: 0.7962 - val_loss: 0.5171 - val_acc: 0.8000\n",
      "Epoch 6/10\n",
      "4250/4250 [==============================] - 1s 211us/sample - loss: 0.5243 - acc: 0.7958 - val_loss: 0.5132 - val_acc: 0.8000\n",
      "Epoch 7/10\n",
      "4250/4250 [==============================] - 1s 197us/sample - loss: 0.5195 - acc: 0.7962 - val_loss: 0.5054 - val_acc: 0.8000\n",
      "Epoch 8/10\n",
      "4250/4250 [==============================] - 1s 234us/sample - loss: 0.5188 - acc: 0.7953 - val_loss: 0.6026 - val_acc: 0.8000\n",
      "Epoch 9/10\n",
      "4250/4250 [==============================] - 1s 220us/sample - loss: 0.7611 - acc: 0.7609 - val_loss: 0.5279 - val_acc: 0.7987\n",
      "Epoch 10/10\n",
      "4250/4250 [==============================] - 1s 220us/sample - loss: 0.5331 - acc: 0.7894 - val_loss: 0.5022 - val_acc: 0.8000\n",
      "Epoch 58 out of 200\n",
      "Train on 4250 samples, validate on 750 samples\n",
      "Epoch 1/10\n",
      "4250/4250 [==============================] - 1s 226us/sample - loss: 0.5317 - acc: 0.7929 - val_loss: 0.5556 - val_acc: 0.8000\n",
      "Epoch 2/10\n",
      "4250/4250 [==============================] - 1s 191us/sample - loss: 91.1170 - acc: 0.6459 - val_loss: 623.6337 - val_acc: 0.5387\n",
      "Epoch 3/10\n",
      "4250/4250 [==============================] - 1s 208us/sample - loss: 589.3316 - acc: 0.5468 - val_loss: 238.7776 - val_acc: 0.4387\n",
      "Epoch 4/10\n",
      "4250/4250 [==============================] - 1s 198us/sample - loss: 93.4952 - acc: 0.5899 - val_loss: 45.1815 - val_acc: 0.4320\n",
      "Epoch 5/10\n",
      "4250/4250 [==============================] - 1s 214us/sample - loss: 21.6561 - acc: 0.6581 - val_loss: 1.0133 - val_acc: 0.6787\n",
      "Epoch 6/10\n",
      "4250/4250 [==============================] - 1s 234us/sample - loss: 0.7752 - acc: 0.7812 - val_loss: 0.6721 - val_acc: 0.8000\n",
      "Epoch 7/10\n",
      "4250/4250 [==============================] - 1s 274us/sample - loss: 0.6432 - acc: 0.7887 - val_loss: 0.5523 - val_acc: 0.8000\n",
      "Epoch 8/10\n",
      "4250/4250 [==============================] - 1s 279us/sample - loss: 0.5713 - acc: 0.7880 - val_loss: 0.5233 - val_acc: 0.8000\n",
      "Epoch 9/10\n",
      "4250/4250 [==============================] - 1s 215us/sample - loss: 0.5622 - acc: 0.7904 - val_loss: 0.5271 - val_acc: 0.7853\n",
      "Epoch 10/10\n",
      "4250/4250 [==============================] - 1s 191us/sample - loss: 0.5247 - acc: 0.7951 - val_loss: 0.5096 - val_acc: 0.8000\n",
      "Epoch 59 out of 200\n",
      "Train on 4250 samples, validate on 750 samples\n",
      "Epoch 1/10\n",
      "4250/4250 [==============================] - 1s 203us/sample - loss: 0.5326 - acc: 0.7892 - val_loss: 0.5475 - val_acc: 0.7947\n",
      "Epoch 2/10\n",
      "4250/4250 [==============================] - 1s 237us/sample - loss: 0.5595 - acc: 0.7816 - val_loss: 0.5150 - val_acc: 0.8000\n",
      "Epoch 3/10\n",
      "4250/4250 [==============================] - 1s 231us/sample - loss: 0.5058 - acc: 0.8000 - val_loss: 0.5004 - val_acc: 0.8000\n",
      "Epoch 4/10\n",
      "4250/4250 [==============================] - 1s 239us/sample - loss: 0.5319 - acc: 0.7920 - val_loss: 0.5075 - val_acc: 0.8000\n",
      "Epoch 5/10\n",
      "4250/4250 [==============================] - 1s 244us/sample - loss: 0.7796 - acc: 0.7671 - val_loss: 0.6963 - val_acc: 0.6520\n",
      "Epoch 6/10\n",
      "4250/4250 [==============================] - 1s 240us/sample - loss: 119.6874 - acc: 0.6649 - val_loss: 1276.8111 - val_acc: 0.5373\n",
      "Epoch 7/10\n",
      "4250/4250 [==============================] - 1s 243us/sample - loss: 1891.5173 - acc: 0.5384 - val_loss: 800.9128 - val_acc: 0.5400\n",
      "Epoch 8/10\n",
      "4250/4250 [==============================] - 1s 272us/sample - loss: 153.2978 - acc: 0.5995 - val_loss: 2.5905 - val_acc: 0.7693\n",
      "Epoch 9/10\n",
      "4250/4250 [==============================] - 1s 268us/sample - loss: 1.7627 - acc: 0.7454 - val_loss: 0.6959 - val_acc: 0.8000\n",
      "Epoch 10/10\n",
      "4250/4250 [==============================] - 1s 249us/sample - loss: 0.6217 - acc: 0.7880 - val_loss: 0.5771 - val_acc: 0.7867\n",
      "Epoch 60 out of 200\n",
      "Train on 4250 samples, validate on 750 samples\n",
      "Epoch 1/10\n",
      "4250/4250 [==============================] - 1s 257us/sample - loss: 0.5674 - acc: 0.7859 - val_loss: 0.5285 - val_acc: 0.8000\n",
      "Epoch 2/10\n",
      "4250/4250 [==============================] - 1s 184us/sample - loss: 0.5380 - acc: 0.7955 - val_loss: 0.5155 - val_acc: 0.8000\n",
      "Epoch 3/10\n",
      "4250/4250 [==============================] - 1s 191us/sample - loss: 0.5267 - acc: 0.7941 - val_loss: 0.5789 - val_acc: 0.7987\n",
      "Epoch 4/10\n",
      "4250/4250 [==============================] - 1s 216us/sample - loss: 0.5262 - acc: 0.7953 - val_loss: 0.5018 - val_acc: 0.8000\n",
      "Epoch 5/10\n",
      "4250/4250 [==============================] - ETA: 0s - loss: 0.5321 - acc: 0.787 - 1s 234us/sample - loss: 0.5333 - acc: 0.7866 - val_loss: 0.5684 - val_acc: 0.8000\n",
      "Epoch 6/10\n",
      "4250/4250 [==============================] - 1s 195us/sample - loss: 0.5297 - acc: 0.7929 - val_loss: 0.5030 - val_acc: 0.8000\n",
      "Epoch 7/10\n",
      "4250/4250 [==============================] - 1s 227us/sample - loss: 0.5428 - acc: 0.7882 - val_loss: 0.5076 - val_acc: 0.8000\n",
      "Epoch 8/10\n",
      "4250/4250 [==============================] - 1s 238us/sample - loss: 0.5310 - acc: 0.7901 - val_loss: 0.5141 - val_acc: 0.8000\n",
      "Epoch 9/10\n",
      "4250/4250 [==============================] - 1s 284us/sample - loss: 0.5569 - acc: 0.7847 - val_loss: 0.6002 - val_acc: 0.7107\n",
      "Epoch 10/10\n",
      "4250/4250 [==============================] - 1s 230us/sample - loss: 1.0161 - acc: 0.7494 - val_loss: 0.8969 - val_acc: 0.7720\n",
      "Epoch 61 out of 200\n",
      "Train on 4250 samples, validate on 750 samples\n",
      "Epoch 1/10\n",
      "4250/4250 [==============================] - 1s 332us/sample - loss: 129.1466 - acc: 0.5379 - val_loss: 219.9602 - val_acc: 0.5400\n",
      "Epoch 2/10\n",
      "4250/4250 [==============================] - 1s 275us/sample - loss: 78.7668 - acc: 0.5464 - val_loss: 316.6740 - val_acc: 0.4573\n",
      "Epoch 3/10\n",
      "4250/4250 [==============================] - 1s 286us/sample - loss: 488.0650 - acc: 0.5419 - val_loss: 1675.2417 - val_acc: 0.5373\n",
      "Epoch 4/10\n",
      "4250/4250 [==============================] - 1s 235us/sample - loss: 3505.3998 - acc: 0.5478 - val_loss: 506.2837 - val_acc: 0.4533\n",
      "Epoch 5/10\n",
      "4250/4250 [==============================] - 1s 301us/sample - loss: 170.0966 - acc: 0.5758 - val_loss: 1.3559 - val_acc: 0.8000\n",
      "Epoch 6/10\n",
      "4250/4250 [==============================] - 1s 233us/sample - loss: 1.3802 - acc: 0.7701 - val_loss: 0.9426 - val_acc: 0.7853\n",
      "Epoch 7/10\n",
      "4250/4250 [==============================] - ETA: 0s - loss: 0.9892 - acc: 0.775 - 1s 178us/sample - loss: 0.9744 - acc: 0.7779 - val_loss: 0.7987 - val_acc: 0.8000\n",
      "Epoch 8/10\n",
      "4250/4250 [==============================] - 1s 193us/sample - loss: 0.7733 - acc: 0.7847 - val_loss: 0.7647 - val_acc: 0.8000\n",
      "Epoch 9/10\n",
      "4250/4250 [==============================] - 1s 209us/sample - loss: 0.6776 - acc: 0.7824 - val_loss: 0.6015 - val_acc: 0.8000\n",
      "Epoch 10/10\n",
      "4250/4250 [==============================] - 1s 203us/sample - loss: 0.5994 - acc: 0.7889 - val_loss: 0.5298 - val_acc: 0.8000\n",
      "Epoch 62 out of 200\n",
      "Train on 4250 samples, validate on 750 samples\n",
      "Epoch 1/10\n",
      "4250/4250 [==============================] - 1s 207us/sample - loss: 0.5517 - acc: 0.7918 - val_loss: 0.5268 - val_acc: 0.8000\n",
      "Epoch 2/10\n",
      "4250/4250 [==============================] - 1s 228us/sample - loss: 0.5277 - acc: 0.7955 - val_loss: 0.5100 - val_acc: 0.8000\n",
      "Epoch 3/10\n",
      "4250/4250 [==============================] - 1s 310us/sample - loss: 0.5116 - acc: 0.7981 - val_loss: 0.5063 - val_acc: 0.8000\n",
      "Epoch 4/10\n",
      "4250/4250 [==============================] - 1s 271us/sample - loss: 0.5151 - acc: 0.7965 - val_loss: 0.5014 - val_acc: 0.8000\n",
      "Epoch 5/10\n",
      "4250/4250 [==============================] - 1s 249us/sample - loss: 0.5253 - acc: 0.7915 - val_loss: 0.5777 - val_acc: 0.8000\n",
      "Epoch 6/10\n",
      "4250/4250 [==============================] - 1s 238us/sample - loss: 0.5242 - acc: 0.7965 - val_loss: 0.5200 - val_acc: 0.7973\n",
      "Epoch 7/10\n",
      "4250/4250 [==============================] - 1s 264us/sample - loss: 0.5262 - acc: 0.7913 - val_loss: 0.5026 - val_acc: 0.8000\n",
      "Epoch 8/10\n",
      "4250/4250 [==============================] - 1s 238us/sample - loss: 0.5182 - acc: 0.7962 - val_loss: 0.5053 - val_acc: 0.8000\n",
      "Epoch 9/10\n",
      "4250/4250 [==============================] - 1s 266us/sample - loss: 0.5218 - acc: 0.7953 - val_loss: 0.5150 - val_acc: 0.8000\n",
      "Epoch 10/10\n",
      "4250/4250 [==============================] - 1s 266us/sample - loss: 1.1459 - acc: 0.7209 - val_loss: 0.6071 - val_acc: 0.7080\n",
      "Epoch 63 out of 200\n",
      "Train on 4250 samples, validate on 750 samples\n",
      "Epoch 1/10\n",
      "4250/4250 [==============================] - 1s 284us/sample - loss: 0.5825 - acc: 0.7779 - val_loss: 0.5178 - val_acc: 0.8000\n",
      "Epoch 2/10\n",
      "4250/4250 [==============================] - 1s 274us/sample - loss: 0.5453 - acc: 0.7882 - val_loss: 0.5091 - val_acc: 0.8000\n",
      "Epoch 3/10\n",
      "4250/4250 [==============================] - 1s 282us/sample - loss: 0.5425 - acc: 0.7889 - val_loss: 0.5011 - val_acc: 0.8000\n",
      "Epoch 4/10\n",
      "4250/4250 [==============================] - 1s 216us/sample - loss: 0.5719 - acc: 0.7833 - val_loss: 0.5765 - val_acc: 0.8000\n",
      "Epoch 5/10\n",
      "4250/4250 [==============================] - 1s 221us/sample - loss: 0.7690 - acc: 0.7609 - val_loss: 1.1918 - val_acc: 0.7253\n",
      "Epoch 6/10\n",
      "4250/4250 [==============================] - 1s 286us/sample - loss: 248.0653 - acc: 0.5555 - val_loss: 223.3407 - val_acc: 0.5387\n",
      "Epoch 7/10\n",
      "4250/4250 [==============================] - 1s 232us/sample - loss: 310.7227 - acc: 0.5386 - val_loss: 298.4424 - val_acc: 0.5400\n",
      "Epoch 8/10\n",
      "4250/4250 [==============================] - 1s 199us/sample - loss: 478.8637 - acc: 0.5525 - val_loss: 185.4472 - val_acc: 0.5467\n",
      "Epoch 9/10\n",
      "4250/4250 [==============================] - 1s 189us/sample - loss: 296.7529 - acc: 0.5551 - val_loss: 134.4476 - val_acc: 0.5533\n",
      "Epoch 10/10\n",
      "4250/4250 [==============================] - 1s 220us/sample - loss: 70.8207 - acc: 0.6096 - val_loss: 1.3338 - val_acc: 0.7053\n",
      "Epoch 64 out of 200\n",
      "Train on 4250 samples, validate on 750 samples\n",
      "Epoch 1/10\n",
      "4250/4250 [==============================] - 1s 202us/sample - loss: 1.4214 - acc: 0.7680 - val_loss: 0.9533 - val_acc: 0.8000\n",
      "Epoch 2/10\n",
      "4250/4250 [==============================] - 1s 309us/sample - loss: 0.8634 - acc: 0.7819 - val_loss: 0.7271 - val_acc: 0.7653\n",
      "Epoch 3/10\n",
      "4250/4250 [==============================] - 1s 203us/sample - loss: 0.7220 - acc: 0.7854 - val_loss: 0.6184 - val_acc: 0.7867\n",
      "Epoch 4/10\n",
      "4250/4250 [==============================] - 1s 193us/sample - loss: 0.6690 - acc: 0.7769 - val_loss: 0.6263 - val_acc: 0.8000\n",
      "Epoch 5/10\n",
      "4250/4250 [==============================] - 1s 181us/sample - loss: 0.6034 - acc: 0.7873 - val_loss: 0.5755 - val_acc: 0.8000\n",
      "Epoch 6/10\n",
      "4250/4250 [==============================] - 1s 198us/sample - loss: 0.7136 - acc: 0.7614 - val_loss: 0.5211 - val_acc: 0.8000\n",
      "Epoch 7/10\n",
      "4250/4250 [==============================] - 1s 187us/sample - loss: 0.6155 - acc: 0.7809 - val_loss: 0.5249 - val_acc: 0.8000\n",
      "Epoch 8/10\n",
      "4250/4250 [==============================] - 1s 236us/sample - loss: 0.5272 - acc: 0.7960 - val_loss: 0.5012 - val_acc: 0.8000\n",
      "Epoch 9/10\n",
      "4250/4250 [==============================] - 1s 271us/sample - loss: 0.5327 - acc: 0.7913 - val_loss: 0.5022 - val_acc: 0.8000\n",
      "Epoch 10/10\n",
      "4250/4250 [==============================] - 1s 219us/sample - loss: 0.6085 - acc: 0.7751 - val_loss: 0.5311 - val_acc: 0.8000\n",
      "Epoch 65 out of 200\n",
      "Train on 4250 samples, validate on 750 samples\n",
      "Epoch 1/10\n",
      "4250/4250 [==============================] - 1s 266us/sample - loss: 752.2925 - acc: 0.5821 - val_loss: 19.6719 - val_acc: 0.6120\n",
      "Epoch 2/10\n",
      "4250/4250 [==============================] - 1s 276us/sample - loss: 1905.1804 - acc: 0.5402 - val_loss: 168.3630 - val_acc: 0.4360\n",
      "Epoch 3/10\n",
      "4250/4250 [==============================] - 1s 217us/sample - loss: 35.0659 - acc: 0.6445 - val_loss: 0.6645 - val_acc: 0.7813\n",
      "Epoch 4/10\n",
      "4250/4250 [==============================] - 1s 215us/sample - loss: 0.6452 - acc: 0.7871 - val_loss: 0.5803 - val_acc: 0.8000\n",
      "Epoch 5/10\n",
      "4250/4250 [==============================] - 1s 207us/sample - loss: 0.5489 - acc: 0.7929 - val_loss: 0.5351 - val_acc: 0.7867\n",
      "Epoch 6/10\n",
      "4250/4250 [==============================] - 1s 253us/sample - loss: 0.5258 - acc: 0.7976 - val_loss: 0.5121 - val_acc: 0.8000\n",
      "Epoch 7/10\n",
      "4250/4250 [==============================] - 1s 225us/sample - loss: 0.5095 - acc: 0.7991 - val_loss: 0.5101 - val_acc: 0.8000\n",
      "Epoch 8/10\n",
      "4250/4250 [==============================] - 1s 245us/sample - loss: 0.5204 - acc: 0.7981 - val_loss: 0.5011 - val_acc: 0.8000\n",
      "Epoch 9/10\n",
      "4250/4250 [==============================] - 1s 241us/sample - loss: 0.5070 - acc: 0.7995 - val_loss: 0.5009 - val_acc: 0.8000\n",
      "Epoch 10/10\n",
      "4250/4250 [==============================] - 1s 256us/sample - loss: 0.5092 - acc: 0.7976 - val_loss: 0.5026 - val_acc: 0.8000\n",
      "Epoch 66 out of 200\n",
      "Train on 4250 samples, validate on 750 samples\n",
      "Epoch 1/10\n",
      "4250/4250 [==============================] - 1s 276us/sample - loss: 0.5269 - acc: 0.7920 - val_loss: 0.5008 - val_acc: 0.8000\n",
      "Epoch 2/10\n",
      "4250/4250 [==============================] - 1s 244us/sample - loss: 0.5083 - acc: 0.8000 - val_loss: 0.5070 - val_acc: 0.8000\n",
      "Epoch 3/10\n",
      "4250/4250 [==============================] - 1s 226us/sample - loss: 0.5144 - acc: 0.7979 - val_loss: 0.5007 - val_acc: 0.8000\n",
      "Epoch 4/10\n",
      "4250/4250 [==============================] - 1s 231us/sample - loss: 0.5462 - acc: 0.7873 - val_loss: 0.5455 - val_acc: 0.8000\n",
      "Epoch 5/10\n",
      "4250/4250 [==============================] - 1s 261us/sample - loss: 0.5510 - acc: 0.7922 - val_loss: 0.5646 - val_acc: 0.8000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/10\n",
      "4250/4250 [==============================] - 1s 287us/sample - loss: 0.5224 - acc: 0.7960 - val_loss: 0.5029 - val_acc: 0.8000\n",
      "Epoch 7/10\n",
      "4250/4250 [==============================] - 1s 240us/sample - loss: 0.5317 - acc: 0.7934 - val_loss: 0.5116 - val_acc: 0.8000\n",
      "Epoch 8/10\n",
      "4250/4250 [==============================] - 1s 256us/sample - loss: 48.5019 - acc: 0.6842 - val_loss: 101.5232 - val_acc: 0.5400\n",
      "Epoch 9/10\n",
      "4250/4250 [==============================] - 1s 241us/sample - loss: 2006.8754 - acc: 0.5362 - val_loss: 507.3129 - val_acc: 0.5387\n",
      "Epoch 10/10\n",
      "4250/4250 [==============================] - 1s 232us/sample - loss: 783.4004 - acc: 0.5402 - val_loss: 44.8490 - val_acc: 0.4360\n",
      "Epoch 67 out of 200\n",
      "Train on 4250 samples, validate on 750 samples\n",
      "Epoch 1/10\n",
      "4250/4250 [==============================] - 1s 251us/sample - loss: 84.6485 - acc: 0.5711 - val_loss: 13.6558 - val_acc: 0.5947\n",
      "Epoch 2/10\n",
      "4250/4250 [==============================] - 1s 228us/sample - loss: 3.6749 - acc: 0.7146 - val_loss: 0.8034 - val_acc: 0.7867\n",
      "Epoch 3/10\n",
      "4250/4250 [==============================] - 1s 235us/sample - loss: 0.8117 - acc: 0.7840 - val_loss: 0.6728 - val_acc: 0.7707\n",
      "Epoch 4/10\n",
      "4250/4250 [==============================] - 1s 245us/sample - loss: 0.6549 - acc: 0.7875 - val_loss: 0.5632 - val_acc: 0.7987\n",
      "Epoch 5/10\n",
      "4250/4250 [==============================] - 1s 236us/sample - loss: 0.5693 - acc: 0.7920 - val_loss: 0.5314 - val_acc: 0.8000\n",
      "Epoch 6/10\n",
      "4250/4250 [==============================] - 1s 261us/sample - loss: 0.5376 - acc: 0.7948 - val_loss: 0.5130 - val_acc: 0.8000\n",
      "Epoch 7/10\n",
      "4250/4250 [==============================] - 1s 275us/sample - loss: 0.5321 - acc: 0.7929 - val_loss: 0.6417 - val_acc: 0.8000\n",
      "Epoch 8/10\n",
      "4250/4250 [==============================] - 1s 234us/sample - loss: 0.5132 - acc: 0.7979 - val_loss: 0.5011 - val_acc: 0.8000\n",
      "Epoch 9/10\n",
      "4250/4250 [==============================] - 1s 224us/sample - loss: 0.5283 - acc: 0.7929 - val_loss: 0.5100 - val_acc: 0.8000\n",
      "Epoch 10/10\n",
      "4250/4250 [==============================] - 1s 232us/sample - loss: 0.5128 - acc: 0.7969 - val_loss: 0.5036 - val_acc: 0.8000\n",
      "Epoch 68 out of 200\n",
      "Train on 4250 samples, validate on 750 samples\n",
      "Epoch 1/10\n",
      "4250/4250 [==============================] - 1s 240us/sample - loss: 0.5346 - acc: 0.7873 - val_loss: 0.5190 - val_acc: 0.7987\n",
      "Epoch 2/10\n",
      "4250/4250 [==============================] - 1s 263us/sample - loss: 0.5529 - acc: 0.7927 - val_loss: 0.5411 - val_acc: 0.8000\n",
      "Epoch 3/10\n",
      "4250/4250 [==============================] - 1s 220us/sample - loss: 0.6022 - acc: 0.7793 - val_loss: 0.5411 - val_acc: 0.8000\n",
      "Epoch 4/10\n",
      "4250/4250 [==============================] - 1s 220us/sample - loss: 0.5124 - acc: 0.7988 - val_loss: 0.5034 - val_acc: 0.8000\n",
      "Epoch 5/10\n",
      "4250/4250 [==============================] - 1s 227us/sample - loss: 0.5180 - acc: 0.7958 - val_loss: 0.5098 - val_acc: 0.8000\n",
      "Epoch 6/10\n",
      "4250/4250 [==============================] - 1s 207us/sample - loss: 1.0071 - acc: 0.7581 - val_loss: 20.0102 - val_acc: 0.5400\n",
      "Epoch 7/10\n",
      "4250/4250 [==============================] - 1s 214us/sample - loss: 341.7345 - acc: 0.5442 - val_loss: 895.7491 - val_acc: 0.5387\n",
      "Epoch 8/10\n",
      "4250/4250 [==============================] - 1s 211us/sample - loss: 1388.2715 - acc: 0.5456 - val_loss: 306.1689 - val_acc: 0.5560\n",
      "Epoch 9/10\n",
      "4250/4250 [==============================] - 1s 184us/sample - loss: 545.1073 - acc: 0.5501 - val_loss: 6.7938 - val_acc: 0.6747\n",
      "Epoch 10/10\n",
      "4250/4250 [==============================] - 1s 234us/sample - loss: 1.6355 - acc: 0.7553 - val_loss: 0.7644 - val_acc: 0.8000\n",
      "Epoch 69 out of 200\n",
      "Train on 4250 samples, validate on 750 samples\n",
      "Epoch 1/10\n",
      "4250/4250 [==============================] - 1s 242us/sample - loss: 0.7223 - acc: 0.7854 - val_loss: 0.6541 - val_acc: 0.8000\n",
      "Epoch 2/10\n",
      "4250/4250 [==============================] - 1s 203us/sample - loss: 0.6194 - acc: 0.7927 - val_loss: 0.5469 - val_acc: 0.8000\n",
      "Epoch 3/10\n",
      "4250/4250 [==============================] - 1s 196us/sample - loss: 0.5490 - acc: 0.7941 - val_loss: 0.5240 - val_acc: 0.8000\n",
      "Epoch 4/10\n",
      "4250/4250 [==============================] - 1s 304us/sample - loss: 0.5220 - acc: 0.7969 - val_loss: 0.5141 - val_acc: 0.8000\n",
      "Epoch 5/10\n",
      "4250/4250 [==============================] - 1s 258us/sample - loss: 0.5101 - acc: 0.7993 - val_loss: 0.5081 - val_acc: 0.8000\n",
      "Epoch 6/10\n",
      "4250/4250 [==============================] - 1s 266us/sample - loss: 0.5111 - acc: 0.7972 - val_loss: 0.5066 - val_acc: 0.8000\n",
      "Epoch 7/10\n",
      "4250/4250 [==============================] - 1s 260us/sample - loss: 0.5100 - acc: 0.7991 - val_loss: 0.5010 - val_acc: 0.8000\n",
      "Epoch 8/10\n",
      "4250/4250 [==============================] - 1s 206us/sample - loss: 0.5224 - acc: 0.7936 - val_loss: 0.5004 - val_acc: 0.8000\n",
      "Epoch 9/10\n",
      "4250/4250 [==============================] - 1s 283us/sample - loss: 0.5189 - acc: 0.7972 - val_loss: 0.5101 - val_acc: 0.8000\n",
      "Epoch 10/10\n",
      "4250/4250 [==============================] - 1s 192us/sample - loss: 0.5153 - acc: 0.7998 - val_loss: 0.5007 - val_acc: 0.8000\n",
      "Epoch 70 out of 200\n",
      "Train on 4250 samples, validate on 750 samples\n",
      "Epoch 1/10\n",
      "4250/4250 [==============================] - 1s 268us/sample - loss: 0.5235 - acc: 0.7946 - val_loss: 0.5074 - val_acc: 0.8000\n",
      "Epoch 2/10\n",
      "4250/4250 [==============================] - 1s 220us/sample - loss: 0.5736 - acc: 0.7816 - val_loss: 0.5091 - val_acc: 0.8000\n",
      "Epoch 3/10\n",
      "4250/4250 [==============================] - 1s 228us/sample - loss: 0.5140 - acc: 0.7988 - val_loss: 0.5247 - val_acc: 0.8000\n",
      "Epoch 4/10\n",
      "4250/4250 [==============================] - 1s 250us/sample - loss: 0.5641 - acc: 0.7793 - val_loss: 0.5054 - val_acc: 0.8000\n",
      "Epoch 5/10\n",
      "4250/4250 [==============================] - 1s 290us/sample - loss: 0.5209 - acc: 0.7969 - val_loss: 0.5052 - val_acc: 0.8000s - loss: 0.5160 - \n",
      "Epoch 6/10\n",
      "4250/4250 [==============================] - 1s 293us/sample - loss: 0.6155 - acc: 0.7774 - val_loss: 1.5401 - val_acc: 0.6400\n",
      "Epoch 7/10\n",
      "4250/4250 [==============================] - 1s 249us/sample - loss: 84.0435 - acc: 0.5913 - val_loss: 346.9977 - val_acc: 0.5373\n",
      "Epoch 8/10\n",
      "4250/4250 [==============================] - 1s 238us/sample - loss: 201.6389 - acc: 0.5529 - val_loss: 288.0188 - val_acc: 0.5413\n",
      "Epoch 9/10\n",
      "4250/4250 [==============================] - 1s 229us/sample - loss: 850.7043 - acc: 0.5461 - val_loss: 1349.0136 - val_acc: 0.5400\n",
      "Epoch 10/10\n",
      "4250/4250 [==============================] - 1s 234us/sample - loss: 788.9463 - acc: 0.5438 - val_loss: 427.3607 - val_acc: 0.5387\n",
      "Epoch 71 out of 200\n",
      "Train on 4250 samples, validate on 750 samples\n",
      "Epoch 1/10\n",
      "4250/4250 [==============================] - 1s 248us/sample - loss: 94.9903 - acc: 0.6219 - val_loss: 1.1416 - val_acc: 0.7973\n",
      "Epoch 2/10\n",
      "4250/4250 [==============================] - 1s 209us/sample - loss: 1.0989 - acc: 0.7755 - val_loss: 0.9767 - val_acc: 0.8000\n",
      "Epoch 3/10\n",
      "4250/4250 [==============================] - 1s 222us/sample - loss: 0.8565 - acc: 0.7840 - val_loss: 0.7349 - val_acc: 0.7987\n",
      "Epoch 4/10\n",
      "4250/4250 [==============================] - 1s 218us/sample - loss: 0.7223 - acc: 0.7835 - val_loss: 0.6180 - val_acc: 0.8000\n",
      "Epoch 5/10\n",
      "4250/4250 [==============================] - 1s 222us/sample - loss: 0.6265 - acc: 0.7856 - val_loss: 0.5584 - val_acc: 0.8000\n",
      "Epoch 6/10\n",
      "4250/4250 [==============================] - 1s 263us/sample - loss: 0.5479 - acc: 0.7936 - val_loss: 0.5680 - val_acc: 0.8000\n",
      "Epoch 7/10\n",
      "4250/4250 [==============================] - 1s 236us/sample - loss: 0.5252 - acc: 0.7958 - val_loss: 0.5200 - val_acc: 0.8000\n",
      "Epoch 8/10\n",
      "4250/4250 [==============================] - 1s 254us/sample - loss: 0.5358 - acc: 0.7892 - val_loss: 0.5509 - val_acc: 0.8000\n",
      "Epoch 9/10\n",
      "4250/4250 [==============================] - 1s 222us/sample - loss: 0.5278 - acc: 0.7934 - val_loss: 0.5030 - val_acc: 0.8000\n",
      "Epoch 10/10\n",
      "4250/4250 [==============================] - 1s 256us/sample - loss: 0.5347 - acc: 0.7946 - val_loss: 0.5172 - val_acc: 0.7947\n",
      "Epoch 72 out of 200\n",
      "Train on 4250 samples, validate on 750 samples\n",
      "Epoch 1/10\n",
      "4250/4250 [==============================] - 1s 262us/sample - loss: 0.5483 - acc: 0.7878 - val_loss: 0.5715 - val_acc: 0.7280\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/10\n",
      "4250/4250 [==============================] - 1s 218us/sample - loss: 0.5337 - acc: 0.7939 - val_loss: 0.5015 - val_acc: 0.8000\n",
      "Epoch 3/10\n",
      "4250/4250 [==============================] - 1s 232us/sample - loss: 0.5076 - acc: 0.7993 - val_loss: 0.5009 - val_acc: 0.8000\n",
      "Epoch 4/10\n",
      "4250/4250 [==============================] - 1s 224us/sample - loss: 0.5138 - acc: 0.7962 - val_loss: 0.5051 - val_acc: 0.8000\n",
      "Epoch 5/10\n",
      "4250/4250 [==============================] - 1s 229us/sample - loss: 0.5198 - acc: 0.7948 - val_loss: 0.5253 - val_acc: 0.7947\n",
      "Epoch 6/10\n",
      "4250/4250 [==============================] - 1s 234us/sample - loss: 32.9823 - acc: 0.6899 - val_loss: 5.7146 - val_acc: 0.5973\n",
      "Epoch 7/10\n",
      "4250/4250 [==============================] - 1s 212us/sample - loss: 3040.9354 - acc: 0.5353 - val_loss: 1579.1426 - val_acc: 0.5387\n",
      "Epoch 8/10\n",
      "4250/4250 [==============================] - 1s 218us/sample - loss: 476.5634 - acc: 0.5798 - val_loss: 15.6691 - val_acc: 0.5893\n",
      "Epoch 9/10\n",
      "4250/4250 [==============================] - 1s 210us/sample - loss: 5.6532 - acc: 0.6784 - val_loss: 3.1281 - val_acc: 0.7373\n",
      "Epoch 10/10\n",
      "4250/4250 [==============================] - 1s 217us/sample - loss: 1.3537 - acc: 0.7539 - val_loss: 0.6030 - val_acc: 0.7853\n",
      "Epoch 73 out of 200\n",
      "Train on 4250 samples, validate on 750 samples\n",
      "Epoch 1/10\n",
      "4250/4250 [==============================] - 1s 274us/sample - loss: 0.6215 - acc: 0.7854 - val_loss: 0.5544 - val_acc: 0.8000\n",
      "Epoch 2/10\n",
      "4250/4250 [==============================] - 1s 293us/sample - loss: 0.5460 - acc: 0.7927 - val_loss: 0.5154 - val_acc: 0.8000\n",
      "Epoch 3/10\n",
      "4250/4250 [==============================] - 1s 212us/sample - loss: 0.5152 - acc: 0.7991 - val_loss: 0.5029 - val_acc: 0.8000\n",
      "Epoch 4/10\n",
      "4250/4250 [==============================] - 1s 201us/sample - loss: 0.5069 - acc: 0.8000 - val_loss: 0.5031 - val_acc: 0.8000\n",
      "Epoch 5/10\n",
      "4250/4250 [==============================] - 1s 193us/sample - loss: 0.5092 - acc: 0.8000 - val_loss: 0.5013 - val_acc: 0.8000\n",
      "Epoch 6/10\n",
      "4250/4250 [==============================] - 1s 227us/sample - loss: 0.5039 - acc: 0.7998 - val_loss: 0.5118 - val_acc: 0.8000\n",
      "Epoch 7/10\n",
      "4250/4250 [==============================] - 1s 281us/sample - loss: 0.5083 - acc: 0.7995 - val_loss: 0.4999 - val_acc: 0.8000\n",
      "Epoch 8/10\n",
      "4250/4250 [==============================] - 1s 261us/sample - loss: 0.5237 - acc: 0.7936 - val_loss: 0.5054 - val_acc: 0.8000\n",
      "Epoch 9/10\n",
      "4250/4250 [==============================] - 1s 245us/sample - loss: 0.5140 - acc: 0.7993 - val_loss: 0.5137 - val_acc: 0.8000\n",
      "Epoch 10/10\n",
      "4250/4250 [==============================] - 1s 246us/sample - loss: 0.5159 - acc: 0.7976 - val_loss: 0.5057 - val_acc: 0.8000\n",
      "Epoch 74 out of 200\n",
      "Train on 4250 samples, validate on 750 samples\n",
      "Epoch 1/10\n",
      "4250/4250 [==============================] - 2s 537us/sample - loss: 0.5803 - acc: 0.7821 - val_loss: 0.5055 - val_acc: 0.8000\n",
      "Epoch 2/10\n",
      "4250/4250 [==============================] - 5s 1ms/sample - loss: 119.3674 - acc: 0.6638 - val_loss: 518.5916 - val_acc: 0.5400\n",
      "Epoch 3/10\n",
      "4250/4250 [==============================] - 5s 1ms/sample - loss: 3722.7780 - acc: 0.5438 - val_loss: 611.8884 - val_acc: 0.5400\n",
      "Epoch 4/10\n",
      "4250/4250 [==============================] - 5s 1ms/sample - loss: 168.3856 - acc: 0.5715 - val_loss: 20.1069 - val_acc: 0.5760\n",
      "Epoch 5/10\n",
      "4250/4250 [==============================] - 2s 559us/sample - loss: 4.5280 - acc: 0.7231 - val_loss: 1.0196 - val_acc: 0.8000\n",
      "Epoch 6/10\n",
      "4250/4250 [==============================] - 1s 246us/sample - loss: 0.6634 - acc: 0.7871 - val_loss: 0.7025 - val_acc: 0.8000\n",
      "Epoch 7/10\n",
      "4250/4250 [==============================] - 2s 369us/sample - loss: 0.6135 - acc: 0.7859 - val_loss: 0.5445 - val_acc: 0.8000\n",
      "Epoch 8/10\n",
      "4250/4250 [==============================] - 2s 365us/sample - loss: 0.5514 - acc: 0.7899 - val_loss: 0.5657 - val_acc: 0.8000\n",
      "Epoch 9/10\n",
      "4250/4250 [==============================] - 1s 317us/sample - loss: 0.5194 - acc: 0.7991 - val_loss: 0.5052 - val_acc: 0.8000\n",
      "Epoch 10/10\n",
      "4250/4250 [==============================] - 1s 223us/sample - loss: 0.5162 - acc: 0.7953 - val_loss: 0.5006 - val_acc: 0.8000\n",
      "Epoch 75 out of 200\n",
      "Train on 4250 samples, validate on 750 samples\n",
      "Epoch 1/10\n",
      "4250/4250 [==============================] - 1s 265us/sample - loss: 0.5140 - acc: 0.7984 - val_loss: 0.5019 - val_acc: 0.8000\n",
      "Epoch 2/10\n",
      "4250/4250 [==============================] - 1s 261us/sample - loss: 0.5182 - acc: 0.7974 - val_loss: 0.5189 - val_acc: 0.8000\n",
      "Epoch 3/10\n",
      "4250/4250 [==============================] - 1s 226us/sample - loss: 0.5117 - acc: 0.7991 - val_loss: 0.5076 - val_acc: 0.8000\n",
      "Epoch 4/10\n",
      "4250/4250 [==============================] - 1s 262us/sample - loss: 0.5106 - acc: 0.7979 - val_loss: 0.5092 - val_acc: 0.8000\n",
      "Epoch 5/10\n",
      "4250/4250 [==============================] - 1s 290us/sample - loss: 0.5724 - acc: 0.7826 - val_loss: 0.7560 - val_acc: 0.6160\n",
      "Epoch 6/10\n",
      "4250/4250 [==============================] - 1s 248us/sample - loss: 0.9670 - acc: 0.7301 - val_loss: 0.5297 - val_acc: 0.8000\n",
      "Epoch 7/10\n",
      "4250/4250 [==============================] - 1s 187us/sample - loss: 0.5242 - acc: 0.7929 - val_loss: 0.5076 - val_acc: 0.8000\n",
      "Epoch 8/10\n",
      "4250/4250 [==============================] - 1s 217us/sample - loss: 0.5311 - acc: 0.7965 - val_loss: 0.5004 - val_acc: 0.8000\n",
      "Epoch 9/10\n",
      "4250/4250 [==============================] - 1s 223us/sample - loss: 0.5254 - acc: 0.7920 - val_loss: 0.5884 - val_acc: 0.7840\n",
      "Epoch 10/10\n",
      "4250/4250 [==============================] - 1s 234us/sample - loss: 245.8492 - acc: 0.5704 - val_loss: 312.0260 - val_acc: 0.5373\n",
      "Epoch 76 out of 200\n",
      "Train on 4250 samples, validate on 750 samples\n",
      "Epoch 1/10\n",
      "4250/4250 [==============================] - 1s 244us/sample - loss: 2659.1718 - acc: 0.5393 - val_loss: 406.7484 - val_acc: 0.5387\n",
      "Epoch 2/10\n",
      "4250/4250 [==============================] - 1s 212us/sample - loss: 198.4406 - acc: 0.5409 - val_loss: 8.0066 - val_acc: 0.3947\n",
      "Epoch 3/10\n",
      "4250/4250 [==============================] - 1s 223us/sample - loss: 2.4588 - acc: 0.7471 - val_loss: 0.7540 - val_acc: 0.8000\n",
      "Epoch 4/10\n",
      "4250/4250 [==============================] - 1s 225us/sample - loss: 0.7332 - acc: 0.7828 - val_loss: 0.6095 - val_acc: 0.7933\n",
      "Epoch 5/10\n",
      "4250/4250 [==============================] - 1s 265us/sample - loss: 0.6211 - acc: 0.7911 - val_loss: 0.5721 - val_acc: 0.8000\n",
      "Epoch 6/10\n",
      "4250/4250 [==============================] - 1s 209us/sample - loss: 0.5455 - acc: 0.7927 - val_loss: 0.5304 - val_acc: 0.8000\n",
      "Epoch 7/10\n",
      "4250/4250 [==============================] - 1s 202us/sample - loss: 0.5214 - acc: 0.7969 - val_loss: 0.5233 - val_acc: 0.8000\n",
      "Epoch 8/10\n",
      "4250/4250 [==============================] - 1s 222us/sample - loss: 0.5211 - acc: 0.7951 - val_loss: 0.5062 - val_acc: 0.8000\n",
      "Epoch 9/10\n",
      "4250/4250 [==============================] - 1s 242us/sample - loss: 0.5111 - acc: 0.7995 - val_loss: 0.5107 - val_acc: 0.8000\n",
      "Epoch 10/10\n",
      "4250/4250 [==============================] - 1s 272us/sample - loss: 0.5144 - acc: 0.7965 - val_loss: 0.5014 - val_acc: 0.8000\n",
      "Epoch 77 out of 200\n",
      "Train on 4250 samples, validate on 750 samples\n",
      "Epoch 1/10\n",
      "4250/4250 [==============================] - 1s 272us/sample - loss: 0.5065 - acc: 0.7995 - val_loss: 0.4998 - val_acc: 0.8000\n",
      "Epoch 2/10\n",
      "4250/4250 [==============================] - 1s 255us/sample - loss: 0.5168 - acc: 0.7951 - val_loss: 0.5086 - val_acc: 0.8000\n",
      "Epoch 3/10\n",
      "4250/4250 [==============================] - 1s 249us/sample - loss: 0.5226 - acc: 0.7911 - val_loss: 0.5068 - val_acc: 0.8000\n",
      "Epoch 4/10\n",
      "4250/4250 [==============================] - 1s 242us/sample - loss: 0.5169 - acc: 0.7962 - val_loss: 0.5024 - val_acc: 0.8000\n",
      "Epoch 5/10\n",
      "4250/4250 [==============================] - 1s 244us/sample - loss: 0.5187 - acc: 0.7941 - val_loss: 0.5037 - val_acc: 0.8000\n",
      "Epoch 6/10\n",
      "4250/4250 [==============================] - 1s 236us/sample - loss: 0.5258 - acc: 0.7908 - val_loss: 0.5994 - val_acc: 0.7173\n",
      "Epoch 7/10\n",
      "4250/4250 [==============================] - 1s 220us/sample - loss: 0.5526 - acc: 0.7873 - val_loss: 0.5369 - val_acc: 0.7773\n",
      "Epoch 8/10\n",
      "4250/4250 [==============================] - 1s 214us/sample - loss: 0.5307 - acc: 0.7946 - val_loss: 0.5067 - val_acc: 0.8000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/10\n",
      "4250/4250 [==============================] - 1s 207us/sample - loss: 0.5716 - acc: 0.7805 - val_loss: 0.5101 - val_acc: 0.8000\n",
      "Epoch 10/10\n",
      "4250/4250 [==============================] - 1s 217us/sample - loss: 0.5319 - acc: 0.7913 - val_loss: 0.6771 - val_acc: 0.6733\n",
      "Epoch 78 out of 200\n",
      "Train on 4250 samples, validate on 750 samples\n",
      "Epoch 1/10\n",
      "4250/4250 [==============================] - 1s 243us/sample - loss: 462.9027 - acc: 0.5849 - val_loss: 3682.0627 - val_acc: 0.5360\n",
      "Epoch 2/10\n",
      "4250/4250 [==============================] - 1s 197us/sample - loss: 1557.5444 - acc: 0.5496 - val_loss: 65.3426 - val_acc: 0.5480\n",
      "Epoch 3/10\n",
      "4250/4250 [==============================] - 1s 234us/sample - loss: 16.8960 - acc: 0.6744 - val_loss: 0.9101 - val_acc: 0.8000\n",
      "Epoch 4/10\n",
      "4250/4250 [==============================] - 1s 221us/sample - loss: 0.6778 - acc: 0.7882 - val_loss: 0.6396 - val_acc: 0.8000\n",
      "Epoch 5/10\n",
      "4250/4250 [==============================] - 1s 219us/sample - loss: 0.5629 - acc: 0.7953 - val_loss: 0.5276 - val_acc: 0.8000\n",
      "Epoch 6/10\n",
      "4250/4250 [==============================] - 1s 227us/sample - loss: 0.5258 - acc: 0.7955 - val_loss: 0.5218 - val_acc: 0.8000\n",
      "Epoch 7/10\n",
      "4250/4250 [==============================] - 1s 247us/sample - loss: 0.5192 - acc: 0.7986 - val_loss: 0.5080 - val_acc: 0.8000\n",
      "Epoch 8/10\n",
      "4250/4250 [==============================] - 1s 208us/sample - loss: 0.5093 - acc: 0.7986 - val_loss: 0.5026 - val_acc: 0.8000\n",
      "Epoch 9/10\n",
      "4250/4250 [==============================] - 1s 209us/sample - loss: 0.5192 - acc: 0.7979 - val_loss: 0.5029 - val_acc: 0.8000\n",
      "Epoch 10/10\n",
      "4250/4250 [==============================] - 1s 200us/sample - loss: 0.5274 - acc: 0.7913 - val_loss: 0.5294 - val_acc: 0.7813\n",
      "Epoch 79 out of 200\n",
      "Train on 4250 samples, validate on 750 samples\n",
      "Epoch 1/10\n",
      "4250/4250 [==============================] - 1s 203us/sample - loss: 0.5225 - acc: 0.7960 - val_loss: 0.5210 - val_acc: 0.7960\n",
      "Epoch 2/10\n",
      "4250/4250 [==============================] - 1s 202us/sample - loss: 0.5137 - acc: 0.7965 - val_loss: 0.5020 - val_acc: 0.8000\n",
      "Epoch 3/10\n",
      "4250/4250 [==============================] - 1s 223us/sample - loss: 0.5170 - acc: 0.7972 - val_loss: 0.5169 - val_acc: 0.7987\n",
      "Epoch 4/10\n",
      "4250/4250 [==============================] - 1s 215us/sample - loss: 0.5090 - acc: 0.7993 - val_loss: 0.5005 - val_acc: 0.8000\n",
      "Epoch 5/10\n",
      "4250/4250 [==============================] - 1s 224us/sample - loss: 0.5126 - acc: 0.7986 - val_loss: 0.5003 - val_acc: 0.8000\n",
      "Epoch 6/10\n",
      "4250/4250 [==============================] - 1s 214us/sample - loss: 0.5173 - acc: 0.7960 - val_loss: 0.6792 - val_acc: 0.6507\n",
      "Epoch 7/10\n",
      "4250/4250 [==============================] - 1s 223us/sample - loss: 64.3144 - acc: 0.6654 - val_loss: 3.4786 - val_acc: 0.6773\n",
      "Epoch 8/10\n",
      "4250/4250 [==============================] - 1s 220us/sample - loss: 184.5701 - acc: 0.5358 - val_loss: 1733.0328 - val_acc: 0.4600\n",
      "Epoch 9/10\n",
      "4250/4250 [==============================] - 1s 232us/sample - loss: 1291.3167 - acc: 0.5501 - val_loss: 109.6595 - val_acc: 0.5413\n",
      "Epoch 10/10\n",
      "4250/4250 [==============================] - 1s 198us/sample - loss: 36.0583 - acc: 0.6929 - val_loss: 0.7821 - val_acc: 0.8000\n",
      "Epoch 80 out of 200\n",
      "Train on 4250 samples, validate on 750 samples\n",
      "Epoch 1/10\n",
      "4250/4250 [==============================] - 1s 218us/sample - loss: 0.7508 - acc: 0.7849 - val_loss: 0.7121 - val_acc: 0.7720\n",
      "Epoch 2/10\n",
      "4250/4250 [==============================] - 1s 215us/sample - loss: 0.6269 - acc: 0.7889 - val_loss: 0.5616 - val_acc: 0.8000\n",
      "Epoch 3/10\n",
      "4250/4250 [==============================] - 1s 214us/sample - loss: 0.5651 - acc: 0.7906 - val_loss: 0.5331 - val_acc: 0.8000\n",
      "Epoch 4/10\n",
      "4250/4250 [==============================] - 1s 226us/sample - loss: 0.5268 - acc: 0.7967 - val_loss: 0.5058 - val_acc: 0.8000\n",
      "Epoch 5/10\n",
      "4250/4250 [==============================] - 1s 229us/sample - loss: 0.5206 - acc: 0.7969 - val_loss: 0.5069 - val_acc: 0.8000\n",
      "Epoch 6/10\n",
      "4250/4250 [==============================] - 1s 214us/sample - loss: 0.5290 - acc: 0.7864 - val_loss: 0.7369 - val_acc: 0.7573\n",
      "Epoch 7/10\n",
      "4250/4250 [==============================] - 1s 227us/sample - loss: 0.5465 - acc: 0.7901 - val_loss: 0.4998 - val_acc: 0.8000\n",
      "Epoch 8/10\n",
      "4250/4250 [==============================] - 1s 228us/sample - loss: 0.6759 - acc: 0.7727 - val_loss: 0.5695 - val_acc: 0.7253\n",
      "Epoch 9/10\n",
      "4250/4250 [==============================] - 1s 231us/sample - loss: 0.5862 - acc: 0.7776 - val_loss: 0.5721 - val_acc: 0.7227\n",
      "Epoch 10/10\n",
      "4250/4250 [==============================] - 1s 231us/sample - loss: 0.6327 - acc: 0.7767 - val_loss: 0.5071 - val_acc: 0.8000\n",
      "Epoch 81 out of 200\n",
      "Train on 4250 samples, validate on 750 samples\n",
      "Epoch 1/10\n",
      "4250/4250 [==============================] - 1s 223us/sample - loss: 0.5189 - acc: 0.7965 - val_loss: 0.5046 - val_acc: 0.8000\n",
      "Epoch 2/10\n",
      "4250/4250 [==============================] - 1s 208us/sample - loss: 0.5329 - acc: 0.7939 - val_loss: 0.5932 - val_acc: 0.8000\n",
      "Epoch 3/10\n",
      "4250/4250 [==============================] - 1s 225us/sample - loss: 1.3031 - acc: 0.7614 - val_loss: 1.4492 - val_acc: 0.6720\n",
      "Epoch 4/10\n",
      "4250/4250 [==============================] - 1s 213us/sample - loss: 646.5671 - acc: 0.5336 - val_loss: 187.7733 - val_acc: 0.5480\n",
      "Epoch 5/10\n",
      "4250/4250 [==============================] - 1s 206us/sample - loss: 643.1778 - acc: 0.5435 - val_loss: 44.9580 - val_acc: 0.5547\n",
      "Epoch 6/10\n",
      "4250/4250 [==============================] - 1s 177us/sample - loss: 60.4154 - acc: 0.5769 - val_loss: 17.0878 - val_acc: 0.5880\n",
      "Epoch 7/10\n",
      "4250/4250 [==============================] - 1s 211us/sample - loss: 3.2377 - acc: 0.7409 - val_loss: 0.7214 - val_acc: 0.8000\n",
      "Epoch 8/10\n",
      "4250/4250 [==============================] - 1s 220us/sample - loss: 0.7163 - acc: 0.7824 - val_loss: 0.8245 - val_acc: 0.8000\n",
      "Epoch 9/10\n",
      "4250/4250 [==============================] - 1s 218us/sample - loss: 0.6917 - acc: 0.7805 - val_loss: 0.5520 - val_acc: 0.8000\n",
      "Epoch 10/10\n",
      "4250/4250 [==============================] - 1s 266us/sample - loss: 0.5595 - acc: 0.7920 - val_loss: 0.5259 - val_acc: 0.8000\n",
      "Epoch 82 out of 200\n",
      "Train on 4250 samples, validate on 750 samples\n",
      "Epoch 1/10\n",
      "4250/4250 [==============================] - 1s 269us/sample - loss: 0.5208 - acc: 0.7967 - val_loss: 0.5132 - val_acc: 0.8000\n",
      "Epoch 2/10\n",
      "4250/4250 [==============================] - 1s 214us/sample - loss: 0.5392 - acc: 0.7882 - val_loss: 0.5135 - val_acc: 0.8000\n",
      "Epoch 3/10\n",
      "4250/4250 [==============================] - 1s 226us/sample - loss: 0.5134 - acc: 0.7969 - val_loss: 0.5209 - val_acc: 0.8000\n",
      "Epoch 4/10\n",
      "4250/4250 [==============================] - 1s 250us/sample - loss: 0.5213 - acc: 0.7951 - val_loss: 0.5559 - val_acc: 0.7533\n",
      "Epoch 5/10\n",
      "4250/4250 [==============================] - 1s 208us/sample - loss: 0.5154 - acc: 0.7984 - val_loss: 0.5028 - val_acc: 0.8000\n",
      "Epoch 6/10\n",
      "4250/4250 [==============================] - 1s 253us/sample - loss: 0.5122 - acc: 0.7979 - val_loss: 0.5155 - val_acc: 0.8000\n",
      "Epoch 7/10\n",
      "4250/4250 [==============================] - 1s 251us/sample - loss: 0.5093 - acc: 0.7976 - val_loss: 0.5055 - val_acc: 0.8000\n",
      "Epoch 8/10\n",
      "4250/4250 [==============================] - 1s 273us/sample - loss: 0.6398 - acc: 0.7772 - val_loss: 0.6012 - val_acc: 0.8000\n",
      "Epoch 9/10\n",
      "4250/4250 [==============================] - 1s 284us/sample - loss: 2771.4442 - acc: 0.5393 - val_loss: 873.0467 - val_acc: 0.4533\n",
      "Epoch 10/10\n",
      "4250/4250 [==============================] - 1s 211us/sample - loss: 127.7884 - acc: 0.5685 - val_loss: 29.1737 - val_acc: 0.5640\n",
      "Epoch 83 out of 200\n",
      "Train on 4250 samples, validate on 750 samples\n",
      "Epoch 1/10\n",
      "4250/4250 [==============================] - 1s 223us/sample - loss: 5.2127 - acc: 0.7200 - val_loss: 0.6212 - val_acc: 0.7840\n",
      "Epoch 2/10\n",
      "4250/4250 [==============================] - 1s 205us/sample - loss: 0.5841 - acc: 0.7901 - val_loss: 0.5403 - val_acc: 0.8000\n",
      "Epoch 3/10\n",
      "4250/4250 [==============================] - 1s 226us/sample - loss: 0.5314 - acc: 0.7955 - val_loss: 0.5209 - val_acc: 0.8000\n",
      "Epoch 4/10\n",
      "4250/4250 [==============================] - 1s 240us/sample - loss: 0.5120 - acc: 0.7993 - val_loss: 0.5059 - val_acc: 0.8000\n",
      "Epoch 5/10\n",
      "4250/4250 [==============================] - 1s 260us/sample - loss: 0.5103 - acc: 0.7979 - val_loss: 0.5039 - val_acc: 0.8000\n",
      "Epoch 6/10\n",
      "4250/4250 [==============================] - 1s 220us/sample - loss: 0.5054 - acc: 0.7998 - val_loss: 0.5073 - val_acc: 0.8000\n",
      "Epoch 7/10\n",
      "4250/4250 [==============================] - 1s 268us/sample - loss: 0.5405 - acc: 0.7906 - val_loss: 0.5036 - val_acc: 0.8000\n",
      "Epoch 8/10\n",
      "4250/4250 [==============================] - 1s 238us/sample - loss: 0.5103 - acc: 0.7981 - val_loss: 0.5030 - val_acc: 0.8000\n",
      "Epoch 9/10\n",
      "4250/4250 [==============================] - 1s 230us/sample - loss: 0.5067 - acc: 0.8002 - val_loss: 0.5008 - val_acc: 0.8000\n",
      "Epoch 10/10\n",
      "4250/4250 [==============================] - 1s 290us/sample - loss: 0.5114 - acc: 0.7979 - val_loss: 0.5005 - val_acc: 0.8000\n",
      "Epoch 84 out of 200\n",
      "Train on 4250 samples, validate on 750 samples\n",
      "Epoch 1/10\n",
      "4250/4250 [==============================] - 1s 235us/sample - loss: 0.5114 - acc: 0.7960 - val_loss: 0.5257 - val_acc: 0.7827\n",
      "Epoch 2/10\n",
      "4250/4250 [==============================] - 1s 217us/sample - loss: 17.1116 - acc: 0.6638 - val_loss: 19.7566 - val_acc: 0.5600\n",
      "Epoch 3/10\n",
      "4250/4250 [==============================] - 1s 255us/sample - loss: 35.9650 - acc: 0.5751 - val_loss: 11.6528 - val_acc: 0.5720\n",
      "Epoch 4/10\n",
      "4250/4250 [==============================] - 1s 192us/sample - loss: 35.8487 - acc: 0.5845 - val_loss: 20.3247 - val_acc: 0.4333\n",
      "Epoch 5/10\n",
      "4250/4250 [==============================] - ETA: 0s - loss: 361.8317 - acc: 0.553 - 1s 221us/sample - loss: 347.6639 - acc: 0.5518 - val_loss: 204.9185 - val_acc: 0.5413\n",
      "Epoch 6/10\n",
      "4250/4250 [==============================] - 1s 244us/sample - loss: 92.4083 - acc: 0.5894 - val_loss: 46.8676 - val_acc: 0.5640\n",
      "Epoch 7/10\n",
      "4250/4250 [==============================] - 1s 242us/sample - loss: 213.3452 - acc: 0.5678 - val_loss: 1.7084 - val_acc: 0.7707\n",
      "Epoch 8/10\n",
      "4250/4250 [==============================] - 1s 216us/sample - loss: 3.5329 - acc: 0.7296 - val_loss: 1.0826 - val_acc: 0.8000\n",
      "Epoch 9/10\n",
      "4250/4250 [==============================] - 1s 213us/sample - loss: 0.9255 - acc: 0.7800 - val_loss: 1.0256 - val_acc: 0.6640\n",
      "Epoch 10/10\n",
      "4250/4250 [==============================] - 1s 222us/sample - loss: 0.8332 - acc: 0.7762 - val_loss: 0.6756 - val_acc: 0.8000\n",
      "Epoch 85 out of 200\n",
      "Train on 4250 samples, validate on 750 samples\n",
      "Epoch 1/10\n",
      "4250/4250 [==============================] - 1s 217us/sample - loss: 0.6579 - acc: 0.7892 - val_loss: 0.5979 - val_acc: 0.8000\n",
      "Epoch 2/10\n",
      "4250/4250 [==============================] - 1s 216us/sample - loss: 3.5020 - acc: 0.7299 - val_loss: 10.7780 - val_acc: 0.5627\n",
      "Epoch 3/10\n",
      "4250/4250 [==============================] - 1s 221us/sample - loss: 10.0881 - acc: 0.6165 - val_loss: 23.9951 - val_acc: 0.4280\n",
      "Epoch 4/10\n",
      "4250/4250 [==============================] - 1s 200us/sample - loss: 670.6276 - acc: 0.5402 - val_loss: 636.7619 - val_acc: 0.5400\n",
      "Epoch 5/10\n",
      "4250/4250 [==============================] - 1s 214us/sample - loss: 1588.0610 - acc: 0.5386 - val_loss: 655.5507 - val_acc: 0.5427\n",
      "Epoch 6/10\n",
      "4250/4250 [==============================] - 1s 238us/sample - loss: 625.5977 - acc: 0.5553 - val_loss: 342.5171 - val_acc: 0.4507\n",
      "Epoch 7/10\n",
      "4250/4250 [==============================] - 1s 250us/sample - loss: 27.4923 - acc: 0.6941 - val_loss: 0.9348 - val_acc: 0.8000\n",
      "Epoch 8/10\n",
      "4250/4250 [==============================] - 1s 206us/sample - loss: 0.8438 - acc: 0.7816 - val_loss: 0.7343 - val_acc: 0.7920\n",
      "Epoch 9/10\n",
      "4250/4250 [==============================] - 1s 250us/sample - loss: 0.7274 - acc: 0.7868 - val_loss: 0.6263 - val_acc: 0.7853\n",
      "Epoch 10/10\n",
      "4250/4250 [==============================] - 1s 206us/sample - loss: 0.6272 - acc: 0.7864 - val_loss: 0.6041 - val_acc: 0.8000\n",
      "Epoch 86 out of 200\n",
      "Train on 4250 samples, validate on 750 samples\n",
      "Epoch 1/10\n",
      "4250/4250 [==============================] - 1s 223us/sample - loss: 0.5626 - acc: 0.7922 - val_loss: 0.5402 - val_acc: 0.8000\n",
      "Epoch 2/10\n",
      "4250/4250 [==============================] - 1s 223us/sample - loss: 0.5317 - acc: 0.7974 - val_loss: 0.5098 - val_acc: 0.8000\n",
      "Epoch 3/10\n",
      "4250/4250 [==============================] - 1s 213us/sample - loss: 0.5187 - acc: 0.7972 - val_loss: 0.5353 - val_acc: 0.7747\n",
      "Epoch 4/10\n",
      "4250/4250 [==============================] - 1s 219us/sample - loss: 0.5138 - acc: 0.7962 - val_loss: 0.5247 - val_acc: 0.8000\n",
      "Epoch 5/10\n",
      "4250/4250 [==============================] - 1s 233us/sample - loss: 0.5124 - acc: 0.7986 - val_loss: 0.5120 - val_acc: 0.8000\n",
      "Epoch 6/10\n",
      "4250/4250 [==============================] - 1s 206us/sample - loss: 0.5068 - acc: 0.8000 - val_loss: 0.5009 - val_acc: 0.8000\n",
      "Epoch 7/10\n",
      "4250/4250 [==============================] - 1s 243us/sample - loss: 0.5101 - acc: 0.7991 - val_loss: 0.5002 - val_acc: 0.8000\n",
      "Epoch 8/10\n",
      "4250/4250 [==============================] - 1s 221us/sample - loss: 0.5096 - acc: 0.7979 - val_loss: 0.5030 - val_acc: 0.8000\n",
      "Epoch 9/10\n",
      "4250/4250 [==============================] - 1s 282us/sample - loss: 0.5125 - acc: 0.7988 - val_loss: 0.5047 - val_acc: 0.8000\n",
      "Epoch 10/10\n",
      "4250/4250 [==============================] - 1s 254us/sample - loss: 0.5140 - acc: 0.7974 - val_loss: 0.5003 - val_acc: 0.8000\n",
      "Epoch 87 out of 200\n",
      "Train on 4250 samples, validate on 750 samples\n",
      "Epoch 1/10\n",
      "4250/4250 [==============================] - 1s 211us/sample - loss: 0.6386 - acc: 0.7689 - val_loss: 0.5296 - val_acc: 0.8000\n",
      "Epoch 2/10\n",
      "4250/4250 [==============================] - 1s 218us/sample - loss: 0.7495 - acc: 0.7558 - val_loss: 0.5869 - val_acc: 0.8000\n",
      "Epoch 3/10\n",
      "4250/4250 [==============================] - 1s 271us/sample - loss: 0.7649 - acc: 0.7595 - val_loss: 0.5048 - val_acc: 0.8000\n",
      "Epoch 4/10\n",
      "4250/4250 [==============================] - 1s 245us/sample - loss: 10.1230 - acc: 0.6419 - val_loss: 148.6294 - val_acc: 0.5413\n",
      "Epoch 5/10\n",
      "4250/4250 [==============================] - 1s 227us/sample - loss: 487.8130 - acc: 0.5388 - val_loss: 31.1813 - val_acc: 0.4427\n",
      "Epoch 6/10\n",
      "4250/4250 [==============================] - 1s 261us/sample - loss: 1304.8717 - acc: 0.5282 - val_loss: 1862.9084 - val_acc: 0.5373\n",
      "Epoch 7/10\n",
      "4250/4250 [==============================] - ETA: 0s - loss: 1042.1778 - acc: 0.56 - 1s 225us/sample - loss: 1014.2948 - acc: 0.5694 - val_loss: 15.1807 - val_acc: 0.6427\n",
      "Epoch 8/10\n",
      "4250/4250 [==============================] - 1s 192us/sample - loss: 71.6950 - acc: 0.5744 - val_loss: 1.7571 - val_acc: 0.7933\n",
      "Epoch 9/10\n",
      "4250/4250 [==============================] - 1s 189us/sample - loss: 2.1484 - acc: 0.7574 - val_loss: 0.8386 - val_acc: 0.7400\n",
      "Epoch 10/10\n",
      "4250/4250 [==============================] - 1s 196us/sample - loss: 0.7958 - acc: 0.7812 - val_loss: 0.7336 - val_acc: 0.8000\n",
      "Epoch 88 out of 200\n",
      "Train on 4250 samples, validate on 750 samples\n",
      "Epoch 1/10\n",
      "4250/4250 [==============================] - 1s 271us/sample - loss: 0.6992 - acc: 0.7824 - val_loss: 0.6584 - val_acc: 0.8000\n",
      "Epoch 2/10\n",
      "4250/4250 [==============================] - 1s 227us/sample - loss: 0.6415 - acc: 0.7821 - val_loss: 0.5367 - val_acc: 0.8000\n",
      "Epoch 3/10\n",
      "4250/4250 [==============================] - 1s 254us/sample - loss: 0.5512 - acc: 0.7946 - val_loss: 0.5333 - val_acc: 0.8000\n",
      "Epoch 4/10\n",
      "4250/4250 [==============================] - 1s 250us/sample - loss: 0.5252 - acc: 0.7960 - val_loss: 0.5261 - val_acc: 0.7947\n",
      "Epoch 5/10\n",
      "4250/4250 [==============================] - 1s 232us/sample - loss: 0.5148 - acc: 0.7988 - val_loss: 0.5028 - val_acc: 0.8000\n",
      "Epoch 6/10\n",
      "4250/4250 [==============================] - 1s 219us/sample - loss: 0.5459 - acc: 0.7849 - val_loss: 0.5347 - val_acc: 0.7747\n",
      "Epoch 7/10\n",
      "4250/4250 [==============================] - 1s 246us/sample - loss: 0.5255 - acc: 0.7988 - val_loss: 0.5007 - val_acc: 0.8000\n",
      "Epoch 8/10\n",
      "4250/4250 [==============================] - 1s 233us/sample - loss: 0.5782 - acc: 0.7788 - val_loss: 0.5556 - val_acc: 0.8000\n",
      "Epoch 9/10\n",
      "4250/4250 [==============================] - 1s 210us/sample - loss: 0.5560 - acc: 0.7831 - val_loss: 0.5115 - val_acc: 0.8000\n",
      "Epoch 10/10\n",
      "4250/4250 [==============================] - 1s 268us/sample - loss: 0.5343 - acc: 0.7922 - val_loss: 0.5158 - val_acc: 0.8000\n",
      "Epoch 89 out of 200\n",
      "Train on 4250 samples, validate on 750 samples\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4250/4250 [==============================] - 1s 259us/sample - loss: 0.5134 - acc: 0.7965 - val_loss: 0.5013 - val_acc: 0.8000\n",
      "Epoch 2/10\n",
      "4250/4250 [==============================] - 1s 269us/sample - loss: 0.5237 - acc: 0.7932 - val_loss: 0.5123 - val_acc: 0.8000\n",
      "Epoch 3/10\n",
      "4250/4250 [==============================] - 1s 239us/sample - loss: 0.5350 - acc: 0.7904 - val_loss: 0.5638 - val_acc: 0.8000\n",
      "Epoch 4/10\n",
      "4250/4250 [==============================] - 1s 239us/sample - loss: 0.5593 - acc: 0.7831 - val_loss: 0.5171 - val_acc: 0.7947\n",
      "Epoch 5/10\n",
      "4250/4250 [==============================] - 1s 235us/sample - loss: 0.9050 - acc: 0.7273 - val_loss: 0.5281 - val_acc: 0.7920\n",
      "Epoch 6/10\n",
      "4250/4250 [==============================] - 1s 220us/sample - loss: 52.0087 - acc: 0.5939 - val_loss: 24.3646 - val_acc: 0.5693\n",
      "Epoch 7/10\n",
      "4250/4250 [==============================] - 1s 259us/sample - loss: 1877.3406 - acc: 0.5522 - val_loss: 373.8162 - val_acc: 0.4387\n",
      "Epoch 8/10\n",
      "4250/4250 [==============================] - 1s 294us/sample - loss: 281.1536 - acc: 0.6198 - val_loss: 0.7191 - val_acc: 0.7987\n",
      "Epoch 9/10\n",
      "4250/4250 [==============================] - 1s 247us/sample - loss: 0.7172 - acc: 0.7821 - val_loss: 0.6064 - val_acc: 0.8000\n",
      "Epoch 10/10\n",
      "4250/4250 [==============================] - 1s 250us/sample - loss: 0.5763 - acc: 0.7906 - val_loss: 0.5323 - val_acc: 0.8000\n",
      "Epoch 90 out of 200\n",
      "Train on 4250 samples, validate on 750 samples\n",
      "Epoch 1/10\n",
      "4250/4250 [==============================] - 1s 270us/sample - loss: 0.5471 - acc: 0.7960 - val_loss: 0.5096 - val_acc: 0.8000\n",
      "Epoch 2/10\n",
      "4250/4250 [==============================] - 1s 225us/sample - loss: 0.5121 - acc: 0.7998 - val_loss: 0.5156 - val_acc: 0.8000\n",
      "Epoch 3/10\n",
      "4250/4250 [==============================] - 1s 238us/sample - loss: 0.5105 - acc: 0.7998 - val_loss: 0.5128 - val_acc: 0.8000\n",
      "Epoch 4/10\n",
      "4250/4250 [==============================] - 1s 222us/sample - loss: 0.5164 - acc: 0.7972 - val_loss: 0.5008 - val_acc: 0.8000\n",
      "Epoch 5/10\n",
      "4250/4250 [==============================] - 1s 219us/sample - loss: 0.5105 - acc: 0.7976 - val_loss: 0.5123 - val_acc: 0.8000\n",
      "Epoch 6/10\n",
      "4250/4250 [==============================] - 1s 226us/sample - loss: 0.5119 - acc: 0.7972 - val_loss: 0.5035 - val_acc: 0.8000\n",
      "Epoch 7/10\n",
      "4250/4250 [==============================] - 1s 232us/sample - loss: 0.5105 - acc: 0.7984 - val_loss: 0.5367 - val_acc: 0.7667\n",
      "Epoch 8/10\n",
      "4250/4250 [==============================] - 1s 259us/sample - loss: 0.5277 - acc: 0.7906 - val_loss: 0.5034 - val_acc: 0.8000\n",
      "Epoch 9/10\n",
      "4250/4250 [==============================] - 1s 236us/sample - loss: 0.5249 - acc: 0.7925 - val_loss: 0.5339 - val_acc: 0.7947\n",
      "Epoch 10/10\n",
      "4250/4250 [==============================] - 1s 289us/sample - loss: 0.5226 - acc: 0.7958 - val_loss: 0.5081 - val_acc: 0.8000\n",
      "Epoch 91 out of 200\n",
      "Train on 4250 samples, validate on 750 samples\n",
      "Epoch 1/10\n",
      "4250/4250 [==============================] - 1s 225us/sample - loss: 0.5388 - acc: 0.7878 - val_loss: 0.5018 - val_acc: 0.8000\n",
      "Epoch 2/10\n",
      "4250/4250 [==============================] - 1s 295us/sample - loss: 0.5324 - acc: 0.7920 - val_loss: 0.5151 - val_acc: 0.8000\n",
      "Epoch 3/10\n",
      "4250/4250 [==============================] - 1s 315us/sample - loss: 0.5243 - acc: 0.7960 - val_loss: 0.5788 - val_acc: 0.7800\n",
      "Epoch 4/10\n",
      "4250/4250 [==============================] - 1s 256us/sample - loss: 0.5907 - acc: 0.7793 - val_loss: 0.5110 - val_acc: 0.8000\n",
      "Epoch 5/10\n",
      "4250/4250 [==============================] - 2s 440us/sample - loss: 0.7360 - acc: 0.7506 - val_loss: 0.5421 - val_acc: 0.8000\n",
      "Epoch 6/10\n",
      "4250/4250 [==============================] - 1s 260us/sample - loss: 934.4158 - acc: 0.5922 - val_loss: 4334.1954 - val_acc: 0.5373\n",
      "Epoch 7/10\n",
      "4250/4250 [==============================] - 1s 344us/sample - loss: 1061.5449 - acc: 0.5553 - val_loss: 44.2104 - val_acc: 0.5547\n",
      "Epoch 8/10\n",
      "4250/4250 [==============================] - 1s 329us/sample - loss: 31.0893 - acc: 0.6280 - val_loss: 1.0346 - val_acc: 0.8000\n",
      "Epoch 9/10\n",
      "4250/4250 [==============================] - 1s 245us/sample - loss: 0.9030 - acc: 0.7654 - val_loss: 0.6570 - val_acc: 0.8000\n",
      "Epoch 10/10\n",
      "4250/4250 [==============================] - 1s 240us/sample - loss: 0.6347 - acc: 0.7882 - val_loss: 0.5575 - val_acc: 0.8000\n",
      "Epoch 92 out of 200\n",
      "Train on 4250 samples, validate on 750 samples\n",
      "Epoch 1/10\n",
      "4250/4250 [==============================] - 1s 240us/sample - loss: 0.5674 - acc: 0.7894 - val_loss: 0.5142 - val_acc: 0.8000\n",
      "Epoch 2/10\n",
      "4250/4250 [==============================] - 1s 212us/sample - loss: 0.5176 - acc: 0.7991 - val_loss: 0.5387 - val_acc: 0.7973\n",
      "Epoch 3/10\n",
      "4250/4250 [==============================] - 1s 216us/sample - loss: 0.5274 - acc: 0.7955 - val_loss: 0.5084 - val_acc: 0.8000\n",
      "Epoch 4/10\n",
      "4250/4250 [==============================] - 1s 192us/sample - loss: 0.5294 - acc: 0.7936 - val_loss: 0.5059 - val_acc: 0.8000\n",
      "Epoch 5/10\n",
      "4250/4250 [==============================] - 1s 194us/sample - loss: 0.5455 - acc: 0.7885 - val_loss: 0.5262 - val_acc: 0.8000\n",
      "Epoch 6/10\n",
      "4250/4250 [==============================] - 1s 235us/sample - loss: 0.6215 - acc: 0.7704 - val_loss: 0.5239 - val_acc: 0.8000\n",
      "Epoch 7/10\n",
      "4250/4250 [==============================] - 1s 243us/sample - loss: 0.6058 - acc: 0.7704 - val_loss: 0.5371 - val_acc: 0.7827\n",
      "Epoch 8/10\n",
      "4250/4250 [==============================] - 1s 282us/sample - loss: 0.5963 - acc: 0.7748 - val_loss: 0.5493 - val_acc: 0.7733\n",
      "Epoch 9/10\n",
      "4250/4250 [==============================] - 1s 210us/sample - loss: 1700.8410 - acc: 0.5880 - val_loss: 1106.6836 - val_acc: 0.5387\n",
      "Epoch 10/10\n",
      "4250/4250 [==============================] - 1s 252us/sample - loss: 454.2576 - acc: 0.5452 - val_loss: 247.2932 - val_acc: 0.5400\n",
      "Epoch 93 out of 200\n",
      "Train on 4250 samples, validate on 750 samples\n",
      "Epoch 1/10\n",
      "4250/4250 [==============================] - 1s 225us/sample - loss: 41.9809 - acc: 0.6475 - val_loss: 0.8729 - val_acc: 0.8000\n",
      "Epoch 2/10\n",
      "4250/4250 [==============================] - 1s 222us/sample - loss: 0.7981 - acc: 0.7734 - val_loss: 0.5891 - val_acc: 0.8000\n",
      "Epoch 3/10\n",
      "4250/4250 [==============================] - 1s 200us/sample - loss: 0.5823 - acc: 0.7934 - val_loss: 0.5625 - val_acc: 0.7960\n",
      "Epoch 4/10\n",
      "4250/4250 [==============================] - 1s 186us/sample - loss: 0.5307 - acc: 0.7960 - val_loss: 0.5085 - val_acc: 0.8000\n",
      "Epoch 5/10\n",
      "4250/4250 [==============================] - 1s 263us/sample - loss: 0.5322 - acc: 0.7962 - val_loss: 0.5070 - val_acc: 0.8000\n",
      "Epoch 6/10\n",
      "4250/4250 [==============================] - 1s 285us/sample - loss: 0.5151 - acc: 0.7988 - val_loss: 0.5038 - val_acc: 0.8000\n",
      "Epoch 7/10\n",
      "4250/4250 [==============================] - 1s 220us/sample - loss: 0.5112 - acc: 0.7981 - val_loss: 0.5268 - val_acc: 0.8000\n",
      "Epoch 8/10\n",
      "4250/4250 [==============================] - 1s 235us/sample - loss: 0.5193 - acc: 0.7913 - val_loss: 0.5121 - val_acc: 0.8000\n",
      "Epoch 9/10\n",
      "4250/4250 [==============================] - 1s 240us/sample - loss: 0.5226 - acc: 0.7932 - val_loss: 0.5117 - val_acc: 0.8000\n",
      "Epoch 10/10\n",
      "4250/4250 [==============================] - ETA: 0s - loss: 0.5268 - acc: 0.792 - 1s 264us/sample - loss: 0.5275 - acc: 0.7920 - val_loss: 0.5028 - val_acc: 0.8000\n",
      "Epoch 94 out of 200\n",
      "Train on 4250 samples, validate on 750 samples\n",
      "Epoch 1/10\n",
      "4250/4250 [==============================] - 1s 325us/sample - loss: 0.5400 - acc: 0.7899 - val_loss: 0.5194 - val_acc: 0.7867\n",
      "Epoch 2/10\n",
      "4250/4250 [==============================] - 1s 232us/sample - loss: 0.5664 - acc: 0.7814 - val_loss: 0.5481 - val_acc: 0.7533\n",
      "Epoch 3/10\n",
      "4250/4250 [==============================] - 1s 213us/sample - loss: 0.7210 - acc: 0.7544 - val_loss: 1.5769 - val_acc: 0.7213\n",
      "Epoch 4/10\n",
      "4250/4250 [==============================] - 1s 323us/sample - loss: 0.6367 - acc: 0.7741 - val_loss: 0.5104 - val_acc: 0.8000\n",
      "Epoch 5/10\n",
      "4250/4250 [==============================] - 1s 299us/sample - loss: 0.5497 - acc: 0.7868 - val_loss: 0.5536 - val_acc: 0.8000\n",
      "Epoch 6/10\n",
      "4250/4250 [==============================] - 1s 296us/sample - loss: 0.6608 - acc: 0.7616 - val_loss: 0.8247 - val_acc: 0.6027\n",
      "Epoch 7/10\n",
      "4250/4250 [==============================] - 1s 316us/sample - loss: 250.3052 - acc: 0.6134 - val_loss: 507.4221 - val_acc: 0.5413\n",
      "Epoch 8/10\n",
      "4250/4250 [==============================] - 1s 296us/sample - loss: 1747.2806 - acc: 0.5400 - val_loss: 1337.2321 - val_acc: 0.5400\n",
      "Epoch 9/10\n",
      "4250/4250 [==============================] - 1s 254us/sample - loss: 778.6125 - acc: 0.5489 - val_loss: 60.5627 - val_acc: 0.5627\n",
      "Epoch 10/10\n",
      "4250/4250 [==============================] - 1s 236us/sample - loss: 29.1170 - acc: 0.6259 - val_loss: 2.9318 - val_acc: 0.5280\n",
      "Epoch 95 out of 200\n",
      "Train on 4250 samples, validate on 750 samples\n",
      "Epoch 1/10\n",
      "4250/4250 [==============================] - 1s 258us/sample - loss: 1.2724 - acc: 0.7713 - val_loss: 0.7388 - val_acc: 0.8000\n",
      "Epoch 2/10\n",
      "4250/4250 [==============================] - 1s 235us/sample - loss: 0.6754 - acc: 0.7880 - val_loss: 0.6477 - val_acc: 0.7533\n",
      "Epoch 3/10\n",
      "4250/4250 [==============================] - 1s 249us/sample - loss: 0.5936 - acc: 0.7906 - val_loss: 0.5572 - val_acc: 0.8000\n",
      "Epoch 4/10\n",
      "4250/4250 [==============================] - 1s 227us/sample - loss: 0.5666 - acc: 0.7896 - val_loss: 0.9757 - val_acc: 0.7387\n",
      "Epoch 5/10\n",
      "4250/4250 [==============================] - 1s 230us/sample - loss: 0.6072 - acc: 0.7791 - val_loss: 0.5058 - val_acc: 0.8000\n",
      "Epoch 6/10\n",
      "4250/4250 [==============================] - 1s 233us/sample - loss: 0.5120 - acc: 0.7972 - val_loss: 0.5534 - val_acc: 0.7587\n",
      "Epoch 7/10\n",
      "4250/4250 [==============================] - 1s 246us/sample - loss: 0.5181 - acc: 0.7967 - val_loss: 0.5013 - val_acc: 0.8000\n",
      "Epoch 8/10\n",
      "4250/4250 [==============================] - 1s 243us/sample - loss: 0.5128 - acc: 0.7974 - val_loss: 0.5029 - val_acc: 0.8000\n",
      "Epoch 9/10\n",
      "4250/4250 [==============================] - 1s 265us/sample - loss: 0.5097 - acc: 0.7991 - val_loss: 0.5036 - val_acc: 0.8000\n",
      "Epoch 10/10\n",
      "4250/4250 [==============================] - 1s 219us/sample - loss: 0.5146 - acc: 0.7972 - val_loss: 0.5028 - val_acc: 0.8000\n",
      "Epoch 96 out of 200\n",
      "Train on 4250 samples, validate on 750 samples\n",
      "Epoch 1/10\n",
      "4250/4250 [==============================] - 1s 269us/sample - loss: 0.5093 - acc: 0.7991 - val_loss: 0.5030 - val_acc: 0.8000\n",
      "Epoch 2/10\n",
      "4250/4250 [==============================] - 1s 228us/sample - loss: 0.5106 - acc: 0.7981 - val_loss: 0.5057 - val_acc: 0.8000\n",
      "Epoch 3/10\n",
      "4250/4250 [==============================] - 1s 258us/sample - loss: 0.5125 - acc: 0.7998 - val_loss: 0.5266 - val_acc: 0.8000\n",
      "Epoch 4/10\n",
      "4250/4250 [==============================] - 1s 255us/sample - loss: 0.5336 - acc: 0.7915 - val_loss: 0.5638 - val_acc: 0.7640\n",
      "Epoch 5/10\n",
      "4250/4250 [==============================] - 1s 242us/sample - loss: 0.9697 - acc: 0.7391 - val_loss: 4.0513 - val_acc: 0.4253\n",
      "Epoch 6/10\n",
      "4250/4250 [==============================] - 1s 252us/sample - loss: 183.1049 - acc: 0.5784 - val_loss: 132.9189 - val_acc: 0.5400\n",
      "Epoch 7/10\n",
      "4250/4250 [==============================] - 1s 278us/sample - loss: 39.4639 - acc: 0.5784 - val_loss: 7.3164 - val_acc: 0.6240\n",
      "Epoch 8/10\n",
      "4250/4250 [==============================] - 1s 244us/sample - loss: 1217.1947 - acc: 0.5301 - val_loss: 1142.5501 - val_acc: 0.5373\n",
      "Epoch 9/10\n",
      "4250/4250 [==============================] - 1s 243us/sample - loss: 357.2992 - acc: 0.6016 - val_loss: 1.5488 - val_acc: 0.8000\n",
      "Epoch 10/10\n",
      "4250/4250 [==============================] - 1s 247us/sample - loss: 1.1925 - acc: 0.7605 - val_loss: 0.7882 - val_acc: 0.7373\n",
      "Epoch 97 out of 200\n",
      "Train on 4250 samples, validate on 750 samples\n",
      "Epoch 1/10\n",
      "4250/4250 [==============================] - 1s 255us/sample - loss: 0.7146 - acc: 0.7826 - val_loss: 0.6092 - val_acc: 0.8000\n",
      "Epoch 2/10\n",
      "4250/4250 [==============================] - 1s 242us/sample - loss: 0.6750 - acc: 0.7767 - val_loss: 0.5916 - val_acc: 0.7947\n",
      "Epoch 3/10\n",
      "4250/4250 [==============================] - 1s 241us/sample - loss: 0.5663 - acc: 0.7899 - val_loss: 0.5354 - val_acc: 0.8000\n",
      "Epoch 4/10\n",
      "4250/4250 [==============================] - 1s 269us/sample - loss: 0.5455 - acc: 0.7927 - val_loss: 0.5203 - val_acc: 0.8000\n",
      "Epoch 5/10\n",
      "4250/4250 [==============================] - 1s 282us/sample - loss: 0.5266 - acc: 0.7936 - val_loss: 0.5134 - val_acc: 0.8000\n",
      "Epoch 6/10\n",
      "4250/4250 [==============================] - 1s 243us/sample - loss: 0.5317 - acc: 0.7927 - val_loss: 0.5184 - val_acc: 0.8000\n",
      "Epoch 7/10\n",
      "4250/4250 [==============================] - 1s 239us/sample - loss: 0.5141 - acc: 0.7972 - val_loss: 0.5202 - val_acc: 0.7987\n",
      "Epoch 8/10\n",
      "4250/4250 [==============================] - 1s 256us/sample - loss: 0.5680 - acc: 0.7861 - val_loss: 0.5012 - val_acc: 0.8000\n",
      "Epoch 9/10\n",
      "4250/4250 [==============================] - 1s 260us/sample - loss: 0.5407 - acc: 0.7849 - val_loss: 0.5269 - val_acc: 0.8000\n",
      "Epoch 10/10\n",
      "4250/4250 [==============================] - 1s 259us/sample - loss: 0.5621 - acc: 0.7819 - val_loss: 0.5019 - val_acc: 0.8000\n",
      "Epoch 98 out of 200\n",
      "Train on 4250 samples, validate on 750 samples\n",
      "Epoch 1/10\n",
      "4250/4250 [==============================] - 1s 287us/sample - loss: 0.5547 - acc: 0.7854 - val_loss: 0.5127 - val_acc: 0.8000\n",
      "Epoch 2/10\n",
      "4250/4250 [==============================] - 1s 248us/sample - loss: 0.6158 - acc: 0.7659 - val_loss: 0.5675 - val_acc: 0.7720\n",
      "Epoch 3/10\n",
      "4250/4250 [==============================] - 1s 244us/sample - loss: 0.5294 - acc: 0.7932 - val_loss: 0.5367 - val_acc: 0.8000\n",
      "Epoch 4/10\n",
      "4250/4250 [==============================] - 1s 248us/sample - loss: 50.7504 - acc: 0.6200 - val_loss: 111.2158 - val_acc: 0.4307\n",
      "Epoch 5/10\n",
      "4250/4250 [==============================] - 1s 234us/sample - loss: 2330.5138 - acc: 0.5212 - val_loss: 76.6795 - val_acc: 0.5787\n",
      "Epoch 6/10\n",
      "4250/4250 [==============================] - 1s 232us/sample - loss: 709.6187 - acc: 0.5478 - val_loss: 121.1504 - val_acc: 0.4413\n",
      "Epoch 7/10\n",
      "4250/4250 [==============================] - 1s 217us/sample - loss: 65.0609 - acc: 0.6252 - val_loss: 2.6611 - val_acc: 0.7787\n",
      "Epoch 8/10\n",
      "4250/4250 [==============================] - 1s 230us/sample - loss: 0.9644 - acc: 0.7800 - val_loss: 0.6916 - val_acc: 0.7813\n",
      "Epoch 9/10\n",
      "4250/4250 [==============================] - 1s 202us/sample - loss: 0.7298 - acc: 0.7805 - val_loss: 0.6401 - val_acc: 0.8000\n",
      "Epoch 10/10\n",
      "4250/4250 [==============================] - 1s 192us/sample - loss: 0.6154 - acc: 0.7880 - val_loss: 0.5375 - val_acc: 0.7987\n",
      "Epoch 99 out of 200\n",
      "Train on 4250 samples, validate on 750 samples\n",
      "Epoch 1/10\n",
      "4250/4250 [==============================] - 1s 229us/sample - loss: 0.5470 - acc: 0.7934 - val_loss: 0.5139 - val_acc: 0.8000\n",
      "Epoch 2/10\n",
      "4250/4250 [==============================] - 1s 208us/sample - loss: 0.5320 - acc: 0.7946 - val_loss: 0.5074 - val_acc: 0.8000\n",
      "Epoch 3/10\n",
      "4250/4250 [==============================] - 1s 218us/sample - loss: 0.5331 - acc: 0.7915 - val_loss: 0.5251 - val_acc: 0.8000\n",
      "Epoch 4/10\n",
      "4250/4250 [==============================] - 1s 220us/sample - loss: 0.5124 - acc: 0.7995 - val_loss: 0.5031 - val_acc: 0.8000\n",
      "Epoch 5/10\n",
      "4250/4250 [==============================] - 1s 204us/sample - loss: 0.5954 - acc: 0.7725 - val_loss: 0.5447 - val_acc: 0.7560\n",
      "Epoch 6/10\n",
      "4250/4250 [==============================] - 1s 207us/sample - loss: 0.5225 - acc: 0.7934 - val_loss: 0.5091 - val_acc: 0.8000\n",
      "Epoch 7/10\n",
      "4250/4250 [==============================] - 1s 223us/sample - loss: 0.5109 - acc: 0.7967 - val_loss: 0.5014 - val_acc: 0.8000\n",
      "Epoch 8/10\n",
      "4250/4250 [==============================] - 1s 202us/sample - loss: 0.5080 - acc: 0.7981 - val_loss: 0.5005 - val_acc: 0.8000\n",
      "Epoch 9/10\n",
      "4250/4250 [==============================] - 1s 239us/sample - loss: 0.5290 - acc: 0.7939 - val_loss: 0.5043 - val_acc: 0.8000\n",
      "Epoch 10/10\n",
      "4250/4250 [==============================] - 1s 247us/sample - loss: 0.5253 - acc: 0.7927 - val_loss: 0.5072 - val_acc: 0.8000\n",
      "Epoch 100 out of 200\n",
      "Train on 4250 samples, validate on 750 samples\n",
      "Epoch 1/10\n",
      "4250/4250 [==============================] - 1s 205us/sample - loss: 0.5554 - acc: 0.7854 - val_loss: 0.5534 - val_acc: 0.7920\n",
      "Epoch 2/10\n",
      "4250/4250 [==============================] - 1s 233us/sample - loss: 0.5889 - acc: 0.7805 - val_loss: 0.5115 - val_acc: 0.8000\n",
      "Epoch 3/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4250/4250 [==============================] - 1s 235us/sample - loss: 1.1453 - acc: 0.7478 - val_loss: 25.8287 - val_acc: 0.4387\n",
      "Epoch 4/10\n",
      "4250/4250 [==============================] - 1s 203us/sample - loss: 3091.3646 - acc: 0.5365 - val_loss: 6606.3235 - val_acc: 0.5360\n",
      "Epoch 5/10\n",
      "4250/4250 [==============================] - 1s 248us/sample - loss: 920.8454 - acc: 0.5548 - val_loss: 17.2502 - val_acc: 0.5840\n",
      "Epoch 6/10\n",
      "4250/4250 [==============================] - 1s 216us/sample - loss: 21.7134 - acc: 0.6125 - val_loss: 1.3139 - val_acc: 0.8000\n",
      "Epoch 7/10\n",
      "4250/4250 [==============================] - 1s 253us/sample - loss: 1.1227 - acc: 0.7725 - val_loss: 0.7653 - val_acc: 0.8000\n",
      "Epoch 8/10\n",
      "4250/4250 [==============================] - 1s 232us/sample - loss: 0.6339 - acc: 0.7908 - val_loss: 0.5919 - val_acc: 0.8000\n",
      "Epoch 9/10\n",
      "4250/4250 [==============================] - 1s 247us/sample - loss: 0.5628 - acc: 0.7953 - val_loss: 0.6019 - val_acc: 0.7533\n",
      "Epoch 10/10\n",
      "4250/4250 [==============================] - 1s 211us/sample - loss: 0.5264 - acc: 0.7958 - val_loss: 0.5165 - val_acc: 0.8000\n",
      "Epoch 101 out of 200\n",
      "Train on 4250 samples, validate on 750 samples\n",
      "Epoch 1/10\n",
      "4250/4250 [==============================] - 1s 253us/sample - loss: 0.5111 - acc: 0.7993 - val_loss: 0.5253 - val_acc: 0.8000\n",
      "Epoch 2/10\n",
      "4250/4250 [==============================] - 1s 236us/sample - loss: 0.5085 - acc: 0.7998 - val_loss: 0.5263 - val_acc: 0.7960\n",
      "Epoch 3/10\n",
      "4250/4250 [==============================] - 1s 239us/sample - loss: 0.5098 - acc: 0.7993 - val_loss: 0.5003 - val_acc: 0.8000\n",
      "Epoch 4/10\n",
      "4250/4250 [==============================] - 1s 223us/sample - loss: 0.5131 - acc: 0.7972 - val_loss: 0.5404 - val_acc: 0.7787\n",
      "Epoch 5/10\n",
      "4250/4250 [==============================] - 1s 236us/sample - loss: 0.5353 - acc: 0.7922 - val_loss: 0.5167 - val_acc: 0.8000\n",
      "Epoch 6/10\n",
      "4250/4250 [==============================] - 1s 252us/sample - loss: 0.5286 - acc: 0.7894 - val_loss: 0.5001 - val_acc: 0.8000\n",
      "Epoch 7/10\n",
      "4250/4250 [==============================] - 1s 258us/sample - loss: 0.5156 - acc: 0.7995 - val_loss: 0.5000 - val_acc: 0.8000\n",
      "Epoch 8/10\n",
      "4250/4250 [==============================] - 1s 233us/sample - loss: 0.5081 - acc: 0.7988 - val_loss: 0.5275 - val_acc: 0.7840\n",
      "Epoch 9/10\n",
      "4250/4250 [==============================] - 1s 223us/sample - loss: 0.5138 - acc: 0.7974 - val_loss: 0.5251 - val_acc: 0.7947\n",
      "Epoch 10/10\n",
      "4250/4250 [==============================] - 1s 228us/sample - loss: 0.5289 - acc: 0.7899 - val_loss: 0.5141 - val_acc: 0.8000\n",
      "Epoch 102 out of 200\n",
      "Train on 4250 samples, validate on 750 samples\n",
      "Epoch 1/10\n",
      "4250/4250 [==============================] - 1s 228us/sample - loss: 0.5463 - acc: 0.7864 - val_loss: 0.5005 - val_acc: 0.8000\n",
      "Epoch 2/10\n",
      "4250/4250 [==============================] - 1s 264us/sample - loss: 0.5147 - acc: 0.7946 - val_loss: 0.5312 - val_acc: 0.8000\n",
      "Epoch 3/10\n",
      "4250/4250 [==============================] - 1s 221us/sample - loss: 0.5265 - acc: 0.7920 - val_loss: 0.5029 - val_acc: 0.8000\n",
      "Epoch 4/10\n",
      "4250/4250 [==============================] - 1s 209us/sample - loss: 2.3619 - acc: 0.7005 - val_loss: 3.0072 - val_acc: 0.6520\n",
      "Epoch 5/10\n",
      "4250/4250 [==============================] - 1s 279us/sample - loss: 98.4860 - acc: 0.5551 - val_loss: 27.4682 - val_acc: 0.5573\n",
      "Epoch 6/10\n",
      "4250/4250 [==============================] - 1s 241us/sample - loss: 502.1631 - acc: 0.5416 - val_loss: 141.3964 - val_acc: 0.4480\n",
      "Epoch 7/10\n",
      "4250/4250 [==============================] - 1s 257us/sample - loss: 140.1963 - acc: 0.5581 - val_loss: 447.0065 - val_acc: 0.5360\n",
      "Epoch 8/10\n",
      "4250/4250 [==============================] - 1s 250us/sample - loss: 114.3737 - acc: 0.6334 - val_loss: 2.4141 - val_acc: 0.7920\n",
      "Epoch 9/10\n",
      "4250/4250 [==============================] - 1s 251us/sample - loss: 1.2703 - acc: 0.7628 - val_loss: 1.0940 - val_acc: 0.8000\n",
      "Epoch 10/10\n",
      "4250/4250 [==============================] - 1s 243us/sample - loss: 0.8458 - acc: 0.7798 - val_loss: 0.6391 - val_acc: 0.7987\n",
      "Epoch 103 out of 200\n",
      "Train on 4250 samples, validate on 750 samples\n",
      "Epoch 1/10\n",
      "4250/4250 [==============================] - 1s 247us/sample - loss: 0.6789 - acc: 0.7838 - val_loss: 0.5662 - val_acc: 0.8000\n",
      "Epoch 2/10\n",
      "4250/4250 [==============================] - 1s 236us/sample - loss: 0.6050 - acc: 0.7861 - val_loss: 0.5522 - val_acc: 0.8000\n",
      "Epoch 3/10\n",
      "4250/4250 [==============================] - 1s 264us/sample - loss: 0.5960 - acc: 0.7838 - val_loss: 0.5655 - val_acc: 0.7587\n",
      "Epoch 4/10\n",
      "4250/4250 [==============================] - 1s 257us/sample - loss: 0.5251 - acc: 0.7951 - val_loss: 0.5272 - val_acc: 0.8000\n",
      "Epoch 5/10\n",
      "4250/4250 [==============================] - 1s 243us/sample - loss: 0.7144 - acc: 0.7649 - val_loss: 0.8617 - val_acc: 0.5733\n",
      "Epoch 6/10\n",
      "4250/4250 [==============================] - 1s 238us/sample - loss: 1939.1861 - acc: 0.5635 - val_loss: 2662.7957 - val_acc: 0.5373\n",
      "Epoch 7/10\n",
      "4250/4250 [==============================] - 1s 246us/sample - loss: 670.3187 - acc: 0.5489 - val_loss: 97.7409 - val_acc: 0.5507\n",
      "Epoch 8/10\n",
      "4250/4250 [==============================] - 1s 241us/sample - loss: 6.8945 - acc: 0.7332 - val_loss: 0.6802 - val_acc: 0.8000\n",
      "Epoch 9/10\n",
      "4250/4250 [==============================] - 1s 242us/sample - loss: 0.5870 - acc: 0.7936 - val_loss: 0.5295 - val_acc: 0.8000\n",
      "Epoch 10/10\n",
      "4250/4250 [==============================] - 1s 246us/sample - loss: 0.5455 - acc: 0.7929 - val_loss: 0.5436 - val_acc: 0.7987\n",
      "Epoch 104 out of 200\n",
      "Train on 4250 samples, validate on 750 samples\n",
      "Epoch 1/10\n",
      "4250/4250 [==============================] - 1s 239us/sample - loss: 0.5135 - acc: 0.7991 - val_loss: 0.5083 - val_acc: 0.8000\n",
      "Epoch 2/10\n",
      "4250/4250 [==============================] - 1s 224us/sample - loss: 0.5142 - acc: 0.7984 - val_loss: 0.5192 - val_acc: 0.7933\n",
      "Epoch 3/10\n",
      "4250/4250 [==============================] - 1s 235us/sample - loss: 0.5090 - acc: 0.7984 - val_loss: 0.5048 - val_acc: 0.8000\n",
      "Epoch 4/10\n",
      "4250/4250 [==============================] - 1s 243us/sample - loss: 0.5079 - acc: 0.7991 - val_loss: 0.5005 - val_acc: 0.8000\n",
      "Epoch 5/10\n",
      "4250/4250 [==============================] - 1s 230us/sample - loss: 0.5058 - acc: 0.7993 - val_loss: 0.5075 - val_acc: 0.8000\n",
      "Epoch 6/10\n",
      "4250/4250 [==============================] - 1s 250us/sample - loss: 0.5109 - acc: 0.7960 - val_loss: 0.5000 - val_acc: 0.8000\n",
      "Epoch 7/10\n",
      "4250/4250 [==============================] - 1s 237us/sample - loss: 0.5155 - acc: 0.7958 - val_loss: 0.5015 - val_acc: 0.8000\n",
      "Epoch 8/10\n",
      "4250/4250 [==============================] - 1s 253us/sample - loss: 0.5103 - acc: 0.7998 - val_loss: 0.5102 - val_acc: 0.8000\n",
      "Epoch 9/10\n",
      "4250/4250 [==============================] - 1s 243us/sample - loss: 0.5118 - acc: 0.7991 - val_loss: 0.5177 - val_acc: 0.8000\n",
      "Epoch 10/10\n",
      "4250/4250 [==============================] - 1s 253us/sample - loss: 0.6214 - acc: 0.7708 - val_loss: 0.7857 - val_acc: 0.7747\n",
      "Epoch 105 out of 200\n",
      "Train on 4250 samples, validate on 750 samples\n",
      "Epoch 1/10\n",
      "4250/4250 [==============================] - 1s 235us/sample - loss: 7.1155 - acc: 0.6567 - val_loss: 1.0247 - val_acc: 0.7600\n",
      "Epoch 2/10\n",
      "4250/4250 [==============================] - 1s 217us/sample - loss: 609.3063 - acc: 0.6033 - val_loss: 122.7866 - val_acc: 0.5400\n",
      "Epoch 3/10\n",
      "4250/4250 [==============================] - 1s 257us/sample - loss: 381.4514 - acc: 0.5471 - val_loss: 297.3033 - val_acc: 0.4507\n",
      "Epoch 4/10\n",
      "4250/4250 [==============================] - 1s 214us/sample - loss: 200.2378 - acc: 0.5668 - val_loss: 10.2337 - val_acc: 0.6173\n",
      "Epoch 5/10\n",
      "4250/4250 [==============================] - 1s 227us/sample - loss: 18.6277 - acc: 0.6292 - val_loss: 1.5612 - val_acc: 0.6093\n",
      "Epoch 6/10\n",
      "4250/4250 [==============================] - 1s 217us/sample - loss: 1.0141 - acc: 0.7685 - val_loss: 1.1121 - val_acc: 0.8000\n",
      "Epoch 7/10\n",
      "4250/4250 [==============================] - 1s 265us/sample - loss: 0.7362 - acc: 0.7833 - val_loss: 0.6155 - val_acc: 0.8000\n",
      "Epoch 8/10\n",
      "4250/4250 [==============================] - 1s 223us/sample - loss: 0.6181 - acc: 0.7866 - val_loss: 0.5512 - val_acc: 0.8000\n",
      "Epoch 9/10\n",
      "4250/4250 [==============================] - 1s 229us/sample - loss: 0.5642 - acc: 0.7901 - val_loss: 0.5180 - val_acc: 0.8000\n",
      "Epoch 10/10\n",
      "4250/4250 [==============================] - 1s 258us/sample - loss: 0.5277 - acc: 0.7960 - val_loss: 0.5167 - val_acc: 0.8000\n",
      "Epoch 106 out of 200\n",
      "Train on 4250 samples, validate on 750 samples\n",
      "Epoch 1/10\n",
      "4250/4250 [==============================] - 1s 237us/sample - loss: 0.5232 - acc: 0.7939 - val_loss: 0.5030 - val_acc: 0.8000\n",
      "Epoch 2/10\n",
      "4250/4250 [==============================] - 1s 215us/sample - loss: 0.5169 - acc: 0.7951 - val_loss: 0.5148 - val_acc: 0.8000\n",
      "Epoch 3/10\n",
      "4250/4250 [==============================] - 1s 229us/sample - loss: 0.5266 - acc: 0.7944 - val_loss: 0.5094 - val_acc: 0.8000\n",
      "Epoch 4/10\n",
      "4250/4250 [==============================] - 1s 243us/sample - loss: 0.6159 - acc: 0.7786 - val_loss: 1.3641 - val_acc: 0.4920\n",
      "Epoch 5/10\n",
      "4250/4250 [==============================] - 1s 244us/sample - loss: 0.7418 - acc: 0.7536 - val_loss: 0.7322 - val_acc: 0.6200\n",
      "Epoch 6/10\n",
      "4250/4250 [==============================] - 1s 236us/sample - loss: 136.0824 - acc: 0.5774 - val_loss: 4.7019 - val_acc: 0.6333\n",
      "Epoch 7/10\n",
      "4250/4250 [==============================] - 1s 242us/sample - loss: 1500.6047 - acc: 0.5315 - val_loss: 378.4925 - val_acc: 0.5400\n",
      "Epoch 8/10\n",
      "4250/4250 [==============================] - 1s 221us/sample - loss: 370.1407 - acc: 0.5522 - val_loss: 144.7026 - val_acc: 0.5440\n",
      "Epoch 9/10\n",
      "4250/4250 [==============================] - 1s 213us/sample - loss: 22.6718 - acc: 0.6416 - val_loss: 3.6703 - val_acc: 0.7373\n",
      "Epoch 10/10\n",
      "4250/4250 [==============================] - 1s 238us/sample - loss: 11.6392 - acc: 0.6624 - val_loss: 1.4425 - val_acc: 0.8000\n",
      "Epoch 107 out of 200\n",
      "Train on 4250 samples, validate on 750 samples\n",
      "Epoch 1/10\n",
      "4250/4250 [==============================] - 1s 270us/sample - loss: 0.8944 - acc: 0.7751 - val_loss: 0.6656 - val_acc: 0.7947 0.8999 - acc: 0\n",
      "Epoch 2/10\n",
      "4250/4250 [==============================] - 1s 258us/sample - loss: 0.6730 - acc: 0.7861 - val_loss: 0.6319 - val_acc: 0.8000\n",
      "Epoch 3/10\n",
      "4250/4250 [==============================] - 1s 246us/sample - loss: 0.6401 - acc: 0.7776 - val_loss: 0.6195 - val_acc: 0.8000\n",
      "Epoch 4/10\n",
      "4250/4250 [==============================] - 1s 224us/sample - loss: 0.5378 - acc: 0.7965 - val_loss: 0.5174 - val_acc: 0.8000\n",
      "Epoch 5/10\n",
      "4250/4250 [==============================] - 1s 225us/sample - loss: 0.5346 - acc: 0.7904 - val_loss: 0.5060 - val_acc: 0.8000\n",
      "Epoch 6/10\n",
      "4250/4250 [==============================] - 1s 249us/sample - loss: 0.5119 - acc: 0.7993 - val_loss: 0.5163 - val_acc: 0.8000\n",
      "Epoch 7/10\n",
      "4250/4250 [==============================] - 1s 220us/sample - loss: 0.5141 - acc: 0.7965 - val_loss: 0.5017 - val_acc: 0.8000\n",
      "Epoch 8/10\n",
      "4250/4250 [==============================] - 1s 227us/sample - loss: 0.6595 - acc: 0.7668 - val_loss: 0.7113 - val_acc: 0.7960\n",
      "Epoch 9/10\n",
      "4250/4250 [==============================] - 1s 238us/sample - loss: 0.5872 - acc: 0.7868 - val_loss: 0.5122 - val_acc: 0.8000\n",
      "Epoch 10/10\n",
      "4250/4250 [==============================] - 1s 237us/sample - loss: 0.5300 - acc: 0.7913 - val_loss: 0.5016 - val_acc: 0.8000\n",
      "Epoch 108 out of 200\n",
      "Train on 4250 samples, validate on 750 samples\n",
      "Epoch 1/10\n",
      "4250/4250 [==============================] - 1s 278us/sample - loss: 0.5195 - acc: 0.7951 - val_loss: 0.5146 - val_acc: 0.8000\n",
      "Epoch 2/10\n",
      "4250/4250 [==============================] - 1s 244us/sample - loss: 0.5227 - acc: 0.7946 - val_loss: 0.5381 - val_acc: 0.8000\n",
      "Epoch 3/10\n",
      "4250/4250 [==============================] - 1s 233us/sample - loss: 0.5918 - acc: 0.7767 - val_loss: 0.6103 - val_acc: 0.7960\n",
      "Epoch 4/10\n",
      "4250/4250 [==============================] - 1s 275us/sample - loss: 103.0907 - acc: 0.6955 - val_loss: 1057.9438 - val_acc: 0.5387\n",
      "Epoch 5/10\n",
      "4250/4250 [==============================] - 1s 252us/sample - loss: 700.1296 - acc: 0.5384 - val_loss: 77.7892 - val_acc: 0.5453\n",
      "Epoch 6/10\n",
      "4250/4250 [==============================] - 1s 189us/sample - loss: 259.3140 - acc: 0.5419 - val_loss: 347.4200 - val_acc: 0.4560\n",
      "Epoch 7/10\n",
      "4250/4250 [==============================] - 1s 231us/sample - loss: 138.8236 - acc: 0.5758 - val_loss: 2.6233 - val_acc: 0.7853\n",
      "Epoch 8/10\n",
      "4250/4250 [==============================] - 1s 200us/sample - loss: 2.2830 - acc: 0.7513 - val_loss: 0.7722 - val_acc: 0.8000\n",
      "Epoch 9/10\n",
      "4250/4250 [==============================] - 1s 184us/sample - loss: 0.7715 - acc: 0.7812 - val_loss: 0.6651 - val_acc: 0.7640\n",
      "Epoch 10/10\n",
      "4250/4250 [==============================] - 1s 229us/sample - loss: 0.6510 - acc: 0.7861 - val_loss: 0.6292 - val_acc: 0.8000\n",
      "Epoch 109 out of 200\n",
      "Train on 4250 samples, validate on 750 samples\n",
      "Epoch 1/10\n",
      "4250/4250 [==============================] - 1s 177us/sample - loss: 0.5732 - acc: 0.7892 - val_loss: 0.5171 - val_acc: 0.8000\n",
      "Epoch 2/10\n",
      "4250/4250 [==============================] - 1s 245us/sample - loss: 0.5331 - acc: 0.7944 - val_loss: 0.5210 - val_acc: 0.8000\n",
      "Epoch 3/10\n",
      "4250/4250 [==============================] - 1s 211us/sample - loss: 0.5174 - acc: 0.7979 - val_loss: 0.5009 - val_acc: 0.8000\n",
      "Epoch 4/10\n",
      "4250/4250 [==============================] - 1s 189us/sample - loss: 0.5222 - acc: 0.7960 - val_loss: 0.5115 - val_acc: 0.8000\n",
      "Epoch 5/10\n",
      "4250/4250 [==============================] - 1s 196us/sample - loss: 0.5604 - acc: 0.7892 - val_loss: 0.5001 - val_acc: 0.8000\n",
      "Epoch 6/10\n",
      "4250/4250 [==============================] - 1s 209us/sample - loss: 0.6045 - acc: 0.7824 - val_loss: 0.5133 - val_acc: 0.8000\n",
      "Epoch 7/10\n",
      "4250/4250 [==============================] - 1s 198us/sample - loss: 0.5442 - acc: 0.7875 - val_loss: 0.5112 - val_acc: 0.8000\n",
      "Epoch 8/10\n",
      "4250/4250 [==============================] - 1s 222us/sample - loss: 0.5130 - acc: 0.7988 - val_loss: 0.5035 - val_acc: 0.8000\n",
      "Epoch 9/10\n",
      "4250/4250 [==============================] - 1s 228us/sample - loss: 0.5151 - acc: 0.7958 - val_loss: 0.5063 - val_acc: 0.8000\n",
      "Epoch 10/10\n",
      "4250/4250 [==============================] - 1s 200us/sample - loss: 2.6602 - acc: 0.7021 - val_loss: 15.4743 - val_acc: 0.5453\n",
      "Epoch 110 out of 200\n",
      "Train on 4250 samples, validate on 750 samples\n",
      "Epoch 1/10\n",
      "4250/4250 [==============================] - 1s 274us/sample - loss: 1280.5218 - acc: 0.5424 - val_loss: 1078.9995 - val_acc: 0.5360\n",
      "Epoch 2/10\n",
      "4250/4250 [==============================] - 1s 240us/sample - loss: 855.1270 - acc: 0.5480 - val_loss: 1.0483 - val_acc: 0.8000\n",
      "Epoch 3/10\n",
      "4250/4250 [==============================] - 1s 246us/sample - loss: 1.7781 - acc: 0.7499 - val_loss: 0.7385 - val_acc: 0.8000\n",
      "Epoch 4/10\n",
      "4250/4250 [==============================] - 1s 223us/sample - loss: 0.6520 - acc: 0.7856 - val_loss: 0.5656 - val_acc: 0.8000\n",
      "Epoch 5/10\n",
      "4250/4250 [==============================] - 1s 250us/sample - loss: 0.5596 - acc: 0.7906 - val_loss: 0.5283 - val_acc: 0.8000\n",
      "Epoch 6/10\n",
      "4250/4250 [==============================] - 1s 220us/sample - loss: 0.5170 - acc: 0.7981 - val_loss: 0.5076 - val_acc: 0.8000\n",
      "Epoch 7/10\n",
      "4250/4250 [==============================] - 1s 204us/sample - loss: 0.5154 - acc: 0.7953 - val_loss: 0.5068 - val_acc: 0.8000\n",
      "Epoch 8/10\n",
      "4250/4250 [==============================] - 1s 237us/sample - loss: 0.5113 - acc: 0.7958 - val_loss: 0.5007 - val_acc: 0.8000\n",
      "Epoch 9/10\n",
      "4250/4250 [==============================] - 1s 231us/sample - loss: 0.5137 - acc: 0.7965 - val_loss: 0.5007 - val_acc: 0.8000\n",
      "Epoch 10/10\n",
      "4250/4250 [==============================] - 1s 225us/sample - loss: 0.5194 - acc: 0.7941 - val_loss: 0.5021 - val_acc: 0.8000\n",
      "Epoch 111 out of 200\n",
      "Train on 4250 samples, validate on 750 samples\n",
      "Epoch 1/10\n",
      "4250/4250 [==============================] - 1s 239us/sample - loss: 0.5164 - acc: 0.7979 - val_loss: 0.5030 - val_acc: 0.8000\n",
      "Epoch 2/10\n",
      "4250/4250 [==============================] - 1s 241us/sample - loss: 0.5065 - acc: 0.8000 - val_loss: 0.5295 - val_acc: 0.8000\n",
      "Epoch 3/10\n",
      "4250/4250 [==============================] - 1s 214us/sample - loss: 0.5292 - acc: 0.7889 - val_loss: 0.6178 - val_acc: 0.6813\n",
      "Epoch 4/10\n",
      "4250/4250 [==============================] - 1s 242us/sample - loss: 0.5305 - acc: 0.7920 - val_loss: 0.5009 - val_acc: 0.8000\n",
      "Epoch 5/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4250/4250 [==============================] - 1s 243us/sample - loss: 0.5349 - acc: 0.7960 - val_loss: 0.5388 - val_acc: 0.8000\n",
      "Epoch 6/10\n",
      "4250/4250 [==============================] - 1s 218us/sample - loss: 0.5172 - acc: 0.7951 - val_loss: 0.5117 - val_acc: 0.8000\n",
      "Epoch 7/10\n",
      "4250/4250 [==============================] - 1s 231us/sample - loss: 0.5225 - acc: 0.7944 - val_loss: 0.5580 - val_acc: 0.8000\n",
      "Epoch 8/10\n",
      "4250/4250 [==============================] - 1s 209us/sample - loss: 6.8055 - acc: 0.6788 - val_loss: 7.8168 - val_acc: 0.5480\n",
      "Epoch 9/10\n",
      "4250/4250 [==============================] - 1s 240us/sample - loss: 920.9237 - acc: 0.5353 - val_loss: 383.8130 - val_acc: 0.5360\n",
      "Epoch 10/10\n",
      "4250/4250 [==============================] - 1s 262us/sample - loss: 270.0135 - acc: 0.5614 - val_loss: 12.2060 - val_acc: 0.6187\n",
      "Epoch 112 out of 200\n",
      "Train on 4250 samples, validate on 750 samples\n",
      "Epoch 1/10\n",
      "4250/4250 [==============================] - 1s 271us/sample - loss: 54.9659 - acc: 0.5984 - val_loss: 1.2804 - val_acc: 0.6480\n",
      "Epoch 2/10\n",
      "4250/4250 [==============================] - 1s 261us/sample - loss: 1.1220 - acc: 0.7758 - val_loss: 0.6908 - val_acc: 0.7813\n",
      "Epoch 3/10\n",
      "4250/4250 [==============================] - 1s 262us/sample - loss: 0.7170 - acc: 0.7835 - val_loss: 0.5962 - val_acc: 0.7933\n",
      "Epoch 4/10\n",
      "4250/4250 [==============================] - 1s 266us/sample - loss: 0.6064 - acc: 0.7915 - val_loss: 0.5381 - val_acc: 0.8000\n",
      "Epoch 5/10\n",
      "4250/4250 [==============================] - 1s 233us/sample - loss: 0.5419 - acc: 0.7946 - val_loss: 0.5249 - val_acc: 0.8000\n",
      "Epoch 6/10\n",
      "4250/4250 [==============================] - 1s 223us/sample - loss: 0.5221 - acc: 0.7967 - val_loss: 0.5028 - val_acc: 0.8000\n",
      "Epoch 7/10\n",
      "4250/4250 [==============================] - 1s 221us/sample - loss: 0.5076 - acc: 0.7993 - val_loss: 0.5016 - val_acc: 0.8000\n",
      "Epoch 8/10\n",
      "4250/4250 [==============================] - 1s 252us/sample - loss: 0.5286 - acc: 0.7927 - val_loss: 0.5281 - val_acc: 0.7840\n",
      "Epoch 9/10\n",
      "4250/4250 [==============================] - 1s 241us/sample - loss: 0.5431 - acc: 0.7913 - val_loss: 0.5011 - val_acc: 0.8000\n",
      "Epoch 10/10\n",
      "4250/4250 [==============================] - 1s 210us/sample - loss: 0.5370 - acc: 0.7896 - val_loss: 0.4997 - val_acc: 0.8000\n",
      "Epoch 113 out of 200\n",
      "Train on 4250 samples, validate on 750 samples\n",
      "Epoch 1/10\n",
      "4250/4250 [==============================] - 1s 245us/sample - loss: 0.5271 - acc: 0.7944 - val_loss: 0.5198 - val_acc: 0.7947\n",
      "Epoch 2/10\n",
      "4250/4250 [==============================] - 1s 184us/sample - loss: 0.5604 - acc: 0.7842 - val_loss: 0.5069 - val_acc: 0.8000\n",
      "Epoch 3/10\n",
      "4250/4250 [==============================] - 1s 189us/sample - loss: 1.7406 - acc: 0.7614 - val_loss: 13.9491 - val_acc: 0.4320\n",
      "Epoch 4/10\n",
      "4250/4250 [==============================] - 1s 175us/sample - loss: 554.6091 - acc: 0.5419 - val_loss: 32.5136 - val_acc: 0.5653\n",
      "Epoch 5/10\n",
      "4250/4250 [==============================] - 1s 183us/sample - loss: 494.1854 - acc: 0.5369 - val_loss: 108.1087 - val_acc: 0.5400\n",
      "Epoch 6/10\n",
      "4250/4250 [==============================] - 1s 178us/sample - loss: 16.0072 - acc: 0.6892 - val_loss: 0.6975 - val_acc: 0.7693\n",
      "Epoch 7/10\n",
      "4250/4250 [==============================] - 1s 181us/sample - loss: 0.6777 - acc: 0.7880 - val_loss: 0.6177 - val_acc: 0.8000\n",
      "Epoch 8/10\n",
      "4250/4250 [==============================] - 1s 180us/sample - loss: 0.5902 - acc: 0.7906 - val_loss: 0.5691 - val_acc: 0.8000\n",
      "Epoch 9/10\n",
      "4250/4250 [==============================] - 1s 196us/sample - loss: 0.5560 - acc: 0.7887 - val_loss: 0.5323 - val_acc: 0.8000\n",
      "Epoch 10/10\n",
      "4250/4250 [==============================] - 1s 194us/sample - loss: 0.5234 - acc: 0.7951 - val_loss: 0.5203 - val_acc: 0.8000\n",
      "Epoch 114 out of 200\n",
      "Train on 4250 samples, validate on 750 samples\n",
      "Epoch 1/10\n",
      "4250/4250 [==============================] - 1s 201us/sample - loss: 0.5201 - acc: 0.7948 - val_loss: 0.5130 - val_acc: 0.8000\n",
      "Epoch 2/10\n",
      "4250/4250 [==============================] - 1s 226us/sample - loss: 0.5085 - acc: 0.7981 - val_loss: 0.5034 - val_acc: 0.8000\n",
      "Epoch 3/10\n",
      "4250/4250 [==============================] - 1s 209us/sample - loss: 0.5053 - acc: 0.8000 - val_loss: 0.5000 - val_acc: 0.8000\n",
      "Epoch 4/10\n",
      "4250/4250 [==============================] - 1s 193us/sample - loss: 0.5112 - acc: 0.7988 - val_loss: 0.5346 - val_acc: 0.7760\n",
      "Epoch 5/10\n",
      "4250/4250 [==============================] - 1s 197us/sample - loss: 2.5047 - acc: 0.7393 - val_loss: 3.2575 - val_acc: 0.6400\n",
      "Epoch 6/10\n",
      "4250/4250 [==============================] - 1s 178us/sample - loss: 702.5744 - acc: 0.5701 - val_loss: 653.9321 - val_acc: 0.5427\n",
      "Epoch 7/10\n",
      "4250/4250 [==============================] - 1s 232us/sample - loss: 1161.0338 - acc: 0.5386 - val_loss: 260.9211 - val_acc: 0.5573\n",
      "Epoch 8/10\n",
      "4250/4250 [==============================] - 1s 223us/sample - loss: 78.8120 - acc: 0.5986 - val_loss: 2.4801 - val_acc: 0.7747\n",
      "Epoch 9/10\n",
      "4250/4250 [==============================] - 1s 210us/sample - loss: 1.6968 - acc: 0.7598 - val_loss: 0.6241 - val_acc: 0.8000\n",
      "Epoch 10/10\n",
      "4250/4250 [==============================] - 1s 216us/sample - loss: 0.6846 - acc: 0.7821 - val_loss: 0.6043 - val_acc: 0.8000\n",
      "Epoch 115 out of 200\n",
      "Train on 4250 samples, validate on 750 samples\n",
      "Epoch 1/10\n",
      "4250/4250 [==============================] - 1s 257us/sample - loss: 0.5835 - acc: 0.7889 - val_loss: 0.5270 - val_acc: 0.8000\n",
      "Epoch 2/10\n",
      "4250/4250 [==============================] - 1s 238us/sample - loss: 0.5214 - acc: 0.7955 - val_loss: 0.5427 - val_acc: 0.8000\n",
      "Epoch 3/10\n",
      "4250/4250 [==============================] - 1s 227us/sample - loss: 0.5137 - acc: 0.7984 - val_loss: 0.5107 - val_acc: 0.8000\n",
      "Epoch 4/10\n",
      "4250/4250 [==============================] - 1s 204us/sample - loss: 0.5107 - acc: 0.7965 - val_loss: 0.5068 - val_acc: 0.8000\n",
      "Epoch 5/10\n",
      "4250/4250 [==============================] - 1s 252us/sample - loss: 0.5065 - acc: 0.7995 - val_loss: 0.5070 - val_acc: 0.8000\n",
      "Epoch 6/10\n",
      "4250/4250 [==============================] - 1s 220us/sample - loss: 0.5165 - acc: 0.7939 - val_loss: 0.5024 - val_acc: 0.8000\n",
      "Epoch 7/10\n",
      "4250/4250 [==============================] - 1s 229us/sample - loss: 0.5163 - acc: 0.7953 - val_loss: 0.5052 - val_acc: 0.8000\n",
      "Epoch 8/10\n",
      "4250/4250 [==============================] - 1s 230us/sample - loss: 0.5196 - acc: 0.7913 - val_loss: 0.5010 - val_acc: 0.8000\n",
      "Epoch 9/10\n",
      "4250/4250 [==============================] - 1s 225us/sample - loss: 0.5148 - acc: 0.7958 - val_loss: 0.5139 - val_acc: 0.8000\n",
      "Epoch 10/10\n",
      "4250/4250 [==============================] - 1s 223us/sample - loss: 0.5679 - acc: 0.7774 - val_loss: 0.5817 - val_acc: 0.8000\n",
      "Epoch 116 out of 200\n",
      "Train on 4250 samples, validate on 750 samples\n",
      "Epoch 1/10\n",
      "4250/4250 [==============================] - 1s 236us/sample - loss: 0.5582 - acc: 0.7826 - val_loss: 0.5094 - val_acc: 0.8000\n",
      "Epoch 2/10\n",
      "4250/4250 [==============================] - 1s 214us/sample - loss: 0.5380 - acc: 0.7885 - val_loss: 0.5063 - val_acc: 0.8000\n",
      "Epoch 3/10\n",
      "4250/4250 [==============================] - 1s 229us/sample - loss: 0.5593 - acc: 0.7849 - val_loss: 0.5002 - val_acc: 0.8000\n",
      "Epoch 4/10\n",
      "4250/4250 [==============================] - 1s 247us/sample - loss: 0.5318 - acc: 0.7889 - val_loss: 0.5033 - val_acc: 0.8000\n",
      "Epoch 5/10\n",
      "4250/4250 [==============================] - 1s 249us/sample - loss: 0.6082 - acc: 0.7753 - val_loss: 0.5354 - val_acc: 0.8000\n",
      "Epoch 6/10\n",
      "4250/4250 [==============================] - 1s 246us/sample - loss: 289.5764 - acc: 0.6369 - val_loss: 1027.7731 - val_acc: 0.5400\n",
      "Epoch 7/10\n",
      "4250/4250 [==============================] - 1s 231us/sample - loss: 765.5810 - acc: 0.5466 - val_loss: 870.8378 - val_acc: 0.4613\n",
      "Epoch 8/10\n",
      "4250/4250 [==============================] - 1s 233us/sample - loss: 72.3632 - acc: 0.6652 - val_loss: 8.5416 - val_acc: 0.4293\n",
      "Epoch 9/10\n",
      "4250/4250 [==============================] - 1s 229us/sample - loss: 130.2694 - acc: 0.6353 - val_loss: 232.0806 - val_acc: 0.5467\n",
      "Epoch 10/10\n",
      "4250/4250 [==============================] - 1s 226us/sample - loss: 741.8651 - acc: 0.5407 - val_loss: 174.2469 - val_acc: 0.5400\n",
      "Epoch 117 out of 200\n",
      "Train on 4250 samples, validate on 750 samples\n",
      "Epoch 1/10\n",
      "4250/4250 [==============================] - 1s 237us/sample - loss: 197.8194 - acc: 0.5247 - val_loss: 310.1183 - val_acc: 0.5413\n",
      "Epoch 2/10\n",
      "4250/4250 [==============================] - 1s 245us/sample - loss: 67.8532 - acc: 0.6144 - val_loss: 1.1408 - val_acc: 0.7347\n",
      "Epoch 3/10\n",
      "4250/4250 [==============================] - 1s 236us/sample - loss: 1.3164 - acc: 0.7666 - val_loss: 0.8712 - val_acc: 0.7667\n",
      "Epoch 4/10\n",
      "4250/4250 [==============================] - 1s 241us/sample - loss: 0.8635 - acc: 0.7791 - val_loss: 0.9054 - val_acc: 0.8000\n",
      "Epoch 5/10\n",
      "4250/4250 [==============================] - 1s 221us/sample - loss: 0.7417 - acc: 0.7816 - val_loss: 0.6689 - val_acc: 0.8000\n",
      "Epoch 6/10\n",
      "4250/4250 [==============================] - 1s 240us/sample - loss: 0.6444 - acc: 0.7852 - val_loss: 0.5949 - val_acc: 0.8000\n",
      "Epoch 7/10\n",
      "4250/4250 [==============================] - 1s 213us/sample - loss: 0.5767 - acc: 0.7918 - val_loss: 0.5850 - val_acc: 0.7387\n",
      "Epoch 8/10\n",
      "4250/4250 [==============================] - 1s 214us/sample - loss: 0.5581 - acc: 0.7882 - val_loss: 0.5210 - val_acc: 0.8000\n",
      "Epoch 9/10\n",
      "4250/4250 [==============================] - 1s 255us/sample - loss: 0.5473 - acc: 0.7915 - val_loss: 0.5094 - val_acc: 0.8000\n",
      "Epoch 10/10\n",
      "4250/4250 [==============================] - 1s 252us/sample - loss: 0.5283 - acc: 0.7944 - val_loss: 0.5338 - val_acc: 0.7720\n",
      "Epoch 118 out of 200\n",
      "Train on 4250 samples, validate on 750 samples\n",
      "Epoch 1/10\n",
      "4250/4250 [==============================] - 1s 235us/sample - loss: 0.5244 - acc: 0.7941 - val_loss: 0.5536 - val_acc: 0.7427\n",
      "Epoch 2/10\n",
      "4250/4250 [==============================] - 1s 254us/sample - loss: 3.2252 - acc: 0.6944 - val_loss: 1.8138 - val_acc: 0.5240\n",
      "Epoch 3/10\n",
      "4250/4250 [==============================] - 1s 193us/sample - loss: 89.8074 - acc: 0.5979 - val_loss: 59.2497 - val_acc: 0.5493\n",
      "Epoch 4/10\n",
      "4250/4250 [==============================] - 1s 183us/sample - loss: 3163.6488 - acc: 0.5489 - val_loss: 12.9179 - val_acc: 0.6067\n",
      "Epoch 5/10\n",
      "4250/4250 [==============================] - 1s 184us/sample - loss: 3.4992 - acc: 0.7416 - val_loss: 0.6178 - val_acc: 0.8000\n",
      "Epoch 6/10\n",
      "4250/4250 [==============================] - 1s 190us/sample - loss: 0.5992 - acc: 0.7901 - val_loss: 0.5279 - val_acc: 0.8000\n",
      "Epoch 7/10\n",
      "4250/4250 [==============================] - 1s 204us/sample - loss: 0.5377 - acc: 0.7958 - val_loss: 0.5121 - val_acc: 0.8000\n",
      "Epoch 8/10\n",
      "4250/4250 [==============================] - 1s 184us/sample - loss: 0.5210 - acc: 0.7969 - val_loss: 0.5043 - val_acc: 0.8000\n",
      "Epoch 9/10\n",
      "4250/4250 [==============================] - 1s 288us/sample - loss: 0.5237 - acc: 0.7941 - val_loss: 0.5061 - val_acc: 0.8000\n",
      "Epoch 10/10\n",
      "4250/4250 [==============================] - 1s 314us/sample - loss: 0.5135 - acc: 0.7969 - val_loss: 0.5003 - val_acc: 0.8000\n",
      "Epoch 119 out of 200\n",
      "Train on 4250 samples, validate on 750 samples\n",
      "Epoch 1/10\n",
      "4250/4250 [==============================] - 1s 254us/sample - loss: 0.5115 - acc: 0.7998 - val_loss: 0.5019 - val_acc: 0.8000\n",
      "Epoch 2/10\n",
      "4250/4250 [==============================] - 1s 230us/sample - loss: 0.5195 - acc: 0.7934 - val_loss: 0.5056 - val_acc: 0.8000\n",
      "Epoch 3/10\n",
      "4250/4250 [==============================] - 1s 249us/sample - loss: 0.5114 - acc: 0.8000 - val_loss: 0.5263 - val_acc: 0.7960\n",
      "Epoch 4/10\n",
      "4250/4250 [==============================] - 1s 262us/sample - loss: 0.5249 - acc: 0.7929 - val_loss: 0.5408 - val_acc: 0.8000\n",
      "Epoch 5/10\n",
      "4250/4250 [==============================] - 1s 265us/sample - loss: 0.5274 - acc: 0.7939 - val_loss: 0.5315 - val_acc: 0.8000\n",
      "Epoch 6/10\n",
      "4250/4250 [==============================] - 1s 236us/sample - loss: 0.5345 - acc: 0.7929 - val_loss: 0.5548 - val_acc: 0.7467\n",
      "Epoch 7/10\n",
      "4250/4250 [==============================] - 1s 215us/sample - loss: 0.5242 - acc: 0.7899 - val_loss: 0.5020 - val_acc: 0.8000\n",
      "Epoch 8/10\n",
      "4250/4250 [==============================] - 1s 200us/sample - loss: 2.2672 - acc: 0.7179 - val_loss: 0.8994 - val_acc: 0.6627\n",
      "Epoch 9/10\n",
      "4250/4250 [==============================] - 1s 188us/sample - loss: 565.0342 - acc: 0.5496 - val_loss: 5.1743 - val_acc: 0.6067\n",
      "Epoch 10/10\n",
      "4250/4250 [==============================] - 1s 208us/sample - loss: 555.7482 - acc: 0.5278 - val_loss: 298.5449 - val_acc: 0.4493\n",
      "Epoch 120 out of 200\n",
      "Train on 4250 samples, validate on 750 samples\n",
      "Epoch 1/10\n",
      "4250/4250 [==============================] - 1s 215us/sample - loss: 351.8928 - acc: 0.5626 - val_loss: 4.3772 - val_acc: 0.7227\n",
      "Epoch 2/10\n",
      "4250/4250 [==============================] - 1s 187us/sample - loss: 2.3459 - acc: 0.7471 - val_loss: 0.7569 - val_acc: 0.7987\n",
      "Epoch 3/10\n",
      "4250/4250 [==============================] - 1s 187us/sample - loss: 0.8131 - acc: 0.7788 - val_loss: 0.7233 - val_acc: 0.8000\n",
      "Epoch 4/10\n",
      "4250/4250 [==============================] - 1s 220us/sample - loss: 0.8075 - acc: 0.7729 - val_loss: 1.5316 - val_acc: 0.7987\n",
      "Epoch 5/10\n",
      "4250/4250 [==============================] - 1s 207us/sample - loss: 0.7824 - acc: 0.7689 - val_loss: 0.5544 - val_acc: 0.8000\n",
      "Epoch 6/10\n",
      "4250/4250 [==============================] - 1s 233us/sample - loss: 0.5486 - acc: 0.7929 - val_loss: 0.6033 - val_acc: 0.7920\n",
      "Epoch 7/10\n",
      "4250/4250 [==============================] - 1s 244us/sample - loss: 0.5358 - acc: 0.7889 - val_loss: 0.5256 - val_acc: 0.7987\n",
      "Epoch 8/10\n",
      "4250/4250 [==============================] - 1s 201us/sample - loss: 0.5254 - acc: 0.7939 - val_loss: 0.5431 - val_acc: 0.7867\n",
      "Epoch 9/10\n",
      "4250/4250 [==============================] - 1s 220us/sample - loss: 0.5245 - acc: 0.7932 - val_loss: 0.5269 - val_acc: 0.7973\n",
      "Epoch 10/10\n",
      "4250/4250 [==============================] - 1s 276us/sample - loss: 0.5524 - acc: 0.7842 - val_loss: 0.5202 - val_acc: 0.8000\n",
      "Epoch 121 out of 200\n",
      "Train on 4250 samples, validate on 750 samples\n",
      "Epoch 1/10\n",
      "4250/4250 [==============================] - 1s 222us/sample - loss: 0.5234 - acc: 0.7936 - val_loss: 0.5040 - val_acc: 0.8000\n",
      "Epoch 2/10\n",
      "4250/4250 [==============================] - 1s 194us/sample - loss: 0.7270 - acc: 0.7572 - val_loss: 0.6125 - val_acc: 0.7600\n",
      "Epoch 3/10\n",
      "4250/4250 [==============================] - 1s 226us/sample - loss: 0.8808 - acc: 0.7464 - val_loss: 0.5011 - val_acc: 0.8000\n",
      "Epoch 4/10\n",
      "4250/4250 [==============================] - 1s 197us/sample - loss: 507.9966 - acc: 0.5701 - val_loss: 1075.9438 - val_acc: 0.5400\n",
      "Epoch 5/10\n",
      "4250/4250 [==============================] - 1s 208us/sample - loss: 644.1254 - acc: 0.5635 - val_loss: 1.8316 - val_acc: 0.7920\n",
      "Epoch 6/10\n",
      "4250/4250 [==============================] - 1s 196us/sample - loss: 3.9149 - acc: 0.6725 - val_loss: 1.5918 - val_acc: 0.7867\n",
      "Epoch 7/10\n",
      "4250/4250 [==============================] - 1s 185us/sample - loss: 0.7651 - acc: 0.7776 - val_loss: 0.6485 - val_acc: 0.8000\n",
      "Epoch 8/10\n",
      "4250/4250 [==============================] - 1s 250us/sample - loss: 0.6100 - acc: 0.7854 - val_loss: 0.5416 - val_acc: 0.8000\n",
      "Epoch 9/10\n",
      "4250/4250 [==============================] - 1s 251us/sample - loss: 0.5485 - acc: 0.7885 - val_loss: 0.5103 - val_acc: 0.8000\n",
      "Epoch 10/10\n",
      "4250/4250 [==============================] - 1s 251us/sample - loss: 0.5281 - acc: 0.7929 - val_loss: 0.5090 - val_acc: 0.8000\n",
      "Epoch 122 out of 200\n",
      "Train on 4250 samples, validate on 750 samples\n",
      "Epoch 1/10\n",
      "4250/4250 [==============================] - 1s 260us/sample - loss: 0.5170 - acc: 0.7958 - val_loss: 0.5210 - val_acc: 0.8000\n",
      "Epoch 2/10\n",
      "4250/4250 [==============================] - 1s 235us/sample - loss: 0.5314 - acc: 0.7913 - val_loss: 0.5249 - val_acc: 0.7973\n",
      "Epoch 3/10\n",
      "4250/4250 [==============================] - 1s 252us/sample - loss: 0.5219 - acc: 0.7922 - val_loss: 0.5394 - val_acc: 0.8000\n",
      "Epoch 4/10\n",
      "4250/4250 [==============================] - 1s 248us/sample - loss: 0.5251 - acc: 0.7929 - val_loss: 0.5599 - val_acc: 0.8000\n",
      "Epoch 5/10\n",
      "4250/4250 [==============================] - 1s 216us/sample - loss: 0.6272 - acc: 0.7605 - val_loss: 0.5092 - val_acc: 0.8000\n",
      "Epoch 6/10\n",
      "4250/4250 [==============================] - 1s 234us/sample - loss: 518.2694 - acc: 0.6311 - val_loss: 4525.8555 - val_acc: 0.4627\n",
      "Epoch 7/10\n",
      "4250/4250 [==============================] - 1s 220us/sample - loss: 1382.2750 - acc: 0.5407 - val_loss: 1965.0030 - val_acc: 0.4600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/10\n",
      "4250/4250 [==============================] - 1s 244us/sample - loss: 388.9164 - acc: 0.5513 - val_loss: 31.8540 - val_acc: 0.5707\n",
      "Epoch 9/10\n",
      "4250/4250 [==============================] - 1s 264us/sample - loss: 6.0195 - acc: 0.7047 - val_loss: 0.7574 - val_acc: 0.7280\n",
      "Epoch 10/10\n",
      "4250/4250 [==============================] - 1s 236us/sample - loss: 0.7549 - acc: 0.7784 - val_loss: 0.6230 - val_acc: 0.7947\n",
      "Epoch 123 out of 200\n",
      "Train on 4250 samples, validate on 750 samples\n",
      "Epoch 1/10\n",
      "4250/4250 [==============================] - 1s 245us/sample - loss: 0.6248 - acc: 0.7847 - val_loss: 0.5884 - val_acc: 0.7693\n",
      "Epoch 2/10\n",
      "4250/4250 [==============================] - 1s 242us/sample - loss: 0.5589 - acc: 0.7894 - val_loss: 0.5166 - val_acc: 0.8000\n",
      "Epoch 3/10\n",
      "4250/4250 [==============================] - 1s 245us/sample - loss: 0.5183 - acc: 0.7981 - val_loss: 0.5034 - val_acc: 0.8000\n",
      "Epoch 4/10\n",
      "4250/4250 [==============================] - 1s 234us/sample - loss: 0.5260 - acc: 0.7922 - val_loss: 0.5794 - val_acc: 0.8000\n",
      "Epoch 5/10\n",
      "4250/4250 [==============================] - 1s 249us/sample - loss: 0.5618 - acc: 0.7854 - val_loss: 0.5030 - val_acc: 0.8000\n",
      "Epoch 6/10\n",
      "4250/4250 [==============================] - 1s 233us/sample - loss: 0.5245 - acc: 0.7944 - val_loss: 0.5041 - val_acc: 0.8000\n",
      "Epoch 7/10\n",
      "4250/4250 [==============================] - 1s 271us/sample - loss: 0.5096 - acc: 0.7986 - val_loss: 0.5145 - val_acc: 0.8000\n",
      "Epoch 8/10\n",
      "4250/4250 [==============================] - 1s 234us/sample - loss: 0.5112 - acc: 0.7986 - val_loss: 0.5198 - val_acc: 0.8000\n",
      "Epoch 9/10\n",
      "4250/4250 [==============================] - 1s 223us/sample - loss: 0.5494 - acc: 0.7911 - val_loss: 0.6968 - val_acc: 0.8000\n",
      "Epoch 10/10\n",
      "4250/4250 [==============================] - 1s 275us/sample - loss: 1.2373 - acc: 0.7125 - val_loss: 0.6675 - val_acc: 0.7120\n",
      "Epoch 124 out of 200\n",
      "Train on 4250 samples, validate on 750 samples\n",
      "Epoch 1/10\n",
      "4250/4250 [==============================] - 1s 243us/sample - loss: 0.7053 - acc: 0.7628 - val_loss: 0.8345 - val_acc: 0.7880\n",
      "Epoch 2/10\n",
      "4250/4250 [==============================] - 1s 250us/sample - loss: 81.3001 - acc: 0.6075 - val_loss: 269.7267 - val_acc: 0.5387\n",
      "Epoch 3/10\n",
      "4250/4250 [==============================] - 1s 244us/sample - loss: 1976.5226 - acc: 0.5318 - val_loss: 55.9794 - val_acc: 0.5413\n",
      "Epoch 4/10\n",
      "4250/4250 [==============================] - 1s 234us/sample - loss: 7.8944 - acc: 0.7193 - val_loss: 0.6060 - val_acc: 0.8000\n",
      "Epoch 5/10\n",
      "4250/4250 [==============================] - 1s 228us/sample - loss: 0.6007 - acc: 0.7880 - val_loss: 0.5351 - val_acc: 0.8000\n",
      "Epoch 6/10\n",
      "4250/4250 [==============================] - 1s 226us/sample - loss: 0.5360 - acc: 0.7962 - val_loss: 0.5126 - val_acc: 0.8000\n",
      "Epoch 7/10\n",
      "4250/4250 [==============================] - 1s 232us/sample - loss: 0.5199 - acc: 0.7979 - val_loss: 0.5111 - val_acc: 0.8000\n",
      "Epoch 8/10\n",
      "4250/4250 [==============================] - 1s 223us/sample - loss: 0.5141 - acc: 0.7993 - val_loss: 0.5090 - val_acc: 0.8000\n",
      "Epoch 9/10\n",
      "4250/4250 [==============================] - 1s 217us/sample - loss: 0.5223 - acc: 0.7967 - val_loss: 0.5015 - val_acc: 0.8000\n",
      "Epoch 10/10\n",
      "4250/4250 [==============================] - 1s 231us/sample - loss: 0.7061 - acc: 0.7729 - val_loss: 0.5035 - val_acc: 0.8000\n",
      "Epoch 125 out of 200\n",
      "Train on 4250 samples, validate on 750 samples\n",
      "Epoch 1/10\n",
      "4250/4250 [==============================] - 1s 280us/sample - loss: 67.9474 - acc: 0.6068 - val_loss: 84.4477 - val_acc: 0.5400\n",
      "Epoch 2/10\n",
      "4250/4250 [==============================] - 1s 232us/sample - loss: 501.4795 - acc: 0.5414 - val_loss: 43.1467 - val_acc: 0.5427\n",
      "Epoch 3/10\n",
      "4250/4250 [==============================] - 1s 241us/sample - loss: 33.2989 - acc: 0.6386 - val_loss: 0.6851 - val_acc: 0.7760\n",
      "Epoch 4/10\n",
      "4250/4250 [==============================] - 1s 230us/sample - loss: 0.6849 - acc: 0.7824 - val_loss: 0.6069 - val_acc: 0.8000\n",
      "Epoch 5/10\n",
      "4250/4250 [==============================] - 1s 238us/sample - loss: 0.5927 - acc: 0.7906 - val_loss: 0.5416 - val_acc: 0.7720\n",
      "Epoch 6/10\n",
      "4250/4250 [==============================] - 1s 262us/sample - loss: 0.5441 - acc: 0.7941 - val_loss: 0.5161 - val_acc: 0.8000\n",
      "Epoch 7/10\n",
      "4250/4250 [==============================] - 1s 260us/sample - loss: 0.5179 - acc: 0.7981 - val_loss: 0.5028 - val_acc: 0.8000\n",
      "Epoch 8/10\n",
      "4250/4250 [==============================] - 1s 224us/sample - loss: 0.5143 - acc: 0.7969 - val_loss: 0.5059 - val_acc: 0.8000\n",
      "Epoch 9/10\n",
      "4250/4250 [==============================] - 1s 242us/sample - loss: 0.5175 - acc: 0.7972 - val_loss: 0.5026 - val_acc: 0.8000\n",
      "Epoch 10/10\n",
      "4250/4250 [==============================] - 1s 264us/sample - loss: 0.5212 - acc: 0.7946 - val_loss: 0.5198 - val_acc: 0.7867\n",
      "Epoch 126 out of 200\n",
      "Train on 4250 samples, validate on 750 samples\n",
      "Epoch 1/10\n",
      "4250/4250 [==============================] - 1s 274us/sample - loss: 0.5196 - acc: 0.7946 - val_loss: 0.5071 - val_acc: 0.8000\n",
      "Epoch 2/10\n",
      "4250/4250 [==============================] - 1s 225us/sample - loss: 0.7544 - acc: 0.7607 - val_loss: 15.9591 - val_acc: 0.5587\n",
      "Epoch 3/10\n",
      "4250/4250 [==============================] - 1s 236us/sample - loss: 1322.5378 - acc: 0.5459 - val_loss: 123.4713 - val_acc: 0.5400\n",
      "Epoch 4/10\n",
      "4250/4250 [==============================] - 1s 233us/sample - loss: 95.6739 - acc: 0.6021 - val_loss: 0.7118 - val_acc: 0.7533\n",
      "Epoch 5/10\n",
      "4250/4250 [==============================] - 1s 242us/sample - loss: 0.6486 - acc: 0.7854 - val_loss: 0.5788 - val_acc: 0.8000\n",
      "Epoch 6/10\n",
      "4250/4250 [==============================] - 1s 243us/sample - loss: 0.5641 - acc: 0.7922 - val_loss: 0.5480 - val_acc: 0.8000\n",
      "Epoch 7/10\n",
      "4250/4250 [==============================] - 1s 236us/sample - loss: 0.5454 - acc: 0.7904 - val_loss: 0.5253 - val_acc: 0.7987\n",
      "Epoch 8/10\n",
      "4250/4250 [==============================] - 1s 247us/sample - loss: 0.5131 - acc: 0.7991 - val_loss: 0.5123 - val_acc: 0.8000\n",
      "Epoch 9/10\n",
      "4250/4250 [==============================] - 1s 223us/sample - loss: 0.5135 - acc: 0.7958 - val_loss: 0.5023 - val_acc: 0.8000\n",
      "Epoch 10/10\n",
      "4250/4250 [==============================] - 1s 246us/sample - loss: 0.5299 - acc: 0.7939 - val_loss: 0.5154 - val_acc: 0.7960\n",
      "Epoch 127 out of 200\n",
      "Train on 4250 samples, validate on 750 samples\n",
      "Epoch 1/10\n",
      "4250/4250 [==============================] - 1s 306us/sample - loss: 0.5166 - acc: 0.7955 - val_loss: 0.5037 - val_acc: 0.8000\n",
      "Epoch 2/10\n",
      "4250/4250 [==============================] - 1s 188us/sample - loss: 0.5426 - acc: 0.7868 - val_loss: 0.5087 - val_acc: 0.8000\n",
      "Epoch 3/10\n",
      "4250/4250 [==============================] - 1s 216us/sample - loss: 0.5427 - acc: 0.7904 - val_loss: 0.5132 - val_acc: 0.8000\n",
      "Epoch 4/10\n",
      "4250/4250 [==============================] - 1s 276us/sample - loss: 0.5822 - acc: 0.7779 - val_loss: 0.5872 - val_acc: 0.8000\n",
      "Epoch 5/10\n",
      "4250/4250 [==============================] - 1s 196us/sample - loss: 0.5992 - acc: 0.7654 - val_loss: 0.9840 - val_acc: 0.7587\n",
      "Epoch 6/10\n",
      "4250/4250 [==============================] - 1s 215us/sample - loss: 1.9719 - acc: 0.6899 - val_loss: 0.9025 - val_acc: 0.7827\n",
      "Epoch 7/10\n",
      "4250/4250 [==============================] - 1s 181us/sample - loss: 2289.0922 - acc: 0.5292 - val_loss: 860.1189 - val_acc: 0.5427\n",
      "Epoch 8/10\n",
      "4250/4250 [==============================] - 1s 215us/sample - loss: 901.0203 - acc: 0.5527 - val_loss: 8.2979 - val_acc: 0.5440\n",
      "Epoch 9/10\n",
      "4250/4250 [==============================] - 1s 198us/sample - loss: 44.1117 - acc: 0.5772 - val_loss: 13.5503 - val_acc: 0.5893\n",
      "Epoch 10/10\n",
      "4250/4250 [==============================] - 1s 192us/sample - loss: 3.6713 - acc: 0.7188 - val_loss: 0.9319 - val_acc: 0.8000\n",
      "Epoch 128 out of 200\n",
      "Train on 4250 samples, validate on 750 samples\n",
      "Epoch 1/10\n",
      "4250/4250 [==============================] - 1s 240us/sample - loss: 0.7186 - acc: 0.7878 - val_loss: 0.6448 - val_acc: 0.8000\n",
      "Epoch 2/10\n",
      "4250/4250 [==============================] - 1s 195us/sample - loss: 0.6159 - acc: 0.7859 - val_loss: 0.5640 - val_acc: 0.8000\n",
      "Epoch 3/10\n",
      "4250/4250 [==============================] - 1s 201us/sample - loss: 0.5443 - acc: 0.7944 - val_loss: 0.5295 - val_acc: 0.8000\n",
      "Epoch 4/10\n",
      "4250/4250 [==============================] - 1s 272us/sample - loss: 0.5202 - acc: 0.7979 - val_loss: 0.5148 - val_acc: 0.8000\n",
      "Epoch 5/10\n",
      "4250/4250 [==============================] - 1s 246us/sample - loss: 0.5112 - acc: 0.7986 - val_loss: 0.5104 - val_acc: 0.8000\n",
      "Epoch 6/10\n",
      "4250/4250 [==============================] - 1s 255us/sample - loss: 0.5101 - acc: 0.8000 - val_loss: 0.5011 - val_acc: 0.8000\n",
      "Epoch 7/10\n",
      "4250/4250 [==============================] - 1s 259us/sample - loss: 0.5170 - acc: 0.7939 - val_loss: 0.5011 - val_acc: 0.8000\n",
      "Epoch 8/10\n",
      "4250/4250 [==============================] - 1s 227us/sample - loss: 0.5063 - acc: 0.7974 - val_loss: 0.5074 - val_acc: 0.8000\n",
      "Epoch 9/10\n",
      "4250/4250 [==============================] - 1s 257us/sample - loss: 0.5200 - acc: 0.7974 - val_loss: 0.5018 - val_acc: 0.8000\n",
      "Epoch 10/10\n",
      "4250/4250 [==============================] - 1s 203us/sample - loss: 0.5148 - acc: 0.7991 - val_loss: 0.5508 - val_acc: 0.7480\n",
      "Epoch 129 out of 200\n",
      "Train on 4250 samples, validate on 750 samples\n",
      "Epoch 1/10\n",
      "4250/4250 [==============================] - 1s 183us/sample - loss: 0.5495 - acc: 0.7875 - val_loss: 0.5086 - val_acc: 0.8000\n",
      "Epoch 2/10\n",
      "4250/4250 [==============================] - 1s 223us/sample - loss: 0.5362 - acc: 0.7934 - val_loss: 0.5005 - val_acc: 0.8000\n",
      "Epoch 3/10\n",
      "4250/4250 [==============================] - 1s 206us/sample - loss: 0.5388 - acc: 0.7906 - val_loss: 0.6947 - val_acc: 0.6627\n",
      "Epoch 4/10\n",
      "4250/4250 [==============================] - 1s 203us/sample - loss: 0.5779 - acc: 0.7795 - val_loss: 0.5108 - val_acc: 0.8000\n",
      "Epoch 5/10\n",
      "4250/4250 [==============================] - 1s 272us/sample - loss: 3.0036 - acc: 0.7096 - val_loss: 0.9480 - val_acc: 0.7013\n",
      "Epoch 6/10\n",
      "4250/4250 [==============================] - 1s 209us/sample - loss: 460.9586 - acc: 0.5449 - val_loss: 14.7092 - val_acc: 0.6213\n",
      "Epoch 7/10\n",
      "4250/4250 [==============================] - 1s 214us/sample - loss: 2415.4149 - acc: 0.5525 - val_loss: 140.1944 - val_acc: 0.4493\n",
      "Epoch 8/10\n",
      "4250/4250 [==============================] - 1s 244us/sample - loss: 10.9127 - acc: 0.6941 - val_loss: 0.7141 - val_acc: 0.7827\n",
      "Epoch 9/10\n",
      "4250/4250 [==============================] - 1s 185us/sample - loss: 0.7449 - acc: 0.7826 - val_loss: 0.6330 - val_acc: 0.7947\n",
      "Epoch 10/10\n",
      "4250/4250 [==============================] - 1s 216us/sample - loss: 0.5980 - acc: 0.7906 - val_loss: 0.5359 - val_acc: 0.8000\n",
      "Epoch 130 out of 200\n",
      "Train on 4250 samples, validate on 750 samples\n",
      "Epoch 1/10\n",
      "4250/4250 [==============================] - 1s 219us/sample - loss: 0.5462 - acc: 0.7965 - val_loss: 0.5222 - val_acc: 0.8000\n",
      "Epoch 2/10\n",
      "4250/4250 [==============================] - 1s 195us/sample - loss: 0.5248 - acc: 0.7939 - val_loss: 0.5096 - val_acc: 0.8000\n",
      "Epoch 3/10\n",
      "4250/4250 [==============================] - 1s 289us/sample - loss: 0.5124 - acc: 0.7986 - val_loss: 0.5169 - val_acc: 0.8000\n",
      "Epoch 4/10\n",
      "4250/4250 [==============================] - 1s 199us/sample - loss: 0.5234 - acc: 0.7925 - val_loss: 0.5064 - val_acc: 0.8000\n",
      "Epoch 5/10\n",
      "4250/4250 [==============================] - 1s 217us/sample - loss: 0.5172 - acc: 0.7958 - val_loss: 0.5006 - val_acc: 0.8000\n",
      "Epoch 6/10\n",
      "4250/4250 [==============================] - 1s 191us/sample - loss: 0.5171 - acc: 0.7969 - val_loss: 0.5039 - val_acc: 0.8000\n",
      "Epoch 7/10\n",
      "4250/4250 [==============================] - 1s 251us/sample - loss: 0.5582 - acc: 0.7821 - val_loss: 0.5784 - val_acc: 0.7680\n",
      "Epoch 8/10\n",
      "4250/4250 [==============================] - 1s 239us/sample - loss: 0.5967 - acc: 0.7718 - val_loss: 0.5070 - val_acc: 0.8000\n",
      "Epoch 9/10\n",
      "4250/4250 [==============================] - 1s 236us/sample - loss: 0.5965 - acc: 0.7833 - val_loss: 0.7985 - val_acc: 0.7907\n",
      "Epoch 10/10\n",
      "4250/4250 [==============================] - 1s 259us/sample - loss: 0.7621 - acc: 0.7576 - val_loss: 0.6151 - val_acc: 0.6840\n",
      "Epoch 131 out of 200\n",
      "Train on 4250 samples, validate on 750 samples\n",
      "Epoch 1/10\n",
      "4250/4250 [==============================] - 1s 236us/sample - loss: 0.5254 - acc: 0.7946 - val_loss: 0.5667 - val_acc: 0.7253\n",
      "Epoch 2/10\n",
      "4250/4250 [==============================] - 1s 211us/sample - loss: 0.5262 - acc: 0.7915 - val_loss: 0.5004 - val_acc: 0.8000\n",
      "Epoch 3/10\n",
      "4250/4250 [==============================] - 1s 232us/sample - loss: 0.5217 - acc: 0.7969 - val_loss: 0.5252 - val_acc: 0.7827\n",
      "Epoch 4/10\n",
      "4250/4250 [==============================] - 1s 229us/sample - loss: 0.5660 - acc: 0.7800 - val_loss: 0.5086 - val_acc: 0.8000\n",
      "Epoch 5/10\n",
      "4250/4250 [==============================] - 1s 212us/sample - loss: 1.2672 - acc: 0.7313 - val_loss: 1.3789 - val_acc: 0.7053\n",
      "Epoch 6/10\n",
      "4250/4250 [==============================] - 1s 224us/sample - loss: 866.8145 - acc: 0.5395 - val_loss: 601.0655 - val_acc: 0.4613\n",
      "Epoch 7/10\n",
      "4250/4250 [==============================] - 1s 208us/sample - loss: 709.0020 - acc: 0.5489 - val_loss: 4.7293 - val_acc: 0.6773\n",
      "Epoch 8/10\n",
      "4250/4250 [==============================] - 1s 214us/sample - loss: 7.4408 - acc: 0.7031 - val_loss: 0.6824 - val_acc: 0.7933\n",
      "Epoch 9/10\n",
      "4250/4250 [==============================] - 1s 223us/sample - loss: 0.7002 - acc: 0.7831 - val_loss: 0.6085 - val_acc: 0.8000\n",
      "Epoch 10/10\n",
      "4250/4250 [==============================] - 1s 225us/sample - loss: 0.5809 - acc: 0.7885 - val_loss: 0.5381 - val_acc: 0.8000\n",
      "Epoch 132 out of 200\n",
      "Train on 4250 samples, validate on 750 samples\n",
      "Epoch 1/10\n",
      "4250/4250 [==============================] - 1s 255us/sample - loss: 0.5399 - acc: 0.7955 - val_loss: 0.5142 - val_acc: 0.8000\n",
      "Epoch 2/10\n",
      "4250/4250 [==============================] - 1s 205us/sample - loss: 0.5249 - acc: 0.7946 - val_loss: 0.5269 - val_acc: 0.8000\n",
      "Epoch 3/10\n",
      "4250/4250 [==============================] - 1s 237us/sample - loss: 0.5113 - acc: 0.7979 - val_loss: 0.5063 - val_acc: 0.8000\n",
      "Epoch 4/10\n",
      "4250/4250 [==============================] - 1s 223us/sample - loss: 0.5120 - acc: 0.7986 - val_loss: 0.5049 - val_acc: 0.8000\n",
      "Epoch 5/10\n",
      "4250/4250 [==============================] - 1s 233us/sample - loss: 0.5072 - acc: 0.7972 - val_loss: 0.5044 - val_acc: 0.8000\n",
      "Epoch 6/10\n",
      "4250/4250 [==============================] - 1s 232us/sample - loss: 0.5481 - acc: 0.7833 - val_loss: 0.5160 - val_acc: 0.8000\n",
      "Epoch 7/10\n",
      "4250/4250 [==============================] - 1s 226us/sample - loss: 0.5383 - acc: 0.7929 - val_loss: 0.5797 - val_acc: 0.7227\n",
      "Epoch 8/10\n",
      "4250/4250 [==============================] - 1s 220us/sample - loss: 615.6248 - acc: 0.5586 - val_loss: 244.3400 - val_acc: 0.5560\n",
      "Epoch 9/10\n",
      "4250/4250 [==============================] - 1s 229us/sample - loss: 849.2644 - acc: 0.5468 - val_loss: 1470.1791 - val_acc: 0.4547\n",
      "Epoch 10/10\n",
      "4250/4250 [==============================] - 1s 282us/sample - loss: 132.1761 - acc: 0.6579 - val_loss: 0.9485 - val_acc: 0.8000\n",
      "Epoch 133 out of 200\n",
      "Train on 4250 samples, validate on 750 samples\n",
      "Epoch 1/10\n",
      "4250/4250 [==============================] - 1s 272us/sample - loss: 0.7211 - acc: 0.7842 - val_loss: 0.6396 - val_acc: 0.8000\n",
      "Epoch 2/10\n",
      "4250/4250 [==============================] - 1s 227us/sample - loss: 0.6006 - acc: 0.7866 - val_loss: 0.5397 - val_acc: 0.8000\n",
      "Epoch 3/10\n",
      "4250/4250 [==============================] - 1s 224us/sample - loss: 0.5340 - acc: 0.7979 - val_loss: 0.5196 - val_acc: 0.8000\n",
      "Epoch 4/10\n",
      "4250/4250 [==============================] - 1s 244us/sample - loss: 0.5159 - acc: 0.7979 - val_loss: 0.5122 - val_acc: 0.8000\n",
      "Epoch 5/10\n",
      "4250/4250 [==============================] - 1s 237us/sample - loss: 0.5162 - acc: 0.7972 - val_loss: 0.5141 - val_acc: 0.8000\n",
      "Epoch 6/10\n",
      "4250/4250 [==============================] - 1s 218us/sample - loss: 0.5152 - acc: 0.7981 - val_loss: 0.5011 - val_acc: 0.8000\n",
      "Epoch 7/10\n",
      "4250/4250 [==============================] - 1s 222us/sample - loss: 0.5117 - acc: 0.7986 - val_loss: 0.5000 - val_acc: 0.8000\n",
      "Epoch 8/10\n",
      "4250/4250 [==============================] - 1s 255us/sample - loss: 0.5103 - acc: 0.7988 - val_loss: 0.5042 - val_acc: 0.8000\n",
      "Epoch 9/10\n",
      "4250/4250 [==============================] - 1s 267us/sample - loss: 0.5586 - acc: 0.7849 - val_loss: 0.5098 - val_acc: 0.8000\n",
      "Epoch 10/10\n",
      "4250/4250 [==============================] - 1s 255us/sample - loss: 0.7110 - acc: 0.7619 - val_loss: 0.5002 - val_acc: 0.8000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 134 out of 200\n",
      "Train on 4250 samples, validate on 750 samples\n",
      "Epoch 1/10\n",
      "4250/4250 [==============================] - 1s 246us/sample - loss: 0.5183 - acc: 0.7984 - val_loss: 0.5128 - val_acc: 0.8000\n",
      "Epoch 2/10\n",
      "4250/4250 [==============================] - 1s 246us/sample - loss: 0.5426 - acc: 0.7939 - val_loss: 0.5300 - val_acc: 0.7960\n",
      "Epoch 3/10\n",
      "4250/4250 [==============================] - 1s 273us/sample - loss: 0.5537 - acc: 0.7824 - val_loss: 0.5269 - val_acc: 0.8000\n",
      "Epoch 4/10\n",
      "4250/4250 [==============================] - 1s 272us/sample - loss: 0.6179 - acc: 0.7760 - val_loss: 0.9725 - val_acc: 0.7520\n",
      "Epoch 5/10\n",
      "4250/4250 [==============================] - 1s 262us/sample - loss: 3.9092 - acc: 0.7205 - val_loss: 61.3863 - val_acc: 0.4480\n",
      "Epoch 6/10\n",
      "4250/4250 [==============================] - 1s 267us/sample - loss: 2227.2118 - acc: 0.5322 - val_loss: 16591.3932 - val_acc: 0.5373\n",
      "Epoch 7/10\n",
      "4250/4250 [==============================] - 1s 241us/sample - loss: 4243.8686 - acc: 0.5656 - val_loss: 48.8399 - val_acc: 0.4533\n",
      "Epoch 8/10\n",
      "4250/4250 [==============================] - 1s 226us/sample - loss: 76.7070 - acc: 0.5908 - val_loss: 3.6592 - val_acc: 0.7693\n",
      "Epoch 9/10\n",
      "4250/4250 [==============================] - 1s 227us/sample - loss: 4.8290 - acc: 0.7049 - val_loss: 3.2508 - val_acc: 0.7573\n",
      "Epoch 10/10\n",
      "4250/4250 [==============================] - 1s 231us/sample - loss: 1.1049 - acc: 0.7680 - val_loss: 0.8306 - val_acc: 0.7987\n",
      "Epoch 135 out of 200\n",
      "Train on 4250 samples, validate on 750 samples\n",
      "Epoch 1/10\n",
      "4250/4250 [==============================] - 1s 271us/sample - loss: 0.7223 - acc: 0.7741 - val_loss: 0.5678 - val_acc: 0.8000\n",
      "Epoch 2/10\n",
      "4250/4250 [==============================] - 1s 246us/sample - loss: 0.5849 - acc: 0.7866 - val_loss: 0.5444 - val_acc: 0.7747\n",
      "Epoch 3/10\n",
      "4250/4250 [==============================] - 1s 221us/sample - loss: 0.5468 - acc: 0.7908 - val_loss: 0.5072 - val_acc: 0.8000\n",
      "Epoch 4/10\n",
      "4250/4250 [==============================] - 1s 245us/sample - loss: 0.5182 - acc: 0.7960 - val_loss: 0.5072 - val_acc: 0.8000\n",
      "Epoch 5/10\n",
      "4250/4250 [==============================] - 1s 252us/sample - loss: 0.5249 - acc: 0.7934 - val_loss: 0.5631 - val_acc: 0.7387\n",
      "Epoch 6/10\n",
      "4250/4250 [==============================] - 1s 241us/sample - loss: 0.5267 - acc: 0.7929 - val_loss: 0.5176 - val_acc: 0.7960\n",
      "Epoch 7/10\n",
      "4250/4250 [==============================] - 1s 231us/sample - loss: 0.5148 - acc: 0.7981 - val_loss: 0.5295 - val_acc: 0.7973\n",
      "Epoch 8/10\n",
      "4250/4250 [==============================] - 1s 231us/sample - loss: 0.5177 - acc: 0.7969 - val_loss: 0.5085 - val_acc: 0.8000\n",
      "Epoch 9/10\n",
      "4250/4250 [==============================] - 1s 209us/sample - loss: 0.5186 - acc: 0.7972 - val_loss: 0.5007 - val_acc: 0.8000\n",
      "Epoch 10/10\n",
      "4250/4250 [==============================] - 1s 210us/sample - loss: 0.5180 - acc: 0.7948 - val_loss: 0.5050 - val_acc: 0.8000\n",
      "Epoch 136 out of 200\n",
      "Train on 4250 samples, validate on 750 samples\n",
      "Epoch 1/10\n",
      "4250/4250 [==============================] - 1s 273us/sample - loss: 0.5340 - acc: 0.7896 - val_loss: 0.5014 - val_acc: 0.8000\n",
      "Epoch 2/10\n",
      "4250/4250 [==============================] - 1s 228us/sample - loss: 0.5139 - acc: 0.7946 - val_loss: 0.5079 - val_acc: 0.8000\n",
      "Epoch 3/10\n",
      "4250/4250 [==============================] - 1s 258us/sample - loss: 0.5242 - acc: 0.7927 - val_loss: 0.5300 - val_acc: 0.7787\n",
      "Epoch 4/10\n",
      "4250/4250 [==============================] - 1s 208us/sample - loss: 0.5338 - acc: 0.7896 - val_loss: 0.5152 - val_acc: 0.8000\n",
      "Epoch 5/10\n",
      "4250/4250 [==============================] - 1s 210us/sample - loss: 0.6934 - acc: 0.7682 - val_loss: 0.9470 - val_acc: 0.7053\n",
      "Epoch 6/10\n",
      "4250/4250 [==============================] - 1s 235us/sample - loss: 35.3157 - acc: 0.6005 - val_loss: 3.9265 - val_acc: 0.6467\n",
      "Epoch 7/10\n",
      "4250/4250 [==============================] - 1s 211us/sample - loss: 326.5784 - acc: 0.5821 - val_loss: 163.9181 - val_acc: 0.5480\n",
      "Epoch 8/10\n",
      "4250/4250 [==============================] - 1s 232us/sample - loss: 1602.8488 - acc: 0.5348 - val_loss: 113.9435 - val_acc: 0.4480\n",
      "Epoch 9/10\n",
      "4250/4250 [==============================] - 1s 229us/sample - loss: 10.1938 - acc: 0.6854 - val_loss: 0.9235 - val_acc: 0.8000\n",
      "Epoch 10/10\n",
      "4250/4250 [==============================] - 1s 230us/sample - loss: 0.7584 - acc: 0.7816 - val_loss: 0.6638 - val_acc: 0.8000\n",
      "Epoch 137 out of 200\n",
      "Train on 4250 samples, validate on 750 samples\n",
      "Epoch 1/10\n",
      "4250/4250 [==============================] - 1s 240us/sample - loss: 0.6479 - acc: 0.7828 - val_loss: 0.5926 - val_acc: 0.8000\n",
      "Epoch 2/10\n",
      "4250/4250 [==============================] - 1s 215us/sample - loss: 0.6230 - acc: 0.7784 - val_loss: 0.5748 - val_acc: 0.8000\n",
      "Epoch 3/10\n",
      "4250/4250 [==============================] - 1s 203us/sample - loss: 0.5599 - acc: 0.7904 - val_loss: 0.5035 - val_acc: 0.8000\n",
      "Epoch 4/10\n",
      "4250/4250 [==============================] - 1s 208us/sample - loss: 0.5512 - acc: 0.7847 - val_loss: 0.5033 - val_acc: 0.8000\n",
      "Epoch 5/10\n",
      "4250/4250 [==============================] - 1s 244us/sample - loss: 0.5323 - acc: 0.7899 - val_loss: 0.5048 - val_acc: 0.8000\n",
      "Epoch 6/10\n",
      "4250/4250 [==============================] - 1s 226us/sample - loss: 0.5453 - acc: 0.7887 - val_loss: 0.5419 - val_acc: 0.8000\n",
      "Epoch 7/10\n",
      "4250/4250 [==============================] - 1s 233us/sample - loss: 0.6330 - acc: 0.7605 - val_loss: 1.0200 - val_acc: 0.7520\n",
      "Epoch 8/10\n",
      "4250/4250 [==============================] - 1s 226us/sample - loss: 0.6782 - acc: 0.7602 - val_loss: 0.5122 - val_acc: 0.8000\n",
      "Epoch 9/10\n",
      "4250/4250 [==============================] - 1s 245us/sample - loss: 0.5569 - acc: 0.7812 - val_loss: 0.5114 - val_acc: 0.8000\n",
      "Epoch 10/10\n",
      "4250/4250 [==============================] - 1s 298us/sample - loss: 0.5972 - acc: 0.7732 - val_loss: 0.5073 - val_acc: 0.8000\n",
      "Epoch 138 out of 200\n",
      "Train on 4250 samples, validate on 750 samples\n",
      "Epoch 1/10\n",
      "4250/4250 [==============================] - 1s 311us/sample - loss: 953.5396 - acc: 0.5826 - val_loss: 682.8066 - val_acc: 0.4547\n",
      "Epoch 2/10\n",
      "4250/4250 [==============================] - 1s 250us/sample - loss: 223.7753 - acc: 0.5506 - val_loss: 3.8707 - val_acc: 0.6973\n",
      "Epoch 3/10\n",
      "4250/4250 [==============================] - 1s 303us/sample - loss: 2.1183 - acc: 0.7468 - val_loss: 0.5895 - val_acc: 0.7893\n",
      "Epoch 4/10\n",
      "4250/4250 [==============================] - 1s 275us/sample - loss: 0.5855 - acc: 0.7873 - val_loss: 0.5222 - val_acc: 0.8000\n",
      "Epoch 5/10\n",
      "4250/4250 [==============================] - 2s 374us/sample - loss: 0.5380 - acc: 0.7946 - val_loss: 0.5089 - val_acc: 0.8000\n",
      "Epoch 6/10\n",
      "4250/4250 [==============================] - 2s 371us/sample - loss: 0.5171 - acc: 0.7976 - val_loss: 0.5019 - val_acc: 0.8000\n",
      "Epoch 7/10\n",
      "4250/4250 [==============================] - 1s 346us/sample - loss: 0.5081 - acc: 0.7995 - val_loss: 0.5007 - val_acc: 0.8000\n",
      "Epoch 8/10\n",
      "4250/4250 [==============================] - 2s 380us/sample - loss: 0.5146 - acc: 0.7969 - val_loss: 0.5002 - val_acc: 0.8000\n",
      "Epoch 9/10\n",
      "4250/4250 [==============================] - 1s 309us/sample - loss: 0.5214 - acc: 0.7955 - val_loss: 0.5285 - val_acc: 0.7840\n",
      "Epoch 10/10\n",
      "4250/4250 [==============================] - 1s 340us/sample - loss: 14.4472 - acc: 0.6518 - val_loss: 3.3017 - val_acc: 0.6093\n",
      "Epoch 139 out of 200\n",
      "Train on 4250 samples, validate on 750 samples\n",
      "Epoch 1/10\n",
      "4250/4250 [==============================] - 1s 313us/sample - loss: 0.9497 - acc: 0.7595 - val_loss: 0.5201 - val_acc: 0.8000\n",
      "Epoch 2/10\n",
      "4250/4250 [==============================] - 1s 297us/sample - loss: 0.5210 - acc: 0.7944 - val_loss: 0.5192 - val_acc: 0.8000\n",
      "Epoch 3/10\n",
      "4250/4250 [==============================] - 1s 294us/sample - loss: 0.5196 - acc: 0.7988 - val_loss: 0.5120 - val_acc: 0.8000\n",
      "Epoch 4/10\n",
      "4250/4250 [==============================] - 1s 299us/sample - loss: 0.5166 - acc: 0.7972 - val_loss: 0.5018 - val_acc: 0.8000\n",
      "Epoch 5/10\n",
      "4250/4250 [==============================] - 1s 299us/sample - loss: 0.5172 - acc: 0.7932 - val_loss: 0.5189 - val_acc: 0.8000\n",
      "Epoch 6/10\n",
      "4250/4250 [==============================] - 1s 266us/sample - loss: 0.5217 - acc: 0.7979 - val_loss: 0.5068 - val_acc: 0.8000\n",
      "Epoch 7/10\n",
      "4250/4250 [==============================] - 1s 278us/sample - loss: 0.5670 - acc: 0.7831 - val_loss: 0.5010 - val_acc: 0.8000\n",
      "Epoch 8/10\n",
      "4250/4250 [==============================] - 1s 283us/sample - loss: 0.5175 - acc: 0.7988 - val_loss: 0.5003 - val_acc: 0.8000\n",
      "Epoch 9/10\n",
      "4250/4250 [==============================] - 1s 287us/sample - loss: 86.7703 - acc: 0.7275 - val_loss: 115.2777 - val_acc: 0.5480\n",
      "Epoch 10/10\n",
      "4250/4250 [==============================] - 1s 267us/sample - loss: 2521.6925 - acc: 0.5369 - val_loss: 84.7065 - val_acc: 0.5453\n",
      "Epoch 140 out of 200\n",
      "Train on 4250 samples, validate on 750 samples\n",
      "Epoch 1/10\n",
      "4250/4250 [==============================] - 1s 263us/sample - loss: 11.0419 - acc: 0.7122 - val_loss: 0.6622 - val_acc: 0.8000\n",
      "Epoch 2/10\n",
      "4250/4250 [==============================] - 1s 263us/sample - loss: 0.5854 - acc: 0.7932 - val_loss: 0.5235 - val_acc: 0.8000\n",
      "Epoch 3/10\n",
      "4250/4250 [==============================] - 1s 247us/sample - loss: 0.5204 - acc: 0.7974 - val_loss: 0.5065 - val_acc: 0.8000\n",
      "Epoch 4/10\n",
      "4250/4250 [==============================] - 1s 247us/sample - loss: 0.5089 - acc: 0.7988 - val_loss: 0.5034 - val_acc: 0.8000\n",
      "Epoch 5/10\n",
      "4250/4250 [==============================] - 1s 258us/sample - loss: 0.5071 - acc: 0.7986 - val_loss: 0.5002 - val_acc: 0.8000\n",
      "Epoch 6/10\n",
      "4250/4250 [==============================] - 1s 248us/sample - loss: 0.5067 - acc: 0.7993 - val_loss: 0.5011 - val_acc: 0.8000\n",
      "Epoch 7/10\n",
      "4250/4250 [==============================] - 1s 251us/sample - loss: 0.5048 - acc: 0.7979 - val_loss: 0.5017 - val_acc: 0.8000\n",
      "Epoch 8/10\n",
      "4250/4250 [==============================] - 1s 222us/sample - loss: 0.5031 - acc: 0.8000 - val_loss: 0.5081 - val_acc: 0.8000\n",
      "Epoch 9/10\n",
      "4250/4250 [==============================] - 1s 227us/sample - loss: 0.5024 - acc: 0.7993 - val_loss: 0.5012 - val_acc: 0.8000\n",
      "Epoch 10/10\n",
      "4250/4250 [==============================] - 1s 264us/sample - loss: 0.5095 - acc: 0.7988 - val_loss: 0.5001 - val_acc: 0.8000\n",
      "Epoch 141 out of 200\n",
      "Train on 4250 samples, validate on 750 samples\n",
      "Epoch 1/10\n",
      "4250/4250 [==============================] - 1s 248us/sample - loss: 0.5050 - acc: 0.7998 - val_loss: 0.5011 - val_acc: 0.8000\n",
      "Epoch 2/10\n",
      "4250/4250 [==============================] - 1s 218us/sample - loss: 0.5045 - acc: 0.7995 - val_loss: 0.5014 - val_acc: 0.8000\n",
      "Epoch 3/10\n",
      "4250/4250 [==============================] - 1s 241us/sample - loss: 0.5035 - acc: 0.8000 - val_loss: 0.5013 - val_acc: 0.8000\n",
      "Epoch 4/10\n",
      "4250/4250 [==============================] - 1s 249us/sample - loss: 0.5569 - acc: 0.7918 - val_loss: 0.5160 - val_acc: 0.7987\n",
      "Epoch 5/10\n",
      "4250/4250 [==============================] - 1s 233us/sample - loss: 0.5144 - acc: 0.7972 - val_loss: 0.5009 - val_acc: 0.8000\n",
      "Epoch 6/10\n",
      "4250/4250 [==============================] - 1s 246us/sample - loss: 0.5621 - acc: 0.7920 - val_loss: 0.5210 - val_acc: 0.8000\n",
      "Epoch 7/10\n",
      "4250/4250 [==============================] - 1s 255us/sample - loss: 0.5388 - acc: 0.7859 - val_loss: 0.5056 - val_acc: 0.8000\n",
      "Epoch 8/10\n",
      "4250/4250 [==============================] - 1s 279us/sample - loss: 0.5489 - acc: 0.7908 - val_loss: 0.5110 - val_acc: 0.8000\n",
      "Epoch 9/10\n",
      "4250/4250 [==============================] - 1s 250us/sample - loss: 0.6628 - acc: 0.7887 - val_loss: 3.4088 - val_acc: 0.4320\n",
      "Epoch 10/10\n",
      "4250/4250 [==============================] - 1s 238us/sample - loss: 2779.9459 - acc: 0.5271 - val_loss: 266.6638 - val_acc: 0.5600\n",
      "Epoch 142 out of 200\n",
      "Train on 4250 samples, validate on 750 samples\n",
      "Epoch 1/10\n",
      "4250/4250 [==============================] - 1s 299us/sample - loss: 759.5948 - acc: 0.5569 - val_loss: 42.1700 - val_acc: 0.4347\n",
      "Epoch 2/10\n",
      "4250/4250 [==============================] - 1s 268us/sample - loss: 18.4875 - acc: 0.6515 - val_loss: 0.9078 - val_acc: 0.8000\n",
      "Epoch 3/10\n",
      "4250/4250 [==============================] - 1s 250us/sample - loss: 0.7399 - acc: 0.7861 - val_loss: 0.6677 - val_acc: 0.8000\n",
      "Epoch 4/10\n",
      "4250/4250 [==============================] - 1s 246us/sample - loss: 0.6061 - acc: 0.7934 - val_loss: 0.5351 - val_acc: 0.8000\n",
      "Epoch 5/10\n",
      "4250/4250 [==============================] - 1s 249us/sample - loss: 0.5403 - acc: 0.7946 - val_loss: 0.5197 - val_acc: 0.8000\n",
      "Epoch 6/10\n",
      "4250/4250 [==============================] - 1s 240us/sample - loss: 0.5295 - acc: 0.7951 - val_loss: 0.5094 - val_acc: 0.8000\n",
      "Epoch 7/10\n",
      "4250/4250 [==============================] - 1s 231us/sample - loss: 0.5105 - acc: 0.7988 - val_loss: 0.5004 - val_acc: 0.8000\n",
      "Epoch 8/10\n",
      "4250/4250 [==============================] - 1s 257us/sample - loss: 0.5049 - acc: 0.8000 - val_loss: 0.5033 - val_acc: 0.8000\n",
      "Epoch 9/10\n",
      "4250/4250 [==============================] - 1s 248us/sample - loss: 0.5088 - acc: 0.7986 - val_loss: 0.5159 - val_acc: 0.8000\n",
      "Epoch 10/10\n",
      "4250/4250 [==============================] - 1s 223us/sample - loss: 0.5265 - acc: 0.7920 - val_loss: 0.5004 - val_acc: 0.8000\n",
      "Epoch 143 out of 200\n",
      "Train on 4250 samples, validate on 750 samples\n",
      "Epoch 1/10\n",
      "4250/4250 [==============================] - 1s 250us/sample - loss: 0.5184 - acc: 0.7955 - val_loss: 0.5027 - val_acc: 0.8000\n",
      "Epoch 2/10\n",
      "4250/4250 [==============================] - 1s 211us/sample - loss: 0.5115 - acc: 0.7984 - val_loss: 0.5008 - val_acc: 0.8000\n",
      "Epoch 3/10\n",
      "4250/4250 [==============================] - 1s 235us/sample - loss: 0.5069 - acc: 0.7998 - val_loss: 0.5197 - val_acc: 0.8000\n",
      "Epoch 4/10\n",
      "4250/4250 [==============================] - 1s 244us/sample - loss: 0.5558 - acc: 0.7861 - val_loss: 0.5092 - val_acc: 0.8000\n",
      "Epoch 5/10\n",
      "4250/4250 [==============================] - 1s 249us/sample - loss: 3.1058 - acc: 0.6838 - val_loss: 2.3891 - val_acc: 0.6800\n",
      "Epoch 6/10\n",
      "4250/4250 [==============================] - 1s 242us/sample - loss: 0.9050 - acc: 0.7602 - val_loss: 1.7182 - val_acc: 0.4827\n",
      "Epoch 7/10\n",
      "4250/4250 [==============================] - 1s 236us/sample - loss: 13.2035 - acc: 0.6176 - val_loss: 107.6869 - val_acc: 0.5387\n",
      "Epoch 8/10\n",
      "4250/4250 [==============================] - 1s 270us/sample - loss: 2043.5314 - acc: 0.5374 - val_loss: 21.1751 - val_acc: 0.5693\n",
      "Epoch 9/10\n",
      "4250/4250 [==============================] - 1s 252us/sample - loss: 9.2442 - acc: 0.6468 - val_loss: 1.7042 - val_acc: 0.7920\n",
      "Epoch 10/10\n",
      "4250/4250 [==============================] - 1s 251us/sample - loss: 0.9378 - acc: 0.7689 - val_loss: 0.6164 - val_acc: 0.8000\n",
      "Epoch 144 out of 200\n",
      "Train on 4250 samples, validate on 750 samples\n",
      "Epoch 1/10\n",
      "4250/4250 [==============================] - 1s 248us/sample - loss: 0.5873 - acc: 0.7913 - val_loss: 0.5398 - val_acc: 0.8000\n",
      "Epoch 2/10\n",
      "4250/4250 [==============================] - 1s 217us/sample - loss: 0.5284 - acc: 0.7960 - val_loss: 0.5281 - val_acc: 0.7867\n",
      "Epoch 3/10\n",
      "4250/4250 [==============================] - 1s 225us/sample - loss: 0.5179 - acc: 0.7974 - val_loss: 0.5033 - val_acc: 0.8000\n",
      "Epoch 4/10\n",
      "4250/4250 [==============================] - 1s 226us/sample - loss: 0.5175 - acc: 0.7932 - val_loss: 0.5034 - val_acc: 0.8000\n",
      "Epoch 5/10\n",
      "4250/4250 [==============================] - 1s 239us/sample - loss: 0.5113 - acc: 0.7998 - val_loss: 0.5096 - val_acc: 0.8000\n",
      "Epoch 6/10\n",
      "4250/4250 [==============================] - 1s 255us/sample - loss: 0.5210 - acc: 0.7939 - val_loss: 0.5004 - val_acc: 0.8000\n",
      "Epoch 7/10\n",
      "4250/4250 [==============================] - 1s 253us/sample - loss: 0.5151 - acc: 0.7974 - val_loss: 0.5079 - val_acc: 0.8000\n",
      "Epoch 8/10\n",
      "4250/4250 [==============================] - 1s 247us/sample - loss: 0.5082 - acc: 0.8000 - val_loss: 0.5051 - val_acc: 0.8000\n",
      "Epoch 9/10\n",
      "4250/4250 [==============================] - 1s 261us/sample - loss: 0.5131 - acc: 0.7979 - val_loss: 0.5019 - val_acc: 0.8000\n",
      "Epoch 10/10\n",
      "4250/4250 [==============================] - 1s 228us/sample - loss: 0.5081 - acc: 0.7995 - val_loss: 0.5103 - val_acc: 0.8000\n",
      "Epoch 145 out of 200\n",
      "Train on 4250 samples, validate on 750 samples\n",
      "Epoch 1/10\n",
      "4250/4250 [==============================] - 1s 248us/sample - loss: 0.6123 - acc: 0.7699 - val_loss: 0.8089 - val_acc: 0.7933\n",
      "Epoch 2/10\n",
      "4250/4250 [==============================] - 1s 223us/sample - loss: 0.6001 - acc: 0.7840 - val_loss: 0.5148 - val_acc: 0.8000\n",
      "Epoch 3/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4250/4250 [==============================] - 1s 238us/sample - loss: 0.5281 - acc: 0.7948 - val_loss: 0.5013 - val_acc: 0.8000\n",
      "Epoch 4/10\n",
      "4250/4250 [==============================] - 1s 227us/sample - loss: 9.2971 - acc: 0.6718 - val_loss: 7.8155 - val_acc: 0.5947\n",
      "Epoch 5/10\n",
      "4250/4250 [==============================] - 1s 247us/sample - loss: 1517.1832 - acc: 0.5445 - val_loss: 4925.2642 - val_acc: 0.5373\n",
      "Epoch 6/10\n",
      "4250/4250 [==============================] - 1s 260us/sample - loss: 1241.9420 - acc: 0.6228 - val_loss: 0.9051 - val_acc: 0.8000\n",
      "Epoch 7/10\n",
      "4250/4250 [==============================] - 1s 228us/sample - loss: 0.6857 - acc: 0.7824 - val_loss: 0.5886 - val_acc: 0.8000\n",
      "Epoch 8/10\n",
      "4250/4250 [==============================] - 1s 262us/sample - loss: 0.5728 - acc: 0.7906 - val_loss: 0.5315 - val_acc: 0.8000\n",
      "Epoch 9/10\n",
      "4250/4250 [==============================] - 1s 245us/sample - loss: 0.5313 - acc: 0.7974 - val_loss: 0.5105 - val_acc: 0.8000\n",
      "Epoch 10/10\n",
      "4250/4250 [==============================] - 1s 234us/sample - loss: 0.5105 - acc: 0.7993 - val_loss: 0.5041 - val_acc: 0.8000\n",
      "Epoch 146 out of 200\n",
      "Train on 4250 samples, validate on 750 samples\n",
      "Epoch 1/10\n",
      "4250/4250 [==============================] - 1s 274us/sample - loss: 0.5156 - acc: 0.7991 - val_loss: 0.5013 - val_acc: 0.8000\n",
      "Epoch 2/10\n",
      "4250/4250 [==============================] - 1s 288us/sample - loss: 0.5107 - acc: 0.7976 - val_loss: 0.5018 - val_acc: 0.8000\n",
      "Epoch 3/10\n",
      "4250/4250 [==============================] - 1s 270us/sample - loss: 0.5120 - acc: 0.7981 - val_loss: 0.5068 - val_acc: 0.8000\n",
      "Epoch 4/10\n",
      "4250/4250 [==============================] - 1s 257us/sample - loss: 0.5179 - acc: 0.7958 - val_loss: 0.5020 - val_acc: 0.8000\n",
      "Epoch 5/10\n",
      "4250/4250 [==============================] - 1s 244us/sample - loss: 0.5200 - acc: 0.7953 - val_loss: 0.5140 - val_acc: 0.8000\n",
      "Epoch 6/10\n",
      "4250/4250 [==============================] - 1s 242us/sample - loss: 0.5259 - acc: 0.7972 - val_loss: 0.5017 - val_acc: 0.8000\n",
      "Epoch 7/10\n",
      "4250/4250 [==============================] - 1s 236us/sample - loss: 0.5277 - acc: 0.7934 - val_loss: 0.6368 - val_acc: 0.7867\n",
      "Epoch 8/10\n",
      "4250/4250 [==============================] - 1s 249us/sample - loss: 0.6001 - acc: 0.7708 - val_loss: 0.5014 - val_acc: 0.8000\n",
      "Epoch 9/10\n",
      "4250/4250 [==============================] - 1s 283us/sample - loss: 0.6132 - acc: 0.7732 - val_loss: 0.6919 - val_acc: 0.6640\n",
      "Epoch 10/10\n",
      "4250/4250 [==============================] - ETA: 0s - loss: 0.5721 - acc: 0.776 - 1s 260us/sample - loss: 0.5755 - acc: 0.7753 - val_loss: 0.5643 - val_acc: 0.8000\n",
      "Epoch 147 out of 200\n",
      "Train on 4250 samples, validate on 750 samples\n",
      "Epoch 1/10\n",
      "4250/4250 [==============================] - 1s 275us/sample - loss: 0.7653 - acc: 0.7433 - val_loss: 0.6329 - val_acc: 0.8000\n",
      "Epoch 2/10\n",
      "4250/4250 [==============================] - 1s 270us/sample - loss: 24.9932 - acc: 0.6619 - val_loss: 174.4308 - val_acc: 0.4507\n",
      "Epoch 3/10\n",
      "4250/4250 [==============================] - 1s 225us/sample - loss: 107.9429 - acc: 0.5631 - val_loss: 6.7256 - val_acc: 0.6387\n",
      "Epoch 4/10\n",
      "4250/4250 [==============================] - 1s 235us/sample - loss: 419.5923 - acc: 0.5388 - val_loss: 224.8186 - val_acc: 0.5400\n",
      "Epoch 5/10\n",
      "4250/4250 [==============================] - 1s 228us/sample - loss: 454.4971 - acc: 0.5454 - val_loss: 68.3438 - val_acc: 0.5907\n",
      "Epoch 6/10\n",
      "4250/4250 [==============================] - 1s 297us/sample - loss: 897.6507 - acc: 0.5605 - val_loss: 20.8329 - val_acc: 0.4400\n",
      "Epoch 7/10\n",
      "4250/4250 [==============================] - 1s 275us/sample - loss: 6.5342 - acc: 0.7193 - val_loss: 1.0344 - val_acc: 0.8000\n",
      "Epoch 8/10\n",
      "4250/4250 [==============================] - 1s 226us/sample - loss: 1.0200 - acc: 0.7779 - val_loss: 0.7970 - val_acc: 0.7760\n",
      "Epoch 9/10\n",
      "4250/4250 [==============================] - 1s 211us/sample - loss: 0.8486 - acc: 0.7769 - val_loss: 0.7102 - val_acc: 0.7813\n",
      "Epoch 10/10\n",
      "4250/4250 [==============================] - 1s 201us/sample - loss: 0.6913 - acc: 0.7847 - val_loss: 0.6526 - val_acc: 0.8000\n",
      "Epoch 148 out of 200\n",
      "Train on 4250 samples, validate on 750 samples\n",
      "Epoch 1/10\n",
      "4250/4250 [==============================] - 1s 275us/sample - loss: 0.6702 - acc: 0.7755 - val_loss: 0.5567 - val_acc: 0.8000\n",
      "Epoch 2/10\n",
      "4250/4250 [==============================] - 1s 266us/sample - loss: 0.5638 - acc: 0.7852 - val_loss: 0.5407 - val_acc: 0.8000\n",
      "Epoch 3/10\n",
      "4250/4250 [==============================] - 1s 236us/sample - loss: 0.5985 - acc: 0.7835 - val_loss: 0.5067 - val_acc: 0.8000\n",
      "Epoch 4/10\n",
      "4250/4250 [==============================] - 1s 209us/sample - loss: 0.5308 - acc: 0.7936 - val_loss: 0.5055 - val_acc: 0.8000\n",
      "Epoch 5/10\n",
      "4250/4250 [==============================] - 1s 222us/sample - loss: 0.5372 - acc: 0.7908 - val_loss: 0.6399 - val_acc: 0.8000\n",
      "Epoch 6/10\n",
      "4250/4250 [==============================] - 1s 221us/sample - loss: 0.5378 - acc: 0.7904 - val_loss: 0.5005 - val_acc: 0.8000\n",
      "Epoch 7/10\n",
      "4250/4250 [==============================] - 1s 261us/sample - loss: 0.6562 - acc: 0.7720 - val_loss: 0.5594 - val_acc: 0.8000\n",
      "Epoch 8/10\n",
      "4250/4250 [==============================] - 1s 231us/sample - loss: 40.6376 - acc: 0.6209 - val_loss: 111.1516 - val_acc: 0.5427\n",
      "Epoch 9/10\n",
      "4250/4250 [==============================] - 1s 209us/sample - loss: 3769.8863 - acc: 0.5296 - val_loss: 1580.0218 - val_acc: 0.5373\n",
      "Epoch 10/10\n",
      "4250/4250 [==============================] - 1s 220us/sample - loss: 479.3461 - acc: 0.5600 - val_loss: 30.1203 - val_acc: 0.5707\n",
      "Epoch 149 out of 200\n",
      "Train on 4250 samples, validate on 750 samples\n",
      "Epoch 1/10\n",
      "4250/4250 [==============================] - 1s 296us/sample - loss: 4.4821 - acc: 0.7468 - val_loss: 0.7020 - val_acc: 0.8000\n",
      "Epoch 2/10\n",
      "4250/4250 [==============================] - 1s 264us/sample - loss: 0.6563 - acc: 0.7864 - val_loss: 0.5776 - val_acc: 0.8000\n",
      "Epoch 3/10\n",
      "4250/4250 [==============================] - 1s 298us/sample - loss: 0.5647 - acc: 0.7904 - val_loss: 0.5414 - val_acc: 0.8000\n",
      "Epoch 4/10\n",
      "4250/4250 [==============================] - 1s 273us/sample - loss: 0.5265 - acc: 0.7967 - val_loss: 0.5148 - val_acc: 0.8000\n",
      "Epoch 5/10\n",
      "4250/4250 [==============================] - 1s 251us/sample - loss: 0.5143 - acc: 0.8005 - val_loss: 0.5064 - val_acc: 0.8000\n",
      "Epoch 6/10\n",
      "4250/4250 [==============================] - 1s 268us/sample - loss: 0.5090 - acc: 0.7998 - val_loss: 0.5112 - val_acc: 0.8000\n",
      "Epoch 7/10\n",
      "4250/4250 [==============================] - 1s 253us/sample - loss: 0.5155 - acc: 0.7967 - val_loss: 0.5082 - val_acc: 0.8000\n",
      "Epoch 8/10\n",
      "4250/4250 [==============================] - 1s 240us/sample - loss: 0.5091 - acc: 0.7991 - val_loss: 0.5005 - val_acc: 0.8000\n",
      "Epoch 9/10\n",
      "4250/4250 [==============================] - 1s 220us/sample - loss: 0.5067 - acc: 0.7995 - val_loss: 0.5338 - val_acc: 0.8000\n",
      "Epoch 10/10\n",
      "4250/4250 [==============================] - 1s 235us/sample - loss: 0.5112 - acc: 0.7986 - val_loss: 0.5033 - val_acc: 0.8000\n",
      "Epoch 150 out of 200\n",
      "Train on 4250 samples, validate on 750 samples\n",
      "Epoch 1/10\n",
      "4250/4250 [==============================] - 1s 288us/sample - loss: 0.5145 - acc: 0.7993 - val_loss: 0.5052 - val_acc: 0.8000\n",
      "Epoch 2/10\n",
      "4250/4250 [==============================] - 1s 227us/sample - loss: 0.5171 - acc: 0.7951 - val_loss: 0.5110 - val_acc: 0.8000\n",
      "Epoch 3/10\n",
      "4250/4250 [==============================] - 1s 238us/sample - loss: 0.5128 - acc: 0.7955 - val_loss: 0.5189 - val_acc: 0.8000\n",
      "Epoch 4/10\n",
      "4250/4250 [==============================] - 1s 237us/sample - loss: 3.4472 - acc: 0.6746 - val_loss: 0.5439 - val_acc: 0.8000\n",
      "Epoch 5/10\n",
      "4250/4250 [==============================] - 1s 235us/sample - loss: 1.0419 - acc: 0.7485 - val_loss: 0.5028 - val_acc: 0.8000\n",
      "Epoch 6/10\n",
      "4250/4250 [==============================] - 1s 219us/sample - loss: 0.5150 - acc: 0.7993 - val_loss: 0.5003 - val_acc: 0.8000\n",
      "Epoch 7/10\n",
      "4250/4250 [==============================] - 1s 243us/sample - loss: 0.5165 - acc: 0.7974 - val_loss: 0.5227 - val_acc: 0.7973\n",
      "Epoch 8/10\n",
      "4250/4250 [==============================] - 1s 240us/sample - loss: 0.5373 - acc: 0.7911 - val_loss: 0.5072 - val_acc: 0.8000\n",
      "Epoch 9/10\n",
      "4250/4250 [==============================] - 1s 221us/sample - loss: 0.5150 - acc: 0.7981 - val_loss: 0.5012 - val_acc: 0.8000\n",
      "Epoch 10/10\n",
      "4250/4250 [==============================] - 1s 202us/sample - loss: 27.5961 - acc: 0.6626 - val_loss: 73.0092 - val_acc: 0.5400\n",
      "Epoch 151 out of 200\n",
      "Train on 4250 samples, validate on 750 samples\n",
      "Epoch 1/10\n",
      "4250/4250 [==============================] - 1s 261us/sample - loss: 402.5981 - acc: 0.5369 - val_loss: 421.1395 - val_acc: 0.4520\n",
      "Epoch 2/10\n",
      "4250/4250 [==============================] - 1s 244us/sample - loss: 206.2685 - acc: 0.5744 - val_loss: 6.0175 - val_acc: 0.4653\n",
      "Epoch 3/10\n",
      "4250/4250 [==============================] - 1s 217us/sample - loss: 2.1811 - acc: 0.7346 - val_loss: 0.6946 - val_acc: 0.7947\n",
      "Epoch 4/10\n",
      "4250/4250 [==============================] - 1s 230us/sample - loss: 3.0665 - acc: 0.6944 - val_loss: 8.0570 - val_acc: 0.6000\n",
      "Epoch 5/10\n",
      "4250/4250 [==============================] - 1s 231us/sample - loss: 176.2201 - acc: 0.5621 - val_loss: 227.2717 - val_acc: 0.5360\n",
      "Epoch 6/10\n",
      "4250/4250 [==============================] - 1s 238us/sample - loss: 18.1964 - acc: 0.6600 - val_loss: 0.9378 - val_acc: 0.8000\n",
      "Epoch 7/10\n",
      "4250/4250 [==============================] - 1s 290us/sample - loss: 0.7520 - acc: 0.7824 - val_loss: 0.6358 - val_acc: 0.8000\n",
      "Epoch 8/10\n",
      "4250/4250 [==============================] - 1s 226us/sample - loss: 0.6349 - acc: 0.7856 - val_loss: 0.5614 - val_acc: 0.7867\n",
      "Epoch 9/10\n",
      "4250/4250 [==============================] - 1s 220us/sample - loss: 0.5669 - acc: 0.7904 - val_loss: 0.5321 - val_acc: 0.8000\n",
      "Epoch 10/10\n",
      "4250/4250 [==============================] - 1s 219us/sample - loss: 0.6477 - acc: 0.7748 - val_loss: 0.5066 - val_acc: 0.8000\n",
      "Epoch 152 out of 200\n",
      "Train on 4250 samples, validate on 750 samples\n",
      "Epoch 1/10\n",
      "4250/4250 [==============================] - 1s 246us/sample - loss: 0.5673 - acc: 0.7816 - val_loss: 0.5438 - val_acc: 0.7987\n",
      "Epoch 2/10\n",
      "4250/4250 [==============================] - 1s 250us/sample - loss: 0.5521 - acc: 0.7882 - val_loss: 0.5116 - val_acc: 0.8000\n",
      "Epoch 3/10\n",
      "4250/4250 [==============================] - 1s 247us/sample - loss: 1.7317 - acc: 0.7193 - val_loss: 1.9729 - val_acc: 0.5027\n",
      "Epoch 4/10\n",
      "4250/4250 [==============================] - 1s 319us/sample - loss: 56.2310 - acc: 0.6165 - val_loss: 86.8947 - val_acc: 0.5360\n",
      "Epoch 5/10\n",
      "4250/4250 [==============================] - 1s 201us/sample - loss: 2858.8138 - acc: 0.5478 - val_loss: 2588.5404 - val_acc: 0.5387\n",
      "Epoch 6/10\n",
      "4250/4250 [==============================] - 1s 235us/sample - loss: 1845.9649 - acc: 0.5435 - val_loss: 59.0891 - val_acc: 0.5640\n",
      "Epoch 7/10\n",
      "4250/4250 [==============================] - 1s 187us/sample - loss: 71.9308 - acc: 0.5948 - val_loss: 3.9113 - val_acc: 0.7253\n",
      "Epoch 8/10\n",
      "4250/4250 [==============================] - 1s 189us/sample - loss: 1.9736 - acc: 0.7546 - val_loss: 0.6719 - val_acc: 0.8000\n",
      "Epoch 9/10\n",
      "4250/4250 [==============================] - 1s 189us/sample - loss: 0.6992 - acc: 0.7847 - val_loss: 0.6275 - val_acc: 0.8000\n",
      "Epoch 10/10\n",
      "4250/4250 [==============================] - 1s 158us/sample - loss: 0.7154 - acc: 0.7795 - val_loss: 0.5662 - val_acc: 0.8000\n",
      "Epoch 153 out of 200\n",
      "Train on 4250 samples, validate on 750 samples\n",
      "Epoch 1/10\n",
      "4250/4250 [==============================] - 1s 252us/sample - loss: 0.5929 - acc: 0.7854 - val_loss: 0.5290 - val_acc: 0.8000\n",
      "Epoch 2/10\n",
      "4250/4250 [==============================] - 1s 157us/sample - loss: 0.5334 - acc: 0.7948 - val_loss: 0.5158 - val_acc: 0.8000\n",
      "Epoch 3/10\n",
      "4250/4250 [==============================] - 1s 220us/sample - loss: 0.5109 - acc: 0.7974 - val_loss: 0.5025 - val_acc: 0.8000\n",
      "Epoch 4/10\n",
      "4250/4250 [==============================] - 1s 246us/sample - loss: 0.5069 - acc: 0.7991 - val_loss: 0.5032 - val_acc: 0.8000\n",
      "Epoch 5/10\n",
      "4250/4250 [==============================] - 1s 225us/sample - loss: 0.5050 - acc: 0.7995 - val_loss: 0.5175 - val_acc: 0.8000\n",
      "Epoch 6/10\n",
      "4250/4250 [==============================] - 1s 146us/sample - loss: 0.5076 - acc: 0.7998 - val_loss: 0.5129 - val_acc: 0.8000\n",
      "Epoch 7/10\n",
      "4250/4250 [==============================] - 1s 203us/sample - loss: 0.5484 - acc: 0.7899 - val_loss: 0.5072 - val_acc: 0.8000\n",
      "Epoch 8/10\n",
      "4250/4250 [==============================] - 1s 164us/sample - loss: 0.5614 - acc: 0.7826 - val_loss: 0.5034 - val_acc: 0.8000\n",
      "Epoch 9/10\n",
      "4250/4250 [==============================] - 1s 153us/sample - loss: 0.5269 - acc: 0.7922 - val_loss: 0.4998 - val_acc: 0.8000\n",
      "Epoch 10/10\n",
      "4250/4250 [==============================] - 1s 161us/sample - loss: 0.5115 - acc: 0.7981 - val_loss: 0.5110 - val_acc: 0.8000\n",
      "Epoch 154 out of 200\n",
      "Train on 4250 samples, validate on 750 samples\n",
      "Epoch 1/10\n",
      "4250/4250 [==============================] - 1s 165us/sample - loss: 0.5246 - acc: 0.7920 - val_loss: 0.5210 - val_acc: 0.7987\n",
      "Epoch 2/10\n",
      "4250/4250 [==============================] - 1s 174us/sample - loss: 0.5228 - acc: 0.7953 - val_loss: 0.5154 - val_acc: 0.7947\n",
      "Epoch 3/10\n",
      "4250/4250 [==============================] - 1s 159us/sample - loss: 0.6344 - acc: 0.7694 - val_loss: 1.2702 - val_acc: 0.4933\n",
      "Epoch 4/10\n",
      "4250/4250 [==============================] - 1s 175us/sample - loss: 38.1521 - acc: 0.5555 - val_loss: 156.7204 - val_acc: 0.5427\n",
      "Epoch 5/10\n",
      "4250/4250 [==============================] - 1s 163us/sample - loss: 1416.2181 - acc: 0.5346 - val_loss: 745.3255 - val_acc: 0.5373\n",
      "Epoch 6/10\n",
      "4250/4250 [==============================] - 1s 158us/sample - loss: 511.2997 - acc: 0.5758 - val_loss: 1.9671 - val_acc: 0.5667\n",
      "Epoch 7/10\n",
      "4250/4250 [==============================] - 1s 156us/sample - loss: 1.0049 - acc: 0.7706 - val_loss: 0.6823 - val_acc: 0.8000\n",
      "Epoch 8/10\n",
      "4250/4250 [==============================] - 1s 159us/sample - loss: 0.6859 - acc: 0.7842 - val_loss: 0.5590 - val_acc: 0.8000\n",
      "Epoch 9/10\n",
      "4250/4250 [==============================] - 1s 156us/sample - loss: 0.5910 - acc: 0.7871 - val_loss: 0.5445 - val_acc: 0.8000\n",
      "Epoch 10/10\n",
      "4250/4250 [==============================] - 1s 185us/sample - loss: 0.5537 - acc: 0.7932 - val_loss: 0.5089 - val_acc: 0.8000\n",
      "Epoch 155 out of 200\n",
      "Train on 4250 samples, validate on 750 samples\n",
      "Epoch 1/10\n",
      "4250/4250 [==============================] - 1s 178us/sample - loss: 0.5276 - acc: 0.7925 - val_loss: 0.5235 - val_acc: 0.7920\n",
      "Epoch 2/10\n",
      "4250/4250 [==============================] - 1s 165us/sample - loss: 0.5226 - acc: 0.7951 - val_loss: 0.5027 - val_acc: 0.8000\n",
      "Epoch 3/10\n",
      "4250/4250 [==============================] - 1s 151us/sample - loss: 0.5231 - acc: 0.7953 - val_loss: 0.5006 - val_acc: 0.8000\n",
      "Epoch 4/10\n",
      "4250/4250 [==============================] - 1s 143us/sample - loss: 0.5099 - acc: 0.7986 - val_loss: 0.5002 - val_acc: 0.8000\n",
      "Epoch 5/10\n",
      "4250/4250 [==============================] - 1s 135us/sample - loss: 0.5240 - acc: 0.7962 - val_loss: 0.5016 - val_acc: 0.8000\n",
      "Epoch 6/10\n",
      "4250/4250 [==============================] - 1s 149us/sample - loss: 0.5698 - acc: 0.7831 - val_loss: 1.3632 - val_acc: 0.4973\n",
      "Epoch 7/10\n",
      "4250/4250 [==============================] - 1s 139us/sample - loss: 0.6151 - acc: 0.7640 - val_loss: 0.5133 - val_acc: 0.8000\n",
      "Epoch 8/10\n",
      "4250/4250 [==============================] - 1s 233us/sample - loss: 0.5283 - acc: 0.7894 - val_loss: 0.5003 - val_acc: 0.8000\n",
      "Epoch 9/10\n",
      "4250/4250 [==============================] - 1s 147us/sample - loss: 0.5578 - acc: 0.7826 - val_loss: 0.5156 - val_acc: 0.7947\n",
      "Epoch 10/10\n",
      "4250/4250 [==============================] - 1s 204us/sample - loss: 0.6182 - acc: 0.7805 - val_loss: 3.1956 - val_acc: 0.5960\n",
      "Epoch 156 out of 200\n",
      "Train on 4250 samples, validate on 750 samples\n",
      "Epoch 1/10\n",
      "4250/4250 [==============================] - 1s 190us/sample - loss: 2129.8675 - acc: 0.5856 - val_loss: 167.5012 - val_acc: 0.5587\n",
      "Epoch 2/10\n",
      "4250/4250 [==============================] - 1s 157us/sample - loss: 659.1960 - acc: 0.5539 - val_loss: 92.3043 - val_acc: 0.4400\n",
      "Epoch 3/10\n",
      "4250/4250 [==============================] - 1s 146us/sample - loss: 6.9662 - acc: 0.6998 - val_loss: 0.6652 - val_acc: 0.7787\n",
      "Epoch 4/10\n",
      "4250/4250 [==============================] - 1s 137us/sample - loss: 0.6367 - acc: 0.7866 - val_loss: 0.5575 - val_acc: 0.8000\n",
      "Epoch 5/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4250/4250 [==============================] - 1s 137us/sample - loss: 0.5511 - acc: 0.7934 - val_loss: 0.5419 - val_acc: 0.8000\n",
      "Epoch 6/10\n",
      "4250/4250 [==============================] - 1s 248us/sample - loss: 0.5229 - acc: 0.7965 - val_loss: 0.5214 - val_acc: 0.8000\n",
      "Epoch 7/10\n",
      "4250/4250 [==============================] - 1s 180us/sample - loss: 0.5154 - acc: 0.7991 - val_loss: 0.5011 - val_acc: 0.8000\n",
      "Epoch 8/10\n",
      "4250/4250 [==============================] - 1s 194us/sample - loss: 0.5073 - acc: 0.8000 - val_loss: 0.5012 - val_acc: 0.8000\n",
      "Epoch 9/10\n",
      "4250/4250 [==============================] - 1s 142us/sample - loss: 0.5114 - acc: 0.7974 - val_loss: 0.5001 - val_acc: 0.8000\n",
      "Epoch 10/10\n",
      "4250/4250 [==============================] - 1s 161us/sample - loss: 0.5100 - acc: 0.7988 - val_loss: 0.5345 - val_acc: 0.8000\n",
      "Epoch 157 out of 200\n",
      "Train on 4250 samples, validate on 750 samples\n",
      "Epoch 1/10\n",
      "4250/4250 [==============================] - 1s 142us/sample - loss: 0.5150 - acc: 0.7974 - val_loss: 0.5005 - val_acc: 0.8000\n",
      "Epoch 2/10\n",
      "4250/4250 [==============================] - 1s 155us/sample - loss: 0.5141 - acc: 0.7974 - val_loss: 0.5000 - val_acc: 0.8000\n",
      "Epoch 3/10\n",
      "4250/4250 [==============================] - 1s 139us/sample - loss: 0.5128 - acc: 0.7991 - val_loss: 0.5310 - val_acc: 0.7853\n",
      "Epoch 4/10\n",
      "4250/4250 [==============================] - 1s 140us/sample - loss: 0.5258 - acc: 0.7936 - val_loss: 0.5063 - val_acc: 0.8000\n",
      "Epoch 5/10\n",
      "4250/4250 [==============================] - 1s 141us/sample - loss: 0.5356 - acc: 0.7894 - val_loss: 0.5409 - val_acc: 0.7787\n",
      "Epoch 6/10\n",
      "4250/4250 [==============================] - 1s 228us/sample - loss: 0.5519 - acc: 0.7840 - val_loss: 0.5019 - val_acc: 0.8000\n",
      "Epoch 7/10\n",
      "4250/4250 [==============================] - 1s 281us/sample - loss: 0.5191 - acc: 0.7953 - val_loss: 0.5217 - val_acc: 0.7987\n",
      "Epoch 8/10\n",
      "4250/4250 [==============================] - 1s 156us/sample - loss: 0.5213 - acc: 0.7965 - val_loss: 0.5615 - val_acc: 0.8000\n",
      "Epoch 9/10\n",
      "4250/4250 [==============================] - 1s 247us/sample - loss: 0.5298 - acc: 0.7934 - val_loss: 0.5023 - val_acc: 0.8000\n",
      "Epoch 10/10\n",
      "4250/4250 [==============================] - 1s 211us/sample - loss: 0.5202 - acc: 0.7960 - val_loss: 0.5017 - val_acc: 0.8000\n",
      "Epoch 158 out of 200\n",
      "Train on 4250 samples, validate on 750 samples\n",
      "Epoch 1/10\n",
      "4250/4250 [==============================] - 1s 225us/sample - loss: 0.5241 - acc: 0.7911 - val_loss: 0.5123 - val_acc: 0.8000\n",
      "Epoch 2/10\n",
      "4250/4250 [==============================] - 1s 168us/sample - loss: 0.5991 - acc: 0.7828 - val_loss: 1.1625 - val_acc: 0.7347\n",
      "Epoch 3/10\n",
      "4250/4250 [==============================] - 1s 160us/sample - loss: 887.8527 - acc: 0.5605 - val_loss: 1258.8296 - val_acc: 0.5387\n",
      "Epoch 4/10\n",
      "4250/4250 [==============================] - 1s 169us/sample - loss: 1495.9522 - acc: 0.5428 - val_loss: 711.0960 - val_acc: 0.5400\n",
      "Epoch 5/10\n",
      "4250/4250 [==============================] - 1s 153us/sample - loss: 329.3456 - acc: 0.5854 - val_loss: 2.3873 - val_acc: 0.5280\n",
      "Epoch 6/10\n",
      "4250/4250 [==============================] - 1s 141us/sample - loss: 1.5060 - acc: 0.7642 - val_loss: 0.8198 - val_acc: 0.8000\n",
      "Epoch 7/10\n",
      "4250/4250 [==============================] - 1s 151us/sample - loss: 0.7116 - acc: 0.7894 - val_loss: 0.6031 - val_acc: 0.8000\n",
      "Epoch 8/10\n",
      "4250/4250 [==============================] - 1s 153us/sample - loss: 0.5911 - acc: 0.7904 - val_loss: 0.5394 - val_acc: 0.8000\n",
      "Epoch 9/10\n",
      "4250/4250 [==============================] - 1s 163us/sample - loss: 0.5516 - acc: 0.7939 - val_loss: 0.5292 - val_acc: 0.8000\n",
      "Epoch 10/10\n",
      "4250/4250 [==============================] - 1s 173us/sample - loss: 0.5469 - acc: 0.7904 - val_loss: 0.5339 - val_acc: 0.8000\n",
      "Epoch 159 out of 200\n",
      "Train on 4250 samples, validate on 750 samples\n",
      "Epoch 1/10\n",
      "4250/4250 [==============================] - 1s 171us/sample - loss: 0.5123 - acc: 0.7988 - val_loss: 0.5185 - val_acc: 0.8000\n",
      "Epoch 2/10\n",
      "4250/4250 [==============================] - 1s 150us/sample - loss: 0.5130 - acc: 0.7981 - val_loss: 0.5012 - val_acc: 0.8000\n",
      "Epoch 3/10\n",
      "4250/4250 [==============================] - 1s 144us/sample - loss: 0.5111 - acc: 0.7979 - val_loss: 0.5309 - val_acc: 0.8000\n",
      "Epoch 4/10\n",
      "4250/4250 [==============================] - 1s 143us/sample - loss: 0.5170 - acc: 0.7967 - val_loss: 0.5221 - val_acc: 0.7947\n",
      "Epoch 5/10\n",
      "4250/4250 [==============================] - 1s 140us/sample - loss: 0.5223 - acc: 0.7920 - val_loss: 0.5045 - val_acc: 0.8000\n",
      "Epoch 6/10\n",
      "4250/4250 [==============================] - 1s 145us/sample - loss: 0.5682 - acc: 0.7821 - val_loss: 0.5232 - val_acc: 0.7947\n",
      "Epoch 7/10\n",
      "4250/4250 [==============================] - 1s 144us/sample - loss: 0.5224 - acc: 0.7927 - val_loss: 0.5225 - val_acc: 0.7853\n",
      "Epoch 8/10\n",
      "4250/4250 [==============================] - 1s 139us/sample - loss: 0.5154 - acc: 0.7986 - val_loss: 0.5017 - val_acc: 0.8000\n",
      "Epoch 9/10\n",
      "4250/4250 [==============================] - 1s 144us/sample - loss: 0.5265 - acc: 0.7932 - val_loss: 0.5221 - val_acc: 0.7867\n",
      "Epoch 10/10\n",
      "4250/4250 [==============================] - 1s 155us/sample - loss: 3.4361 - acc: 0.6600 - val_loss: 1.7296 - val_acc: 0.7280\n",
      "Epoch 160 out of 200\n",
      "Train on 4250 samples, validate on 750 samples\n",
      "Epoch 1/10\n",
      "4250/4250 [==============================] - 1s 256us/sample - loss: 51.9320 - acc: 0.5621 - val_loss: 199.0204 - val_acc: 0.4467\n",
      "Epoch 2/10\n",
      "4250/4250 [==============================] - 1s 163us/sample - loss: 668.8181 - acc: 0.5405 - val_loss: 129.4186 - val_acc: 0.5587\n",
      "Epoch 3/10\n",
      "4250/4250 [==============================] - 1s 170us/sample - loss: 101.7346 - acc: 0.5609 - val_loss: 195.3783 - val_acc: 0.5413\n",
      "Epoch 4/10\n",
      "4250/4250 [==============================] - 1s 141us/sample - loss: 726.3643 - acc: 0.5473 - val_loss: 93.8927 - val_acc: 0.4320\n",
      "Epoch 5/10\n",
      "4250/4250 [==============================] - 1s 153us/sample - loss: 818.9374 - acc: 0.5529 - val_loss: 153.9353 - val_acc: 0.5613\n",
      "Epoch 6/10\n",
      "4250/4250 [==============================] - 1s 156us/sample - loss: 120.3770 - acc: 0.6247 - val_loss: 1.6027 - val_acc: 0.8000\n",
      "Epoch 7/10\n",
      "4250/4250 [==============================] - 1s 140us/sample - loss: 1.5473 - acc: 0.7696 - val_loss: 1.1094 - val_acc: 0.8000\n",
      "Epoch 8/10\n",
      "4250/4250 [==============================] - 1s 147us/sample - loss: 1.0201 - acc: 0.7765 - val_loss: 0.9131 - val_acc: 0.8000\n",
      "Epoch 9/10\n",
      "4250/4250 [==============================] - 1s 177us/sample - loss: 0.8908 - acc: 0.7795 - val_loss: 0.8294 - val_acc: 0.8000\n",
      "Epoch 10/10\n",
      "4250/4250 [==============================] - 1s 148us/sample - loss: 1.1521 - acc: 0.7685 - val_loss: 0.6518 - val_acc: 0.7693\n",
      "Epoch 161 out of 200\n",
      "Train on 4250 samples, validate on 750 samples\n",
      "Epoch 1/10\n",
      "4250/4250 [==============================] - 1s 234us/sample - loss: 0.6275 - acc: 0.7889 - val_loss: 0.5629 - val_acc: 0.8000\n",
      "Epoch 2/10\n",
      "4250/4250 [==============================] - 1s 190us/sample - loss: 0.5605 - acc: 0.7906 - val_loss: 0.5350 - val_acc: 0.8000\n",
      "Epoch 3/10\n",
      "4250/4250 [==============================] - 1s 192us/sample - loss: 0.5309 - acc: 0.7976 - val_loss: 0.5057 - val_acc: 0.8000\n",
      "Epoch 4/10\n",
      "4250/4250 [==============================] - 1s 155us/sample - loss: 0.5122 - acc: 0.7988 - val_loss: 0.5043 - val_acc: 0.8000\n",
      "Epoch 5/10\n",
      "4250/4250 [==============================] - 1s 159us/sample - loss: 0.5103 - acc: 0.7984 - val_loss: 0.5004 - val_acc: 0.8000\n",
      "Epoch 6/10\n",
      "4250/4250 [==============================] - 1s 214us/sample - loss: 0.5060 - acc: 0.8000 - val_loss: 0.5027 - val_acc: 0.8000\n",
      "Epoch 7/10\n",
      "4250/4250 [==============================] - 1s 165us/sample - loss: 0.5679 - acc: 0.7814 - val_loss: 0.5077 - val_acc: 0.8000\n",
      "Epoch 8/10\n",
      "4250/4250 [==============================] - 1s 154us/sample - loss: 0.5476 - acc: 0.7866 - val_loss: 0.5064 - val_acc: 0.8000\n",
      "Epoch 9/10\n",
      "4250/4250 [==============================] - 1s 156us/sample - loss: 0.5329 - acc: 0.7922 - val_loss: 0.5693 - val_acc: 0.8000\n",
      "Epoch 10/10\n",
      "4250/4250 [==============================] - 1s 183us/sample - loss: 0.5303 - acc: 0.7920 - val_loss: 0.5130 - val_acc: 0.8000\n",
      "Epoch 162 out of 200\n",
      "Train on 4250 samples, validate on 750 samples\n",
      "Epoch 1/10\n",
      "4250/4250 [==============================] - 1s 148us/sample - loss: 0.6608 - acc: 0.7739 - val_loss: 0.6161 - val_acc: 0.8000\n",
      "Epoch 2/10\n",
      "4250/4250 [==============================] - 1s 218us/sample - loss: 850.0356 - acc: 0.6014 - val_loss: 813.3092 - val_acc: 0.5400\n",
      "Epoch 3/10\n",
      "4250/4250 [==============================] - 1s 202us/sample - loss: 596.9987 - acc: 0.5419 - val_loss: 82.2189 - val_acc: 0.5520\n",
      "Epoch 4/10\n",
      "4250/4250 [==============================] - 1s 161us/sample - loss: 15.2855 - acc: 0.6779 - val_loss: 0.6132 - val_acc: 0.7987\n",
      "Epoch 5/10\n",
      "4250/4250 [==============================] - 1s 151us/sample - loss: 0.6037 - acc: 0.7906 - val_loss: 0.5499 - val_acc: 0.8000\n",
      "Epoch 6/10\n",
      "4250/4250 [==============================] - 1s 145us/sample - loss: 0.5382 - acc: 0.7941 - val_loss: 0.5209 - val_acc: 0.8000\n",
      "Epoch 7/10\n",
      "4250/4250 [==============================] - ETA: 0s - loss: 0.5189 - acc: 0.798 - 1s 170us/sample - loss: 0.5181 - acc: 0.7991 - val_loss: 0.5112 - val_acc: 0.8000\n",
      "Epoch 8/10\n",
      "4250/4250 [==============================] - 1s 145us/sample - loss: 0.5178 - acc: 0.7965 - val_loss: 0.5111 - val_acc: 0.8000\n",
      "Epoch 9/10\n",
      "4250/4250 [==============================] - 1s 173us/sample - loss: 0.5102 - acc: 0.7998 - val_loss: 0.5173 - val_acc: 0.8000\n",
      "Epoch 10/10\n",
      "4250/4250 [==============================] - 1s 168us/sample - loss: 0.5069 - acc: 0.7995 - val_loss: 0.5018 - val_acc: 0.8000\n",
      "Epoch 163 out of 200\n",
      "Train on 4250 samples, validate on 750 samples\n",
      "Epoch 1/10\n",
      "4250/4250 [==============================] - 1s 205us/sample - loss: 0.5052 - acc: 0.7988 - val_loss: 0.5192 - val_acc: 0.8000\n",
      "Epoch 2/10\n",
      "4250/4250 [==============================] - 1s 214us/sample - loss: 0.5094 - acc: 0.7979 - val_loss: 0.5109 - val_acc: 0.8000\n",
      "Epoch 3/10\n",
      "4250/4250 [==============================] - 1s 187us/sample - loss: 0.5129 - acc: 0.7946 - val_loss: 0.5012 - val_acc: 0.8000\n",
      "Epoch 4/10\n",
      "4250/4250 [==============================] - 1s 167us/sample - loss: 0.5158 - acc: 0.7967 - val_loss: 0.5176 - val_acc: 0.7960\n",
      "Epoch 5/10\n",
      "4250/4250 [==============================] - 1s 161us/sample - loss: 0.5261 - acc: 0.7936 - val_loss: 0.5378 - val_acc: 0.7747\n",
      "Epoch 6/10\n",
      "4250/4250 [==============================] - 1s 164us/sample - loss: 0.5234 - acc: 0.7948 - val_loss: 0.5123 - val_acc: 0.8000\n",
      "Epoch 7/10\n",
      "4250/4250 [==============================] - 1s 158us/sample - loss: 1.2100 - acc: 0.7176 - val_loss: 1.1307 - val_acc: 0.7640\n",
      "Epoch 8/10\n",
      "4250/4250 [==============================] - 1s 158us/sample - loss: 596.3134 - acc: 0.5607 - val_loss: 1394.4125 - val_acc: 0.5373\n",
      "Epoch 9/10\n",
      "4250/4250 [==============================] - 1s 168us/sample - loss: 1781.4322 - acc: 0.5456 - val_loss: 22.7186 - val_acc: 0.5480\n",
      "Epoch 10/10\n",
      "4250/4250 [==============================] - 1s 157us/sample - loss: 46.8073 - acc: 0.5656 - val_loss: 10.6186 - val_acc: 0.6200\n",
      "Epoch 164 out of 200\n",
      "Train on 4250 samples, validate on 750 samples\n",
      "Epoch 1/10\n",
      "4250/4250 [==============================] - 1s 252us/sample - loss: 2.2573 - acc: 0.7605 - val_loss: 0.6938 - val_acc: 0.7987\n",
      "Epoch 2/10\n",
      "4250/4250 [==============================] - 1s 212us/sample - loss: 0.6933 - acc: 0.7864 - val_loss: 0.6215 - val_acc: 0.8000\n",
      "Epoch 3/10\n",
      "4250/4250 [==============================] - 1s 189us/sample - loss: 0.5915 - acc: 0.7878 - val_loss: 0.5461 - val_acc: 0.8000\n",
      "Epoch 4/10\n",
      "4250/4250 [==============================] - 1s 162us/sample - loss: 0.5646 - acc: 0.7885 - val_loss: 0.5117 - val_acc: 0.8000\n",
      "Epoch 5/10\n",
      "4250/4250 [==============================] - 1s 157us/sample - loss: 0.5281 - acc: 0.7948 - val_loss: 0.5101 - val_acc: 0.8000\n",
      "Epoch 6/10\n",
      "4250/4250 [==============================] - 1s 159us/sample - loss: 0.5150 - acc: 0.7969 - val_loss: 0.5118 - val_acc: 0.8000\n",
      "Epoch 7/10\n",
      "4250/4250 [==============================] - 1s 204us/sample - loss: 0.5166 - acc: 0.7953 - val_loss: 0.5163 - val_acc: 0.7987\n",
      "Epoch 8/10\n",
      "4250/4250 [==============================] - 1s 232us/sample - loss: 0.5251 - acc: 0.7922 - val_loss: 0.5158 - val_acc: 0.7947\n",
      "Epoch 9/10\n",
      "4250/4250 [==============================] - 1s 165us/sample - loss: 0.5586 - acc: 0.7807 - val_loss: 0.5056 - val_acc: 0.8000\n",
      "Epoch 10/10\n",
      "4250/4250 [==============================] - 1s 153us/sample - loss: 0.5731 - acc: 0.7852 - val_loss: 0.5025 - val_acc: 0.8000\n",
      "Epoch 165 out of 200\n",
      "Train on 4250 samples, validate on 750 samples\n",
      "Epoch 1/10\n",
      "4250/4250 [==============================] - 1s 160us/sample - loss: 0.5557 - acc: 0.7824 - val_loss: 0.5016 - val_acc: 0.8000\n",
      "Epoch 2/10\n",
      "4250/4250 [==============================] - 1s 173us/sample - loss: 0.5137 - acc: 0.7979 - val_loss: 0.5007 - val_acc: 0.8000\n",
      "Epoch 3/10\n",
      "4250/4250 [==============================] - 1s 155us/sample - loss: 0.5183 - acc: 0.7936 - val_loss: 0.5003 - val_acc: 0.8000\n",
      "Epoch 4/10\n",
      "4250/4250 [==============================] - 1s 179us/sample - loss: 0.5582 - acc: 0.7838 - val_loss: 0.5316 - val_acc: 0.7853\n",
      "Epoch 5/10\n",
      "4250/4250 [==============================] - 1s 161us/sample - loss: 1.2037 - acc: 0.7292 - val_loss: 0.6324 - val_acc: 0.8000\n",
      "Epoch 6/10\n",
      "4250/4250 [==============================] - 1s 168us/sample - loss: 2.5872 - acc: 0.6769 - val_loss: 2.0047 - val_acc: 0.6613\n",
      "Epoch 7/10\n",
      "4250/4250 [==============================] - 1s 193us/sample - loss: 633.2427 - acc: 0.5320 - val_loss: 142.0468 - val_acc: 0.5440\n",
      "Epoch 8/10\n",
      "4250/4250 [==============================] - 1s 159us/sample - loss: 2567.4847 - acc: 0.5414 - val_loss: 11.1886 - val_acc: 0.6213\n",
      "Epoch 9/10\n",
      "4250/4250 [==============================] - 1s 270us/sample - loss: 109.6626 - acc: 0.5725 - val_loss: 7.6121 - val_acc: 0.6360\n",
      "Epoch 10/10\n",
      "4250/4250 [==============================] - 1s 186us/sample - loss: 1.3981 - acc: 0.7654 - val_loss: 0.8621 - val_acc: 0.8000\n",
      "Epoch 166 out of 200\n",
      "Train on 4250 samples, validate on 750 samples\n",
      "Epoch 1/10\n",
      "4250/4250 [==============================] - 1s 196us/sample - loss: 0.7847 - acc: 0.7816 - val_loss: 0.6664 - val_acc: 0.7560\n",
      "Epoch 2/10\n",
      "4250/4250 [==============================] - 1s 181us/sample - loss: 0.6343 - acc: 0.7882 - val_loss: 0.5675 - val_acc: 0.8000\n",
      "Epoch 3/10\n",
      "4250/4250 [==============================] - 1s 166us/sample - loss: 0.5727 - acc: 0.7911 - val_loss: 0.5310 - val_acc: 0.7853\n",
      "Epoch 4/10\n",
      "4250/4250 [==============================] - 1s 238us/sample - loss: 0.5200 - acc: 0.7962 - val_loss: 0.5086 - val_acc: 0.8000\n",
      "Epoch 5/10\n",
      "4250/4250 [==============================] - 1s 171us/sample - loss: 0.5240 - acc: 0.7925 - val_loss: 0.5301 - val_acc: 0.7947\n",
      "Epoch 6/10\n",
      "4250/4250 [==============================] - 1s 192us/sample - loss: 0.5068 - acc: 0.7993 - val_loss: 0.5007 - val_acc: 0.8000\n",
      "Epoch 7/10\n",
      "4250/4250 [==============================] - 1s 193us/sample - loss: 0.5096 - acc: 0.7988 - val_loss: 0.5001 - val_acc: 0.8000\n",
      "Epoch 8/10\n",
      "4250/4250 [==============================] - 1s 254us/sample - loss: 0.5106 - acc: 0.7974 - val_loss: 0.5008 - val_acc: 0.8000\n",
      "Epoch 9/10\n",
      "4250/4250 [==============================] - 1s 328us/sample - loss: 0.5091 - acc: 0.7995 - val_loss: 0.5014 - val_acc: 0.8000\n",
      "Epoch 10/10\n",
      "4250/4250 [==============================] - 1s 279us/sample - loss: 0.5139 - acc: 0.7969 - val_loss: 0.5011 - val_acc: 0.8000\n",
      "Epoch 167 out of 200\n",
      "Train on 4250 samples, validate on 750 samples\n",
      "Epoch 1/10\n",
      "4250/4250 [==============================] - 2s 365us/sample - loss: 0.5233 - acc: 0.7960 - val_loss: 0.5422 - val_acc: 0.7680\n",
      "Epoch 2/10\n",
      "4250/4250 [==============================] - 1s 312us/sample - loss: 0.5215 - acc: 0.7944 - val_loss: 0.5048 - val_acc: 0.8000\n",
      "Epoch 3/10\n",
      "4250/4250 [==============================] - 2s 359us/sample - loss: 0.5235 - acc: 0.7929 - val_loss: 0.5986 - val_acc: 0.7280\n",
      "Epoch 4/10\n",
      "4250/4250 [==============================] - 1s 279us/sample - loss: 8.8884 - acc: 0.6508 - val_loss: 8.8561 - val_acc: 0.5560\n",
      "Epoch 5/10\n",
      "4250/4250 [==============================] - 1s 284us/sample - loss: 339.3081 - acc: 0.5506 - val_loss: 285.2893 - val_acc: 0.4627\n",
      "Epoch 6/10\n",
      "4250/4250 [==============================] - 1s 212us/sample - loss: 1147.1292 - acc: 0.5409 - val_loss: 427.4306 - val_acc: 0.5387\n",
      "Epoch 7/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4250/4250 [==============================] - 1s 235us/sample - loss: 52.0276 - acc: 0.6678 - val_loss: 0.9217 - val_acc: 0.8000\n",
      "Epoch 8/10\n",
      "4250/4250 [==============================] - 1s 269us/sample - loss: 0.7637 - acc: 0.7819 - val_loss: 0.6996 - val_acc: 0.8000\n",
      "Epoch 9/10\n",
      "4250/4250 [==============================] - 1s 199us/sample - loss: 0.6281 - acc: 0.7911 - val_loss: 0.5663 - val_acc: 0.7987\n",
      "Epoch 10/10\n",
      "4250/4250 [==============================] - 1s 202us/sample - loss: 0.5582 - acc: 0.7939 - val_loss: 0.5348 - val_acc: 0.8000\n",
      "Epoch 168 out of 200\n",
      "Train on 4250 samples, validate on 750 samples\n",
      "Epoch 1/10\n",
      "4250/4250 [==============================] - 1s 233us/sample - loss: 0.5233 - acc: 0.7944 - val_loss: 0.5029 - val_acc: 0.8000\n",
      "Epoch 2/10\n",
      "4250/4250 [==============================] - 1s 275us/sample - loss: 0.5229 - acc: 0.7958 - val_loss: 0.5127 - val_acc: 0.8000\n",
      "Epoch 3/10\n",
      "4250/4250 [==============================] - 1s 218us/sample - loss: 0.5200 - acc: 0.7958 - val_loss: 0.5979 - val_acc: 0.8000\n",
      "Epoch 4/10\n",
      "4250/4250 [==============================] - 1s 243us/sample - loss: 0.5182 - acc: 0.7976 - val_loss: 0.5070 - val_acc: 0.8000\n",
      "Epoch 5/10\n",
      "4250/4250 [==============================] - 1s 183us/sample - loss: 0.5400 - acc: 0.7887 - val_loss: 0.6259 - val_acc: 0.8000\n",
      "Epoch 6/10\n",
      "4250/4250 [==============================] - 1s 168us/sample - loss: 0.5366 - acc: 0.7915 - val_loss: 0.5598 - val_acc: 0.8000\n",
      "Epoch 7/10\n",
      "4250/4250 [==============================] - 1s 184us/sample - loss: 1.4409 - acc: 0.7287 - val_loss: 12.4675 - val_acc: 0.4307\n",
      "Epoch 8/10\n",
      "4250/4250 [==============================] - 1s 174us/sample - loss: 27.5410 - acc: 0.5871 - val_loss: 6.8711 - val_acc: 0.6027\n",
      "Epoch 9/10\n",
      "4250/4250 [==============================] - 1s 188us/sample - loss: 1288.5496 - acc: 0.5696 - val_loss: 5161.9931 - val_acc: 0.5360\n",
      "Epoch 10/10\n",
      "4250/4250 [==============================] - 1s 174us/sample - loss: 1499.6875 - acc: 0.5409 - val_loss: 11.5286 - val_acc: 0.6493\n",
      "Epoch 169 out of 200\n",
      "Train on 4250 samples, validate on 750 samples\n",
      "Epoch 1/10\n",
      "4250/4250 [==============================] - 1s 168us/sample - loss: 14.0669 - acc: 0.6755 - val_loss: 0.7305 - val_acc: 0.8000\n",
      "Epoch 2/10\n",
      "4250/4250 [==============================] - 1s 199us/sample - loss: 0.7278 - acc: 0.7840 - val_loss: 0.7498 - val_acc: 0.8000\n",
      "Epoch 3/10\n",
      "4250/4250 [==============================] - 1s 172us/sample - loss: 0.5949 - acc: 0.7934 - val_loss: 0.5516 - val_acc: 0.8000\n",
      "Epoch 4/10\n",
      "4250/4250 [==============================] - 1s 173us/sample - loss: 0.5593 - acc: 0.7904 - val_loss: 0.5226 - val_acc: 0.7960\n",
      "Epoch 5/10\n",
      "4250/4250 [==============================] - 1s 168us/sample - loss: 0.5184 - acc: 0.7976 - val_loss: 0.5419 - val_acc: 0.7853\n",
      "Epoch 6/10\n",
      "4250/4250 [==============================] - 1s 178us/sample - loss: 0.5180 - acc: 0.7955 - val_loss: 0.5090 - val_acc: 0.8000\n",
      "Epoch 7/10\n",
      "4250/4250 [==============================] - 1s 183us/sample - loss: 0.5122 - acc: 0.7993 - val_loss: 0.5016 - val_acc: 0.8000\n",
      "Epoch 8/10\n",
      "4250/4250 [==============================] - 1s 209us/sample - loss: 0.5100 - acc: 0.7976 - val_loss: 0.5004 - val_acc: 0.8000\n",
      "Epoch 9/10\n",
      "4250/4250 [==============================] - 1s 261us/sample - loss: 0.5115 - acc: 0.7998 - val_loss: 0.5033 - val_acc: 0.8000\n",
      "Epoch 10/10\n",
      "4250/4250 [==============================] - 1s 238us/sample - loss: 0.5185 - acc: 0.7936 - val_loss: 0.5034 - val_acc: 0.8000\n",
      "Epoch 170 out of 200\n",
      "Train on 4250 samples, validate on 750 samples\n",
      "Epoch 1/10\n",
      "4250/4250 [==============================] - 1s 136us/sample - loss: 0.5537 - acc: 0.7833 - val_loss: 0.5100 - val_acc: 0.8000\n",
      "Epoch 2/10\n",
      "4250/4250 [==============================] - 1s 230us/sample - loss: 0.5349 - acc: 0.7864 - val_loss: 0.5393 - val_acc: 0.7947\n",
      "Epoch 3/10\n",
      "4250/4250 [==============================] - 1s 200us/sample - loss: 0.5488 - acc: 0.7864 - val_loss: 0.5312 - val_acc: 0.8000\n",
      "Epoch 4/10\n",
      "4250/4250 [==============================] - 1s 190us/sample - loss: 11.0142 - acc: 0.6666 - val_loss: 42.4717 - val_acc: 0.5467\n",
      "Epoch 5/10\n",
      "4250/4250 [==============================] - 1s 148us/sample - loss: 4897.1639 - acc: 0.5339 - val_loss: 314.9855 - val_acc: 0.5427\n",
      "Epoch 6/10\n",
      "4250/4250 [==============================] - 1s 152us/sample - loss: 362.7978 - acc: 0.5727 - val_loss: 3.4918 - val_acc: 0.7440\n",
      "Epoch 7/10\n",
      "4250/4250 [==============================] - 1s 150us/sample - loss: 1.4921 - acc: 0.7555 - val_loss: 0.7760 - val_acc: 0.8000\n",
      "Epoch 8/10\n",
      "4250/4250 [==============================] - 1s 140us/sample - loss: 0.7218 - acc: 0.7786 - val_loss: 0.7734 - val_acc: 0.8000\n",
      "Epoch 9/10\n",
      "4250/4250 [==============================] - 1s 249us/sample - loss: 0.6173 - acc: 0.7871 - val_loss: 0.5754 - val_acc: 0.7973\n",
      "Epoch 10/10\n",
      "4250/4250 [==============================] - 1s 158us/sample - loss: 0.5269 - acc: 0.7951 - val_loss: 0.5079 - val_acc: 0.8000\n",
      "Epoch 171 out of 200\n",
      "Train on 4250 samples, validate on 750 samples\n",
      "Epoch 1/10\n",
      "4250/4250 [==============================] - 1s 136us/sample - loss: 0.5122 - acc: 0.7979 - val_loss: 0.5068 - val_acc: 0.8000\n",
      "Epoch 2/10\n",
      "4250/4250 [==============================] - 1s 151us/sample - loss: 0.5072 - acc: 0.8000 - val_loss: 0.5010 - val_acc: 0.8000\n",
      "Epoch 3/10\n",
      "4250/4250 [==============================] - 1s 144us/sample - loss: 0.5051 - acc: 0.7998 - val_loss: 0.5002 - val_acc: 0.8000\n",
      "Epoch 4/10\n",
      "4250/4250 [==============================] - 1s 137us/sample - loss: 0.5068 - acc: 0.7993 - val_loss: 0.5004 - val_acc: 0.8000\n",
      "Epoch 5/10\n",
      "4250/4250 [==============================] - 1s 141us/sample - loss: 0.5064 - acc: 0.8000 - val_loss: 0.5086 - val_acc: 0.8000\n",
      "Epoch 6/10\n",
      "4250/4250 [==============================] - 1s 141us/sample - loss: 0.5155 - acc: 0.7986 - val_loss: 0.5032 - val_acc: 0.8000\n",
      "Epoch 7/10\n",
      "4250/4250 [==============================] - 1s 141us/sample - loss: 0.5094 - acc: 0.7998 - val_loss: 0.5032 - val_acc: 0.8000\n",
      "Epoch 8/10\n",
      "4250/4250 [==============================] - 1s 149us/sample - loss: 0.5093 - acc: 0.7988 - val_loss: 0.5037 - val_acc: 0.8000\n",
      "Epoch 9/10\n",
      "4250/4250 [==============================] - 1s 181us/sample - loss: 0.5152 - acc: 0.7986 - val_loss: 0.5177 - val_acc: 0.8000\n",
      "Epoch 10/10\n",
      "4250/4250 [==============================] - 1s 184us/sample - loss: 0.5270 - acc: 0.7958 - val_loss: 0.5079 - val_acc: 0.8000\n",
      "Epoch 172 out of 200\n",
      "Train on 4250 samples, validate on 750 samples\n",
      "Epoch 1/10\n",
      "4250/4250 [==============================] - 1s 141us/sample - loss: 1.0417 - acc: 0.7384 - val_loss: 0.5377 - val_acc: 0.8000\n",
      "Epoch 2/10\n",
      "4250/4250 [==============================] - 1s 141us/sample - loss: 0.5303 - acc: 0.7913 - val_loss: 0.5008 - val_acc: 0.8000\n",
      "Epoch 3/10\n",
      "4250/4250 [==============================] - 1s 158us/sample - loss: 0.5413 - acc: 0.7859 - val_loss: 0.5064 - val_acc: 0.8000\n",
      "Epoch 4/10\n",
      "4250/4250 [==============================] - 1s 143us/sample - loss: 0.5183 - acc: 0.7969 - val_loss: 0.5074 - val_acc: 0.8000\n",
      "Epoch 5/10\n",
      "4250/4250 [==============================] - 1s 146us/sample - loss: 0.5502 - acc: 0.7864 - val_loss: 0.7061 - val_acc: 0.7880\n",
      "Epoch 6/10\n",
      "4250/4250 [==============================] - 1s 140us/sample - loss: 26.0684 - acc: 0.7162 - val_loss: 612.0657 - val_acc: 0.5373\n",
      "Epoch 7/10\n",
      "4250/4250 [==============================] - 1s 135us/sample - loss: 2148.1448 - acc: 0.5442 - val_loss: 625.9441 - val_acc: 0.5373\n",
      "Epoch 8/10\n",
      "4250/4250 [==============================] - 1s 144us/sample - loss: 116.2543 - acc: 0.5635 - val_loss: 23.8654 - val_acc: 0.5573\n",
      "Epoch 9/10\n",
      "4250/4250 [==============================] - 1s 139us/sample - loss: 5.5973 - acc: 0.7372 - val_loss: 0.7002 - val_acc: 0.7787\n",
      "Epoch 10/10\n",
      "4250/4250 [==============================] - 1s 138us/sample - loss: 0.6764 - acc: 0.7833 - val_loss: 0.6160 - val_acc: 0.8000\n",
      "Epoch 173 out of 200\n",
      "Train on 4250 samples, validate on 750 samples\n",
      "Epoch 1/10\n",
      "4250/4250 [==============================] - 1s 142us/sample - loss: 0.5675 - acc: 0.7913 - val_loss: 0.5309 - val_acc: 0.8000\n",
      "Epoch 2/10\n",
      "4250/4250 [==============================] - 1s 198us/sample - loss: 0.5399 - acc: 0.7939 - val_loss: 0.5133 - val_acc: 0.8000\n",
      "Epoch 3/10\n",
      "4250/4250 [==============================] - 1s 189us/sample - loss: 0.5161 - acc: 0.7988 - val_loss: 0.5063 - val_acc: 0.8000\n",
      "Epoch 4/10\n",
      "4250/4250 [==============================] - 1s 145us/sample - loss: 0.5111 - acc: 0.7998 - val_loss: 0.5157 - val_acc: 0.8000\n",
      "Epoch 5/10\n",
      "4250/4250 [==============================] - 1s 168us/sample - loss: 0.5100 - acc: 0.7991 - val_loss: 0.5004 - val_acc: 0.8000\n",
      "Epoch 6/10\n",
      "4250/4250 [==============================] - 1s 154us/sample - loss: 0.5156 - acc: 0.7955 - val_loss: 0.5096 - val_acc: 0.8000\n",
      "Epoch 7/10\n",
      "4250/4250 [==============================] - 1s 141us/sample - loss: 0.5073 - acc: 0.7993 - val_loss: 0.4998 - val_acc: 0.8000\n",
      "Epoch 8/10\n",
      "4250/4250 [==============================] - 1s 271us/sample - loss: 0.5372 - acc: 0.7842 - val_loss: 0.5144 - val_acc: 0.8000\n",
      "Epoch 9/10\n",
      "4250/4250 [==============================] - 1s 298us/sample - loss: 0.5133 - acc: 0.7974 - val_loss: 0.5008 - val_acc: 0.8000\n",
      "Epoch 10/10\n",
      "4250/4250 [==============================] - 1s 235us/sample - loss: 0.5253 - acc: 0.7925 - val_loss: 0.5078 - val_acc: 0.8000\n",
      "Epoch 174 out of 200\n",
      "Train on 4250 samples, validate on 750 samples\n",
      "Epoch 1/10\n",
      "4250/4250 [==============================] - 1s 173us/sample - loss: 0.5206 - acc: 0.7969 - val_loss: 0.5050 - val_acc: 0.8000\n",
      "Epoch 2/10\n",
      "4250/4250 [==============================] - 1s 142us/sample - loss: 0.5351 - acc: 0.7913 - val_loss: 0.5003 - val_acc: 0.8000\n",
      "Epoch 3/10\n",
      "4250/4250 [==============================] - 1s 201us/sample - loss: 0.5090 - acc: 0.7984 - val_loss: 0.5246 - val_acc: 0.8000\n",
      "Epoch 4/10\n",
      "4250/4250 [==============================] - 1s 138us/sample - loss: 0.5375 - acc: 0.7889 - val_loss: 0.5008 - val_acc: 0.8000\n",
      "Epoch 5/10\n",
      "4250/4250 [==============================] - 1s 139us/sample - loss: 0.5655 - acc: 0.7821 - val_loss: 0.5114 - val_acc: 0.8000\n",
      "Epoch 6/10\n",
      "4250/4250 [==============================] - 1s 141us/sample - loss: 0.5869 - acc: 0.7748 - val_loss: 0.5182 - val_acc: 0.7947\n",
      "Epoch 7/10\n",
      "4250/4250 [==============================] - 1s 135us/sample - loss: 0.9527 - acc: 0.7638 - val_loss: 1.2992 - val_acc: 0.4973\n",
      "Epoch 8/10\n",
      "4250/4250 [==============================] - 1s 214us/sample - loss: 2817.5925 - acc: 0.5398 - val_loss: 4881.3514 - val_acc: 0.4573\n",
      "Epoch 9/10\n",
      "4250/4250 [==============================] - 1s 150us/sample - loss: 1983.4667 - acc: 0.5562 - val_loss: 13.3100 - val_acc: 0.4747\n",
      "Epoch 10/10\n",
      "4250/4250 [==============================] - 1s 158us/sample - loss: 34.0406 - acc: 0.6318 - val_loss: 4.3989 - val_acc: 0.7027\n",
      "Epoch 175 out of 200\n",
      "Train on 4250 samples, validate on 750 samples\n",
      "Epoch 1/10\n",
      "4250/4250 [==============================] - 2s 379us/sample - loss: 1.3124 - acc: 0.7699 - val_loss: 0.6137 - val_acc: 0.8000\n",
      "Epoch 2/10\n",
      "4250/4250 [==============================] - 1s 225us/sample - loss: 0.7175 - acc: 0.7826 - val_loss: 0.6970 - val_acc: 0.8000\n",
      "Epoch 3/10\n",
      "4250/4250 [==============================] - 1s 280us/sample - loss: 0.5693 - acc: 0.7922 - val_loss: 0.5482 - val_acc: 0.8000\n",
      "Epoch 4/10\n",
      "4250/4250 [==============================] - 1s 187us/sample - loss: 0.5391 - acc: 0.7887 - val_loss: 0.5197 - val_acc: 0.7933\n",
      "Epoch 5/10\n",
      "4250/4250 [==============================] - 1s 203us/sample - loss: 0.5217 - acc: 0.7960 - val_loss: 0.5316 - val_acc: 0.8000\n",
      "Epoch 6/10\n",
      "4250/4250 [==============================] - 1s 271us/sample - loss: 0.5214 - acc: 0.7955 - val_loss: 0.5008 - val_acc: 0.8000\n",
      "Epoch 7/10\n",
      "4250/4250 [==============================] - 1s 220us/sample - loss: 0.5079 - acc: 0.7979 - val_loss: 0.5094 - val_acc: 0.8000\n",
      "Epoch 8/10\n",
      "4250/4250 [==============================] - 1s 147us/sample - loss: 0.5126 - acc: 0.7981 - val_loss: 0.5061 - val_acc: 0.8000\n",
      "Epoch 9/10\n",
      "4250/4250 [==============================] - 1s 184us/sample - loss: 0.5139 - acc: 0.7960 - val_loss: 0.5204 - val_acc: 0.7973\n",
      "Epoch 10/10\n",
      "4250/4250 [==============================] - 1s 252us/sample - loss: 0.5138 - acc: 0.7993 - val_loss: 0.5126 - val_acc: 0.8000\n",
      "Epoch 176 out of 200\n",
      "Train on 4250 samples, validate on 750 samples\n",
      "Epoch 1/10\n",
      "4250/4250 [==============================] - 1s 145us/sample - loss: 0.5170 - acc: 0.7969 - val_loss: 0.5203 - val_acc: 0.7987\n",
      "Epoch 2/10\n",
      "4250/4250 [==============================] - 1s 305us/sample - loss: 0.5870 - acc: 0.7798 - val_loss: 0.5028 - val_acc: 0.8000\n",
      "Epoch 3/10\n",
      "4250/4250 [==============================] - 1s 150us/sample - loss: 0.5112 - acc: 0.7972 - val_loss: 0.5027 - val_acc: 0.8000\n",
      "Epoch 4/10\n",
      "4250/4250 [==============================] - 1s 178us/sample - loss: 0.5256 - acc: 0.7984 - val_loss: 0.5178 - val_acc: 0.8000\n",
      "Epoch 5/10\n",
      "4250/4250 [==============================] - 1s 181us/sample - loss: 1.1362 - acc: 0.7678 - val_loss: 1.2951 - val_acc: 0.7467\n",
      "Epoch 6/10\n",
      "4250/4250 [==============================] - 1s 225us/sample - loss: 19.7571 - acc: 0.5659 - val_loss: 5.5685 - val_acc: 0.6173\n",
      "Epoch 7/10\n",
      "4250/4250 [==============================] - 1s 292us/sample - loss: 459.5366 - acc: 0.5471 - val_loss: 51.3081 - val_acc: 0.5440\n",
      "Epoch 8/10\n",
      "4250/4250 [==============================] - 1s 159us/sample - loss: 181.6267 - acc: 0.5579 - val_loss: 128.0744 - val_acc: 0.4453\n",
      "Epoch 9/10\n",
      "4250/4250 [==============================] - ETA: 0s - loss: 70.2555 - acc: 0.58 - 1s 142us/sample - loss: 69.7611 - acc: 0.5819 - val_loss: 45.9137 - val_acc: 0.5520\n",
      "Epoch 10/10\n",
      "4250/4250 [==============================] - 1s 216us/sample - loss: 3.2927 - acc: 0.7353 - val_loss: 0.8570 - val_acc: 0.7187\n",
      "Epoch 177 out of 200\n",
      "Train on 4250 samples, validate on 750 samples\n",
      "Epoch 1/10\n",
      "4250/4250 [==============================] - 1s 188us/sample - loss: 0.8245 - acc: 0.7816 - val_loss: 0.6921 - val_acc: 0.7947\n",
      "Epoch 2/10\n",
      "4250/4250 [==============================] - 1s 191us/sample - loss: 0.9820 - acc: 0.7647 - val_loss: 0.6139 - val_acc: 0.7960\n",
      "Epoch 3/10\n",
      "4250/4250 [==============================] - 1s 181us/sample - loss: 0.6543 - acc: 0.7802 - val_loss: 0.5466 - val_acc: 0.8000\n",
      "Epoch 4/10\n",
      "4250/4250 [==============================] - 1s 149us/sample - loss: 0.5595 - acc: 0.7908 - val_loss: 0.5318 - val_acc: 0.8000\n",
      "Epoch 5/10\n",
      "4250/4250 [==============================] - 1s 168us/sample - loss: 0.5390 - acc: 0.7960 - val_loss: 0.5090 - val_acc: 0.8000\n",
      "Epoch 6/10\n",
      "4250/4250 [==============================] - 1s 248us/sample - loss: 0.5346 - acc: 0.7913 - val_loss: 0.5302 - val_acc: 0.7987\n",
      "Epoch 7/10\n",
      "4250/4250 [==============================] - 1s 240us/sample - loss: 0.5769 - acc: 0.7833 - val_loss: 0.5350 - val_acc: 0.8000\n",
      "Epoch 8/10\n",
      "4250/4250 [==============================] - 1s 263us/sample - loss: 0.7888 - acc: 0.7431 - val_loss: 0.6213 - val_acc: 0.8000\n",
      "Epoch 9/10\n",
      "4250/4250 [==============================] - 1s 270us/sample - loss: 14.1293 - acc: 0.6685 - val_loss: 40.6203 - val_acc: 0.4467\n",
      "Epoch 10/10\n",
      "4250/4250 [==============================] - 1s 326us/sample - loss: 439.6918 - acc: 0.5478 - val_loss: 2715.3760 - val_acc: 0.4613\n",
      "Epoch 178 out of 200\n",
      "Train on 4250 samples, validate on 750 samples\n",
      "Epoch 1/10\n",
      "4250/4250 [==============================] - 1s 301us/sample - loss: 3895.2861 - acc: 0.5454 - val_loss: 76.6732 - val_acc: 0.5640\n",
      "Epoch 2/10\n",
      "4250/4250 [==============================] - 1s 268us/sample - loss: 30.9727 - acc: 0.6687 - val_loss: 0.6924 - val_acc: 0.8000\n",
      "Epoch 3/10\n",
      "4250/4250 [==============================] - 1s 202us/sample - loss: 0.7411 - acc: 0.7819 - val_loss: 0.6817 - val_acc: 0.8000\n",
      "Epoch 4/10\n",
      "4250/4250 [==============================] - 1s 172us/sample - loss: 0.6107 - acc: 0.7868 - val_loss: 0.5364 - val_acc: 0.8000\n",
      "Epoch 5/10\n",
      "4250/4250 [==============================] - 1s 162us/sample - loss: 0.5468 - acc: 0.7936 - val_loss: 0.5226 - val_acc: 0.8000\n",
      "Epoch 6/10\n",
      "4250/4250 [==============================] - 1s 172us/sample - loss: 0.5233 - acc: 0.7969 - val_loss: 0.5096 - val_acc: 0.8000\n",
      "Epoch 7/10\n",
      "4250/4250 [==============================] - 1s 153us/sample - loss: 0.5171 - acc: 0.7955 - val_loss: 0.5079 - val_acc: 0.8000\n",
      "Epoch 8/10\n",
      "4250/4250 [==============================] - 1s 168us/sample - loss: 0.5135 - acc: 0.7986 - val_loss: 0.5015 - val_acc: 0.8000\n",
      "Epoch 9/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4250/4250 [==============================] - 1s 260us/sample - loss: 0.5061 - acc: 0.7998 - val_loss: 0.5003 - val_acc: 0.8000\n",
      "Epoch 10/10\n",
      "4250/4250 [==============================] - 1s 226us/sample - loss: 0.5071 - acc: 0.8000 - val_loss: 0.5112 - val_acc: 0.8000\n",
      "Epoch 179 out of 200\n",
      "Train on 4250 samples, validate on 750 samples\n",
      "Epoch 1/10\n",
      "4250/4250 [==============================] - 1s 153us/sample - loss: 0.5186 - acc: 0.7976 - val_loss: 0.5075 - val_acc: 0.8000\n",
      "Epoch 2/10\n",
      "4250/4250 [==============================] - 1s 195us/sample - loss: 0.5098 - acc: 0.7984 - val_loss: 0.5093 - val_acc: 0.8000\n",
      "Epoch 3/10\n",
      "4250/4250 [==============================] - 1s 337us/sample - loss: 0.5131 - acc: 0.7991 - val_loss: 0.5053 - val_acc: 0.8000\n",
      "Epoch 4/10\n",
      "4250/4250 [==============================] - 1s 236us/sample - loss: 0.5073 - acc: 0.7986 - val_loss: 0.5003 - val_acc: 0.8000\n",
      "Epoch 5/10\n",
      "4250/4250 [==============================] - 1s 309us/sample - loss: 0.5093 - acc: 0.7998 - val_loss: 0.5168 - val_acc: 0.7947\n",
      "Epoch 6/10\n",
      "4250/4250 [==============================] - 1s 159us/sample - loss: 0.5927 - acc: 0.7678 - val_loss: 0.5497 - val_acc: 0.7653\n",
      "Epoch 7/10\n",
      "4250/4250 [==============================] - 1s 195us/sample - loss: 0.5476 - acc: 0.7873 - val_loss: 0.5005 - val_acc: 0.8000\n",
      "Epoch 8/10\n",
      "4250/4250 [==============================] - 1s 201us/sample - loss: 0.9218 - acc: 0.7569 - val_loss: 1.1248 - val_acc: 0.6840\n",
      "Epoch 9/10\n",
      "4250/4250 [==============================] - 1s 187us/sample - loss: 0.6370 - acc: 0.7727 - val_loss: 0.5153 - val_acc: 0.8000\n",
      "Epoch 10/10\n",
      "4250/4250 [==============================] - 1s 254us/sample - loss: 298.9604 - acc: 0.6494 - val_loss: 102.9219 - val_acc: 0.5467\n",
      "Epoch 180 out of 200\n",
      "Train on 4250 samples, validate on 750 samples\n",
      "Epoch 1/10\n",
      "4250/4250 [==============================] - 1s 211us/sample - loss: 1513.6523 - acc: 0.5308 - val_loss: 124.6388 - val_acc: 0.5640\n",
      "Epoch 2/10\n",
      "4250/4250 [==============================] - 1s 217us/sample - loss: 608.7556 - acc: 0.5682 - val_loss: 6.1400 - val_acc: 0.6640\n",
      "Epoch 3/10\n",
      "4250/4250 [==============================] - 1s 201us/sample - loss: 3.7700 - acc: 0.7238 - val_loss: 0.8366 - val_acc: 0.8000\n",
      "Epoch 4/10\n",
      "4250/4250 [==============================] - 1s 162us/sample - loss: 0.7277 - acc: 0.7809 - val_loss: 0.6775 - val_acc: 0.7400\n",
      "Epoch 5/10\n",
      "4250/4250 [==============================] - 1s 199us/sample - loss: 0.6278 - acc: 0.7873 - val_loss: 0.5813 - val_acc: 0.8000\n",
      "Epoch 6/10\n",
      "4250/4250 [==============================] - 1s 197us/sample - loss: 0.5520 - acc: 0.7951 - val_loss: 0.5780 - val_acc: 0.7653\n",
      "Epoch 7/10\n",
      "4250/4250 [==============================] - 1s 138us/sample - loss: 0.5441 - acc: 0.7906 - val_loss: 0.5109 - val_acc: 0.8000\n",
      "Epoch 8/10\n",
      "4250/4250 [==============================] - 1s 261us/sample - loss: 0.5200 - acc: 0.7962 - val_loss: 0.5019 - val_acc: 0.8000\n",
      "Epoch 9/10\n",
      "4250/4250 [==============================] - 1s 305us/sample - loss: 0.5085 - acc: 0.7995 - val_loss: 0.5064 - val_acc: 0.8000\n",
      "Epoch 10/10\n",
      "4250/4250 [==============================] - 1s 278us/sample - loss: 0.5149 - acc: 0.7981 - val_loss: 0.5048 - val_acc: 0.8000\n",
      "Epoch 181 out of 200\n",
      "Train on 4250 samples, validate on 750 samples\n",
      "Epoch 1/10\n",
      "4250/4250 [==============================] - 1s 309us/sample - loss: 0.5586 - acc: 0.7871 - val_loss: 0.5074 - val_acc: 0.8000\n",
      "Epoch 2/10\n",
      "4250/4250 [==============================] - 1s 339us/sample - loss: 0.6847 - acc: 0.7569 - val_loss: 0.5432 - val_acc: 0.7813\n",
      "Epoch 3/10\n",
      "4250/4250 [==============================] - 1s 290us/sample - loss: 0.5511 - acc: 0.7833 - val_loss: 0.5022 - val_acc: 0.8000\n",
      "Epoch 4/10\n",
      "4250/4250 [==============================] - 1s 200us/sample - loss: 0.5298 - acc: 0.7922 - val_loss: 0.5050 - val_acc: 0.8000\n",
      "Epoch 5/10\n",
      "4250/4250 [==============================] - 1s 268us/sample - loss: 0.5273 - acc: 0.7939 - val_loss: 0.5042 - val_acc: 0.8000\n",
      "Epoch 6/10\n",
      "4250/4250 [==============================] - 1s 247us/sample - loss: 0.6137 - acc: 0.7682 - val_loss: 0.5541 - val_acc: 0.8000\n",
      "Epoch 7/10\n",
      "4250/4250 [==============================] - 1s 279us/sample - loss: 0.9534 - acc: 0.7348 - val_loss: 1.3927 - val_acc: 0.6667\n",
      "Epoch 8/10\n",
      "4250/4250 [==============================] - 1s 201us/sample - loss: 4.7539 - acc: 0.7012 - val_loss: 14.4939 - val_acc: 0.5573\n",
      "Epoch 9/10\n",
      "4250/4250 [==============================] - 1s 145us/sample - loss: 448.7330 - acc: 0.5652 - val_loss: 843.4602 - val_acc: 0.5400\n",
      "Epoch 10/10\n",
      "4250/4250 [==============================] - 1s 140us/sample - loss: 1903.0625 - acc: 0.5322 - val_loss: 380.0088 - val_acc: 0.5373\n",
      "Epoch 182 out of 200\n",
      "Train on 4250 samples, validate on 750 samples\n",
      "Epoch 1/10\n",
      "4250/4250 [==============================] - 1s 156us/sample - loss: 45.3021 - acc: 0.6012 - val_loss: 2.6206 - val_acc: 0.6000\n",
      "Epoch 2/10\n",
      "4250/4250 [==============================] - 1s 140us/sample - loss: 1.8251 - acc: 0.7555 - val_loss: 0.7028 - val_acc: 0.7867\n",
      "Epoch 3/10\n",
      "4250/4250 [==============================] - 1s 141us/sample - loss: 0.7367 - acc: 0.7781 - val_loss: 0.6173 - val_acc: 0.8000\n",
      "Epoch 4/10\n",
      "4250/4250 [==============================] - 1s 136us/sample - loss: 0.5917 - acc: 0.7915 - val_loss: 0.5312 - val_acc: 0.8000\n",
      "Epoch 5/10\n",
      "4250/4250 [==============================] - 1s 143us/sample - loss: 0.5341 - acc: 0.7939 - val_loss: 0.5186 - val_acc: 0.8000\n",
      "Epoch 6/10\n",
      "4250/4250 [==============================] - 1s 141us/sample - loss: 0.5245 - acc: 0.7962 - val_loss: 0.5541 - val_acc: 0.7480\n",
      "Epoch 7/10\n",
      "4250/4250 [==============================] - 1s 139us/sample - loss: 0.5162 - acc: 0.7965 - val_loss: 0.5061 - val_acc: 0.8000\n",
      "Epoch 8/10\n",
      "4250/4250 [==============================] - 1s 158us/sample - loss: 0.5179 - acc: 0.7955 - val_loss: 0.5617 - val_acc: 0.8000\n",
      "Epoch 9/10\n",
      "4250/4250 [==============================] - 1s 313us/sample - loss: 0.5222 - acc: 0.7953 - val_loss: 0.5007 - val_acc: 0.8000\n",
      "Epoch 10/10\n",
      "4250/4250 [==============================] - 1s 171us/sample - loss: 0.5110 - acc: 0.7993 - val_loss: 0.5103 - val_acc: 0.8000\n",
      "Epoch 183 out of 200\n",
      "Train on 4250 samples, validate on 750 samples\n",
      "Epoch 1/10\n",
      "4250/4250 [==============================] - 1s 165us/sample - loss: 0.6028 - acc: 0.7767 - val_loss: 0.5035 - val_acc: 0.8000\n",
      "Epoch 2/10\n",
      "4250/4250 [==============================] - 1s 150us/sample - loss: 0.5183 - acc: 0.7941 - val_loss: 0.5049 - val_acc: 0.8000\n",
      "Epoch 3/10\n",
      "4250/4250 [==============================] - 1s 145us/sample - loss: 0.5324 - acc: 0.7927 - val_loss: 0.5081 - val_acc: 0.8000\n",
      "Epoch 4/10\n",
      "4250/4250 [==============================] - 1s 136us/sample - loss: 0.5127 - acc: 0.7972 - val_loss: 0.5589 - val_acc: 0.8000\n",
      "Epoch 5/10\n",
      "4250/4250 [==============================] - 1s 142us/sample - loss: 0.5585 - acc: 0.7847 - val_loss: 0.6282 - val_acc: 0.7027\n",
      "Epoch 6/10\n",
      "4250/4250 [==============================] - 1s 143us/sample - loss: 0.5916 - acc: 0.7781 - val_loss: 0.5009 - val_acc: 0.8000\n",
      "Epoch 7/10\n",
      "4250/4250 [==============================] - 1s 135us/sample - loss: 0.5276 - acc: 0.7946 - val_loss: 0.5444 - val_acc: 0.8000\n",
      "Epoch 8/10\n",
      "4250/4250 [==============================] - 1s 139us/sample - loss: 1.5407 - acc: 0.7546 - val_loss: 6.9723 - val_acc: 0.5720\n",
      "Epoch 9/10\n",
      "4250/4250 [==============================] - 1s 137us/sample - loss: 5313.8788 - acc: 0.5336 - val_loss: 3426.4312 - val_acc: 0.5373\n",
      "Epoch 10/10\n",
      "4250/4250 [==============================] - 1s 142us/sample - loss: 2022.8630 - acc: 0.5428 - val_loss: 296.0154 - val_acc: 0.5440\n",
      "Epoch 184 out of 200\n",
      "Train on 4250 samples, validate on 750 samples\n",
      "Epoch 1/10\n",
      "4250/4250 [==============================] - 1s 141us/sample - loss: 148.6144 - acc: 0.5711 - val_loss: 1.9527 - val_acc: 0.7907\n",
      "Epoch 2/10\n",
      "4250/4250 [==============================] - 1s 153us/sample - loss: 12.4433 - acc: 0.6654 - val_loss: 3.0380 - val_acc: 0.7653\n",
      "Epoch 3/10\n",
      "4250/4250 [==============================] - 1s 167us/sample - loss: 4.6827 - acc: 0.6958 - val_loss: 1.4410 - val_acc: 0.8000\n",
      "Epoch 4/10\n",
      "4250/4250 [==============================] - 1s 158us/sample - loss: 1.9679 - acc: 0.7529 - val_loss: 0.7345 - val_acc: 0.7253\n",
      "Epoch 5/10\n",
      "4250/4250 [==============================] - 1s 218us/sample - loss: 0.7755 - acc: 0.7746 - val_loss: 0.5814 - val_acc: 0.8000\n",
      "Epoch 6/10\n",
      "4250/4250 [==============================] - 1s 170us/sample - loss: 0.6124 - acc: 0.7847 - val_loss: 0.5510 - val_acc: 0.7987\n",
      "Epoch 7/10\n",
      "4250/4250 [==============================] - 1s 291us/sample - loss: 0.5392 - acc: 0.7941 - val_loss: 0.5327 - val_acc: 0.8000\n",
      "Epoch 8/10\n",
      "4250/4250 [==============================] - 1s 324us/sample - loss: 0.5196 - acc: 0.7981 - val_loss: 0.5037 - val_acc: 0.8000\n",
      "Epoch 9/10\n",
      "4250/4250 [==============================] - 1s 295us/sample - loss: 0.5279 - acc: 0.7946 - val_loss: 0.5012 - val_acc: 0.8000\n",
      "Epoch 10/10\n",
      "4250/4250 [==============================] - 1s 215us/sample - loss: 0.5096 - acc: 0.7993 - val_loss: 0.5000 - val_acc: 0.8000\n",
      "Epoch 185 out of 200\n",
      "Train on 4250 samples, validate on 750 samples\n",
      "Epoch 1/10\n",
      "4250/4250 [==============================] - 1s 256us/sample - loss: 0.5118 - acc: 0.7988 - val_loss: 0.5044 - val_acc: 0.8000\n",
      "Epoch 2/10\n",
      "4250/4250 [==============================] - ETA: 0s - loss: 0.5105 - acc: 0.800 - 1s 273us/sample - loss: 0.5111 - acc: 0.8000 - val_loss: 0.5007 - val_acc: 0.8000\n",
      "Epoch 3/10\n",
      "4250/4250 [==============================] - 1s 257us/sample - loss: 0.5150 - acc: 0.7967 - val_loss: 0.5063 - val_acc: 0.8000\n",
      "Epoch 4/10\n",
      "4250/4250 [==============================] - 1s 271us/sample - loss: 0.5148 - acc: 0.7967 - val_loss: 0.5000 - val_acc: 0.8000\n",
      "Epoch 5/10\n",
      "4250/4250 [==============================] - 1s 228us/sample - loss: 0.5680 - acc: 0.7786 - val_loss: 0.7124 - val_acc: 0.7973\n",
      "Epoch 6/10\n",
      "4250/4250 [==============================] - 1s 163us/sample - loss: 0.5396 - acc: 0.7908 - val_loss: 0.5008 - val_acc: 0.8000\n",
      "Epoch 7/10\n",
      "4250/4250 [==============================] - 1s 330us/sample - loss: 0.5253 - acc: 0.7967 - val_loss: 0.5001 - val_acc: 0.8000\n",
      "Epoch 8/10\n",
      "4250/4250 [==============================] - 1s 294us/sample - loss: 0.5311 - acc: 0.7882 - val_loss: 0.5332 - val_acc: 0.8000\n",
      "Epoch 9/10\n",
      "4250/4250 [==============================] - 1s 251us/sample - loss: 0.5443 - acc: 0.7845 - val_loss: 0.5373 - val_acc: 0.8000\n",
      "Epoch 10/10\n",
      "4250/4250 [==============================] - 1s 279us/sample - loss: 0.5315 - acc: 0.7908 - val_loss: 0.5006 - val_acc: 0.8000\n",
      "Epoch 186 out of 200\n",
      "Train on 4250 samples, validate on 750 samples\n",
      "Epoch 1/10\n",
      "4250/4250 [==============================] - 1s 168us/sample - loss: 0.5177 - acc: 0.7974 - val_loss: 0.5051 - val_acc: 0.8000\n",
      "Epoch 2/10\n",
      "4250/4250 [==============================] - 1s 196us/sample - loss: 0.5612 - acc: 0.7805 - val_loss: 0.5635 - val_acc: 0.7947\n",
      "Epoch 3/10\n",
      "4250/4250 [==============================] - 1s 162us/sample - loss: 32.5587 - acc: 0.7052 - val_loss: 279.1275 - val_acc: 0.5400\n",
      "Epoch 4/10\n",
      "4250/4250 [==============================] - 1s 164us/sample - loss: 2491.3428 - acc: 0.5456 - val_loss: 442.5952 - val_acc: 0.4520\n",
      "Epoch 5/10\n",
      "4250/4250 [==============================] - 1s 268us/sample - loss: 123.0878 - acc: 0.5685 - val_loss: 8.3909 - val_acc: 0.6227\n",
      "Epoch 6/10\n",
      "4250/4250 [==============================] - 1s 235us/sample - loss: 9.2037 - acc: 0.6767 - val_loss: 1.1222 - val_acc: 0.8000\n",
      "Epoch 7/10\n",
      "4250/4250 [==============================] - 1s 260us/sample - loss: 0.8761 - acc: 0.7748 - val_loss: 0.6652 - val_acc: 0.7867\n",
      "Epoch 8/10\n",
      "4250/4250 [==============================] - 1s 244us/sample - loss: 0.6104 - acc: 0.7885 - val_loss: 0.5419 - val_acc: 0.8000\n",
      "Epoch 9/10\n",
      "4250/4250 [==============================] - 1s 203us/sample - loss: 0.5459 - acc: 0.7934 - val_loss: 0.5188 - val_acc: 0.8000\n",
      "Epoch 10/10\n",
      "4250/4250 [==============================] - 1s 184us/sample - loss: 0.5257 - acc: 0.7953 - val_loss: 0.5100 - val_acc: 0.8000\n",
      "Epoch 187 out of 200\n",
      "Train on 4250 samples, validate on 750 samples\n",
      "Epoch 1/10\n",
      "4250/4250 [==============================] - 1s 304us/sample - loss: 0.5205 - acc: 0.7918 - val_loss: 0.5228 - val_acc: 0.7960\n",
      "Epoch 2/10\n",
      "4250/4250 [==============================] - 1s 266us/sample - loss: 0.5220 - acc: 0.7972 - val_loss: 0.5265 - val_acc: 0.7880\n",
      "Epoch 3/10\n",
      "4250/4250 [==============================] - 1s 218us/sample - loss: 0.5225 - acc: 0.7960 - val_loss: 0.5005 - val_acc: 0.8000\n",
      "Epoch 4/10\n",
      "4250/4250 [==============================] - 1s 238us/sample - loss: 0.5228 - acc: 0.7960 - val_loss: 0.5134 - val_acc: 0.8000\n",
      "Epoch 5/10\n",
      "4250/4250 [==============================] - 1s 231us/sample - loss: 0.5171 - acc: 0.7969 - val_loss: 0.5016 - val_acc: 0.8000\n",
      "Epoch 6/10\n",
      "4250/4250 [==============================] - 1s 148us/sample - loss: 0.5202 - acc: 0.7941 - val_loss: 0.5151 - val_acc: 0.8000\n",
      "Epoch 7/10\n",
      "4250/4250 [==============================] - 1s 195us/sample - loss: 0.5170 - acc: 0.7979 - val_loss: 0.5000 - val_acc: 0.8000\n",
      "Epoch 8/10\n",
      "4250/4250 [==============================] - 1s 270us/sample - loss: 0.5227 - acc: 0.7953 - val_loss: 0.5867 - val_acc: 0.7920\n",
      "Epoch 9/10\n",
      "4250/4250 [==============================] - 1s 241us/sample - loss: 0.5483 - acc: 0.7901 - val_loss: 0.5173 - val_acc: 0.8000\n",
      "Epoch 10/10\n",
      "4250/4250 [==============================] - 1s 226us/sample - loss: 0.5369 - acc: 0.7913 - val_loss: 0.5023 - val_acc: 0.8000\n",
      "Epoch 188 out of 200\n",
      "Train on 4250 samples, validate on 750 samples\n",
      "Epoch 1/10\n",
      "4250/4250 [==============================] - 1s 275us/sample - loss: 0.6660 - acc: 0.7668 - val_loss: 0.5117 - val_acc: 0.8000\n",
      "Epoch 2/10\n",
      "4250/4250 [==============================] - 1s 241us/sample - loss: 3222.2008 - acc: 0.5456 - val_loss: 2179.0485 - val_acc: 0.5387\n",
      "Epoch 3/10\n",
      "4250/4250 [==============================] - 1s 260us/sample - loss: 676.8422 - acc: 0.5687 - val_loss: 10.6315 - val_acc: 0.6093\n",
      "Epoch 4/10\n",
      "4250/4250 [==============================] - 1s 310us/sample - loss: 2.1134 - acc: 0.7442 - val_loss: 0.6406 - val_acc: 0.8000\n",
      "Epoch 5/10\n",
      "4250/4250 [==============================] - 1s 261us/sample - loss: 0.6380 - acc: 0.7833 - val_loss: 0.6011 - val_acc: 0.8000\n",
      "Epoch 6/10\n",
      "4250/4250 [==============================] - 1s 243us/sample - loss: 0.5456 - acc: 0.7948 - val_loss: 0.5130 - val_acc: 0.8000\n",
      "Epoch 7/10\n",
      "4250/4250 [==============================] - 1s 310us/sample - loss: 0.5225 - acc: 0.7967 - val_loss: 0.5016 - val_acc: 0.8000\n",
      "Epoch 8/10\n",
      "4250/4250 [==============================] - 1s 274us/sample - loss: 0.5242 - acc: 0.7911 - val_loss: 0.5172 - val_acc: 0.8000\n",
      "Epoch 9/10\n",
      "4250/4250 [==============================] - 1s 215us/sample - loss: 0.5151 - acc: 0.7979 - val_loss: 0.5011 - val_acc: 0.8000\n",
      "Epoch 10/10\n",
      "4250/4250 [==============================] - 1s 147us/sample - loss: 0.5224 - acc: 0.7929 - val_loss: 0.5729 - val_acc: 0.8000\n",
      "Epoch 189 out of 200\n",
      "Train on 4250 samples, validate on 750 samples\n",
      "Epoch 1/10\n",
      "4250/4250 [==============================] - 1s 143us/sample - loss: 0.5446 - acc: 0.7852 - val_loss: 0.5072 - val_acc: 0.8000\n",
      "Epoch 2/10\n",
      "4250/4250 [==============================] - 1s 156us/sample - loss: 0.5197 - acc: 0.7936 - val_loss: 0.5184 - val_acc: 0.8000\n",
      "Epoch 3/10\n",
      "4250/4250 [==============================] - 1s 251us/sample - loss: 0.5337 - acc: 0.7854 - val_loss: 0.5228 - val_acc: 0.8000\n",
      "Epoch 4/10\n",
      "4250/4250 [==============================] - 1s 253us/sample - loss: 0.5201 - acc: 0.7927 - val_loss: 0.5021 - val_acc: 0.8000\n",
      "Epoch 5/10\n",
      "4250/4250 [==============================] - 1s 254us/sample - loss: 0.5322 - acc: 0.7918 - val_loss: 0.5741 - val_acc: 0.8000\n",
      "Epoch 6/10\n",
      "4250/4250 [==============================] - 1s 274us/sample - loss: 0.5420 - acc: 0.7871 - val_loss: 0.6106 - val_acc: 0.7787\n",
      "Epoch 7/10\n",
      "4250/4250 [==============================] - 1s 267us/sample - loss: 0.6183 - acc: 0.7647 - val_loss: 0.5133 - val_acc: 0.8000\n",
      "Epoch 8/10\n",
      "4250/4250 [==============================] - 1s 274us/sample - loss: 0.5787 - acc: 0.7802 - val_loss: 0.5387 - val_acc: 0.7973\n",
      "Epoch 9/10\n",
      "4250/4250 [==============================] - 1s 307us/sample - loss: 0.7197 - acc: 0.7558 - val_loss: 0.5822 - val_acc: 0.7880\n",
      "Epoch 10/10\n",
      "4250/4250 [==============================] - 1s 215us/sample - loss: 13.9579 - acc: 0.6329 - val_loss: 43.4070 - val_acc: 0.5600\n",
      "Epoch 190 out of 200\n",
      "Train on 4250 samples, validate on 750 samples\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4250/4250 [==============================] - 1s 303us/sample - loss: 1493.5530 - acc: 0.5468 - val_loss: 4809.8699 - val_acc: 0.4573\n",
      "Epoch 2/10\n",
      "4250/4250 [==============================] - 1s 293us/sample - loss: 368.6139 - acc: 0.5929 - val_loss: 8.7226 - val_acc: 0.4653\n",
      "Epoch 3/10\n",
      "4250/4250 [==============================] - 1s 322us/sample - loss: 2.3048 - acc: 0.7459 - val_loss: 0.6688 - val_acc: 0.7987\n",
      "Epoch 4/10\n",
      "4250/4250 [==============================] - 1s 241us/sample - loss: 0.6911 - acc: 0.7856 - val_loss: 0.5782 - val_acc: 0.7907\n",
      "Epoch 5/10\n",
      "4250/4250 [==============================] - 1s 267us/sample - loss: 0.5647 - acc: 0.7915 - val_loss: 0.5867 - val_acc: 0.7973\n",
      "Epoch 6/10\n",
      "4250/4250 [==============================] - 1s 291us/sample - loss: 0.5548 - acc: 0.7896 - val_loss: 0.5415 - val_acc: 0.7800\n",
      "Epoch 7/10\n",
      "4250/4250 [==============================] - 1s 301us/sample - loss: 0.5196 - acc: 0.7965 - val_loss: 0.5109 - val_acc: 0.8000\n",
      "Epoch 8/10\n",
      "4250/4250 [==============================] - 1s 301us/sample - loss: 0.5523 - acc: 0.7861 - val_loss: 0.5064 - val_acc: 0.8000\n",
      "Epoch 9/10\n",
      "4250/4250 [==============================] - 1s 256us/sample - loss: 0.5619 - acc: 0.7821 - val_loss: 0.5038 - val_acc: 0.8000\n",
      "Epoch 10/10\n",
      "4250/4250 [==============================] - 1s 300us/sample - loss: 0.5332 - acc: 0.7885 - val_loss: 0.5069 - val_acc: 0.8000\n",
      "Epoch 191 out of 200\n",
      "Train on 4250 samples, validate on 750 samples\n",
      "Epoch 1/10\n",
      "4250/4250 [==============================] - 1s 329us/sample - loss: 0.5280 - acc: 0.7925 - val_loss: 0.5671 - val_acc: 0.7507\n",
      "Epoch 2/10\n",
      "4250/4250 [==============================] - 1s 158us/sample - loss: 0.5360 - acc: 0.7915 - val_loss: 0.5160 - val_acc: 0.8000\n",
      "Epoch 3/10\n",
      "4250/4250 [==============================] - 1s 170us/sample - loss: 0.5351 - acc: 0.7885 - val_loss: 0.5084 - val_acc: 0.8000\n",
      "Epoch 4/10\n",
      "4250/4250 [==============================] - 1s 197us/sample - loss: 0.5410 - acc: 0.7861 - val_loss: 0.5188 - val_acc: 0.8000\n",
      "Epoch 5/10\n",
      "4250/4250 [==============================] - 1s 181us/sample - loss: 0.7640 - acc: 0.7466 - val_loss: 2.7849 - val_acc: 0.6307\n",
      "Epoch 6/10\n",
      "4250/4250 [==============================] - 1s 290us/sample - loss: 216.4192 - acc: 0.5772 - val_loss: 5927.7441 - val_acc: 0.4640\n",
      "Epoch 7/10\n",
      "4250/4250 [==============================] - 1s 249us/sample - loss: 2320.9914 - acc: 0.5407 - val_loss: 1173.1677 - val_acc: 0.5387\n",
      "Epoch 8/10\n",
      "4250/4250 [==============================] - 1s 322us/sample - loss: 987.0034 - acc: 0.5541 - val_loss: 158.4013 - val_acc: 0.5533\n",
      "Epoch 9/10\n",
      "4250/4250 [==============================] - 1s 255us/sample - loss: 67.9109 - acc: 0.5861 - val_loss: 3.6337 - val_acc: 0.7480\n",
      "Epoch 10/10\n",
      "4250/4250 [==============================] - 1s 252us/sample - loss: 1.4645 - acc: 0.7668 - val_loss: 0.7279 - val_acc: 0.8000\n",
      "Epoch 192 out of 200\n",
      "Train on 4250 samples, validate on 750 samples\n",
      "Epoch 1/10\n",
      "4250/4250 [==============================] - 1s 189us/sample - loss: 0.7641 - acc: 0.7800 - val_loss: 0.6320 - val_acc: 0.7960\n",
      "Epoch 2/10\n",
      "4250/4250 [==============================] - 1s 176us/sample - loss: 0.6349 - acc: 0.7852 - val_loss: 0.6164 - val_acc: 0.8000\n",
      "Epoch 3/10\n",
      "4250/4250 [==============================] - 1s 180us/sample - loss: 0.5741 - acc: 0.7925 - val_loss: 0.5687 - val_acc: 0.7640\n",
      "Epoch 4/10\n",
      "4250/4250 [==============================] - 1s 188us/sample - loss: 0.5377 - acc: 0.7962 - val_loss: 0.5307 - val_acc: 0.8000\n",
      "Epoch 5/10\n",
      "4250/4250 [==============================] - 1s 204us/sample - loss: 0.5179 - acc: 0.7974 - val_loss: 0.5111 - val_acc: 0.8000\n",
      "Epoch 6/10\n",
      "4250/4250 [==============================] - 1s 201us/sample - loss: 0.5181 - acc: 0.7967 - val_loss: 0.5010 - val_acc: 0.8000\n",
      "Epoch 7/10\n",
      "4250/4250 [==============================] - 1s 209us/sample - loss: 0.5164 - acc: 0.7948 - val_loss: 0.5308 - val_acc: 0.7987\n",
      "Epoch 8/10\n",
      "4250/4250 [==============================] - ETA: 0s - loss: 0.5201 - acc: 0.794 - 1s 276us/sample - loss: 0.5206 - acc: 0.7939 - val_loss: 0.5039 - val_acc: 0.8000\n",
      "Epoch 9/10\n",
      "4250/4250 [==============================] - 1s 308us/sample - loss: 0.5224 - acc: 0.7969 - val_loss: 0.5065 - val_acc: 0.8000\n",
      "Epoch 10/10\n",
      "4250/4250 [==============================] - 1s 299us/sample - loss: 0.5546 - acc: 0.7875 - val_loss: 0.6328 - val_acc: 0.6960\n",
      "Epoch 193 out of 200\n",
      "Train on 4250 samples, validate on 750 samples\n",
      "Epoch 1/10\n",
      "4250/4250 [==============================] - 1s 336us/sample - loss: 0.5254 - acc: 0.7920 - val_loss: 0.5275 - val_acc: 0.8000\n",
      "Epoch 2/10\n",
      "4250/4250 [==============================] - 1s 290us/sample - loss: 0.5160 - acc: 0.7969 - val_loss: 0.5017 - val_acc: 0.8000\n",
      "Epoch 3/10\n",
      "4250/4250 [==============================] - 1s 326us/sample - loss: 0.5317 - acc: 0.7929 - val_loss: 0.5102 - val_acc: 0.8000\n",
      "Epoch 4/10\n",
      "4250/4250 [==============================] - 1s 300us/sample - loss: 0.6844 - acc: 0.7689 - val_loss: 1.9672 - val_acc: 0.6533\n",
      "Epoch 5/10\n",
      "4250/4250 [==============================] - 1s 325us/sample - loss: 1028.1286 - acc: 0.5513 - val_loss: 1087.1363 - val_acc: 0.4600\n",
      "Epoch 6/10\n",
      "4250/4250 [==============================] - 1s 334us/sample - loss: 643.7291 - acc: 0.5842 - val_loss: 1.0991 - val_acc: 0.8000\n",
      "Epoch 7/10\n",
      "4250/4250 [==============================] - 1s 264us/sample - loss: 0.7669 - acc: 0.7812 - val_loss: 0.5872 - val_acc: 0.8000\n",
      "Epoch 8/10\n",
      "4250/4250 [==============================] - 1s 275us/sample - loss: 0.5756 - acc: 0.7908 - val_loss: 0.5324 - val_acc: 0.8000\n",
      "Epoch 9/10\n",
      "4250/4250 [==============================] - 1s 244us/sample - loss: 0.5378 - acc: 0.7941 - val_loss: 0.5190 - val_acc: 0.8000\n",
      "Epoch 10/10\n",
      "4250/4250 [==============================] - 1s 289us/sample - loss: 0.5587 - acc: 0.7878 - val_loss: 0.5049 - val_acc: 0.8000\n",
      "Epoch 194 out of 200\n",
      "Train on 4250 samples, validate on 750 samples\n",
      "Epoch 1/10\n",
      "4250/4250 [==============================] - 1s 314us/sample - loss: 0.5326 - acc: 0.7906 - val_loss: 0.5062 - val_acc: 0.8000\n",
      "Epoch 2/10\n",
      "4250/4250 [==============================] - 1s 296us/sample - loss: 0.5124 - acc: 0.7991 - val_loss: 0.5112 - val_acc: 0.8000\n",
      "Epoch 3/10\n",
      "4250/4250 [==============================] - 1s 301us/sample - loss: 0.5235 - acc: 0.7932 - val_loss: 0.5073 - val_acc: 0.8000\n",
      "Epoch 4/10\n",
      "4250/4250 [==============================] - 1s 301us/sample - loss: 0.5222 - acc: 0.7927 - val_loss: 0.5126 - val_acc: 0.8000\n",
      "Epoch 5/10\n",
      "4250/4250 [==============================] - 1s 203us/sample - loss: 0.5208 - acc: 0.7936 - val_loss: 0.5080 - val_acc: 0.8000\n",
      "Epoch 6/10\n",
      "4250/4250 [==============================] - 1s 271us/sample - loss: 0.5328 - acc: 0.7906 - val_loss: 0.5089 - val_acc: 0.8000\n",
      "Epoch 7/10\n",
      "4250/4250 [==============================] - 1s 305us/sample - loss: 0.5567 - acc: 0.7871 - val_loss: 0.5063 - val_acc: 0.8000\n",
      "Epoch 8/10\n",
      "4250/4250 [==============================] - 1s 215us/sample - loss: 1.2868 - acc: 0.7400 - val_loss: 0.9419 - val_acc: 0.5853\n",
      "Epoch 9/10\n",
      "4250/4250 [==============================] - 1s 226us/sample - loss: 0.9311 - acc: 0.7534 - val_loss: 0.5036 - val_acc: 0.8000\n",
      "Epoch 10/10\n",
      "4250/4250 [==============================] - 1s 212us/sample - loss: 0.5705 - acc: 0.7840 - val_loss: 1.0434 - val_acc: 0.7693\n",
      "Epoch 195 out of 200\n",
      "Train on 4250 samples, validate on 750 samples\n",
      "Epoch 1/10\n",
      "4250/4250 [==============================] - 1s 189us/sample - loss: 136.4816 - acc: 0.5602 - val_loss: 93.4600 - val_acc: 0.5413\n",
      "Epoch 2/10\n",
      "4250/4250 [==============================] - 1s 303us/sample - loss: 747.4880 - acc: 0.5435 - val_loss: 388.4110 - val_acc: 0.5400\n",
      "Epoch 3/10\n",
      "4250/4250 [==============================] - 1s 266us/sample - loss: 322.8686 - acc: 0.5440 - val_loss: 65.9214 - val_acc: 0.5480\n",
      "Epoch 4/10\n",
      "4250/4250 [==============================] - 1s 281us/sample - loss: 526.9078 - acc: 0.5367 - val_loss: 82.0025 - val_acc: 0.5507\n",
      "Epoch 5/10\n",
      "4250/4250 [==============================] - 1s 241us/sample - loss: 19.6097 - acc: 0.7188 - val_loss: 0.9363 - val_acc: 0.8000\n",
      "Epoch 6/10\n",
      "4250/4250 [==============================] - 1s 267us/sample - loss: 0.9070 - acc: 0.7791 - val_loss: 0.8221 - val_acc: 0.8000\n",
      "Epoch 7/10\n",
      "4250/4250 [==============================] - 1s 312us/sample - loss: 0.7945 - acc: 0.7814 - val_loss: 0.7026 - val_acc: 0.7973\n",
      "Epoch 8/10\n",
      "4250/4250 [==============================] - 1s 321us/sample - loss: 0.6612 - acc: 0.7845 - val_loss: 0.5969 - val_acc: 0.8000\n",
      "Epoch 9/10\n",
      "4250/4250 [==============================] - 1s 227us/sample - loss: 0.6082 - acc: 0.7878 - val_loss: 0.6424 - val_acc: 0.7253\n",
      "Epoch 10/10\n",
      "4250/4250 [==============================] - 1s 177us/sample - loss: 0.5586 - acc: 0.7892 - val_loss: 0.5602 - val_acc: 0.7973\n",
      "Epoch 196 out of 200\n",
      "Train on 4250 samples, validate on 750 samples\n",
      "Epoch 1/10\n",
      "4250/4250 [==============================] - 1s 301us/sample - loss: 0.5584 - acc: 0.7882 - val_loss: 0.5335 - val_acc: 0.8000\n",
      "Epoch 2/10\n",
      "4250/4250 [==============================] - 1s 235us/sample - loss: 0.5328 - acc: 0.7908 - val_loss: 0.5019 - val_acc: 0.8000\n",
      "Epoch 3/10\n",
      "4250/4250 [==============================] - 1s 340us/sample - loss: 0.5613 - acc: 0.7741 - val_loss: 0.6728 - val_acc: 0.8000\n",
      "Epoch 4/10\n",
      "4250/4250 [==============================] - 2s 354us/sample - loss: 0.5499 - acc: 0.7904 - val_loss: 0.5008 - val_acc: 0.8000\n",
      "Epoch 5/10\n",
      "4250/4250 [==============================] - 1s 306us/sample - loss: 0.5179 - acc: 0.7939 - val_loss: 0.5085 - val_acc: 0.8000\n",
      "Epoch 6/10\n",
      "4250/4250 [==============================] - 1s 214us/sample - loss: 31.6839 - acc: 0.6522 - val_loss: 71.1661 - val_acc: 0.5467\n",
      "Epoch 7/10\n",
      "4250/4250 [==============================] - 1s 192us/sample - loss: 2349.0379 - acc: 0.5304 - val_loss: 1370.7458 - val_acc: 0.5373\n",
      "Epoch 8/10\n",
      "4250/4250 [==============================] - 1s 195us/sample - loss: 238.2263 - acc: 0.6325 - val_loss: 0.6878 - val_acc: 0.7653\n",
      "Epoch 9/10\n",
      "4250/4250 [==============================] - 1s 222us/sample - loss: 0.6597 - acc: 0.7889 - val_loss: 0.5621 - val_acc: 0.8000\n",
      "Epoch 10/10\n",
      "4250/4250 [==============================] - 1s 284us/sample - loss: 0.5764 - acc: 0.7913 - val_loss: 0.5361 - val_acc: 0.7947\n",
      "Epoch 197 out of 200\n",
      "Train on 4250 samples, validate on 750 samples\n",
      "Epoch 1/10\n",
      "4250/4250 [==============================] - 1s 310us/sample - loss: 0.5298 - acc: 0.7981 - val_loss: 0.5323 - val_acc: 0.7867\n",
      "Epoch 2/10\n",
      "4250/4250 [==============================] - 1s 295us/sample - loss: 0.5124 - acc: 0.7986 - val_loss: 0.5058 - val_acc: 0.8000\n",
      "Epoch 3/10\n",
      "4250/4250 [==============================] - 1s 329us/sample - loss: 0.5080 - acc: 0.7998 - val_loss: 0.5019 - val_acc: 0.8000\n",
      "Epoch 4/10\n",
      "4250/4250 [==============================] - 1s 293us/sample - loss: 0.5128 - acc: 0.7986 - val_loss: 0.5065 - val_acc: 0.8000\n",
      "Epoch 5/10\n",
      "4250/4250 [==============================] - 1s 314us/sample - loss: 0.5195 - acc: 0.7934 - val_loss: 0.5130 - val_acc: 0.8000\n",
      "Epoch 6/10\n",
      "4250/4250 [==============================] - 1s 311us/sample - loss: 0.5185 - acc: 0.7953 - val_loss: 0.5041 - val_acc: 0.8000\n",
      "Epoch 7/10\n",
      "4250/4250 [==============================] - 2s 404us/sample - loss: 0.5170 - acc: 0.7979 - val_loss: 0.5197 - val_acc: 0.8000\n",
      "Epoch 8/10\n",
      "4250/4250 [==============================] - 1s 291us/sample - loss: 0.5109 - acc: 0.7988 - val_loss: 0.4998 - val_acc: 0.8000\n",
      "Epoch 9/10\n",
      "4250/4250 [==============================] - 1s 249us/sample - loss: 0.5099 - acc: 0.7979 - val_loss: 0.5354 - val_acc: 0.7733\n",
      "Epoch 10/10\n",
      "4250/4250 [==============================] - 1s 198us/sample - loss: 0.5265 - acc: 0.7951 - val_loss: 0.5020 - val_acc: 0.8000\n",
      "Epoch 198 out of 200\n",
      "Train on 4250 samples, validate on 750 samples\n",
      "Epoch 1/10\n",
      "4250/4250 [==============================] - 1s 314us/sample - loss: 6.5629 - acc: 0.6696 - val_loss: 20.8304 - val_acc: 0.5520\n",
      "Epoch 2/10\n",
      "4250/4250 [==============================] - 1s 220us/sample - loss: 763.2555 - acc: 0.5339 - val_loss: 475.3864 - val_acc: 0.5400\n",
      "Epoch 3/10\n",
      "4250/4250 [==============================] - 1s 191us/sample - loss: 530.7850 - acc: 0.5419 - val_loss: 54.9065 - val_acc: 0.5600\n",
      "Epoch 4/10\n",
      "4250/4250 [==============================] - 1s 239us/sample - loss: 7.1601 - acc: 0.7299 - val_loss: 0.6920 - val_acc: 0.8000\n",
      "Epoch 5/10\n",
      "4250/4250 [==============================] - 1s 288us/sample - loss: 0.6941 - acc: 0.7856 - val_loss: 0.5866 - val_acc: 0.8000\n",
      "Epoch 6/10\n",
      "4250/4250 [==============================] - 1s 299us/sample - loss: 0.5946 - acc: 0.7925 - val_loss: 0.5340 - val_acc: 0.7987\n",
      "Epoch 7/10\n",
      "4250/4250 [==============================] - 1s 293us/sample - loss: 0.5305 - acc: 0.7965 - val_loss: 0.5058 - val_acc: 0.8000\n",
      "Epoch 8/10\n",
      "4250/4250 [==============================] - 1s 302us/sample - loss: 0.5202 - acc: 0.7965 - val_loss: 0.5100 - val_acc: 0.8000\n",
      "Epoch 9/10\n",
      "4250/4250 [==============================] - 1s 310us/sample - loss: 0.5191 - acc: 0.7972 - val_loss: 0.5017 - val_acc: 0.8000\n",
      "Epoch 10/10\n",
      "4250/4250 [==============================] - 1s 305us/sample - loss: 0.5167 - acc: 0.7946 - val_loss: 0.5116 - val_acc: 0.8000\n",
      "Epoch 199 out of 200\n",
      "Train on 4250 samples, validate on 750 samples\n",
      "Epoch 1/10\n",
      "4250/4250 [==============================] - 1s 284us/sample - loss: 0.5235 - acc: 0.7922 - val_loss: 0.5169 - val_acc: 0.7987\n",
      "Epoch 2/10\n",
      "4250/4250 [==============================] - 1s 238us/sample - loss: 0.5914 - acc: 0.7814 - val_loss: 0.6428 - val_acc: 0.6813\n",
      "Epoch 3/10\n",
      "4250/4250 [==============================] - 1s 153us/sample - loss: 0.5796 - acc: 0.7849 - val_loss: 0.5514 - val_acc: 0.7600\n",
      "Epoch 4/10\n",
      "4250/4250 [==============================] - 1s 155us/sample - loss: 0.6087 - acc: 0.7715 - val_loss: 0.7406 - val_acc: 0.7920\n",
      "Epoch 5/10\n",
      "4250/4250 [==============================] - 1s 153us/sample - loss: 342.7885 - acc: 0.5739 - val_loss: 117.1406 - val_acc: 0.5600\n",
      "Epoch 6/10\n",
      "4250/4250 [==============================] - 1s 148us/sample - loss: 160.4759 - acc: 0.5635 - val_loss: 101.5320 - val_acc: 0.4440\n",
      "Epoch 7/10\n",
      "4250/4250 [==============================] - 1s 182us/sample - loss: 100.7745 - acc: 0.5367 - val_loss: 70.9440 - val_acc: 0.4387\n",
      "Epoch 8/10\n",
      "4250/4250 [==============================] - 1s 332us/sample - loss: 69.7754 - acc: 0.6047 - val_loss: 1.2846 - val_acc: 0.8000\n",
      "Epoch 9/10\n",
      "4250/4250 [==============================] - 1s 203us/sample - loss: 1.1305 - acc: 0.7701 - val_loss: 1.0997 - val_acc: 0.8000\n",
      "Epoch 10/10\n",
      "4250/4250 [==============================] - 1s 180us/sample - loss: 0.8447 - acc: 0.7746 - val_loss: 0.7536 - val_acc: 0.7147\n"
     ]
    }
   ],
   "source": [
    "fit_discriminator(discriminator, Data, 200, lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1800/1800 [==============================] - 0s 114us/sample - loss: 0.1760 - acc: 0.9017\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.17600894825326072, 0.90166664]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TestData = Dataset()\n",
    "TestData.load_data(data_range=15)\n",
    "discriminator.model.evaluate(TestData.x, TestData.y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "Plot('test2').picture(TestData.x, discriminator.model.predict(TestData.x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[-13.9137895 , 193.59353821],\n",
       "        [-13.9137895 , 166.8826954 ],\n",
       "        [-13.9137895 ,   3.34478453],\n",
       "        ...,\n",
       "        [-14.62422688, 180.63495714],\n",
       "        [-14.62422688,  79.86063019],\n",
       "        [-14.62422688, 122.36550899]]), array([1, 0, 0, ..., 0, 0, 0]))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NewData = Dataset()\n",
    "NewData.load_data(data_range=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "gan = define_gan(generator.model, discriminator.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 156us/sample - loss: 1.1178\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 203us/sample - loss: 1.1157\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 280us/sample - loss: 0.4399 - acc: 0.9062\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 215us/sample - loss: 0.1458 - acc: 0.9215 - val_loss: 0.1482 - val_acc: 0.9472\n",
      "Epoch 1\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 156us/sample - loss: 1.1845\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 234us/sample - loss: 1.1803\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 281us/sample - loss: 0.4027 - acc: 0.9219\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 230us/sample - loss: 0.1387 - acc: 0.9340 - val_loss: 0.1577 - val_acc: 0.9333\n",
      "Epoch 2\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 187us/sample - loss: 1.1914\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 312us/sample - loss: 1.1865\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 187us/sample - loss: 0.3980 - acc: 0.9219\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 1s 382us/sample - loss: 0.1475 - acc: 0.9299 - val_loss: 0.1526 - val_acc: 0.9361\n",
      "Epoch 3\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 265us/sample - loss: 1.2087\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 265us/sample - loss: 1.2056\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 327us/sample - loss: 0.3994 - acc: 0.8750\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 295us/sample - loss: 0.1431 - acc: 0.9271 - val_loss: 0.1658 - val_acc: 0.8972\n",
      "Epoch 4\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 343us/sample - loss: 1.2696\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 296us/sample - loss: 1.2670\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 265us/sample - loss: 0.3521 - acc: 0.9844\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 230us/sample - loss: 0.1613 - acc: 0.9194 - val_loss: 0.1635 - val_acc: 0.9222\n",
      "Epoch 5\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 187us/sample - loss: 1.1437\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 312us/sample - loss: 1.1404\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 249us/sample - loss: 0.4348 - acc: 0.8594\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 242us/sample - loss: 0.1519 - acc: 0.9278 - val_loss: 0.1943 - val_acc: 0.9306\n",
      "Epoch 6\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 280us/sample - loss: 1.2274\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 265us/sample - loss: 1.2246\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 296us/sample - loss: 0.3899 - acc: 0.9062\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 225us/sample - loss: 0.1452 - acc: 0.9319 - val_loss: 0.1562 - val_acc: 0.9500\n",
      "Epoch 7\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 218us/sample - loss: 1.1623\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 187us/sample - loss: 1.1610\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 249us/sample - loss: 0.4258 - acc: 0.8594\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 241us/sample - loss: 0.1478 - acc: 0.9264 - val_loss: 0.2267 - val_acc: 0.8889\n",
      "Epoch 8\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 203us/sample - loss: 1.3329\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 280us/sample - loss: 1.3307\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 203us/sample - loss: 0.3560 - acc: 0.9375\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 236us/sample - loss: 0.1655 - acc: 0.9229 - val_loss: 0.2054 - val_acc: 0.9139\n",
      "Epoch 9\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 234us/sample - loss: 1.1706\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 296us/sample - loss: 1.1711\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 203us/sample - loss: 0.4196 - acc: 0.8594\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 228us/sample - loss: 0.1421 - acc: 0.9271 - val_loss: 0.1580 - val_acc: 0.9083\n",
      "Epoch 10\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 225us/sample - loss: 1.2473\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 218us/sample - loss: 1.2471\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 171us/sample - loss: 0.3761 - acc: 0.9062\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 231us/sample - loss: 0.1781 - acc: 0.9111 - val_loss: 0.2601 - val_acc: 0.8972\n",
      "Epoch 11\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 171us/sample - loss: 1.1534\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 171us/sample - loss: 1.1528\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 218us/sample - loss: 0.4280 - acc: 0.8906\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 232us/sample - loss: 0.1676 - acc: 0.9174 - val_loss: 0.1559 - val_acc: 0.9472\n",
      "Epoch 12\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 405us/sample - loss: 1.2348\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 296us/sample - loss: 1.2336\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 327us/sample - loss: 0.3778 - acc: 0.9375\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 237us/sample - loss: 0.1462 - acc: 0.9292 - val_loss: 0.1802 - val_acc: 0.9000\n",
      "Epoch 13\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 203us/sample - loss: 1.1887\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 187us/sample - loss: 1.1818\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 327us/sample - loss: 0.4042 - acc: 0.8750\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 197us/sample - loss: 0.1636 - acc: 0.9132 - val_loss: 0.1540 - val_acc: 0.9139\n",
      "Epoch 14\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 171us/sample - loss: 1.2297\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 249us/sample - loss: 1.2295\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 203us/sample - loss: 0.3947 - acc: 0.9219\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 206us/sample - loss: 0.1356 - acc: 0.9326 - val_loss: 0.1484 - val_acc: 0.9444\n",
      "Epoch 15\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 187us/sample - loss: 1.2245\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 218us/sample - loss: 1.2245\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 218us/sample - loss: 0.3859 - acc: 0.9219\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 191us/sample - loss: 0.1402 - acc: 0.9278 - val_loss: 0.1577 - val_acc: 0.9167\n",
      "Epoch 16\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 171us/sample - loss: 1.3621\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 187us/sample - loss: 1.3615\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - ETA: 0s - loss: 0.3043 - acc: 1.000 - 0s 249us/sample - loss: 0.3226 - acc: 0.9844\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 235us/sample - loss: 0.1407 - acc: 0.9312 - val_loss: 0.1741 - val_acc: 0.9028\n",
      "Epoch 17\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 187us/sample - loss: 1.2530\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 187us/sample - loss: 1.2515\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 250us/sample - loss: 0.3770 - acc: 0.9062\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 191us/sample - loss: 0.1458 - acc: 0.9299 - val_loss: 0.2939 - val_acc: 0.8778\n",
      "Epoch 18\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 265us/sample - loss: 1.1451\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 249us/sample - loss: 1.1445\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 327us/sample - loss: 0.4302 - acc: 0.8906\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 191us/sample - loss: 0.1523 - acc: 0.9229 - val_loss: 0.1950 - val_acc: 0.8972\n",
      "Epoch 19\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 140us/sample - loss: 1.3490\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 203us/sample - loss: 1.3472\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 249us/sample - loss: 0.3320 - acc: 0.9531\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 192us/sample - loss: 0.1454 - acc: 0.9299 - val_loss: 0.1517 - val_acc: 0.9417\n",
      "Epoch 20\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 301us/sample - loss: 1.1164\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 296us/sample - loss: 1.1162\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 234us/sample - loss: 0.4344 - acc: 0.8906\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 190us/sample - loss: 0.1427 - acc: 0.9264 - val_loss: 0.1517 - val_acc: 0.9389\n",
      "Epoch 21\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 187us/sample - loss: 1.2752\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 249us/sample - loss: 1.2721\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 312us/sample - loss: 0.3918 - acc: 0.8750\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 192us/sample - loss: 0.1582 - acc: 0.9146 - val_loss: 0.2036 - val_acc: 0.8833\n",
      "Epoch 22\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 203us/sample - loss: 1.2368\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 187us/sample - loss: 1.2364\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 249us/sample - loss: 0.3915 - acc: 0.8750\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 246us/sample - loss: 0.1471 - acc: 0.9194 - val_loss: 0.1677 - val_acc: 0.9222\n",
      "Epoch 23\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 203us/sample - loss: 1.1875\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 265us/sample - loss: 1.1837\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 203us/sample - loss: 0.4138 - acc: 0.8906\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 190us/sample - loss: 0.1433 - acc: 0.9257 - val_loss: 0.1851 - val_acc: 0.9167\n",
      "Epoch 24\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 156us/sample - loss: 1.2403\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 203us/sample - loss: 1.2407\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 234us/sample - loss: 0.3908 - acc: 0.8750\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 191us/sample - loss: 0.1399 - acc: 0.9312 - val_loss: 0.1755 - val_acc: 0.9167\n",
      "Epoch 25\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 218us/sample - loss: 1.2749\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 218us/sample - loss: 1.2744\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 234us/sample - loss: 0.3610 - acc: 0.9688\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 202us/sample - loss: 0.1548 - acc: 0.9181 - val_loss: 0.1589 - val_acc: 0.9083\n",
      "Epoch 26\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 203us/sample - loss: 1.2607\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 203us/sample - loss: 1.2600\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 374us/sample - loss: 0.3804 - acc: 0.8906\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 199us/sample - loss: 0.1668 - acc: 0.9167 - val_loss: 0.1589 - val_acc: 0.9000\n",
      "Epoch 27\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 171us/sample - loss: 1.3216\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 203us/sample - loss: 1.3026\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 249us/sample - loss: 0.3697 - acc: 0.8906\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 206us/sample - loss: 0.1454 - acc: 0.9201 - val_loss: 0.1725 - val_acc: 0.8944\n",
      "Epoch 28\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 156us/sample - loss: 1.1946\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 249us/sample - loss: 1.1977\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 234us/sample - loss: 0.3934 - acc: 0.9375\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 215us/sample - loss: 0.1584 - acc: 0.9194 - val_loss: 0.1682 - val_acc: 0.9000\n",
      "Epoch 29\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 187us/sample - loss: 1.2437\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 280us/sample - loss: 1.2447\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 327us/sample - loss: 0.3633 - acc: 0.9688\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 201us/sample - loss: 0.1668 - acc: 0.9174 - val_loss: 0.1917 - val_acc: 0.8833\n",
      "Epoch 30\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 160us/sample - loss: 1.3567\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 187us/sample - loss: 1.3457\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 234us/sample - loss: 0.3684 - acc: 0.9375\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 216us/sample - loss: 0.1604 - acc: 0.9187 - val_loss: 0.1933 - val_acc: 0.8861\n",
      "Epoch 31\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 156us/sample - loss: 1.3001\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 203us/sample - loss: 1.3011\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 234us/sample - loss: 0.3566 - acc: 0.9375\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 222us/sample - loss: 0.1709 - acc: 0.9132 - val_loss: 0.2185 - val_acc: 0.8750\n",
      "Epoch 32\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 156us/sample - loss: 1.2472\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 203us/sample - loss: 1.2427\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 234us/sample - loss: 0.4109 - acc: 0.8750\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 257us/sample - loss: 0.1511 - acc: 0.9285 - val_loss: 0.1858 - val_acc: 0.8889\n",
      "Epoch 33\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 187us/sample - loss: 1.2904\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 249us/sample - loss: 1.2917\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 234us/sample - loss: 0.3544 - acc: 0.9531\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 208us/sample - loss: 0.1453 - acc: 0.9319 - val_loss: 0.1633 - val_acc: 0.9000\n",
      "Epoch 34\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 156us/sample - loss: 1.1368\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 171us/sample - loss: 1.1365\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 249us/sample - loss: 0.4395 - acc: 0.8750\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 195us/sample - loss: 0.1572 - acc: 0.9250 - val_loss: 0.1537 - val_acc: 0.9472\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 234us/sample - loss: 1.2980\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 312us/sample - loss: 1.2966\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 374us/sample - loss: 0.3583 - acc: 0.9375\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 191us/sample - loss: 0.1486 - acc: 0.9292 - val_loss: 0.1564 - val_acc: 0.9417\n",
      "Epoch 36\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 187us/sample - loss: 1.2386\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 187us/sample - loss: 1.2377\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 265us/sample - loss: 0.4025 - acc: 0.8594\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 192us/sample - loss: 0.1586 - acc: 0.9229 - val_loss: 0.1919 - val_acc: 0.8833\n",
      "Epoch 37\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 234us/sample - loss: 1.3509\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 312us/sample - loss: 1.3488\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 390us/sample - loss: 0.3448 - acc: 0.9219\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 199us/sample - loss: 0.1569 - acc: 0.9257 - val_loss: 0.1706 - val_acc: 0.9056\n",
      "Epoch 38\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 312us/sample - loss: 1.2657\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 296us/sample - loss: 1.2637\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 296us/sample - loss: 0.3823 - acc: 0.9062\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 184us/sample - loss: 0.1518 - acc: 0.9236 - val_loss: 0.1522 - val_acc: 0.9417\n",
      "Epoch 39\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 187us/sample - loss: 1.2756\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 218us/sample - loss: 1.2734\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 311us/sample - loss: 0.3709 - acc: 0.9375\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 168us/sample - loss: 0.1437 - acc: 0.9229 - val_loss: 0.1610 - val_acc: 0.9028\n",
      "Epoch 40\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 171us/sample - loss: 1.3148\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 452us/sample - loss: 1.3107\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 265us/sample - loss: 0.4187 - acc: 0.8906\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 186us/sample - loss: 0.1436 - acc: 0.9222 - val_loss: 0.1602 - val_acc: 0.8889\n",
      "Epoch 41\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 187us/sample - loss: 1.1943\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 234us/sample - loss: 1.1942\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 312us/sample - loss: 0.3988 - acc: 0.9219\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 216us/sample - loss: 0.1479 - acc: 0.9222 - val_loss: 0.1593 - val_acc: 0.9250\n",
      "Epoch 42\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 218us/sample - loss: 1.2674\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 218us/sample - loss: 1.2659\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 312us/sample - loss: 0.3770 - acc: 0.8750\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 287us/sample - loss: 0.1473 - acc: 0.9285 - val_loss: 0.1570 - val_acc: 0.9083\n",
      "Epoch 43\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 281us/sample - loss: 1.3203\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 281us/sample - loss: 1.3185\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 358us/sample - loss: 0.3573 - acc: 0.9062\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 233us/sample - loss: 0.1535 - acc: 0.9194 - val_loss: 0.1622 - val_acc: 0.9389\n",
      "Epoch 44\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 187us/sample - loss: 1.3395\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 265us/sample - loss: 1.3354\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 234us/sample - loss: 0.3886 - acc: 0.9062\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 241us/sample - loss: 0.1479 - acc: 0.9299 - val_loss: 0.2199 - val_acc: 0.9111\n",
      "Epoch 45\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 203us/sample - loss: 1.2382\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 218us/sample - loss: 1.2391\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 281us/sample - loss: 0.3997 - acc: 0.8750\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 240us/sample - loss: 0.1648 - acc: 0.9174 - val_loss: 0.1566 - val_acc: 0.9444\n",
      "Epoch 46\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 234us/sample - loss: 1.2221\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 390us/sample - loss: 1.2216\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 405us/sample - loss: 0.4007 - acc: 0.8906\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 222us/sample - loss: 0.1459 - acc: 0.9285 - val_loss: 0.1800 - val_acc: 0.9167\n",
      "Epoch 47\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 203us/sample - loss: 1.3171\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 265us/sample - loss: 1.3142\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 281us/sample - loss: 0.3519 - acc: 0.9375\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 210us/sample - loss: 0.1578 - acc: 0.9208 - val_loss: 0.1923 - val_acc: 0.8917\n",
      "Epoch 48\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 156us/sample - loss: 1.2995\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 296us/sample - loss: 1.2981\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 296us/sample - loss: 0.3558 - acc: 0.9688\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 204us/sample - loss: 0.1591 - acc: 0.9229 - val_loss: 0.2594 - val_acc: 0.8889\n",
      "Epoch 49\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 171us/sample - loss: 1.1815\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 203us/sample - loss: 1.1796\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 187us/sample - loss: 0.4222 - acc: 0.8906\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 205us/sample - loss: 0.1729 - acc: 0.9069 - val_loss: 0.1915 - val_acc: 0.8806\n",
      "Epoch 50\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 152us/sample - loss: 1.3299\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 171us/sample - loss: 1.3245\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 265us/sample - loss: 0.3520 - acc: 0.9219\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 187us/sample - loss: 0.1609 - acc: 0.9153 - val_loss: 0.1738 - val_acc: 0.9222\n",
      "Epoch 51\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 218us/sample - loss: 1.1737\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 171us/sample - loss: 1.1740\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 218us/sample - loss: 0.4309 - acc: 0.8594\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 196us/sample - loss: 0.1490 - acc: 0.9243 - val_loss: 0.1690 - val_acc: 0.9222\n",
      "Epoch 52\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 187us/sample - loss: 1.2486\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 296us/sample - loss: 1.2480\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 171us/sample - loss: 0.3774 - acc: 0.9375\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 210us/sample - loss: 0.1492 - acc: 0.9222 - val_loss: 0.1534 - val_acc: 0.9444\n",
      "Epoch 53\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 281us/sample - loss: 1.4800\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 187us/sample - loss: 1.4770\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 234us/sample - loss: 0.3604 - acc: 0.9062\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 158us/sample - loss: 0.1419 - acc: 0.9250 - val_loss: 0.1570 - val_acc: 0.9472\n",
      "Epoch 54\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 265us/sample - loss: 1.2865\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 312us/sample - loss: 1.2875\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 249us/sample - loss: 0.3666 - acc: 0.9219\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 191us/sample - loss: 0.1422 - acc: 0.9278 - val_loss: 0.1570 - val_acc: 0.9111\n",
      "Epoch 55\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 296us/sample - loss: 1.2595\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 234us/sample - loss: 1.2590\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 281us/sample - loss: 0.3783 - acc: 0.9219\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 189us/sample - loss: 0.1416 - acc: 0.9306 - val_loss: 0.1525 - val_acc: 0.9444\n",
      "Epoch 56\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 249us/sample - loss: 1.2761\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 203us/sample - loss: 1.2665\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 218us/sample - loss: 0.3937 - acc: 0.8750\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 194us/sample - loss: 0.1512 - acc: 0.9208 - val_loss: 0.1939 - val_acc: 0.9083\n",
      "Epoch 57\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 187us/sample - loss: 1.1893\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 234us/sample - loss: 1.1907\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 327us/sample - loss: 0.4218 - acc: 0.8750\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 203us/sample - loss: 0.1461 - acc: 0.9257 - val_loss: 0.1962 - val_acc: 0.9083\n",
      "Epoch 58\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 187us/sample - loss: 1.2665\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 218us/sample - loss: 1.2674\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 280us/sample - loss: 0.3791 - acc: 0.9219\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 188us/sample - loss: 0.1496 - acc: 0.9236 - val_loss: 0.1644 - val_acc: 0.9361\n",
      "Epoch 59\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 203us/sample - loss: 1.2339\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 203us/sample - loss: 1.2335\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 296us/sample - loss: 0.3921 - acc: 0.9375\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 193us/sample - loss: 0.1416 - acc: 0.9354 - val_loss: 0.1686 - val_acc: 0.9333\n",
      "Epoch 60\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 181us/sample - loss: 1.2897\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 203us/sample - loss: 1.2877\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 327us/sample - loss: 0.3627 - acc: 0.9531\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 197us/sample - loss: 0.1439 - acc: 0.9222 - val_loss: 0.1979 - val_acc: 0.8972\n",
      "Epoch 61\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 234us/sample - loss: 1.2006\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 281us/sample - loss: 1.1981\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 218us/sample - loss: 0.4043 - acc: 0.9062\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 192us/sample - loss: 0.1647 - acc: 0.9257 - val_loss: 0.1530 - val_acc: 0.9528\n",
      "Epoch 62\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 156us/sample - loss: 1.3278\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 265us/sample - loss: 1.3256\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 203us/sample - loss: 0.3330 - acc: 0.9688\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 260us/sample - loss: 0.1428 - acc: 0.9250 - val_loss: 0.1533 - val_acc: 0.9306\n",
      "Epoch 63\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 171us/sample - loss: 1.1252\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 265us/sample - loss: 1.1220\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 156us/sample - loss: 0.4463 - acc: 0.8594\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 206us/sample - loss: 0.1491 - acc: 0.9250 - val_loss: 0.1562 - val_acc: 0.9306\n",
      "Epoch 64\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 171us/sample - loss: 1.3008\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 218us/sample - loss: 1.2975\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 187us/sample - loss: 0.3605 - acc: 0.9062\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 209us/sample - loss: 0.1557 - acc: 0.9201 - val_loss: 0.1834 - val_acc: 0.8833\n",
      "Epoch 65\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 187us/sample - loss: 1.2834\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 187us/sample - loss: 1.2816\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 296us/sample - loss: 0.3660 - acc: 0.9219\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 192us/sample - loss: 0.1504 - acc: 0.9278 - val_loss: 0.1774 - val_acc: 0.9306\n",
      "Epoch 66\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 156us/sample - loss: 1.1761\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 218us/sample - loss: 1.1714\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 203us/sample - loss: 0.4109 - acc: 0.8906\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 223us/sample - loss: 0.1470 - acc: 0.9319 - val_loss: 0.1496 - val_acc: 0.9500\n",
      "Epoch 67\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 156us/sample - loss: 1.2877\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 234us/sample - loss: 1.2858\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 218us/sample - loss: 0.3651 - acc: 0.9062\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 220us/sample - loss: 0.1536 - acc: 0.9312 - val_loss: 0.2011 - val_acc: 0.8722\n",
      "Epoch 68\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 187us/sample - loss: 1.1500\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 249us/sample - loss: 1.1465\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 171us/sample - loss: 0.4189 - acc: 0.9062\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 196us/sample - loss: 0.1856 - acc: 0.9174 - val_loss: 0.2113 - val_acc: 0.8889\n",
      "Epoch 69\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 171us/sample - loss: 1.4280\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 234us/sample - loss: 1.4261\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 203us/sample - loss: 0.3498 - acc: 0.9219\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 193us/sample - loss: 0.1562 - acc: 0.9278 - val_loss: 0.1614 - val_acc: 0.8944\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 70\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 278us/sample - loss: 1.3269\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 265us/sample - loss: 1.3266\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 218us/sample - loss: 0.3348 - acc: 0.9688\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 192us/sample - loss: 0.1577 - acc: 0.9125 - val_loss: 0.1852 - val_acc: 0.8917\n",
      "Epoch 71\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 187us/sample - loss: 1.2592\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 187us/sample - loss: 1.2537\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 234us/sample - loss: 0.3684 - acc: 0.9688\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 165us/sample - loss: 0.1464 - acc: 0.9319 - val_loss: 0.1648 - val_acc: 0.9361\n",
      "Epoch 72\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 296us/sample - loss: 1.2235\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 203us/sample - loss: 1.2227\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 296us/sample - loss: 0.4015 - acc: 0.8750\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - ETA: 0s - loss: 0.1527 - acc: 0.927 - 0s 242us/sample - loss: 0.1469 - acc: 0.9319 - val_loss: 0.1841 - val_acc: 0.9167\n",
      "Epoch 73\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 156us/sample - loss: 1.2950\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 203us/sample - loss: 1.2948\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 265us/sample - loss: 0.3739 - acc: 0.8906\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 197us/sample - loss: 0.1435 - acc: 0.9333 - val_loss: 0.1718 - val_acc: 0.8944\n",
      "Epoch 74\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 234us/sample - loss: 1.2444\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 312us/sample - loss: 1.2421\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 281us/sample - loss: 0.3712 - acc: 0.9375\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 179us/sample - loss: 0.1607 - acc: 0.9167 - val_loss: 0.1627 - val_acc: 0.9278\n",
      "Epoch 75\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 234us/sample - loss: 1.2651\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 296us/sample - loss: 1.2648\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 468us/sample - loss: 0.3941 - acc: 0.8281\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 195us/sample - loss: 0.1621 - acc: 0.9132 - val_loss: 0.1792 - val_acc: 0.9167\n",
      "Epoch 76\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 234us/sample - loss: 1.2728\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 280us/sample - loss: 1.2700\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 296us/sample - loss: 0.3727 - acc: 0.9219\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 183us/sample - loss: 0.1360 - acc: 0.9326 - val_loss: 0.1587 - val_acc: 0.9389\n",
      "Epoch 77\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 203us/sample - loss: 1.4621\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 280us/sample - loss: 1.4523\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 327us/sample - loss: 0.4396 - acc: 0.8281\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 200us/sample - loss: 0.1382 - acc: 0.9354 - val_loss: 0.1617 - val_acc: 0.9000\n",
      "Epoch 78\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 203us/sample - loss: 1.2896\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 265us/sample - loss: 1.2893\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 249us/sample - loss: 0.3683 - acc: 0.8906\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 187us/sample - loss: 0.1434 - acc: 0.9278 - val_loss: 0.1603 - val_acc: 0.9306\n",
      "Epoch 79\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 171us/sample - loss: 1.2577\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 234us/sample - loss: 1.2592\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 265us/sample - loss: 0.3888 - acc: 0.8750\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 186us/sample - loss: 0.1410 - acc: 0.9299 - val_loss: 0.1929 - val_acc: 0.9139\n",
      "Epoch 80\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 275us/sample - loss: 1.3109\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 171us/sample - loss: 1.3095\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 218us/sample - loss: 0.3438 - acc: 0.9531\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 211us/sample - loss: 0.1567 - acc: 0.9257 - val_loss: 0.1663 - val_acc: 0.9333\n",
      "Epoch 81\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 171us/sample - loss: 1.1325\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 234us/sample - loss: 1.1313\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 265us/sample - loss: 0.4552 - acc: 0.8281\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 198us/sample - loss: 0.1442 - acc: 0.9278 - val_loss: 0.1672 - val_acc: 0.9000\n",
      "Epoch 82\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 249us/sample - loss: 1.3049\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 296us/sample - loss: 1.3027\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 358us/sample - loss: 0.3648 - acc: 0.9219\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 336us/sample - loss: 0.1453 - acc: 0.9257 - val_loss: 0.1596 - val_acc: 0.9472\n",
      "Epoch 83\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 218us/sample - loss: 1.2734\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 327us/sample - loss: 1.2700\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 358us/sample - loss: 0.3775 - acc: 0.8906\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 235us/sample - loss: 0.1398 - acc: 0.9333 - val_loss: 0.1749 - val_acc: 0.9028\n",
      "Epoch 84\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 187us/sample - loss: 1.6107\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 187us/sample - loss: 1.6040\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 187us/sample - loss: 0.3567 - acc: 0.9219\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 233us/sample - loss: 0.1416 - acc: 0.9319 - val_loss: 0.1565 - val_acc: 0.9444\n",
      "Epoch 85\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 249us/sample - loss: 1.2528\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 265us/sample - loss: 1.2536\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 327us/sample - loss: 0.3778 - acc: 0.9375\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 223us/sample - loss: 0.1519 - acc: 0.9257 - val_loss: 0.1772 - val_acc: 0.9167\n",
      "Epoch 86\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 203us/sample - loss: 1.2125\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 265us/sample - loss: 1.2000\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 202us/sample - loss: 0.4455 - acc: 0.8125\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 233us/sample - loss: 0.1488 - acc: 0.9243 - val_loss: 0.2202 - val_acc: 0.8917\n",
      "Epoch 87\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 187us/sample - loss: 1.3436\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 203us/sample - loss: 1.3469\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 280us/sample - loss: 0.3330 - acc: 0.9688\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 237us/sample - loss: 0.1540 - acc: 0.9236 - val_loss: 0.1621 - val_acc: 0.9417\n",
      "Epoch 88\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 187us/sample - loss: 1.3575\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 327us/sample - loss: 1.3314\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 530us/sample - loss: 0.4176 - acc: 0.8750\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 209us/sample - loss: 0.1390 - acc: 0.9292 - val_loss: 0.1531 - val_acc: 0.9361\n",
      "Epoch 89\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 234us/sample - loss: 1.3354\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 296us/sample - loss: 1.3390\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 265us/sample - loss: 0.3321 - acc: 0.9531\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 222us/sample - loss: 0.1418 - acc: 0.9299 - val_loss: 0.1528 - val_acc: 0.9333\n",
      "Epoch 90\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 265us/sample - loss: 1.2129\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 343us/sample - loss: 1.2125\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 281us/sample - loss: 0.4056 - acc: 0.8906\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 189us/sample - loss: 0.1451 - acc: 0.9264 - val_loss: 0.1549 - val_acc: 0.9111\n",
      "Epoch 91\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 265us/sample - loss: 1.2535\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 280us/sample - loss: 1.2520\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 312us/sample - loss: 0.3808 - acc: 0.9375\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 189us/sample - loss: 0.1462 - acc: 0.9306 - val_loss: 0.1689 - val_acc: 0.9250\n",
      "Epoch 92\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 218us/sample - loss: 1.1564\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 296us/sample - loss: 1.1529\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 281us/sample - loss: 0.4477 - acc: 0.8281\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 217us/sample - loss: 0.1483 - acc: 0.9264 - val_loss: 0.1575 - val_acc: 0.9333\n",
      "Epoch 93\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 249us/sample - loss: 1.3531\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 234us/sample - loss: 1.3508\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 249us/sample - loss: 0.3523 - acc: 0.9219\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 192us/sample - loss: 0.1442 - acc: 0.9278 - val_loss: 0.1738 - val_acc: 0.8889\n",
      "Epoch 94\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 156us/sample - loss: 1.1907\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 187us/sample - loss: 1.1900\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 296us/sample - loss: 0.4159 - acc: 0.9062\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 198us/sample - loss: 0.1712 - acc: 0.9187 - val_loss: 0.1633 - val_acc: 0.9056\n",
      "Epoch 95\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 234us/sample - loss: 1.4472\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 249us/sample - loss: 1.4420\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 265us/sample - loss: 0.3050 - acc: 0.9844\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 213us/sample - loss: 0.1473 - acc: 0.9319 - val_loss: 0.1576 - val_acc: 0.9472\n",
      "Epoch 96\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 296us/sample - loss: 1.2121\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 296us/sample - loss: 1.2130\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 250us/sample - loss: 0.4322 - acc: 0.8594\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 204us/sample - loss: 0.1495 - acc: 0.9222 - val_loss: 0.2186 - val_acc: 0.8944\n",
      "Epoch 97\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 187us/sample - loss: 1.3105\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 358us/sample - loss: 1.3106\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 312us/sample - loss: 0.3681 - acc: 0.9219\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 188us/sample - loss: 0.1489 - acc: 0.9264 - val_loss: 0.1513 - val_acc: 0.9444\n",
      "Epoch 98\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 218us/sample - loss: 1.1370\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 218us/sample - loss: 1.1261\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 234us/sample - loss: 0.4455 - acc: 0.8750\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 199us/sample - loss: 0.1480 - acc: 0.9285 - val_loss: 0.1690 - val_acc: 0.9333\n",
      "Epoch 99\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 187us/sample - loss: 1.2980\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 203us/sample - loss: 1.2983\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 312us/sample - loss: 0.3743 - acc: 0.9062\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 211us/sample - loss: 0.1442 - acc: 0.9278 - val_loss: 0.1561 - val_acc: 0.9472\n",
      "Epoch 100\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 156us/sample - loss: 1.1769\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 171us/sample - loss: 1.1743\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 281us/sample - loss: 0.4387 - acc: 0.8594\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 197us/sample - loss: 0.1458 - acc: 0.9326 - val_loss: 0.1574 - val_acc: 0.9139\n",
      "Epoch 101\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 156us/sample - loss: 1.2673\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 171us/sample - loss: 1.2632\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 280us/sample - loss: 0.3845 - acc: 0.8906\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 197us/sample - loss: 0.1628 - acc: 0.9222 - val_loss: 0.1638 - val_acc: 0.9333\n",
      "Epoch 102\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 203us/sample - loss: 1.2489\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 265us/sample - loss: 1.2446\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 218us/sample - loss: 0.3857 - acc: 0.9062\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 233us/sample - loss: 0.1562 - acc: 0.9208 - val_loss: 0.1639 - val_acc: 0.9250\n",
      "Epoch 103\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 171us/sample - loss: 1.1255\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 187us/sample - loss: 1.1198\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 249us/sample - loss: 0.4371 - acc: 0.8906\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 199us/sample - loss: 0.1436 - acc: 0.9319 - val_loss: 0.1515 - val_acc: 0.9500\n",
      "Epoch 104\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 187us/sample - loss: 1.2367\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 234us/sample - loss: 1.2406\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 203us/sample - loss: 0.3848 - acc: 0.9062\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 211us/sample - loss: 0.1396 - acc: 0.9264 - val_loss: 0.1617 - val_acc: 0.8972\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 105\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 171us/sample - loss: 1.3125\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 265us/sample - loss: 1.3116\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 234us/sample - loss: 0.3667 - acc: 0.8906\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 198us/sample - loss: 0.1378 - acc: 0.9319 - val_loss: 0.1579 - val_acc: 0.9472\n",
      "Epoch 106\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 280us/sample - loss: 1.1819\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 327us/sample - loss: 1.1808\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 296us/sample - loss: 0.4250 - acc: 0.8281\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 197us/sample - loss: 0.1557 - acc: 0.9208 - val_loss: 0.1675 - val_acc: 0.9278\n",
      "Epoch 107\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 280us/sample - loss: 1.2069\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 218us/sample - loss: 1.2053\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 358us/sample - loss: 0.4177 - acc: 0.8594\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 196us/sample - loss: 0.1552 - acc: 0.9236 - val_loss: 0.2393 - val_acc: 0.9111\n",
      "Epoch 108\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 265us/sample - loss: 1.2071\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 296us/sample - loss: 1.2046\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 296us/sample - loss: 0.4094 - acc: 0.8438\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 186us/sample - loss: 0.1665 - acc: 0.9208 - val_loss: 0.1969 - val_acc: 0.9250\n",
      "Epoch 109\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 203us/sample - loss: 1.2124\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 249us/sample - loss: 1.2092\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 265us/sample - loss: 0.4163 - acc: 0.8281\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 194us/sample - loss: 0.1512 - acc: 0.9278 - val_loss: 0.1741 - val_acc: 0.9250\n",
      "Epoch 110\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 358us/sample - loss: 1.1536\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 218us/sample - loss: 1.1522\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 280us/sample - loss: 0.4424 - acc: 0.8281\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 181us/sample - loss: 0.1449 - acc: 0.9201 - val_loss: 0.1604 - val_acc: 0.9361\n",
      "Epoch 111\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 171us/sample - loss: 1.2826\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 280us/sample - loss: 1.2779\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 312us/sample - loss: 0.3763 - acc: 0.8906\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 219us/sample - loss: 0.1395 - acc: 0.9333 - val_loss: 0.1791 - val_acc: 0.9000\n",
      "Epoch 112\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 156us/sample - loss: 1.2955\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 249us/sample - loss: 1.2887\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 249us/sample - loss: 0.3681 - acc: 0.8906\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 248us/sample - loss: 0.1568 - acc: 0.9222 - val_loss: 0.1601 - val_acc: 0.9056\n",
      "Epoch 113\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 171us/sample - loss: 1.1837\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 249us/sample - loss: 1.1710\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 249us/sample - loss: 0.4332 - acc: 0.7969\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 187us/sample - loss: 0.1444 - acc: 0.9257 - val_loss: 0.1554 - val_acc: 0.9444\n",
      "Epoch 114\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 171us/sample - loss: 1.2165\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 265us/sample - loss: 1.2157\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 249us/sample - loss: 0.4131 - acc: 0.8281\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 196us/sample - loss: 0.1409 - acc: 0.9354 - val_loss: 0.2018 - val_acc: 0.8972\n",
      "Epoch 115\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 203us/sample - loss: 1.3114\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 218us/sample - loss: 1.3049\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 265us/sample - loss: 0.3532 - acc: 0.8906\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 190us/sample - loss: 0.1645 - acc: 0.9243 - val_loss: 0.2147 - val_acc: 0.8778\n",
      "Epoch 116\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 156us/sample - loss: 1.1946\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 203us/sample - loss: 1.1950\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 187us/sample - loss: 0.4170 - acc: 0.8750\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 235us/sample - loss: 0.1686 - acc: 0.9167 - val_loss: 0.1650 - val_acc: 0.9278\n",
      "Epoch 117\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 203us/sample - loss: 1.1746\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 218us/sample - loss: 1.1734\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 218us/sample - loss: 0.4301 - acc: 0.8594\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 221us/sample - loss: 0.1655 - acc: 0.9194 - val_loss: 0.1964 - val_acc: 0.9278\n",
      "Epoch 118\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 187us/sample - loss: 1.2498\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 171us/sample - loss: 1.2483\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 234us/sample - loss: 0.3776 - acc: 0.8906\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 208us/sample - loss: 0.1680 - acc: 0.9257 - val_loss: 0.2676 - val_acc: 0.8750\n",
      "Epoch 119\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 171us/sample - loss: 1.1612\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 203us/sample - loss: 1.1301\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 234us/sample - loss: 0.4793 - acc: 0.8125\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 193us/sample - loss: 0.1777 - acc: 0.9132 - val_loss: 0.1782 - val_acc: 0.9278\n",
      "Epoch 120\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 202us/sample - loss: 1.3310\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 203us/sample - loss: 1.3236\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 218us/sample - loss: 0.3972 - acc: 0.8750\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 211us/sample - loss: 0.1510 - acc: 0.9292 - val_loss: 0.1535 - val_acc: 0.9528\n",
      "Epoch 121\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 156us/sample - loss: 1.2445\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 171us/sample - loss: 1.2424\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 234us/sample - loss: 0.4096 - acc: 0.8594\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 230us/sample - loss: 0.1402 - acc: 0.9271 - val_loss: 0.1972 - val_acc: 0.9000\n",
      "Epoch 122\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 203us/sample - loss: 1.1476\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 218us/sample - loss: 1.1467\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 187us/sample - loss: 0.4340 - acc: 0.8125\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 279us/sample - loss: 0.1408 - acc: 0.9326 - val_loss: 0.1524 - val_acc: 0.9500\n",
      "Epoch 123\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 249us/sample - loss: 1.2312\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 296us/sample - loss: 1.2298\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 390us/sample - loss: 0.4114 - acc: 0.8438\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 205us/sample - loss: 0.1430 - acc: 0.9250 - val_loss: 0.1681 - val_acc: 0.9333\n",
      "Epoch 124\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 343us/sample - loss: 1.2033\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 281us/sample - loss: 1.1989\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 296us/sample - loss: 0.4472 - acc: 0.7656\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 237us/sample - loss: 0.1425 - acc: 0.9333 - val_loss: 0.1637 - val_acc: 0.9389\n",
      "Epoch 125\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 218us/sample - loss: 1.2535\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 390us/sample - loss: 1.2518\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 312us/sample - loss: 0.3872 - acc: 0.9062\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 204us/sample - loss: 0.1481 - acc: 0.9208 - val_loss: 0.1782 - val_acc: 0.9250\n",
      "Epoch 126\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 265us/sample - loss: 1.2292\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 343us/sample - loss: 1.2260\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - ETA: 0s - loss: 0.4481 - acc: 0.843 - 0s 327us/sample - loss: 0.4023 - acc: 0.8594\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 227us/sample - loss: 0.1450 - acc: 0.9278 - val_loss: 0.1606 - val_acc: 0.9083\n",
      "Epoch 127\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 468us/sample - loss: 1.2943\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 280us/sample - loss: 1.2898\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 187us/sample - loss: 0.3752 - acc: 0.8750\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 226us/sample - loss: 0.1408 - acc: 0.9250 - val_loss: 0.1593 - val_acc: 0.9111\n",
      "Epoch 128\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 234us/sample - loss: 1.2544\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 280us/sample - loss: 1.2516\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 218us/sample - loss: 0.3899 - acc: 0.8750\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 181us/sample - loss: 0.1453 - acc: 0.9292 - val_loss: 0.1707 - val_acc: 0.9361\n",
      "Epoch 129\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 171us/sample - loss: 1.1692\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 281us/sample - loss: 1.1637\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 249us/sample - loss: 0.4376 - acc: 0.8281\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 221us/sample - loss: 0.1484 - acc: 0.9257 - val_loss: 0.1719 - val_acc: 0.8889\n",
      "Epoch 130\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 394us/sample - loss: 1.4902\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 203us/sample - loss: 1.4862\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 218us/sample - loss: 0.4107 - acc: 0.8281\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 212us/sample - loss: 0.1407 - acc: 0.9292 - val_loss: 0.1564 - val_acc: 0.9444\n",
      "Epoch 131\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 250us/sample - loss: 1.2649\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 218us/sample - loss: 1.2613\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 203us/sample - loss: 0.3871 - acc: 0.8750\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 220us/sample - loss: 0.1449 - acc: 0.9264 - val_loss: 0.1743 - val_acc: 0.9222\n",
      "Epoch 132\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 218us/sample - loss: 1.1501\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 203us/sample - loss: 1.1446\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 218us/sample - loss: 0.4588 - acc: 0.7656\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 229us/sample - loss: 0.1742 - acc: 0.9174 - val_loss: 0.1749 - val_acc: 0.9333\n",
      "Epoch 133\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 156us/sample - loss: 1.2307\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 249us/sample - loss: 1.2295\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 265us/sample - loss: 0.3997 - acc: 0.8281\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 188us/sample - loss: 0.1406 - acc: 0.9319 - val_loss: 0.1599 - val_acc: 0.9417\n",
      "Epoch 134\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 187us/sample - loss: 1.2290\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 265us/sample - loss: 1.2278\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 1ms/sample - loss: 0.3962 - acc: 0.8750\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 3s 2ms/sample - loss: 0.1636 - acc: 0.9236 - val_loss: 0.1707 - val_acc: 0.9250\n",
      "Epoch 135\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 1ms/sample - loss: 1.2051\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 1ms/sample - loss: 1.1990\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 1ms/sample - loss: 0.4088 - acc: 0.8750\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 1s 625us/sample - loss: 0.1642 - acc: 0.9118 - val_loss: 0.1939 - val_acc: 0.9278\n",
      "Epoch 136\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 290us/sample - loss: 1.2231\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 334us/sample - loss: 1.2223\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 251us/sample - loss: 0.4210 - acc: 0.8438\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 251us/sample - loss: 0.1613 - acc: 0.9229 - val_loss: 0.1524 - val_acc: 0.9500\n",
      "Epoch 137\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 262us/sample - loss: 1.2269\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 258us/sample - loss: 1.2248\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 234us/sample - loss: 0.3932 - acc: 0.8906\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 240us/sample - loss: 0.1444 - acc: 0.9264 - val_loss: 0.1594 - val_acc: 0.9139\n",
      "Epoch 138\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 208us/sample - loss: 1.2230\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 302us/sample - loss: 1.2216\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 235us/sample - loss: 0.4261 - acc: 0.7500\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 249us/sample - loss: 0.1422 - acc: 0.9326 - val_loss: 0.1662 - val_acc: 0.9278\n",
      "Epoch 139\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 196us/sample - loss: 1.2243\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 384us/sample - loss: 1.2218\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 232us/sample - loss: 0.4024 - acc: 0.8750\n",
      "Train on 1440 samples, validate on 360 samples\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1440/1440 [==============================] - 0s 257us/sample - loss: 0.1441 - acc: 0.9299 - val_loss: 0.1687 - val_acc: 0.9306\n",
      "Epoch 140\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 200us/sample - loss: 1.2746\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 306us/sample - loss: 1.2478\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 249us/sample - loss: 0.4415 - acc: 0.7969\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 248us/sample - loss: 0.1392 - acc: 0.9382 - val_loss: 0.1528 - val_acc: 0.9528\n",
      "Epoch 141\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 352us/sample - loss: 1.1586\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 361us/sample - loss: 1.1591\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 418us/sample - loss: 0.4358 - acc: 0.8281\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 249us/sample - loss: 0.1428 - acc: 0.9299 - val_loss: 0.1593 - val_acc: 0.9389\n",
      "Epoch 142\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 330us/sample - loss: 1.2556\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 319us/sample - loss: 1.2544\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 273us/sample - loss: 0.3802 - acc: 0.8906\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 287us/sample - loss: 0.1543 - acc: 0.9271 - val_loss: 0.2559 - val_acc: 0.9278\n",
      "Epoch 143\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 333us/sample - loss: 1.1308\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 282us/sample - loss: 1.1293\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 324us/sample - loss: 0.4663 - acc: 0.7656\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 276us/sample - loss: 0.1466 - acc: 0.9347 - val_loss: 0.1647 - val_acc: 0.9306\n",
      "Epoch 144\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 255us/sample - loss: 1.2593\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 302us/sample - loss: 1.2505\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 262us/sample - loss: 0.4148 - acc: 0.8594\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 243us/sample - loss: 0.1442 - acc: 0.9340 - val_loss: 0.1931 - val_acc: 0.8972\n",
      "Epoch 145\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - ETA: 0s - loss: 1.244 - 0s 361us/sample - loss: 1.2504\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 375us/sample - loss: 1.2495\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 298us/sample - loss: 0.3946 - acc: 0.8594\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 222us/sample - loss: 0.1722 - acc: 0.9132 - val_loss: 0.1602 - val_acc: 0.9278\n",
      "Epoch 146\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 245us/sample - loss: 1.2848\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 327us/sample - loss: 1.2817\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 316us/sample - loss: 0.3774 - acc: 0.8750\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 251us/sample - loss: 0.1485 - acc: 0.9278 - val_loss: 0.1634 - val_acc: 0.9222\n",
      "Epoch 147\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 218us/sample - loss: 1.1830\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 258us/sample - loss: 1.1809\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 304us/sample - loss: 0.4353 - acc: 0.8594\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 264us/sample - loss: 0.1525 - acc: 0.9236 - val_loss: 0.2597 - val_acc: 0.8778\n",
      "Epoch 148\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 177us/sample - loss: 1.2004\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 230us/sample - loss: 1.1976\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 289us/sample - loss: 0.4317 - acc: 0.8125\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 246us/sample - loss: 0.1700 - acc: 0.9174 - val_loss: 0.1567 - val_acc: 0.9194\n",
      "Epoch 149\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 269us/sample - loss: 1.1636\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 347us/sample - loss: 1.1605\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 281us/sample - loss: 0.4320 - acc: 0.8438\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 248us/sample - loss: 0.1747 - acc: 0.9160 - val_loss: 0.1524 - val_acc: 0.9417\n",
      "Epoch 150\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 253us/sample - loss: 1.1665\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 241us/sample - loss: 1.1625\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 345us/sample - loss: 0.4344 - acc: 0.7656\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 261us/sample - loss: 0.1624 - acc: 0.9278 - val_loss: 0.1931 - val_acc: 0.9000\n",
      "Epoch 151\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 278us/sample - loss: 1.3999\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 233us/sample - loss: 1.3812\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 342us/sample - loss: 0.4048 - acc: 0.8594\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 273us/sample - loss: 0.1579 - acc: 0.9187 - val_loss: 0.2156 - val_acc: 0.9028\n",
      "Epoch 152\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 304us/sample - loss: 1.0727\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 263us/sample - loss: 1.0717\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 452us/sample - loss: 0.4976 - acc: 0.7500\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 249us/sample - loss: 0.1865 - acc: 0.9174 - val_loss: 0.2349 - val_acc: 0.9083\n",
      "Epoch 153\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 262us/sample - loss: 1.1920\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 321us/sample - loss: 1.1927\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 335us/sample - loss: 0.4186 - acc: 0.8750\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 233us/sample - loss: 0.1504 - acc: 0.9292 - val_loss: 0.1694 - val_acc: 0.9417\n",
      "Epoch 154\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 228us/sample - loss: 1.2224\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 265us/sample - loss: 1.2221\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 359us/sample - loss: 0.3860 - acc: 0.9062\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 253us/sample - loss: 0.1801 - acc: 0.9118 - val_loss: 0.2041 - val_acc: 0.8750\n",
      "Epoch 155\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 249us/sample - loss: 1.2655\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 345us/sample - loss: 1.2637\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 245us/sample - loss: 0.3765 - acc: 0.9062\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 250us/sample - loss: 0.1769 - acc: 0.9201 - val_loss: 0.1870 - val_acc: 0.9167\n",
      "Epoch 156\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 225us/sample - loss: 1.1838\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 309us/sample - loss: 1.1811\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 303us/sample - loss: 0.4292 - acc: 0.8438\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 229us/sample - loss: 0.1807 - acc: 0.9125 - val_loss: 0.1939 - val_acc: 0.9056\n",
      "Epoch 157\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 276us/sample - loss: 1.1533\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 352us/sample - loss: 1.1511\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 228us/sample - loss: 0.4419 - acc: 0.8125\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 242us/sample - loss: 0.1554 - acc: 0.9236 - val_loss: 0.1536 - val_acc: 0.9500\n",
      "Epoch 158\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 278us/sample - loss: 1.2400\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 358us/sample - loss: 1.2369\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 367us/sample - loss: 0.4286 - acc: 0.7969\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 275us/sample - loss: 0.1406 - acc: 0.9326 - val_loss: 0.1550 - val_acc: 0.9333\n",
      "Epoch 159\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 177us/sample - loss: 1.2435\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 265us/sample - loss: 1.2298\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 380us/sample - loss: 0.3931 - acc: 0.8750\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 280us/sample - loss: 0.1397 - acc: 0.9306 - val_loss: 0.1623 - val_acc: 0.9056\n",
      "Epoch 160\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 223us/sample - loss: 1.3254\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 311us/sample - loss: 1.3120\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 310us/sample - loss: 0.4217 - acc: 0.8281\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 242us/sample - loss: 0.1410 - acc: 0.9285 - val_loss: 0.1654 - val_acc: 0.9361\n",
      "Epoch 161\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 281us/sample - loss: 1.2960\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 337us/sample - loss: 1.2984\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 355us/sample - loss: 0.4386 - acc: 0.7969\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 217us/sample - loss: 0.1426 - acc: 0.9326 - val_loss: 0.1509 - val_acc: 0.9417\n",
      "Epoch 162\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 250us/sample - loss: 1.1973\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 399us/sample - loss: 1.1993\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 391us/sample - loss: 0.4249 - acc: 0.8125\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 240us/sample - loss: 0.1458 - acc: 0.9319 - val_loss: 0.1525 - val_acc: 0.9222\n",
      "Epoch 163\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 210us/sample - loss: 1.3049\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 323us/sample - loss: 1.2982\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 276us/sample - loss: 0.3638 - acc: 0.9219\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 267us/sample - loss: 0.1368 - acc: 0.9354 - val_loss: 0.1951 - val_acc: 0.9167\n",
      "Epoch 164\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - ETA: 0s - loss: 1.253 - 0s 260us/sample - loss: 1.1777\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 605us/sample - loss: 1.1781\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 321us/sample - loss: 0.4446 - acc: 0.8594\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 232us/sample - loss: 0.1606 - acc: 0.9201 - val_loss: 0.2019 - val_acc: 0.8889\n",
      "Epoch 165\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 331us/sample - loss: 1.2928\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 366us/sample - loss: 1.2918\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 403us/sample - loss: 0.3651 - acc: 0.8906\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 257us/sample - loss: 0.1437 - acc: 0.9292 - val_loss: 0.1607 - val_acc: 0.9306\n",
      "Epoch 166\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 206us/sample - loss: 1.1917\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 272us/sample - loss: 1.1881\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 299us/sample - loss: 0.4200 - acc: 0.8750\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 239us/sample - loss: 0.1463 - acc: 0.9236 - val_loss: 0.1634 - val_acc: 0.9000\n",
      "Epoch 167\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 153us/sample - loss: 1.2782\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 285us/sample - loss: 1.2743\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 419us/sample - loss: 0.3810 - acc: 0.8906\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 251us/sample - loss: 0.1485 - acc: 0.9222 - val_loss: 0.1516 - val_acc: 0.9417\n",
      "Epoch 168\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 260us/sample - loss: 1.2001\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 285us/sample - loss: 1.1963\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 348us/sample - loss: 0.4285 - acc: 0.8125\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 255us/sample - loss: 0.1429 - acc: 0.9326 - val_loss: 0.1596 - val_acc: 0.9417\n",
      "Epoch 169\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 176us/sample - loss: 1.2251\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 354us/sample - loss: 1.2166\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 292us/sample - loss: 0.4136 - acc: 0.8438\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 245us/sample - loss: 0.1429 - acc: 0.9264 - val_loss: 0.1587 - val_acc: 0.9417\n",
      "Epoch 170\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 230us/sample - loss: 1.2692\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 240us/sample - loss: 1.2660\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 333us/sample - loss: 0.3822 - acc: 0.9062\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 252us/sample - loss: 0.1516 - acc: 0.9306 - val_loss: 0.1758 - val_acc: 0.9278\n",
      "Epoch 171\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 187us/sample - loss: 1.1714\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 312us/sample - loss: 1.1680\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 309us/sample - loss: 0.4444 - acc: 0.7812\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 229us/sample - loss: 0.1567 - acc: 0.9243 - val_loss: 0.1621 - val_acc: 0.9500\n",
      "Epoch 172\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 261us/sample - loss: 1.3035\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 390us/sample - loss: 1.2999\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 397us/sample - loss: 0.3605 - acc: 0.9062\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 241us/sample - loss: 0.1410 - acc: 0.9333 - val_loss: 0.1563 - val_acc: 0.9556\n",
      "Epoch 173\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 187us/sample - loss: 1.1472\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 226us/sample - loss: 1.1445\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 408us/sample - loss: 0.4297 - acc: 0.8594\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 240us/sample - loss: 0.1500 - acc: 0.9271 - val_loss: 0.1760 - val_acc: 0.8944\n",
      "Epoch 174\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 265us/sample - loss: 1.4271\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 356us/sample - loss: 1.3962\n",
      "Fitting discriminator\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64/64 [==============================] - 0s 269us/sample - loss: 0.3730 - acc: 0.8750\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 255us/sample - loss: 0.1440 - acc: 0.9257 - val_loss: 0.1597 - val_acc: 0.9389\n",
      "Epoch 175\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 349us/sample - loss: 1.1572\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 373us/sample - loss: 1.1602\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 296us/sample - loss: 0.4331 - acc: 0.8750\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 248us/sample - loss: 0.1454 - acc: 0.9292 - val_loss: 0.2503 - val_acc: 0.8806\n",
      "Epoch 176\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 228us/sample - loss: 1.0412\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 285us/sample - loss: 1.0393\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 287us/sample - loss: 0.5225 - acc: 0.7500\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 275us/sample - loss: 0.1737 - acc: 0.9118 - val_loss: 0.2620 - val_acc: 0.8861\n",
      "Epoch 177\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 394us/sample - loss: 1.2323\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 542us/sample - loss: 1.2060\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 281us/sample - loss: 0.4196 - acc: 0.8438\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 257us/sample - loss: 0.1864 - acc: 0.9056 - val_loss: 0.1714 - val_acc: 0.9278\n",
      "Epoch 178\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 310us/sample - loss: 1.0888\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 293us/sample - loss: 1.0923\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 350us/sample - loss: 0.5013 - acc: 0.7500\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 259us/sample - loss: 0.1393 - acc: 0.9312 - val_loss: 0.1645 - val_acc: 0.9333\n",
      "Epoch 179\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 292us/sample - loss: 1.1381\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 358us/sample - loss: 1.1390\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 289us/sample - loss: 0.4490 - acc: 0.8125\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 246us/sample - loss: 0.1640 - acc: 0.9187 - val_loss: 0.1921 - val_acc: 0.8861\n",
      "Epoch 180\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 330us/sample - loss: 1.2591\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 354us/sample - loss: 1.2561\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 341us/sample - loss: 0.3866 - acc: 0.9062\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 247us/sample - loss: 0.1501 - acc: 0.9215 - val_loss: 0.2294 - val_acc: 0.9056\n",
      "Epoch 181\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 301us/sample - loss: 1.1048\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 289us/sample - loss: 1.1008\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 300us/sample - loss: 0.4720 - acc: 0.8281\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 249us/sample - loss: 0.1540 - acc: 0.9278 - val_loss: 0.1722 - val_acc: 0.8889\n",
      "Epoch 182\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 230us/sample - loss: 1.1406\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 475us/sample - loss: 1.1393\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 544us/sample - loss: 0.4510 - acc: 0.8281\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 262us/sample - loss: 0.1522 - acc: 0.9229 - val_loss: 0.1592 - val_acc: 0.9139\n",
      "Epoch 183\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 190us/sample - loss: 1.3522\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 368us/sample - loss: 1.3490\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 262us/sample - loss: 0.3416 - acc: 0.9219\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 255us/sample - loss: 0.1416 - acc: 0.9333 - val_loss: 0.1802 - val_acc: 0.8861\n",
      "Epoch 184\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 210us/sample - loss: 1.1713\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 198us/sample - loss: 1.1691\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 279us/sample - loss: 0.4378 - acc: 0.8281\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 253us/sample - loss: 0.1556 - acc: 0.9257 - val_loss: 0.1618 - val_acc: 0.9000\n",
      "Epoch 185\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 224us/sample - loss: 1.1287\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 207us/sample - loss: 1.1261\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 275us/sample - loss: 0.4645 - acc: 0.7969\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 231us/sample - loss: 0.1473 - acc: 0.9271 - val_loss: 0.1609 - val_acc: 0.8972\n",
      "Epoch 186\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 238us/sample - loss: 1.3319\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 301us/sample - loss: 1.3275\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 309us/sample - loss: 0.3409 - acc: 0.9531\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 229us/sample - loss: 0.1382 - acc: 0.9264 - val_loss: 0.2058 - val_acc: 0.9000\n",
      "Epoch 187\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 255us/sample - loss: 1.1745\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 357us/sample - loss: 1.1441\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 267us/sample - loss: 0.4561 - acc: 0.7969\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 225us/sample - loss: 0.1490 - acc: 0.9306 - val_loss: 0.1696 - val_acc: 0.9278\n",
      "Epoch 188\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 196us/sample - loss: 1.0722\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 262us/sample - loss: 1.0732\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 324us/sample - loss: 0.4839 - acc: 0.7969\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 257us/sample - loss: 0.1506 - acc: 0.9222 - val_loss: 0.1595 - val_acc: 0.9250\n",
      "Epoch 189\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 203us/sample - loss: 1.1034\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 427us/sample - loss: 1.1030\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 220us/sample - loss: 0.4956 - acc: 0.7656\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 239us/sample - loss: 0.1611 - acc: 0.9229 - val_loss: 0.1783 - val_acc: 0.9167\n",
      "Epoch 190\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 241us/sample - loss: 1.2394\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 264us/sample - loss: 1.2374\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 283us/sample - loss: 0.4263 - acc: 0.7969\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 241us/sample - loss: 0.1469 - acc: 0.9312 - val_loss: 0.1601 - val_acc: 0.9444\n",
      "Epoch 191\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 270us/sample - loss: 1.2638\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 341us/sample - loss: 1.2605\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 257us/sample - loss: 0.3948 - acc: 0.8438\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 223us/sample - loss: 0.1492 - acc: 0.9264 - val_loss: 0.1514 - val_acc: 0.9417\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 192\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 277us/sample - loss: 1.0577\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 323us/sample - loss: 1.0512\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 515us/sample - loss: 0.5086 - acc: 0.7188\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 263us/sample - loss: 0.1545 - acc: 0.9222 - val_loss: 0.1967 - val_acc: 0.9278\n",
      "Epoch 193\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 230us/sample - loss: 1.1003\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 334us/sample - loss: 1.0982\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 297us/sample - loss: 0.4931 - acc: 0.7656\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 224us/sample - loss: 0.1479 - acc: 0.9229 - val_loss: 0.1688 - val_acc: 0.9333\n",
      "Epoch 194\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 233us/sample - loss: 1.2189\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 294us/sample - loss: 1.2142\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 290us/sample - loss: 0.4104 - acc: 0.8125\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 236us/sample - loss: 0.1450 - acc: 0.9257 - val_loss: 0.1538 - val_acc: 0.9306\n",
      "Epoch 195\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 229us/sample - loss: 1.2639\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 272us/sample - loss: 1.2555\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 305us/sample - loss: 0.3981 - acc: 0.8750\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 262us/sample - loss: 0.1454 - acc: 0.9299 - val_loss: 0.1865 - val_acc: 0.9222\n",
      "Epoch 196\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 163us/sample - loss: 1.1335\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 358us/sample - loss: 1.1316\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 291us/sample - loss: 0.4548 - acc: 0.7969\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 238us/sample - loss: 0.1438 - acc: 0.9257 - val_loss: 0.1576 - val_acc: 0.9139\n",
      "Epoch 197\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 324us/sample - loss: 1.2365\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 433us/sample - loss: 1.2340\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 235us/sample - loss: 0.3970 - acc: 0.8594\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 255us/sample - loss: 0.1389 - acc: 0.9306 - val_loss: 0.1568 - val_acc: 0.9361\n",
      "Epoch 198\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 266us/sample - loss: 1.0848\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 462us/sample - loss: 1.0815\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 236us/sample - loss: 0.4864 - acc: 0.7500\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 246us/sample - loss: 0.1523 - acc: 0.9299 - val_loss: 0.1757 - val_acc: 0.8917\n",
      "Epoch 199\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 319us/sample - loss: 1.4467\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 354us/sample - loss: 1.4336\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 350us/sample - loss: 0.3572 - acc: 0.9531\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 265us/sample - loss: 0.1423 - acc: 0.9292 - val_loss: 0.1587 - val_acc: 0.9056\n",
      "Epoch 200\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 167us/sample - loss: 1.1912\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 255us/sample - loss: 1.1901\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 280us/sample - loss: 0.4212 - acc: 0.8125\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 250us/sample - loss: 0.1520 - acc: 0.9271 - val_loss: 0.1593 - val_acc: 0.9389\n",
      "Epoch 201\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 290us/sample - loss: 1.1700\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 319us/sample - loss: 1.1689\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 383us/sample - loss: 0.4250 - acc: 0.8125\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 250us/sample - loss: 0.1483 - acc: 0.9243 - val_loss: 0.1805 - val_acc: 0.9361\n",
      "Epoch 202\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 260us/sample - loss: 1.1582\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 311us/sample - loss: 1.1590\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 298us/sample - loss: 0.4215 - acc: 0.8594\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 258us/sample - loss: 0.1517 - acc: 0.9236 - val_loss: 0.1576 - val_acc: 0.9333\n",
      "Epoch 203\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 232us/sample - loss: 1.2570\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 355us/sample - loss: 1.2542\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 299us/sample - loss: 0.3838 - acc: 0.8594\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 248us/sample - loss: 0.1414 - acc: 0.9271 - val_loss: 0.1562 - val_acc: 0.9528\n",
      "Epoch 204\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 216us/sample - loss: 1.2364\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 294us/sample - loss: 1.2127\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 324us/sample - loss: 0.4112 - acc: 0.8594\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 242us/sample - loss: 0.1501 - acc: 0.9250 - val_loss: 0.1535 - val_acc: 0.9389\n",
      "Epoch 205\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 254us/sample - loss: 1.1505\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 304us/sample - loss: 1.1523\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 266us/sample - loss: 0.4310 - acc: 0.8125\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 275us/sample - loss: 0.1447 - acc: 0.9306 - val_loss: 0.1970 - val_acc: 0.8972\n",
      "Epoch 206\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 197us/sample - loss: 1.1765\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 319us/sample - loss: 1.1764\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 252us/sample - loss: 0.4111 - acc: 0.9219\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 258us/sample - loss: 0.1589 - acc: 0.9187 - val_loss: 0.1853 - val_acc: 0.9167\n",
      "Epoch 207\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 253us/sample - loss: 1.0597\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 285us/sample - loss: 1.0558\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 296us/sample - loss: 0.5087 - acc: 0.6875\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 260us/sample - loss: 0.1445 - acc: 0.9326 - val_loss: 0.1600 - val_acc: 0.9194\n",
      "Epoch 208\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 367us/sample - loss: 1.1160\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 380us/sample - loss: 1.1155\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 291us/sample - loss: 0.4373 - acc: 0.8281\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 238us/sample - loss: 0.1510 - acc: 0.9243 - val_loss: 0.1582 - val_acc: 0.9139\n",
      "Epoch 209\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 304us/sample - loss: 1.2468\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 304us/sample - loss: 1.2456\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 273us/sample - loss: 0.3868 - acc: 0.9062\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 251us/sample - loss: 0.1448 - acc: 0.9243 - val_loss: 0.1870 - val_acc: 0.9333\n",
      "Epoch 210\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 239us/sample - loss: 1.1934\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 343us/sample - loss: 1.1910\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 325us/sample - loss: 0.4127 - acc: 0.8906\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 281us/sample - loss: 0.1526 - acc: 0.9319 - val_loss: 0.1696 - val_acc: 0.9056\n",
      "Epoch 211\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 323us/sample - loss: 1.1125\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 310us/sample - loss: 1.1086\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 312us/sample - loss: 0.4440 - acc: 0.8594\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 248us/sample - loss: 0.1480 - acc: 0.9208 - val_loss: 0.1597 - val_acc: 0.9167\n",
      "Epoch 212\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 303us/sample - loss: 1.0904\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 327us/sample - loss: 1.0821\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 389us/sample - loss: 0.4601 - acc: 0.8281\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 253us/sample - loss: 0.1521 - acc: 0.9257 - val_loss: 0.1589 - val_acc: 0.9389\n",
      "Epoch 213\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 352us/sample - loss: 1.3224\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 464us/sample - loss: 1.3216\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 281us/sample - loss: 0.3760 - acc: 0.8906\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 256us/sample - loss: 0.1577 - acc: 0.9201 - val_loss: 0.1629 - val_acc: 0.9333\n",
      "Epoch 214\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 231us/sample - loss: 1.1287\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 267us/sample - loss: 1.1285\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 310us/sample - loss: 0.4515 - acc: 0.8125\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 251us/sample - loss: 0.1606 - acc: 0.9139 - val_loss: 0.1868 - val_acc: 0.9222\n",
      "Epoch 215\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 236us/sample - loss: 1.1945\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 331us/sample - loss: 1.1870\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 252us/sample - loss: 0.4256 - acc: 0.7969\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 237us/sample - loss: 0.1678 - acc: 0.9167 - val_loss: 0.1930 - val_acc: 0.8861\n",
      "Epoch 216\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 198us/sample - loss: 1.1630\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 184us/sample - loss: 1.1632\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 322us/sample - loss: 0.4229 - acc: 0.9062\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 254us/sample - loss: 0.1681 - acc: 0.9118 - val_loss: 0.1623 - val_acc: 0.9278\n",
      "Epoch 217\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 293us/sample - loss: 1.0365\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 384us/sample - loss: 1.0361\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 402us/sample - loss: 0.5145 - acc: 0.7344\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 273us/sample - loss: 0.1532 - acc: 0.9208 - val_loss: 0.1732 - val_acc: 0.8917\n",
      "Epoch 218\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 408us/sample - loss: 1.2314\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 297us/sample - loss: 1.2297\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 320us/sample - loss: 0.3874 - acc: 0.9219\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 242us/sample - loss: 0.1490 - acc: 0.9215 - val_loss: 0.1556 - val_acc: 0.9417\n",
      "Epoch 219\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 308us/sample - loss: 1.2284\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 257us/sample - loss: 1.2214\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 299us/sample - loss: 0.4064 - acc: 0.9219\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 212us/sample - loss: 0.1552 - acc: 0.9264 - val_loss: 0.1644 - val_acc: 0.8944\n",
      "Epoch 220\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 265us/sample - loss: 1.3250\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 282us/sample - loss: 1.3053\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 314us/sample - loss: 0.4079 - acc: 0.8906\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 288us/sample - loss: 0.1509 - acc: 0.9222 - val_loss: 0.1596 - val_acc: 0.9528\n",
      "Epoch 221\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 232us/sample - loss: 1.1908\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 284us/sample - loss: 1.1908\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 348us/sample - loss: 0.4028 - acc: 0.9688\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 244us/sample - loss: 0.1647 - acc: 0.9167 - val_loss: 0.1681 - val_acc: 0.9333\n",
      "Epoch 222\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 308us/sample - loss: 1.1540\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 363us/sample - loss: 1.1511\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 289us/sample - loss: 0.4121 - acc: 0.9219\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 245us/sample - loss: 0.1505 - acc: 0.9264 - val_loss: 0.1765 - val_acc: 0.8861\n",
      "Epoch 223\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 221us/sample - loss: 1.2007\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 296us/sample - loss: 1.1901\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 231us/sample - loss: 0.3843 - acc: 0.9688\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 244us/sample - loss: 0.1601 - acc: 0.9208 - val_loss: 0.1565 - val_acc: 0.9333\n",
      "Epoch 224\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 173us/sample - loss: 1.1890\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 186us/sample - loss: 1.1671\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 299us/sample - loss: 0.4049 - acc: 0.9219\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 226us/sample - loss: 0.1566 - acc: 0.9201 - val_loss: 0.1566 - val_acc: 0.9278\n",
      "Epoch 225\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 298us/sample - loss: 1.0858\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 263us/sample - loss: 1.0445\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 399us/sample - loss: 0.4694 - acc: 0.8438\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 251us/sample - loss: 0.1399 - acc: 0.9292 - val_loss: 0.1538 - val_acc: 0.9056\n",
      "Epoch 226\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 255us/sample - loss: 1.2916\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 331us/sample - loss: 1.2734\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 225us/sample - loss: 0.3827 - acc: 0.9688\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 254us/sample - loss: 0.1452 - acc: 0.9215 - val_loss: 0.1536 - val_acc: 0.9444\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 227\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 269us/sample - loss: 1.2016\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 313us/sample - loss: 1.2062\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 389us/sample - loss: 0.4236 - acc: 0.8750\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 276us/sample - loss: 0.1384 - acc: 0.9319 - val_loss: 0.1839 - val_acc: 0.8972\n",
      "Epoch 228\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 369us/sample - loss: 1.1669\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 279us/sample - loss: 1.1676\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 257us/sample - loss: 0.4152 - acc: 0.8906\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 227us/sample - loss: 0.1654 - acc: 0.9194 - val_loss: 0.2019 - val_acc: 0.8778\n",
      "Epoch 229\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 358us/sample - loss: 1.1848\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 406us/sample - loss: 1.1755\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 355us/sample - loss: 0.4498 - acc: 0.8281\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 260us/sample - loss: 0.1698 - acc: 0.9167 - val_loss: 0.1579 - val_acc: 0.9083\n",
      "Epoch 230\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 269us/sample - loss: 1.1529\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 357us/sample - loss: 1.1490\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 355us/sample - loss: 0.4394 - acc: 0.8906\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 244us/sample - loss: 0.1417 - acc: 0.9306 - val_loss: 0.2159 - val_acc: 0.8750\n",
      "Epoch 231\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 225us/sample - loss: 1.0788\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 289us/sample - loss: 1.0722\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 336us/sample - loss: 0.4497 - acc: 0.9062\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 327us/sample - loss: 0.1599 - acc: 0.9194 - val_loss: 0.1551 - val_acc: 0.9444\n",
      "Epoch 232\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 403us/sample - loss: 1.1304\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 191us/sample - loss: 1.1233\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 438us/sample - loss: 0.4335 - acc: 0.9219\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 261us/sample - loss: 0.1570 - acc: 0.9125 - val_loss: 0.1605 - val_acc: 0.9028\n",
      "Epoch 233\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 214us/sample - loss: 1.0588\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 244us/sample - loss: 1.0499\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 264us/sample - loss: 0.4888 - acc: 0.8906\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 284us/sample - loss: 0.1427 - acc: 0.9292 - val_loss: 0.1544 - val_acc: 0.9278\n",
      "Epoch 234\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 266us/sample - loss: 1.1033\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 288us/sample - loss: 1.1014\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 331us/sample - loss: 0.4721 - acc: 0.8750\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 257us/sample - loss: 0.1404 - acc: 0.9243 - val_loss: 0.1665 - val_acc: 0.9250\n",
      "Epoch 235\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 288us/sample - loss: 1.0413\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 272us/sample - loss: 1.0363\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 307us/sample - loss: 0.4875 - acc: 0.8906\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 278us/sample - loss: 0.1432 - acc: 0.9278 - val_loss: 0.1518 - val_acc: 0.9389\n",
      "Epoch 236\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 363us/sample - loss: 1.3084\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 282us/sample - loss: 1.2929\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 283us/sample - loss: 0.4152 - acc: 0.9375\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 245us/sample - loss: 0.1392 - acc: 0.9264 - val_loss: 0.1533 - val_acc: 0.9194\n",
      "Epoch 237\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 274us/sample - loss: 1.1351\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 364us/sample - loss: 1.1328\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 289us/sample - loss: 0.4320 - acc: 0.9219\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 250us/sample - loss: 0.1449 - acc: 0.9278 - val_loss: 0.1539 - val_acc: 0.9417\n",
      "Epoch 238\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 263us/sample - loss: 1.3862\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 366us/sample - loss: 1.3292\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 288us/sample - loss: 0.4223 - acc: 0.8906\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 247us/sample - loss: 0.1338 - acc: 0.9340 - val_loss: 0.1552 - val_acc: 0.9472\n",
      "Epoch 239\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 242us/sample - loss: 1.1273\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 356us/sample - loss: 1.1319\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 261us/sample - loss: 0.4329 - acc: 0.8750\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 240us/sample - loss: 0.1424 - acc: 0.9250 - val_loss: 0.1612 - val_acc: 0.9417\n",
      "Epoch 240\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 336us/sample - loss: 1.1605\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 262us/sample - loss: 1.1575\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 377us/sample - loss: 0.4293 - acc: 0.9062\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 261us/sample - loss: 0.1361 - acc: 0.9312 - val_loss: 0.1531 - val_acc: 0.9194\n",
      "Epoch 241\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 245us/sample - loss: 1.1446\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 271us/sample - loss: 1.1432\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 251us/sample - loss: 0.4204 - acc: 0.9531\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 233us/sample - loss: 0.1379 - acc: 0.9292 - val_loss: 0.1529 - val_acc: 0.9472\n",
      "Epoch 242\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 211us/sample - loss: 1.0818\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 356us/sample - loss: 1.0789\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 524us/sample - loss: 0.4522 - acc: 0.9062\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 220us/sample - loss: 0.1374 - acc: 0.9292 - val_loss: 0.1557 - val_acc: 0.9111\n",
      "Epoch 243\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 284us/sample - loss: 1.0696\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 341us/sample - loss: 1.0676\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 283us/sample - loss: 0.4490 - acc: 0.9375\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 258us/sample - loss: 0.1375 - acc: 0.9285 - val_loss: 0.1526 - val_acc: 0.9389\n",
      "Epoch 244\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 282us/sample - loss: 1.1503\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 409us/sample - loss: 1.1503\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 249us/sample - loss: 0.4170 - acc: 0.9688\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 228us/sample - loss: 0.1419 - acc: 0.9271 - val_loss: 0.1573 - val_acc: 0.9083\n",
      "Epoch 245\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 279us/sample - loss: 1.1902\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 315us/sample - loss: 1.1875\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 297us/sample - loss: 0.3873 - acc: 0.9844\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 275us/sample - loss: 0.1461 - acc: 0.9194 - val_loss: 0.1543 - val_acc: 0.9167\n",
      "Epoch 246\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 389us/sample - loss: 1.0964\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 319us/sample - loss: 1.0940\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 280us/sample - loss: 0.4712 - acc: 0.9219\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 254us/sample - loss: 0.1397 - acc: 0.9292 - val_loss: 0.1777 - val_acc: 0.8861\n",
      "Epoch 247\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 219us/sample - loss: 1.1459\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 319us/sample - loss: 1.1420\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 349us/sample - loss: 0.4080 - acc: 0.9844\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 243us/sample - loss: 0.1494 - acc: 0.9236 - val_loss: 0.1608 - val_acc: 0.9389\n",
      "Epoch 248\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 301us/sample - loss: 1.1334\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 330us/sample - loss: 1.1345\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 275us/sample - loss: 0.4136 - acc: 0.9844\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 244us/sample - loss: 0.1469 - acc: 0.9187 - val_loss: 0.1968 - val_acc: 0.9111\n",
      "Epoch 249\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 258us/sample - loss: 1.0579\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 375us/sample - loss: 1.0555\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 311us/sample - loss: 0.4677 - acc: 0.8438\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 249us/sample - loss: 0.1557 - acc: 0.9181 - val_loss: 0.1884 - val_acc: 0.9056\n",
      "Epoch 250\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 177us/sample - loss: 1.1935\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 278us/sample - loss: 1.1888\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 259us/sample - loss: 0.4036 - acc: 0.9844\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 244us/sample - loss: 0.1534 - acc: 0.9208 - val_loss: 0.1494 - val_acc: 0.9361\n",
      "Epoch 251\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 185us/sample - loss: 1.2074\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 250us/sample - loss: 1.1523\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 297us/sample - loss: 0.4079 - acc: 0.9375\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 249us/sample - loss: 0.1412 - acc: 0.9243 - val_loss: 0.1500 - val_acc: 0.9389\n",
      "Epoch 252\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 205us/sample - loss: 1.1374\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 282us/sample - loss: 1.1428\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 597us/sample - loss: 0.4357 - acc: 0.9531\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 279us/sample - loss: 0.1489 - acc: 0.9229 - val_loss: 0.2020 - val_acc: 0.9250\n",
      "Epoch 253\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 342us/sample - loss: 0.9997\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 323us/sample - loss: 1.0011\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 300us/sample - loss: 0.5163 - acc: 0.8594\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 253us/sample - loss: 0.1580 - acc: 0.9174 - val_loss: 0.1556 - val_acc: 0.9444\n",
      "Epoch 254\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 238us/sample - loss: 1.1012\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 293us/sample - loss: 1.0987\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 314us/sample - loss: 0.4405 - acc: 0.9219\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 260us/sample - loss: 0.1527 - acc: 0.9229 - val_loss: 0.1605 - val_acc: 0.9028\n",
      "Epoch 255\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 324us/sample - loss: 1.1184\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 244us/sample - loss: 1.1105\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 268us/sample - loss: 0.4370 - acc: 0.9375\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 253us/sample - loss: 0.1422 - acc: 0.9340 - val_loss: 0.1633 - val_acc: 0.9306\n",
      "Epoch 256\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 270us/sample - loss: 1.1188\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 356us/sample - loss: 1.1160\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 314us/sample - loss: 0.4604 - acc: 0.8750\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 236us/sample - loss: 0.1443 - acc: 0.9236 - val_loss: 0.1661 - val_acc: 0.9139\n",
      "Epoch 257\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 281us/sample - loss: 1.1538\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 338us/sample - loss: 1.1507\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 252us/sample - loss: 0.4151 - acc: 0.8906\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 253us/sample - loss: 0.1598 - acc: 0.9132 - val_loss: 0.1608 - val_acc: 0.9111\n",
      "Epoch 258\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 297us/sample - loss: 1.0271\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 478us/sample - loss: 1.0209\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 241us/sample - loss: 0.4947 - acc: 0.8594\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 250us/sample - loss: 0.1597 - acc: 0.9174 - val_loss: 0.1748 - val_acc: 0.8917\n",
      "Epoch 259\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 229us/sample - loss: 1.1731\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 233us/sample - loss: 1.1662\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 271us/sample - loss: 0.4362 - acc: 0.8594\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 250us/sample - loss: 0.1376 - acc: 0.9361 - val_loss: 0.1530 - val_acc: 0.9472\n",
      "Epoch 260\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 230us/sample - loss: 1.1592\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 342us/sample - loss: 1.1510\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 352us/sample - loss: 0.4311 - acc: 0.9375\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 223us/sample - loss: 0.1416 - acc: 0.9285 - val_loss: 0.1597 - val_acc: 0.9444\n",
      "Epoch 261\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 242us/sample - loss: 1.0688\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 356us/sample - loss: 1.0576\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 290us/sample - loss: 0.4822 - acc: 0.8125\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 251us/sample - loss: 0.1395 - acc: 0.9319 - val_loss: 0.1571 - val_acc: 0.9111\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 262\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 217us/sample - loss: 1.0632\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 291us/sample - loss: 1.0640\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 257us/sample - loss: 0.4765 - acc: 0.8906\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 247us/sample - loss: 0.1533 - acc: 0.9236 - val_loss: 0.1815 - val_acc: 0.8889\n",
      "Epoch 263\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 224us/sample - loss: 1.1717\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 322us/sample - loss: 1.1691\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 317us/sample - loss: 0.4133 - acc: 0.9375\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 276us/sample - loss: 0.1434 - acc: 0.9271 - val_loss: 0.1529 - val_acc: 0.9472\n",
      "Epoch 264\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 267us/sample - loss: 1.0751\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 397us/sample - loss: 1.0748\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 473us/sample - loss: 0.4578 - acc: 0.8750\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 254us/sample - loss: 0.1472 - acc: 0.9181 - val_loss: 0.1509 - val_acc: 0.9278\n",
      "Epoch 265\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 290us/sample - loss: 1.2443\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 334us/sample - loss: 1.2410\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 450us/sample - loss: 0.4513 - acc: 0.9219\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 239us/sample - loss: 0.1435 - acc: 0.9208 - val_loss: 0.1542 - val_acc: 0.9139\n",
      "Epoch 266\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 323us/sample - loss: 1.1466\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 355us/sample - loss: 1.1425\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 324us/sample - loss: 0.4238 - acc: 0.9219\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 235us/sample - loss: 0.1474 - acc: 0.9215 - val_loss: 0.1663 - val_acc: 0.9000\n",
      "Epoch 267\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 316us/sample - loss: 1.0765\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 252us/sample - loss: 1.0764\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 313us/sample - loss: 0.4648 - acc: 0.8750\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 274us/sample - loss: 0.1425 - acc: 0.9264 - val_loss: 0.2360 - val_acc: 0.9028\n",
      "Epoch 268\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 316us/sample - loss: 1.0410\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 326us/sample - loss: 1.0375\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 398us/sample - loss: 0.4948 - acc: 0.8281\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 249us/sample - loss: 0.1507 - acc: 0.9181 - val_loss: 0.1920 - val_acc: 0.9111\n",
      "Epoch 269\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 253us/sample - loss: 1.0438\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 295us/sample - loss: 1.0389\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 295us/sample - loss: 0.4904 - acc: 0.8906\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 276us/sample - loss: 0.1430 - acc: 0.9222 - val_loss: 0.1604 - val_acc: 0.9278\n",
      "Epoch 270\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 214us/sample - loss: 1.0773\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 272us/sample - loss: 1.0715\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 344us/sample - loss: 0.4569 - acc: 0.9219\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 252us/sample - loss: 0.1398 - acc: 0.9278 - val_loss: 0.1717 - val_acc: 0.9194\n",
      "Epoch 271\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 294us/sample - loss: 1.1176\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 281us/sample - loss: 1.1071\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 278us/sample - loss: 0.4583 - acc: 0.8750\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 255us/sample - loss: 0.1423 - acc: 0.9250 - val_loss: 0.1765 - val_acc: 0.9194\n",
      "Epoch 272\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 282us/sample - loss: 1.0926\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 411us/sample - loss: 1.0932\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 215us/sample - loss: 0.4460 - acc: 0.9688\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 248us/sample - loss: 0.1639 - acc: 0.9174 - val_loss: 0.2255 - val_acc: 0.9139\n",
      "Epoch 273\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 282us/sample - loss: 1.1235\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 299us/sample - loss: 1.1162\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 339us/sample - loss: 0.4232 - acc: 0.9375\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 232us/sample - loss: 0.1466 - acc: 0.9201 - val_loss: 0.1659 - val_acc: 0.8861\n",
      "Epoch 274\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 287us/sample - loss: 1.1557\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 427us/sample - loss: 1.1516\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 240us/sample - loss: 0.4340 - acc: 0.9219\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 232us/sample - loss: 0.1481 - acc: 0.9215 - val_loss: 0.1710 - val_acc: 0.8861\n",
      "Epoch 275\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 273us/sample - loss: 1.2279\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 373us/sample - loss: 1.2205\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 266us/sample - loss: 0.4869 - acc: 0.8281\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 250us/sample - loss: 0.1447 - acc: 0.9299 - val_loss: 0.1508 - val_acc: 0.9222\n",
      "Epoch 276\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 272us/sample - loss: 1.2225\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 365us/sample - loss: 1.1698\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 281us/sample - loss: 0.4427 - acc: 0.9688\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 216us/sample - loss: 0.1484 - acc: 0.9243 - val_loss: 0.1765 - val_acc: 0.9139\n",
      "Epoch 277\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 260us/sample - loss: 1.1375\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 404us/sample - loss: 1.1365\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 230us/sample - loss: 0.4279 - acc: 0.9531\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 231us/sample - loss: 0.1536 - acc: 0.9194 - val_loss: 0.1741 - val_acc: 0.9167\n",
      "Epoch 278\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 305us/sample - loss: 1.0155\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 347us/sample - loss: 1.0131\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 244us/sample - loss: 0.4948 - acc: 0.8906\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 254us/sample - loss: 0.1419 - acc: 0.9285 - val_loss: 0.1542 - val_acc: 0.9417\n",
      "Epoch 279\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 295us/sample - loss: 1.0616\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 266us/sample - loss: 1.0478\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 263us/sample - loss: 0.4928 - acc: 0.8438\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 262us/sample - loss: 0.1425 - acc: 0.9271 - val_loss: 0.2174 - val_acc: 0.9056\n",
      "Epoch 280\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 236us/sample - loss: 1.0987\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 363us/sample - loss: 1.1024\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 278us/sample - loss: 0.4484 - acc: 0.9375\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 236us/sample - loss: 0.1588 - acc: 0.9250 - val_loss: 0.1532 - val_acc: 0.9417\n",
      "Epoch 281\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 427us/sample - loss: 1.0717\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 318us/sample - loss: 1.0548\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - ETA: 0s - loss: 0.4864 - acc: 0.750 - 0s 286us/sample - loss: 0.4759 - acc: 0.8281\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 240us/sample - loss: 0.1456 - acc: 0.9271 - val_loss: 0.1767 - val_acc: 0.9194\n",
      "Epoch 282\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - ETA: 0s - loss: 1.134 - 0s 372us/sample - loss: 1.1525\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 400us/sample - loss: 1.1499\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 306us/sample - loss: 0.4344 - acc: 0.9375\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 269us/sample - loss: 0.1522 - acc: 0.9243 - val_loss: 0.1774 - val_acc: 0.9083\n",
      "Epoch 283\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 276us/sample - loss: 1.1122\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 313us/sample - loss: 1.1038\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 286us/sample - loss: 0.4375 - acc: 0.9531\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 241us/sample - loss: 0.1466 - acc: 0.9222 - val_loss: 0.1586 - val_acc: 0.9333\n",
      "Epoch 284\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 239us/sample - loss: 1.0463\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 318us/sample - loss: 1.0424\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 238us/sample - loss: 0.4974 - acc: 0.9062\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 276us/sample - loss: 0.1558 - acc: 0.9257 - val_loss: 0.1733 - val_acc: 0.9278\n",
      "Epoch 285\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 266us/sample - loss: 1.0964\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 250us/sample - loss: 1.0940\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 324us/sample - loss: 0.4412 - acc: 0.9375\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 255us/sample - loss: 0.1504 - acc: 0.9229 - val_loss: 0.1550 - val_acc: 0.9417\n",
      "Epoch 286\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 254us/sample - loss: 1.1202\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 310us/sample - loss: 1.1153\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 341us/sample - loss: 0.4532 - acc: 0.9219\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 245us/sample - loss: 0.1404 - acc: 0.9333 - val_loss: 0.1810 - val_acc: 0.8806\n",
      "Epoch 287\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 215us/sample - loss: 1.1771\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 243us/sample - loss: 1.1791\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 232us/sample - loss: 0.4042 - acc: 0.9531\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 254us/sample - loss: 0.1463 - acc: 0.9215 - val_loss: 0.2471 - val_acc: 0.8889\n",
      "Epoch 288\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 260us/sample - loss: 1.0391\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 315us/sample - loss: 1.0371\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 366us/sample - loss: 0.4935 - acc: 0.8594\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 253us/sample - loss: 0.1491 - acc: 0.9250 - val_loss: 0.1669 - val_acc: 0.8833\n",
      "Epoch 289\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 266us/sample - loss: 1.1393\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 278us/sample - loss: 1.1024\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 283us/sample - loss: 0.4297 - acc: 0.9219\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 242us/sample - loss: 0.1327 - acc: 0.9403 - val_loss: 0.1643 - val_acc: 0.9278\n",
      "Epoch 290\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 315us/sample - loss: 1.0310\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 273us/sample - loss: 1.0233\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 326us/sample - loss: 0.4807 - acc: 0.9531\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 236us/sample - loss: 0.1441 - acc: 0.9285 - val_loss: 0.1664 - val_acc: 0.9278\n",
      "Epoch 291\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 288us/sample - loss: 1.1503\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 227us/sample - loss: 1.1498\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 278us/sample - loss: 0.4223 - acc: 0.9219\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 256us/sample - loss: 0.1438 - acc: 0.9250 - val_loss: 0.1638 - val_acc: 0.9250\n",
      "Epoch 292\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 463us/sample - loss: 1.0247\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 221us/sample - loss: 1.0230\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 254us/sample - loss: 0.4848 - acc: 0.8906\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 259us/sample - loss: 0.1433 - acc: 0.9257 - val_loss: 0.1647 - val_acc: 0.9028\n",
      "Epoch 293\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 217us/sample - loss: 1.1708\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 364us/sample - loss: 1.1664\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 301us/sample - loss: 0.4036 - acc: 0.9688\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 245us/sample - loss: 0.1409 - acc: 0.9236 - val_loss: 0.1732 - val_acc: 0.9222\n",
      "Epoch 294\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 274us/sample - loss: 1.0723\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 298us/sample - loss: 1.0713\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 280us/sample - loss: 0.4611 - acc: 0.9531\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 255us/sample - loss: 0.1660 - acc: 0.9139 - val_loss: 0.2331 - val_acc: 0.8556\n",
      "Epoch 295\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 192us/sample - loss: 0.9795\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 219us/sample - loss: 0.9755\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 228us/sample - loss: 0.5367 - acc: 0.8438\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 250us/sample - loss: 0.1537 - acc: 0.9160 - val_loss: 0.1645 - val_acc: 0.9278\n",
      "Epoch 296\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 244us/sample - loss: 1.1401\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 254us/sample - loss: 1.1405\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 253us/sample - loss: 0.4061 - acc: 0.9688\n",
      "Train on 1440 samples, validate on 360 samples\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1440/1440 [==============================] - 0s 239us/sample - loss: 0.1444 - acc: 0.9319 - val_loss: 0.1513 - val_acc: 0.9250\n",
      "Epoch 297\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 164us/sample - loss: 0.9781\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 384us/sample - loss: 0.9750\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 837us/sample - loss: 0.5318 - acc: 0.8438\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 278us/sample - loss: 0.1433 - acc: 0.9285 - val_loss: 0.1608 - val_acc: 0.8889\n",
      "Epoch 298\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 227us/sample - loss: 1.2707\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 321us/sample - loss: 1.2397\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - ETA: 0s - loss: 0.4063 - acc: 0.968 - 0s 371us/sample - loss: 0.3802 - acc: 0.9844\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 283us/sample - loss: 0.1397 - acc: 0.9264 - val_loss: 0.1549 - val_acc: 0.9417\n",
      "Epoch 299\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 248us/sample - loss: 1.0245\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 359us/sample - loss: 1.0270\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 350us/sample - loss: 0.4849 - acc: 0.8750\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 272us/sample - loss: 0.1519 - acc: 0.9208 - val_loss: 0.1589 - val_acc: 0.9444\n",
      "Epoch 300\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 221us/sample - loss: 1.0864\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 342us/sample - loss: 1.0859\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 335us/sample - loss: 0.4540 - acc: 0.8125\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 275us/sample - loss: 0.1425 - acc: 0.9278 - val_loss: 0.1575 - val_acc: 0.9361\n",
      "Epoch 301\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 321us/sample - loss: 0.9751\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 311us/sample - loss: 0.9722\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 280us/sample - loss: 0.5082 - acc: 0.8906\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 248us/sample - loss: 0.1472 - acc: 0.9257 - val_loss: 0.1717 - val_acc: 0.9222\n",
      "Epoch 302\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - ETA: 0s - loss: 1.189 - 0s 439us/sample - loss: 1.1265\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 338us/sample - loss: 1.1179\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 413us/sample - loss: 0.4285 - acc: 0.9375\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 237us/sample - loss: 0.1551 - acc: 0.9174 - val_loss: 0.2712 - val_acc: 0.8778\n",
      "Epoch 303\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 427us/sample - loss: 1.0657\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 373us/sample - loss: 1.0637\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 320us/sample - loss: 0.4483 - acc: 0.9531\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 243us/sample - loss: 0.1534 - acc: 0.9257 - val_loss: 0.1952 - val_acc: 0.9000\n",
      "Epoch 304\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 233us/sample - loss: 1.1010\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 313us/sample - loss: 1.0987\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 286us/sample - loss: 0.4500 - acc: 0.9219\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 269us/sample - loss: 0.1891 - acc: 0.9056 - val_loss: 0.1570 - val_acc: 0.9194\n",
      "Epoch 305\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 239us/sample - loss: 1.1006\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 230us/sample - loss: 1.0976\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 326us/sample - loss: 0.4326 - acc: 0.9219\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 255us/sample - loss: 0.1411 - acc: 0.9285 - val_loss: 0.1628 - val_acc: 0.8778\n",
      "Epoch 306\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 296us/sample - loss: 1.1063\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 277us/sample - loss: 1.0977\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 322us/sample - loss: 0.4250 - acc: 0.9531\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 270us/sample - loss: 0.1399 - acc: 0.9285 - val_loss: 0.1581 - val_acc: 0.8972\n",
      "Epoch 307\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 258us/sample - loss: 1.0882\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 230us/sample - loss: 1.0760\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 319us/sample - loss: 0.5101 - acc: 0.8906\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 235us/sample - loss: 0.1493 - acc: 0.9250 - val_loss: 0.1539 - val_acc: 0.9250\n",
      "Epoch 308\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 277us/sample - loss: 1.1315\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 322us/sample - loss: 1.1309\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 289us/sample - loss: 0.4317 - acc: 0.9219\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 242us/sample - loss: 0.1376 - acc: 0.9299 - val_loss: 0.1621 - val_acc: 0.8972\n",
      "Epoch 309\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 268us/sample - loss: 1.0350\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 323us/sample - loss: 1.0328\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 292us/sample - loss: 0.5281 - acc: 0.8906\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 247us/sample - loss: 0.1423 - acc: 0.9299 - val_loss: 0.2182 - val_acc: 0.9167\n",
      "Epoch 310\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 248us/sample - loss: 1.1417\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 316us/sample - loss: 1.1395\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 362us/sample - loss: 0.4196 - acc: 0.9531\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 255us/sample - loss: 0.1442 - acc: 0.9264 - val_loss: 0.1649 - val_acc: 0.9194\n",
      "Epoch 311\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 217us/sample - loss: 1.0420\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 213us/sample - loss: 1.0333\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 370us/sample - loss: 0.4996 - acc: 0.9219\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 259us/sample - loss: 0.1704 - acc: 0.9174 - val_loss: 0.1786 - val_acc: 0.8861\n",
      "Epoch 312\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 303us/sample - loss: 1.0770\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 293us/sample - loss: 1.0784\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 358us/sample - loss: 0.4553 - acc: 0.9219\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 276us/sample - loss: 0.1391 - acc: 0.9319 - val_loss: 0.1481 - val_acc: 0.9417\n",
      "Epoch 313\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 253us/sample - loss: 1.0832\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 290us/sample - loss: 1.0793\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 242us/sample - loss: 0.4369 - acc: 0.9531\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 241us/sample - loss: 0.1406 - acc: 0.9194 - val_loss: 0.2091 - val_acc: 0.8972\n",
      "Epoch 314\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 251us/sample - loss: 0.9420\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 316us/sample - loss: 0.9426\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 309us/sample - loss: 0.5401 - acc: 0.7969\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 246us/sample - loss: 0.1564 - acc: 0.9194 - val_loss: 0.1696 - val_acc: 0.9000\n",
      "Epoch 315\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 209us/sample - loss: 1.1970\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 270us/sample - loss: 1.1942\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 247us/sample - loss: 0.3958 - acc: 0.9688\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 247us/sample - loss: 0.1373 - acc: 0.9306 - val_loss: 0.1556 - val_acc: 0.9250\n",
      "Epoch 316\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 342us/sample - loss: 1.0372\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 215us/sample - loss: 1.0365\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 430us/sample - loss: 0.4650 - acc: 0.9375\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 213us/sample - loss: 0.1433 - acc: 0.9215 - val_loss: 0.1828 - val_acc: 0.8750\n",
      "Epoch 317\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 293us/sample - loss: 1.1149\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 346us/sample - loss: 1.1033\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 397us/sample - loss: 0.4465 - acc: 0.9219\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 233us/sample - loss: 0.1412 - acc: 0.9306 - val_loss: 0.1548 - val_acc: 0.9389\n",
      "Epoch 318\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 206us/sample - loss: 1.0809\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 307us/sample - loss: 1.0814\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 315us/sample - loss: 0.4422 - acc: 0.9375\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 251us/sample - loss: 0.1437 - acc: 0.9243 - val_loss: 0.1526 - val_acc: 0.9389\n",
      "Epoch 319\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 347us/sample - loss: 1.2385\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 569us/sample - loss: 1.2212\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 424us/sample - loss: 0.4159 - acc: 0.9375\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 223us/sample - loss: 0.1392 - acc: 0.9347 - val_loss: 0.1726 - val_acc: 0.9222\n",
      "Epoch 320\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 212us/sample - loss: 1.0070\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 330us/sample - loss: 1.0104\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 290us/sample - loss: 0.5059 - acc: 0.8750\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 262us/sample - loss: 0.1481 - acc: 0.9278 - val_loss: 0.1802 - val_acc: 0.9083\n",
      "Epoch 321\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 264us/sample - loss: 1.1192\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 231us/sample - loss: 1.1178\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 285us/sample - loss: 0.4135 - acc: 0.9531\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 240us/sample - loss: 0.1382 - acc: 0.9271 - val_loss: 0.1621 - val_acc: 0.9306\n",
      "Epoch 322\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 397us/sample - loss: 1.1181\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 272us/sample - loss: 1.1148\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 363us/sample - loss: 0.4254 - acc: 0.9688\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 234us/sample - loss: 0.1441 - acc: 0.9271 - val_loss: 0.1509 - val_acc: 0.9250\n",
      "Epoch 323\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 279us/sample - loss: 1.0520\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 315us/sample - loss: 1.0458\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 307us/sample - loss: 0.4728 - acc: 0.9062\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 249us/sample - loss: 0.1401 - acc: 0.9312 - val_loss: 0.1511 - val_acc: 0.9250\n",
      "Epoch 324\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 217us/sample - loss: 1.1819\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 272us/sample - loss: 1.1730\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 361us/sample - loss: 0.4764 - acc: 0.9062\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - ETA: 0s - loss: 0.1435 - acc: 0.930 - 0s 283us/sample - loss: 0.1437 - acc: 0.9299 - val_loss: 0.1717 - val_acc: 0.9250\n",
      "Epoch 325\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 249us/sample - loss: 1.0606\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 376us/sample - loss: 1.0049\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 297us/sample - loss: 0.4884 - acc: 0.8750\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 244us/sample - loss: 0.1608 - acc: 0.9194 - val_loss: 0.1768 - val_acc: 0.8944\n",
      "Epoch 326\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 285us/sample - loss: 1.1287\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 246us/sample - loss: 1.1385\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 326us/sample - loss: 0.4403 - acc: 0.9375\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 252us/sample - loss: 0.1444 - acc: 0.9236 - val_loss: 0.1531 - val_acc: 0.9278\n",
      "Epoch 327\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 258us/sample - loss: 1.0811\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 390us/sample - loss: 1.0806\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 280us/sample - loss: 0.4661 - acc: 0.9062\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 231us/sample - loss: 0.1329 - acc: 0.9340 - val_loss: 0.1559 - val_acc: 0.9361\n",
      "Epoch 328\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 382us/sample - loss: 1.0728\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 340us/sample - loss: 1.0687\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 308us/sample - loss: 0.4503 - acc: 0.9531\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 238us/sample - loss: 0.1479 - acc: 0.9222 - val_loss: 0.1535 - val_acc: 0.9361\n",
      "Epoch 329\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 269us/sample - loss: 0.9637\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 279us/sample - loss: 0.9584\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 323us/sample - loss: 0.5652 - acc: 0.8125\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 249us/sample - loss: 0.1485 - acc: 0.9187 - val_loss: 0.1932 - val_acc: 0.9250\n",
      "Epoch 330\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 314us/sample - loss: 1.2056\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 368us/sample - loss: 1.1998\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 399us/sample - loss: 0.3972 - acc: 0.9688\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 242us/sample - loss: 0.1629 - acc: 0.9146 - val_loss: 0.1709 - val_acc: 0.8889\n",
      "Epoch 331\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 230us/sample - loss: 1.0521\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 358us/sample - loss: 1.0336\n",
      "Fitting discriminator\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64/64 [==============================] - 0s 286us/sample - loss: 0.4919 - acc: 0.8438\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 245us/sample - loss: 0.1424 - acc: 0.9306 - val_loss: 0.1717 - val_acc: 0.9000\n",
      "Epoch 332\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 393us/sample - loss: 1.1741\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 456us/sample - loss: 1.1645\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 491us/sample - loss: 0.4174 - acc: 0.9688\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 247us/sample - loss: 0.1441 - acc: 0.9222 - val_loss: 0.1599 - val_acc: 0.9361\n",
      "Epoch 333\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 267us/sample - loss: 0.9902\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 302us/sample - loss: 0.9877\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 312us/sample - loss: 0.5070 - acc: 0.7188\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 243us/sample - loss: 0.1381 - acc: 0.9257 - val_loss: 0.1657 - val_acc: 0.8806\n",
      "Epoch 334\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 411us/sample - loss: 1.0656\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 378us/sample - loss: 1.0648\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 322us/sample - loss: 0.4544 - acc: 0.9531\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 241us/sample - loss: 0.1423 - acc: 0.9278 - val_loss: 0.1583 - val_acc: 0.9028\n",
      "Epoch 335\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 260us/sample - loss: 1.1187\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 251us/sample - loss: 1.1145\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 367us/sample - loss: 0.4418 - acc: 0.9219\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 248us/sample - loss: 0.1627 - acc: 0.9187 - val_loss: 0.1689 - val_acc: 0.9250\n",
      "Epoch 336\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 268us/sample - loss: 1.0271\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 338us/sample - loss: 1.0287\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 436us/sample - loss: 0.4854 - acc: 0.9062\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 269us/sample - loss: 0.1490 - acc: 0.9243 - val_loss: 0.1548 - val_acc: 0.9389\n",
      "Epoch 337\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 320us/sample - loss: 1.1185\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 273us/sample - loss: 1.1176\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 321us/sample - loss: 0.4308 - acc: 0.9688\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 239us/sample - loss: 0.1477 - acc: 0.9236 - val_loss: 0.1939 - val_acc: 0.9056\n",
      "Epoch 338\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 267us/sample - loss: 1.0203\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 228us/sample - loss: 1.0172\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 360us/sample - loss: 0.4862 - acc: 0.8906\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 252us/sample - loss: 0.1412 - acc: 0.9264 - val_loss: 0.1534 - val_acc: 0.9194\n",
      "Epoch 339\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 251us/sample - loss: 1.0728\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 364us/sample - loss: 1.0693\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 300us/sample - loss: 0.4520 - acc: 0.9531\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 248us/sample - loss: 0.1413 - acc: 0.9264 - val_loss: 0.1731 - val_acc: 0.8972\n",
      "Epoch 340\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 389us/sample - loss: 1.1128\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 352us/sample - loss: 1.1073\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 265us/sample - loss: 0.4378 - acc: 0.9688\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 257us/sample - loss: 0.1536 - acc: 0.9222 - val_loss: 0.1606 - val_acc: 0.8806\n",
      "Epoch 341\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 253us/sample - loss: 1.1186\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 334us/sample - loss: 1.0948\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 364us/sample - loss: 0.4371 - acc: 0.9531\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 235us/sample - loss: 0.1417 - acc: 0.9271 - val_loss: 0.2075 - val_acc: 0.8917\n",
      "Epoch 342\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 191us/sample - loss: 1.1048\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 252us/sample - loss: 1.1062\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 596us/sample - loss: 0.4598 - acc: 0.8750\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 252us/sample - loss: 0.1446 - acc: 0.9299 - val_loss: 0.1549 - val_acc: 0.9389\n",
      "Epoch 343\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 220us/sample - loss: 1.2739\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 250us/sample - loss: 1.2139\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 499us/sample - loss: 0.3786 - acc: 0.9688\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 252us/sample - loss: 0.1399 - acc: 0.9347 - val_loss: 0.1494 - val_acc: 0.9361\n",
      "Epoch 344\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 270us/sample - loss: 1.0844\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 236us/sample - loss: 1.0571\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 309us/sample - loss: 0.4671 - acc: 0.9531\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 277us/sample - loss: 0.1419 - acc: 0.9285 - val_loss: 0.1523 - val_acc: 0.9194\n",
      "Epoch 345\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 244us/sample - loss: 1.0389\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 379us/sample - loss: 1.0479\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 338us/sample - loss: 0.4623 - acc: 0.9844\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 243us/sample - loss: 0.1430 - acc: 0.9250 - val_loss: 0.1679 - val_acc: 0.9222\n",
      "Epoch 346\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 210us/sample - loss: 0.9879\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 323us/sample - loss: 0.9894\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 303us/sample - loss: 0.5550 - acc: 0.9531\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 264us/sample - loss: 0.1552 - acc: 0.9243 - val_loss: 0.2245 - val_acc: 0.9139\n",
      "Epoch 347\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 246us/sample - loss: 1.0749\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 327us/sample - loss: 1.0725\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 241us/sample - loss: 0.4799 - acc: 0.9375\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 270us/sample - loss: 0.1436 - acc: 0.9243 - val_loss: 0.1707 - val_acc: 0.9000\n",
      "Epoch 348\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 188us/sample - loss: 1.1328\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 205us/sample - loss: 1.1258\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 228us/sample - loss: 0.4296 - acc: 0.9688\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 244us/sample - loss: 0.1339 - acc: 0.9319 - val_loss: 0.1602 - val_acc: 0.9306\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 349\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 232us/sample - loss: 0.9796\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 259us/sample - loss: 0.9741\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 285us/sample - loss: 0.4996 - acc: 0.8125\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 214us/sample - loss: 0.1491 - acc: 0.9215 - val_loss: 0.1889 - val_acc: 0.9056\n",
      "Epoch 350\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 181us/sample - loss: 0.9964\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 347us/sample - loss: 0.9918\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 309us/sample - loss: 0.4962 - acc: 0.9375\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 276us/sample - loss: 0.1460 - acc: 0.9299 - val_loss: 0.1579 - val_acc: 0.9389\n",
      "Epoch 351\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 227us/sample - loss: 1.0602\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 286us/sample - loss: 1.0588\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 324us/sample - loss: 0.4813 - acc: 0.9375\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 270us/sample - loss: 0.1494 - acc: 0.9250 - val_loss: 0.1887 - val_acc: 0.8667\n",
      "Epoch 352\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 319us/sample - loss: 1.0952\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 537us/sample - loss: 1.0919\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 363us/sample - loss: 0.4319 - acc: 0.9688\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 238us/sample - loss: 0.1711 - acc: 0.9167 - val_loss: 0.1822 - val_acc: 0.9139\n",
      "Epoch 353\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 231us/sample - loss: 1.0264\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 377us/sample - loss: 1.0253\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 382us/sample - loss: 0.4750 - acc: 0.9219\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 260us/sample - loss: 0.1518 - acc: 0.9222 - val_loss: 0.1689 - val_acc: 0.9056\n",
      "Epoch 354\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 4ms/sample - loss: 1.1568\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 296us/sample - loss: 1.1534\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 255us/sample - loss: 0.4143 - acc: 0.9531\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 266us/sample - loss: 0.1629 - acc: 0.9097 - val_loss: 0.1731 - val_acc: 0.8917\n",
      "Epoch 355\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 339us/sample - loss: 1.0649\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 288us/sample - loss: 1.0546\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 380us/sample - loss: 0.4717 - acc: 0.9688\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 265us/sample - loss: 0.1349 - acc: 0.9326 - val_loss: 0.1517 - val_acc: 0.9389\n",
      "Epoch 356\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 289us/sample - loss: 1.1348\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 247us/sample - loss: 1.1011\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 370us/sample - loss: 0.4207 - acc: 0.9688\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 248us/sample - loss: 0.1453 - acc: 0.9236 - val_loss: 0.1531 - val_acc: 0.9444\n",
      "Epoch 357\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 293us/sample - loss: 1.0020\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 341us/sample - loss: 1.0071\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 318us/sample - loss: 0.5479 - acc: 0.9062\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 252us/sample - loss: 0.1385 - acc: 0.9306 - val_loss: 0.1907 - val_acc: 0.9222\n",
      "Epoch 358\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 212us/sample - loss: 1.0906\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 232us/sample - loss: 1.0931\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 235us/sample - loss: 0.4693 - acc: 0.9219\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 249us/sample - loss: 0.1674 - acc: 0.9229 - val_loss: 0.1896 - val_acc: 0.8694\n",
      "Epoch 359\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 365us/sample - loss: 1.1052\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 320us/sample - loss: 1.1019\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 332us/sample - loss: 0.4301 - acc: 0.9688\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 255us/sample - loss: 0.1563 - acc: 0.9146 - val_loss: 0.1562 - val_acc: 0.9333\n",
      "Epoch 360\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 227us/sample - loss: 1.0527\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 282us/sample - loss: 1.0471\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 279us/sample - loss: 0.4862 - acc: 0.8906\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 260us/sample - loss: 0.1464 - acc: 0.9222 - val_loss: 0.1629 - val_acc: 0.9056\n",
      "Epoch 361\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 228us/sample - loss: 1.1043\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 251us/sample - loss: 1.0971\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 313us/sample - loss: 0.4447 - acc: 0.9375\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 237us/sample - loss: 0.1346 - acc: 0.9285 - val_loss: 0.1716 - val_acc: 0.9250\n",
      "Epoch 362\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 351us/sample - loss: 0.9838\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 293us/sample - loss: 0.9777\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 286us/sample - loss: 0.4923 - acc: 0.8906\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 250us/sample - loss: 0.1594 - acc: 0.9229 - val_loss: 0.2132 - val_acc: 0.8722\n",
      "Epoch 363\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 258us/sample - loss: 1.0940\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 315us/sample - loss: 1.0929\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 334us/sample - loss: 0.4410 - acc: 0.9375\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 228us/sample - loss: 0.1397 - acc: 0.9278 - val_loss: 0.1658 - val_acc: 0.9306\n",
      "Epoch 364\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 357us/sample - loss: 0.9951\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 239us/sample - loss: 0.9864\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 348us/sample - loss: 0.5448 - acc: 0.8125\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 229us/sample - loss: 0.1377 - acc: 0.9312 - val_loss: 0.1592 - val_acc: 0.8972\n",
      "Epoch 365\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 263us/sample - loss: 1.2206\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 257us/sample - loss: 1.2233\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 376us/sample - loss: 0.3627 - acc: 0.9844\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 236us/sample - loss: 0.1505 - acc: 0.9264 - val_loss: 0.3062 - val_acc: 0.9194\n",
      "Epoch 366\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 238us/sample - loss: 1.0330\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 270us/sample - loss: 1.0317\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 392us/sample - loss: 0.4868 - acc: 0.8906\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 271us/sample - loss: 0.1433 - acc: 0.9250 - val_loss: 0.1833 - val_acc: 0.8944\n",
      "Epoch 367\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 423us/sample - loss: 1.1720\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 358us/sample - loss: 1.1690\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 316us/sample - loss: 0.3984 - acc: 1.0000\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 249us/sample - loss: 0.1429 - acc: 0.9187 - val_loss: 0.1590 - val_acc: 0.8972\n",
      "Epoch 368\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 316us/sample - loss: 1.0513\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 264us/sample - loss: 1.0487\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 302us/sample - loss: 0.4891 - acc: 0.9375\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 278us/sample - loss: 0.1364 - acc: 0.9312 - val_loss: 0.1627 - val_acc: 0.8806\n",
      "Epoch 369\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 248us/sample - loss: 1.0238\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 277us/sample - loss: 1.0203\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 368us/sample - loss: 0.5100 - acc: 0.8750\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 277us/sample - loss: 0.1515 - acc: 0.9264 - val_loss: 0.1731 - val_acc: 0.8861\n",
      "Epoch 370\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 230us/sample - loss: 1.0479\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 376us/sample - loss: 1.0496\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 306us/sample - loss: 0.4950 - acc: 0.8906\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 286us/sample - loss: 0.1636 - acc: 0.9194 - val_loss: 0.1943 - val_acc: 0.8750\n",
      "Epoch 371\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 291us/sample - loss: 1.0651\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 414us/sample - loss: 1.0613\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 469us/sample - loss: 0.4528 - acc: 0.9688\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 258us/sample - loss: 0.1499 - acc: 0.9264 - val_loss: 0.1923 - val_acc: 0.9083\n",
      "Epoch 372\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 272us/sample - loss: 1.0806\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 530us/sample - loss: 1.0608\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 332us/sample - loss: 0.4691 - acc: 0.9062\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 276us/sample - loss: 0.1438 - acc: 0.9236 - val_loss: 0.1668 - val_acc: 0.9389\n",
      "Epoch 373\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 294us/sample - loss: 1.0799\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 338us/sample - loss: 1.0687\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 348us/sample - loss: 0.4463 - acc: 0.9219\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 238us/sample - loss: 0.1461 - acc: 0.9250 - val_loss: 0.1533 - val_acc: 0.9444\n",
      "Epoch 374\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 311us/sample - loss: 1.2019\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 367us/sample - loss: 1.1832\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 287us/sample - loss: 0.4415 - acc: 0.9688\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 295us/sample - loss: 0.1378 - acc: 0.9299 - val_loss: 0.1576 - val_acc: 0.8972\n",
      "Epoch 375\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 304us/sample - loss: 1.0637\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 191us/sample - loss: 1.0648\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 279us/sample - loss: 0.4657 - acc: 0.9375\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 250us/sample - loss: 0.1450 - acc: 0.9257 - val_loss: 0.1521 - val_acc: 0.9250\n",
      "Epoch 376\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 277us/sample - loss: 1.0606\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 358us/sample - loss: 1.0512\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 255us/sample - loss: 0.4621 - acc: 0.9062\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 244us/sample - loss: 0.1367 - acc: 0.9326 - val_loss: 0.1514 - val_acc: 0.9417\n",
      "Epoch 377\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 228us/sample - loss: 1.1037\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 239us/sample - loss: 1.1095\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 402us/sample - loss: 0.4263 - acc: 0.9688\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 252us/sample - loss: 0.1417 - acc: 0.9306 - val_loss: 0.1758 - val_acc: 0.8750\n",
      "Epoch 378\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 263us/sample - loss: 1.1342\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 384us/sample - loss: 1.1267\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 285us/sample - loss: 0.4214 - acc: 0.9219\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 247us/sample - loss: 0.1542 - acc: 0.9278 - val_loss: 0.3126 - val_acc: 0.8667\n",
      "Epoch 379\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 252us/sample - loss: 1.1445\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 296us/sample - loss: 1.1424\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 236us/sample - loss: 0.3982 - acc: 0.9688\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 252us/sample - loss: 0.1623 - acc: 0.9174 - val_loss: 0.1517 - val_acc: 0.9389\n",
      "Epoch 380\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 202us/sample - loss: 0.9784\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 267us/sample - loss: 0.9783\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 267us/sample - loss: 0.5051 - acc: 0.9062\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 238us/sample - loss: 0.1375 - acc: 0.9340 - val_loss: 0.1590 - val_acc: 0.9028\n",
      "Epoch 381\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 246us/sample - loss: 1.0605\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 338us/sample - loss: 1.0590\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 271us/sample - loss: 0.4475 - acc: 0.9844\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 237us/sample - loss: 0.1359 - acc: 0.9292 - val_loss: 0.1532 - val_acc: 0.9389\n",
      "Epoch 382\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 419us/sample - loss: 1.0405\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 361us/sample - loss: 1.0382\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 334us/sample - loss: 0.4830 - acc: 0.9375\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 255us/sample - loss: 0.1428 - acc: 0.9264 - val_loss: 0.1914 - val_acc: 0.9194\n",
      "Epoch 383\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 324us/sample - loss: 1.0694\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 242us/sample - loss: 1.0698\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 298us/sample - loss: 0.4679 - acc: 0.9375\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 240us/sample - loss: 0.1509 - acc: 0.9187 - val_loss: 0.1512 - val_acc: 0.9333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 384\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 245us/sample - loss: 1.1132\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 246us/sample - loss: 1.0938\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 398us/sample - loss: 0.4353 - acc: 0.9531\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 234us/sample - loss: 0.1509 - acc: 0.9194 - val_loss: 0.1507 - val_acc: 0.9389\n",
      "Epoch 385\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 159us/sample - loss: 1.0360\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 186us/sample - loss: 1.0316\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 226us/sample - loss: 0.4813 - acc: 0.9375\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 242us/sample - loss: 0.1445 - acc: 0.9271 - val_loss: 0.1668 - val_acc: 0.8806\n",
      "Epoch 386\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 211us/sample - loss: 1.0355\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 235us/sample - loss: 1.0310\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 270us/sample - loss: 0.5237 - acc: 0.9219\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 280us/sample - loss: 0.1457 - acc: 0.9250 - val_loss: 0.1547 - val_acc: 0.9361\n",
      "Epoch 387\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 272us/sample - loss: 1.1431\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 450us/sample - loss: 1.1443\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 814us/sample - loss: 0.4152 - acc: 0.9531\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 252us/sample - loss: 0.1427 - acc: 0.9292 - val_loss: 0.1750 - val_acc: 0.9306\n",
      "Epoch 388\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 320us/sample - loss: 1.1060\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 353us/sample - loss: 1.1041\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 307us/sample - loss: 0.4201 - acc: 0.9844\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 270us/sample - loss: 0.1440 - acc: 0.9299 - val_loss: 0.1530 - val_acc: 0.9389\n",
      "Epoch 389\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 255us/sample - loss: 0.9953\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 280us/sample - loss: 0.9933\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 330us/sample - loss: 0.5097 - acc: 0.9219\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 279us/sample - loss: 0.1448 - acc: 0.9236 - val_loss: 0.1864 - val_acc: 0.9083\n",
      "Epoch 390\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 270us/sample - loss: 1.0782\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 369us/sample - loss: 1.0603\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 397us/sample - loss: 0.4995 - acc: 0.9219\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 285us/sample - loss: 0.1510 - acc: 0.9229 - val_loss: 0.1614 - val_acc: 0.9333\n",
      "Epoch 391\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 350us/sample - loss: 1.0392\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 352us/sample - loss: 1.0379\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 296us/sample - loss: 0.4635 - acc: 0.9375\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 272us/sample - loss: 0.1539 - acc: 0.9194 - val_loss: 0.1799 - val_acc: 0.8806\n",
      "Epoch 392\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 434us/sample - loss: 1.1291\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 318us/sample - loss: 1.1294\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 290us/sample - loss: 0.4010 - acc: 1.0000\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 209us/sample - loss: 0.1407 - acc: 0.9292 - val_loss: 0.1489 - val_acc: 0.9417\n",
      "Epoch 393\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 309us/sample - loss: 1.0610\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 292us/sample - loss: 1.0607\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 313us/sample - loss: 0.4423 - acc: 1.0000\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 250us/sample - loss: 0.1433 - acc: 0.9312 - val_loss: 0.2084 - val_acc: 0.8750\n",
      "Epoch 394\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 378us/sample - loss: 1.1358\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 239us/sample - loss: 1.1306\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 323us/sample - loss: 0.4097 - acc: 0.9844\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 268us/sample - loss: 0.1711 - acc: 0.9181 - val_loss: 0.2424 - val_acc: 0.8972\n",
      "Epoch 395\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 332us/sample - loss: 0.9930\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 296us/sample - loss: 0.9901\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 318us/sample - loss: 0.5379 - acc: 0.9531\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 244us/sample - loss: 0.1705 - acc: 0.9069 - val_loss: 0.1611 - val_acc: 0.9333\n",
      "Epoch 396\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 286us/sample - loss: 1.0841\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 285us/sample - loss: 1.0829\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 264us/sample - loss: 0.4493 - acc: 0.9531\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 239us/sample - loss: 0.1383 - acc: 0.9347 - val_loss: 0.1709 - val_acc: 0.9278\n",
      "Epoch 397\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 260us/sample - loss: 0.9920\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 356us/sample - loss: 0.9799\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 327us/sample - loss: 0.4926 - acc: 0.8594\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 249us/sample - loss: 0.1619 - acc: 0.9174 - val_loss: 0.2306 - val_acc: 0.8861\n",
      "Epoch 398\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 251us/sample - loss: 1.1334\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 386us/sample - loss: 1.1167\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 297us/sample - loss: 0.4490 - acc: 0.9688\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 253us/sample - loss: 0.1384 - acc: 0.9299 - val_loss: 0.1519 - val_acc: 0.9250\n",
      "Epoch 399\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 259us/sample - loss: 1.0443\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 332us/sample - loss: 1.0468\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 277us/sample - loss: 0.4716 - acc: 0.9062\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 269us/sample - loss: 0.1419 - acc: 0.9271 - val_loss: 0.1672 - val_acc: 0.9250\n",
      "Epoch 400\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 252us/sample - loss: 1.2054\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 252us/sample - loss: 1.1932\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 301us/sample - loss: 0.4429 - acc: 0.9531\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 229us/sample - loss: 0.1510 - acc: 0.9222 - val_loss: 0.1645 - val_acc: 0.8917\n",
      "Epoch 401\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 244us/sample - loss: 1.1323\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 314us/sample - loss: 1.1348\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 293us/sample - loss: 0.4031 - acc: 0.9844\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 263us/sample - loss: 0.1354 - acc: 0.9306 - val_loss: 0.1519 - val_acc: 0.9417\n",
      "Epoch 402\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 333us/sample - loss: 1.2089\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 469us/sample - loss: 1.1864\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 393us/sample - loss: 0.4279 - acc: 0.9688\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 227us/sample - loss: 0.1398 - acc: 0.9264 - val_loss: 0.1625 - val_acc: 0.8861\n",
      "Epoch 403\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 415us/sample - loss: 1.0531\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 373us/sample - loss: 1.0565\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 349us/sample - loss: 0.4517 - acc: 0.9531\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 261us/sample - loss: 0.1346 - acc: 0.9340 - val_loss: 0.1722 - val_acc: 0.8917\n",
      "Epoch 404\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 259us/sample - loss: 1.1653\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 304us/sample - loss: 1.1477\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 557us/sample - loss: 0.3918 - acc: 0.9688\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 259us/sample - loss: 0.1815 - acc: 0.9146 - val_loss: 0.1786 - val_acc: 0.9083\n",
      "Epoch 405\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - ETA: 0s - loss: 1.164 - 0s 286us/sample - loss: 1.1477\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 382us/sample - loss: 1.1522\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 404us/sample - loss: 0.3967 - acc: 0.9844\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 203us/sample - loss: 0.1725 - acc: 0.9104 - val_loss: 0.2075 - val_acc: 0.9194\n",
      "Epoch 406\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 310us/sample - loss: 0.9418\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 346us/sample - loss: 0.9386\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 286us/sample - loss: 0.5623 - acc: 0.7031\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 273us/sample - loss: 0.1590 - acc: 0.9201 - val_loss: 0.1865 - val_acc: 0.9111\n",
      "Epoch 407\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 312us/sample - loss: 1.0033\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 398us/sample - loss: 1.0028\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 303us/sample - loss: 0.5163 - acc: 0.9375\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 271us/sample - loss: 0.1448 - acc: 0.9271 - val_loss: 0.2270 - val_acc: 0.8806\n",
      "Epoch 408\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 262us/sample - loss: 1.1057\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 326us/sample - loss: 1.1005\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 368us/sample - loss: 0.4569 - acc: 0.9219\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 275us/sample - loss: 0.1507 - acc: 0.9229 - val_loss: 0.1785 - val_acc: 0.8861\n",
      "Epoch 409\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 296us/sample - loss: 1.1120\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 234us/sample - loss: 1.1079\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 294us/sample - loss: 0.4548 - acc: 0.8906\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 251us/sample - loss: 0.1360 - acc: 0.9333 - val_loss: 0.1478 - val_acc: 0.9389\n",
      "Epoch 410\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 208us/sample - loss: 0.9986\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 227us/sample - loss: 0.9972\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 464us/sample - loss: 0.5297 - acc: 0.8750\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 259us/sample - loss: 0.1465 - acc: 0.9264 - val_loss: 0.1958 - val_acc: 0.8972\n",
      "Epoch 411\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 239us/sample - loss: 1.0699\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 313us/sample - loss: 1.0684\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 219us/sample - loss: 0.4538 - acc: 0.9688\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 257us/sample - loss: 0.1391 - acc: 0.9347 - val_loss: 0.1605 - val_acc: 0.9222\n",
      "Epoch 412\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 258us/sample - loss: 1.0475\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 458us/sample - loss: 1.0110\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 422us/sample - loss: 0.5088 - acc: 0.9062\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 264us/sample - loss: 0.1386 - acc: 0.9340 - val_loss: 0.1785 - val_acc: 0.8861\n",
      "Epoch 413\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 249us/sample - loss: 1.0856\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 443us/sample - loss: 1.0885\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 340us/sample - loss: 0.4421 - acc: 0.9375\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 236us/sample - loss: 0.1427 - acc: 0.9229 - val_loss: 0.1670 - val_acc: 0.9278\n",
      "Epoch 414\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 434us/sample - loss: 1.0250\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 293us/sample - loss: 1.0238\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 280us/sample - loss: 0.4788 - acc: 0.9531\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 246us/sample - loss: 0.1431 - acc: 0.9278 - val_loss: 0.1834 - val_acc: 0.9278\n",
      "Epoch 415\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 282us/sample - loss: 0.9995\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 462us/sample - loss: 0.9942\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 247us/sample - loss: 0.5282 - acc: 0.9375\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 242us/sample - loss: 0.1362 - acc: 0.9354 - val_loss: 0.1538 - val_acc: 0.9389\n",
      "Epoch 416\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 270us/sample - loss: 1.0138\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 285us/sample - loss: 1.0061\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 204us/sample - loss: 0.5099 - acc: 0.9531\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 269us/sample - loss: 0.1394 - acc: 0.9333 - val_loss: 0.1530 - val_acc: 0.9389\n",
      "Epoch 417\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 290us/sample - loss: 1.0916\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 322us/sample - loss: 1.0878\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 259us/sample - loss: 0.4506 - acc: 0.9219\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 251us/sample - loss: 0.1393 - acc: 0.9278 - val_loss: 0.1498 - val_acc: 0.9417\n",
      "Epoch 418\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 172us/sample - loss: 1.0612\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 281us/sample - loss: 1.0471\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 297us/sample - loss: 0.4885 - acc: 0.9375\n",
      "Train on 1440 samples, validate on 360 samples\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1440/1440 [==============================] - 0s 226us/sample - loss: 0.1421 - acc: 0.9243 - val_loss: 0.1932 - val_acc: 0.9028\n",
      "Epoch 419\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 281us/sample - loss: 1.0849\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 247us/sample - loss: 1.0710\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 215us/sample - loss: 0.5074 - acc: 0.8750\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 213us/sample - loss: 0.1751 - acc: 0.9160 - val_loss: 0.1899 - val_acc: 0.9000\n",
      "Epoch 420\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 224us/sample - loss: 1.0282\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 284us/sample - loss: 1.0298\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 295us/sample - loss: 0.5217 - acc: 0.8750\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 254us/sample - loss: 0.1624 - acc: 0.9097 - val_loss: 0.1625 - val_acc: 0.9194\n",
      "Epoch 421\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 332us/sample - loss: 1.0439\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 320us/sample - loss: 1.0459\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 378us/sample - loss: 0.4992 - acc: 0.9531\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 245us/sample - loss: 0.1574 - acc: 0.9271 - val_loss: 0.2337 - val_acc: 0.9083\n",
      "Epoch 422\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 434us/sample - loss: 1.0479\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 390us/sample - loss: 1.0458\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 293us/sample - loss: 0.4884 - acc: 0.9375\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 254us/sample - loss: 0.1493 - acc: 0.9264 - val_loss: 0.1566 - val_acc: 0.9417\n",
      "Epoch 423\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 253us/sample - loss: 1.0828\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 321us/sample - loss: 1.0808\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 452us/sample - loss: 0.4484 - acc: 0.9688\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 223us/sample - loss: 0.1511 - acc: 0.9229 - val_loss: 0.1487 - val_acc: 0.9389\n",
      "Epoch 424\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 336us/sample - loss: 1.0970\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 309us/sample - loss: 1.0918\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 334us/sample - loss: 0.4348 - acc: 0.9531\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 278us/sample - loss: 0.1399 - acc: 0.9271 - val_loss: 0.1546 - val_acc: 0.9417\n",
      "Epoch 425\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 218us/sample - loss: 0.9949\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 296us/sample - loss: 0.9840\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 301us/sample - loss: 0.5329 - acc: 0.9531\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 263us/sample - loss: 0.1385 - acc: 0.9333 - val_loss: 0.1569 - val_acc: 0.9361\n",
      "Epoch 426\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 242us/sample - loss: 1.0575\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 240us/sample - loss: 1.0520\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 271us/sample - loss: 0.4719 - acc: 0.9062\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 253us/sample - loss: 0.1375 - acc: 0.9285 - val_loss: 0.1533 - val_acc: 0.9250\n",
      "Epoch 427\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 293us/sample - loss: 1.0883\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 391us/sample - loss: 1.0701\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 327us/sample - loss: 0.4637 - acc: 0.9219\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 245us/sample - loss: 0.1499 - acc: 0.9167 - val_loss: 0.1689 - val_acc: 0.9306\n",
      "Epoch 428\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 236us/sample - loss: 1.0478\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 342us/sample - loss: 0.9895\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 310us/sample - loss: 0.5085 - acc: 0.9219\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 250us/sample - loss: 0.1442 - acc: 0.9250 - val_loss: 0.1843 - val_acc: 0.8778\n",
      "Epoch 429\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 236us/sample - loss: 1.2039\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 318us/sample - loss: 1.2081\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 289us/sample - loss: 0.3820 - acc: 0.9844\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 250us/sample - loss: 0.1679 - acc: 0.9104 - val_loss: 0.1667 - val_acc: 0.8861\n",
      "Epoch 430\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 265us/sample - loss: 1.1185\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 297us/sample - loss: 1.1187\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 508us/sample - loss: 0.4365 - acc: 0.9844\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 244us/sample - loss: 0.1444 - acc: 0.9236 - val_loss: 0.1915 - val_acc: 0.8667\n",
      "Epoch 431\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 265us/sample - loss: 1.1281\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 301us/sample - loss: 1.1220\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 308us/sample - loss: 0.4418 - acc: 0.9531\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 233us/sample - loss: 0.1473 - acc: 0.9257 - val_loss: 0.1922 - val_acc: 0.8694\n",
      "Epoch 432\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 248us/sample - loss: 1.1097\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 390us/sample - loss: 1.1101\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 230us/sample - loss: 0.4259 - acc: 0.9688\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 253us/sample - loss: 0.1496 - acc: 0.9167 - val_loss: 0.1863 - val_acc: 0.8778\n",
      "Epoch 433\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 258us/sample - loss: 1.0853\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 328us/sample - loss: 1.0812\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 269us/sample - loss: 0.4819 - acc: 0.9219\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 239us/sample - loss: 0.1402 - acc: 0.9264 - val_loss: 0.1654 - val_acc: 0.9250\n",
      "Epoch 434\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 210us/sample - loss: 1.2251\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 173us/sample - loss: 1.2048\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 278us/sample - loss: 0.4583 - acc: 0.9844\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 243us/sample - loss: 0.1431 - acc: 0.9271 - val_loss: 0.1593 - val_acc: 0.9278\n",
      "Epoch 435\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 261us/sample - loss: 1.0652\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 328us/sample - loss: 1.0670\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 309us/sample - loss: 0.4497 - acc: 0.9688\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 244us/sample - loss: 0.1383 - acc: 0.9257 - val_loss: 0.1670 - val_acc: 0.9306\n",
      "Epoch 436\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 182us/sample - loss: 1.0057\n",
      "Epoch 2/2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64/64 [==============================] - 0s 260us/sample - loss: 1.0033\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 251us/sample - loss: 0.4894 - acc: 0.9375\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 250us/sample - loss: 0.1452 - acc: 0.9243 - val_loss: 0.1495 - val_acc: 0.9444\n",
      "Epoch 437\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 348us/sample - loss: 1.0727\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 324us/sample - loss: 1.0682\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 337us/sample - loss: 0.4617 - acc: 0.9062\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 273us/sample - loss: 0.1437 - acc: 0.9243 - val_loss: 0.1484 - val_acc: 0.9361\n",
      "Epoch 438\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 343us/sample - loss: 0.9582\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 298us/sample - loss: 0.9497\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 329us/sample - loss: 0.5483 - acc: 0.8750\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 250us/sample - loss: 0.1365 - acc: 0.9326 - val_loss: 0.1849 - val_acc: 0.9111\n",
      "Epoch 439\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 255us/sample - loss: 0.9957\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 308us/sample - loss: 0.9885\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 324us/sample - loss: 0.5314 - acc: 0.9375\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 282us/sample - loss: 0.1631 - acc: 0.9194 - val_loss: 0.1663 - val_acc: 0.9000\n",
      "Epoch 440\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 273us/sample - loss: 1.1180\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 342us/sample - loss: 1.1224\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 474us/sample - loss: 0.4443 - acc: 0.9062\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 247us/sample - loss: 0.1413 - acc: 0.9278 - val_loss: 0.1828 - val_acc: 0.9139\n",
      "Epoch 441\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 295us/sample - loss: 1.0446\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 305us/sample - loss: 1.0355\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 260us/sample - loss: 0.4706 - acc: 0.9219\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 253us/sample - loss: 0.1422 - acc: 0.9271 - val_loss: 0.1503 - val_acc: 0.9417\n",
      "Epoch 442\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 312us/sample - loss: 1.1404\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 294us/sample - loss: 1.1352\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 231us/sample - loss: 0.4246 - acc: 0.9844\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 282us/sample - loss: 0.1352 - acc: 0.9292 - val_loss: 0.1580 - val_acc: 0.8944\n",
      "Epoch 443\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 279us/sample - loss: 1.0178\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 261us/sample - loss: 1.0193\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 310us/sample - loss: 0.5167 - acc: 0.9062\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 238us/sample - loss: 0.1368 - acc: 0.9326 - val_loss: 0.1534 - val_acc: 0.9389\n",
      "Epoch 444\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 223us/sample - loss: 1.0931\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 377us/sample - loss: 1.0900\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 225us/sample - loss: 0.4361 - acc: 0.9375\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 248us/sample - loss: 0.1417 - acc: 0.9306 - val_loss: 0.1785 - val_acc: 0.9306\n",
      "Epoch 445\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 155us/sample - loss: 1.0951\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 182us/sample - loss: 1.0914\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 244us/sample - loss: 0.4264 - acc: 0.9688\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 253us/sample - loss: 0.1430 - acc: 0.9312 - val_loss: 0.1746 - val_acc: 0.8806\n",
      "Epoch 446\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 276us/sample - loss: 1.0191\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 372us/sample - loss: 1.0175\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 233us/sample - loss: 0.5690 - acc: 0.8594\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 245us/sample - loss: 0.1473 - acc: 0.9181 - val_loss: 0.1743 - val_acc: 0.9250\n",
      "Epoch 447\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 226us/sample - loss: 1.0459\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 259us/sample - loss: 1.0442\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 255us/sample - loss: 0.4854 - acc: 0.9375\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 279us/sample - loss: 0.1442 - acc: 0.9271 - val_loss: 0.1648 - val_acc: 0.9361\n",
      "Epoch 448\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 277us/sample - loss: 1.0688\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 259us/sample - loss: 1.0646\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 269us/sample - loss: 0.4785 - acc: 0.8750\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 241us/sample - loss: 0.1431 - acc: 0.9264 - val_loss: 0.1633 - val_acc: 0.9056\n",
      "Epoch 449\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 257us/sample - loss: 1.0478\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 331us/sample - loss: 1.0402\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 295us/sample - loss: 0.4589 - acc: 0.9531\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 226us/sample - loss: 0.1519 - acc: 0.9208 - val_loss: 0.1619 - val_acc: 0.8972\n",
      "Epoch 450\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 236us/sample - loss: 1.0459\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 254us/sample - loss: 1.0446\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 394us/sample - loss: 0.4557 - acc: 0.9531\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 251us/sample - loss: 0.1465 - acc: 0.9319 - val_loss: 0.1651 - val_acc: 0.9028\n",
      "Epoch 451\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 238us/sample - loss: 1.0377\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 391us/sample - loss: 1.0353\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 360us/sample - loss: 0.4863 - acc: 0.8906\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 282us/sample - loss: 0.1465 - acc: 0.9215 - val_loss: 0.2015 - val_acc: 0.9000\n",
      "Epoch 452\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 264us/sample - loss: 1.0399\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 290us/sample - loss: 1.0377\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 255us/sample - loss: 0.5269 - acc: 0.8906\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 246us/sample - loss: 0.1704 - acc: 0.9174 - val_loss: 0.1971 - val_acc: 0.8917\n",
      "Epoch 453\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 268us/sample - loss: 1.1366\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 285us/sample - loss: 1.1264\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 261us/sample - loss: 0.4304 - acc: 0.9688\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 238us/sample - loss: 0.1478 - acc: 0.9201 - val_loss: 0.1579 - val_acc: 0.9222\n",
      "Epoch 454\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 378us/sample - loss: 1.0005\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 391us/sample - loss: 0.9988\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 193us/sample - loss: 0.5152 - acc: 0.9062\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 236us/sample - loss: 0.1461 - acc: 0.9236 - val_loss: 0.1825 - val_acc: 0.8722\n",
      "Epoch 455\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 387us/sample - loss: 1.2086\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 379us/sample - loss: 1.2061\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 301us/sample - loss: 0.4207 - acc: 0.9688\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 251us/sample - loss: 0.1526 - acc: 0.9264 - val_loss: 0.1662 - val_acc: 0.9222\n",
      "Epoch 456\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 228us/sample - loss: 1.0007\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 369us/sample - loss: 0.9840\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 318us/sample - loss: 0.5640 - acc: 0.8906\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 245us/sample - loss: 0.1509 - acc: 0.9229 - val_loss: 0.1587 - val_acc: 0.9250\n",
      "Epoch 457\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 216us/sample - loss: 1.1003\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 321us/sample - loss: 1.1028\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 344us/sample - loss: 0.4571 - acc: 0.9531\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 251us/sample - loss: 0.1658 - acc: 0.9139 - val_loss: 0.2198 - val_acc: 0.9111\n",
      "Epoch 458\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 232us/sample - loss: 1.0395\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 295us/sample - loss: 1.0389\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 334us/sample - loss: 0.4658 - acc: 0.9844\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 248us/sample - loss: 0.1719 - acc: 0.9160 - val_loss: 0.2278 - val_acc: 0.8917\n",
      "Epoch 459\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 292us/sample - loss: 1.0541\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 357us/sample - loss: 1.0521\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 324us/sample - loss: 0.4668 - acc: 0.9531\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 257us/sample - loss: 0.1617 - acc: 0.9208 - val_loss: 0.1852 - val_acc: 0.8778\n",
      "Epoch 460\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 170us/sample - loss: 1.1404\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 328us/sample - loss: 1.1372\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 170us/sample - loss: 0.3982 - acc: 0.9688\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 238us/sample - loss: 0.1635 - acc: 0.9097 - val_loss: 0.1540 - val_acc: 0.9139\n",
      "Epoch 461\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 306us/sample - loss: 1.0650\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 246us/sample - loss: 1.0591\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 337us/sample - loss: 0.4390 - acc: 1.0000\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 253us/sample - loss: 0.1446 - acc: 0.9292 - val_loss: 0.1720 - val_acc: 0.9167\n",
      "Epoch 462\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 295us/sample - loss: 1.0323\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 412us/sample - loss: 1.0307\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 403us/sample - loss: 0.5051 - acc: 0.9219\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 242us/sample - loss: 0.1406 - acc: 0.9278 - val_loss: 0.1675 - val_acc: 0.9222\n",
      "Epoch 463\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 279us/sample - loss: 1.0723\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 291us/sample - loss: 1.0708\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 283us/sample - loss: 0.4549 - acc: 0.9531\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 270us/sample - loss: 0.1372 - acc: 0.9326 - val_loss: 0.1526 - val_acc: 0.9333\n",
      "Epoch 464\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 265us/sample - loss: 1.0725\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 249us/sample - loss: 1.0623\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 375us/sample - loss: 0.4705 - acc: 0.9531\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 242us/sample - loss: 0.1360 - acc: 0.9375 - val_loss: 0.1556 - val_acc: 0.9361\n",
      "Epoch 465\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 190us/sample - loss: 1.0860\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 268us/sample - loss: 1.0842\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 268us/sample - loss: 0.4560 - acc: 0.9531\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 234us/sample - loss: 0.1425 - acc: 0.9306 - val_loss: 0.1518 - val_acc: 0.9333\n",
      "Epoch 466\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 273us/sample - loss: 1.0211\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 233us/sample - loss: 1.0200\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 298us/sample - loss: 0.4980 - acc: 0.8750\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 255us/sample - loss: 0.1507 - acc: 0.9187 - val_loss: 0.1739 - val_acc: 0.9167\n",
      "Epoch 467\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 217us/sample - loss: 0.9800\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 198us/sample - loss: 0.9767\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 416us/sample - loss: 0.5452 - acc: 0.9219\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 241us/sample - loss: 0.1517 - acc: 0.9222 - val_loss: 0.1744 - val_acc: 0.9194\n",
      "Epoch 468\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 225us/sample - loss: 1.0757\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 431us/sample - loss: 1.0698\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 296us/sample - loss: 0.4580 - acc: 0.9219\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 241us/sample - loss: 0.1487 - acc: 0.9208 - val_loss: 0.1582 - val_acc: 0.9222\n",
      "Epoch 469\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 263us/sample - loss: 1.1316\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 246us/sample - loss: 1.1328\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 309us/sample - loss: 0.4624 - acc: 0.9531\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 233us/sample - loss: 0.1387 - acc: 0.9278 - val_loss: 0.1577 - val_acc: 0.9056\n",
      "Epoch 470\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 208us/sample - loss: 1.0499\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 268us/sample - loss: 1.0459\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 298us/sample - loss: 0.4663 - acc: 0.9531\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 294us/sample - loss: 0.1390 - acc: 0.9299 - val_loss: 0.1578 - val_acc: 0.9056\n",
      "Epoch 471\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 204us/sample - loss: 1.0933\n",
      "Epoch 2/2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64/64 [==============================] - 0s 245us/sample - loss: 1.0812\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 225us/sample - loss: 0.4661 - acc: 0.9375\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 246us/sample - loss: 0.1480 - acc: 0.9257 - val_loss: 0.1559 - val_acc: 0.9361\n",
      "Epoch 472\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 350us/sample - loss: 1.1106\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 338us/sample - loss: 1.0991\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 334us/sample - loss: 0.4354 - acc: 0.9844\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 286us/sample - loss: 0.1388 - acc: 0.9292 - val_loss: 0.1486 - val_acc: 0.9417\n",
      "Epoch 473\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 321us/sample - loss: 1.0181\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 492us/sample - loss: 1.0156\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 414us/sample - loss: 0.4738 - acc: 0.9375\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 246us/sample - loss: 0.1428 - acc: 0.9187 - val_loss: 0.1817 - val_acc: 0.9167\n",
      "Epoch 474\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 288us/sample - loss: 1.0310\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 295us/sample - loss: 1.0319\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 288us/sample - loss: 0.5235 - acc: 0.8594\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 239us/sample - loss: 0.1357 - acc: 0.9271 - val_loss: 0.2105 - val_acc: 0.8917\n",
      "Epoch 475\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 292us/sample - loss: 0.9512\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 302us/sample - loss: 0.9496\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 268us/sample - loss: 0.5673 - acc: 0.8906\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 226us/sample - loss: 0.1533 - acc: 0.9264 - val_loss: 0.1526 - val_acc: 0.9361\n",
      "Epoch 476\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 385us/sample - loss: 1.0285\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 352us/sample - loss: 1.0262\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 269us/sample - loss: 0.5014 - acc: 0.9375\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 240us/sample - loss: 0.1424 - acc: 0.9292 - val_loss: 0.2045 - val_acc: 0.9000\n",
      "Epoch 477\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 152us/sample - loss: 1.0280\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 211us/sample - loss: 1.0162\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 387us/sample - loss: 0.4866 - acc: 0.9688\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 243us/sample - loss: 0.1437 - acc: 0.9257 - val_loss: 0.1536 - val_acc: 0.9389\n",
      "Epoch 478\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 222us/sample - loss: 1.0021\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 266us/sample - loss: 0.9957\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 279us/sample - loss: 0.5148 - acc: 0.8906\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 243us/sample - loss: 0.1342 - acc: 0.9347 - val_loss: 0.1720 - val_acc: 0.8861\n",
      "Epoch 479\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 345us/sample - loss: 1.1273\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 310us/sample - loss: 1.1108\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 310us/sample - loss: 0.4103 - acc: 0.9688\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 251us/sample - loss: 0.1577 - acc: 0.9153 - val_loss: 0.1740 - val_acc: 0.9194\n",
      "Epoch 480\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 242us/sample - loss: 1.1718\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 443us/sample - loss: 1.1684\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 348us/sample - loss: 0.5232 - acc: 0.9375\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 257us/sample - loss: 0.1481 - acc: 0.9278 - val_loss: 0.1631 - val_acc: 0.8917\n",
      "Epoch 481\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 212us/sample - loss: 1.1077\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 299us/sample - loss: 1.1034\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 285us/sample - loss: 0.4360 - acc: 0.9375\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 272us/sample - loss: 0.1507 - acc: 0.9215 - val_loss: 0.1586 - val_acc: 0.9250\n",
      "Epoch 482\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 217us/sample - loss: 0.9735\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 409us/sample - loss: 0.9713\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 518us/sample - loss: 0.5537 - acc: 0.9062\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 225us/sample - loss: 0.1430 - acc: 0.9201 - val_loss: 0.1576 - val_acc: 0.9333\n",
      "Epoch 483\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 277us/sample - loss: 1.0235\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 248us/sample - loss: 1.0211\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 352us/sample - loss: 0.4725 - acc: 0.9844\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 229us/sample - loss: 0.1536 - acc: 0.9174 - val_loss: 0.1647 - val_acc: 0.9306\n",
      "Epoch 484\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 244us/sample - loss: 1.0073\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 327us/sample - loss: 1.0016\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 292us/sample - loss: 0.4825 - acc: 0.8906\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 245us/sample - loss: 0.1348 - acc: 0.9271 - val_loss: 0.1599 - val_acc: 0.8944\n",
      "Epoch 485\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 189us/sample - loss: 0.9969\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 177us/sample - loss: 0.9965\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 274us/sample - loss: 0.5331 - acc: 0.8906\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 231us/sample - loss: 0.1378 - acc: 0.9312 - val_loss: 0.1847 - val_acc: 0.9278\n",
      "Epoch 486\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 185us/sample - loss: 0.9746\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 341us/sample - loss: 0.9697\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 284us/sample - loss: 0.5025 - acc: 0.8750\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 251us/sample - loss: 0.1471 - acc: 0.9271 - val_loss: 0.1901 - val_acc: 0.8667\n",
      "Epoch 487\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 251us/sample - loss: 1.0097\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 313us/sample - loss: 1.0011\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 197us/sample - loss: 0.5066 - acc: 0.9219\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 243us/sample - loss: 0.1701 - acc: 0.9167 - val_loss: 0.1664 - val_acc: 0.8806\n",
      "Epoch 488\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 251us/sample - loss: 1.1186\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 325us/sample - loss: 1.1128\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 241us/sample - loss: 0.4196 - acc: 0.9688\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 273us/sample - loss: 0.1433 - acc: 0.9271 - val_loss: 0.1594 - val_acc: 0.9361\n",
      "Epoch 489\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 227us/sample - loss: 1.0326\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 253us/sample - loss: 1.0337\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 284us/sample - loss: 0.5181 - acc: 0.9219\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 267us/sample - loss: 0.1440 - acc: 0.9299 - val_loss: 0.1533 - val_acc: 0.9389\n",
      "Epoch 490\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 271us/sample - loss: 1.0155\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 354us/sample - loss: 1.0126\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 259us/sample - loss: 0.5154 - acc: 0.9219\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 283us/sample - loss: 0.1444 - acc: 0.9278 - val_loss: 0.1928 - val_acc: 0.9028\n",
      "Epoch 491\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 297us/sample - loss: 1.0793\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 314us/sample - loss: 1.0762\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 281us/sample - loss: 0.4642 - acc: 0.9531\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 269us/sample - loss: 0.1510 - acc: 0.9215 - val_loss: 0.1924 - val_acc: 0.9139\n",
      "Epoch 492\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 473us/sample - loss: 0.9609\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 262us/sample - loss: 0.9593\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 386us/sample - loss: 0.5270 - acc: 0.8438\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 248us/sample - loss: 0.1348 - acc: 0.9333 - val_loss: 0.1773 - val_acc: 0.9167\n",
      "Epoch 493\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 219us/sample - loss: 1.0458\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 229us/sample - loss: 1.0176\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 239us/sample - loss: 0.4953 - acc: 0.9531\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 239us/sample - loss: 0.1489 - acc: 0.9257 - val_loss: 0.1925 - val_acc: 0.8778\n",
      "Epoch 494\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 319us/sample - loss: 1.1186\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 274us/sample - loss: 1.1184\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 362us/sample - loss: 0.4126 - acc: 0.9688\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 275us/sample - loss: 0.1706 - acc: 0.9146 - val_loss: 0.1982 - val_acc: 0.9083\n",
      "Epoch 495\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 379us/sample - loss: 0.9780\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 420us/sample - loss: 0.9742\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 391us/sample - loss: 0.5441 - acc: 0.8750\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 239us/sample - loss: 0.1675 - acc: 0.9201 - val_loss: 0.1633 - val_acc: 0.9278\n",
      "Epoch 496\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 306us/sample - loss: 1.0112\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 263us/sample - loss: 1.0094\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 254us/sample - loss: 0.4904 - acc: 0.9219\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 251us/sample - loss: 0.1491 - acc: 0.9285 - val_loss: 0.1647 - val_acc: 0.8917\n",
      "Epoch 497\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 289us/sample - loss: 1.1021\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 267us/sample - loss: 1.1018\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 276us/sample - loss: 0.4154 - acc: 1.0000\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 245us/sample - loss: 0.1410 - acc: 0.9278 - val_loss: 0.1549 - val_acc: 0.9444\n",
      "Epoch 498\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 272us/sample - loss: 1.0765\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 363us/sample - loss: 1.0705\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 280us/sample - loss: 0.4499 - acc: 0.9844\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 251us/sample - loss: 0.1456 - acc: 0.9194 - val_loss: 0.1653 - val_acc: 0.9250\n",
      "Epoch 499\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 279us/sample - loss: 0.9980\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 319us/sample - loss: 0.9707\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 302us/sample - loss: 0.5407 - acc: 0.7500\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 246us/sample - loss: 0.1447 - acc: 0.9215 - val_loss: 0.1768 - val_acc: 0.8806\n",
      "Epoch 500\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 293us/sample - loss: 1.0627\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 285us/sample - loss: 1.0601\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 361us/sample - loss: 0.4751 - acc: 0.9375\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 286us/sample - loss: 0.1426 - acc: 0.9278 - val_loss: 0.1761 - val_acc: 0.9222\n",
      "Epoch 501\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 200us/sample - loss: 1.1074\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 357us/sample - loss: 1.1089\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 282us/sample - loss: 0.4312 - acc: 0.9531\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 251us/sample - loss: 0.1379 - acc: 0.9306 - val_loss: 0.1489 - val_acc: 0.9361\n",
      "Epoch 502\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 304us/sample - loss: 0.9743\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 215us/sample - loss: 0.9684\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 238us/sample - loss: 0.6176 - acc: 0.8750\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 236us/sample - loss: 0.1421 - acc: 0.9333 - val_loss: 0.2111 - val_acc: 0.8861\n",
      "Epoch 503\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 265us/sample - loss: 1.1174\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 273us/sample - loss: 1.1162\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 315us/sample - loss: 0.4241 - acc: 0.9688\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 222us/sample - loss: 0.1449 - acc: 0.9208 - val_loss: 0.1876 - val_acc: 0.9056\n",
      "Epoch 504\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 200us/sample - loss: 0.9505\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 352us/sample - loss: 0.9454\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 255us/sample - loss: 0.5426 - acc: 0.8906\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 256us/sample - loss: 0.1392 - acc: 0.9389 - val_loss: 0.1516 - val_acc: 0.9389\n",
      "Epoch 505\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 254us/sample - loss: 1.0680\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 307us/sample - loss: 1.0659\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 264us/sample - loss: 0.4551 - acc: 0.9688\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 258us/sample - loss: 0.1413 - acc: 0.9285 - val_loss: 0.1669 - val_acc: 0.9250\n",
      "Epoch 506\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 312us/sample - loss: 1.1191\n",
      "Epoch 2/2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64/64 [==============================] - 0s 260us/sample - loss: 1.1168\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 277us/sample - loss: 0.4060 - acc: 1.0000\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 232us/sample - loss: 0.1479 - acc: 0.9250 - val_loss: 0.1528 - val_acc: 0.9306\n",
      "Epoch 507\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 305us/sample - loss: 1.0264\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 292us/sample - loss: 1.0237\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 283us/sample - loss: 0.4747 - acc: 0.9375\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 251us/sample - loss: 0.1444 - acc: 0.9250 - val_loss: 0.1605 - val_acc: 0.9306\n",
      "Epoch 508\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 257us/sample - loss: 1.0268\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 333us/sample - loss: 1.0259\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 285us/sample - loss: 0.5252 - acc: 0.9062\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 239us/sample - loss: 0.1428 - acc: 0.9278 - val_loss: 0.1596 - val_acc: 0.8944\n",
      "Epoch 509\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 262us/sample - loss: 1.0966\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 386us/sample - loss: 1.0861\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 298us/sample - loss: 0.4357 - acc: 0.9531\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 248us/sample - loss: 0.1460 - acc: 0.9264 - val_loss: 0.1635 - val_acc: 0.9056\n",
      "Epoch 510\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 196us/sample - loss: 1.0666\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 226us/sample - loss: 1.0646\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 252us/sample - loss: 0.4334 - acc: 1.0000\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 273us/sample - loss: 0.1530 - acc: 0.9278 - val_loss: 0.1856 - val_acc: 0.8694\n",
      "Epoch 511\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 321us/sample - loss: 1.0251\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 395us/sample - loss: 1.0240\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 442us/sample - loss: 0.4830 - acc: 0.9219\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 214us/sample - loss: 0.1467 - acc: 0.9250 - val_loss: 0.1516 - val_acc: 0.9361\n",
      "Epoch 512\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 271us/sample - loss: 1.1346\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 1ms/sample - loss: 1.1286\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 368us/sample - loss: 0.4214 - acc: 0.9531\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 222us/sample - loss: 0.1402 - acc: 0.9368 - val_loss: 0.1596 - val_acc: 0.9250\n",
      "Epoch 513\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 313us/sample - loss: 1.0423\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 357us/sample - loss: 1.0399\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 260us/sample - loss: 0.4959 - acc: 0.9531\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 217us/sample - loss: 0.1556 - acc: 0.9160 - val_loss: 0.1966 - val_acc: 0.8861\n",
      "Epoch 514\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 264us/sample - loss: 1.0813\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 312us/sample - loss: 1.0788\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 360us/sample - loss: 0.4477 - acc: 0.9531\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 245us/sample - loss: 0.1361 - acc: 0.9271 - val_loss: 0.1774 - val_acc: 0.8861\n",
      "Epoch 515\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 286us/sample - loss: 0.9968\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 293us/sample - loss: 0.9905\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 347us/sample - loss: 0.5250 - acc: 0.8906\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 238us/sample - loss: 0.1414 - acc: 0.9299 - val_loss: 0.1522 - val_acc: 0.9278\n",
      "Epoch 516\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 278us/sample - loss: 1.0615\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 300us/sample - loss: 1.0589\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 302us/sample - loss: 0.4422 - acc: 0.9688\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 255us/sample - loss: 0.1595 - acc: 0.9181 - val_loss: 0.2102 - val_acc: 0.9111\n",
      "Epoch 517\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 259us/sample - loss: 0.9889\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 282us/sample - loss: 0.9818\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 345us/sample - loss: 0.5401 - acc: 0.8750\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 248us/sample - loss: 0.1621 - acc: 0.9160 - val_loss: 0.1561 - val_acc: 0.9389\n",
      "Epoch 518\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 222us/sample - loss: 0.9768\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 256us/sample - loss: 0.9748\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 307us/sample - loss: 0.5102 - acc: 0.9219\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 249us/sample - loss: 0.1399 - acc: 0.9312 - val_loss: 0.1569 - val_acc: 0.9444\n",
      "Epoch 519\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 229us/sample - loss: 1.0645\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 329us/sample - loss: 1.0585\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 231us/sample - loss: 0.4602 - acc: 0.9375\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 271us/sample - loss: 0.1479 - acc: 0.9222 - val_loss: 0.1592 - val_acc: 0.9333\n",
      "Epoch 520\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 194us/sample - loss: 1.0766\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 243us/sample - loss: 1.0762\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 398us/sample - loss: 0.4435 - acc: 0.9531\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 256us/sample - loss: 0.1484 - acc: 0.9278 - val_loss: 0.1782 - val_acc: 0.9167\n",
      "Epoch 521\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 265us/sample - loss: 1.1018\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 387us/sample - loss: 1.0673\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 321us/sample - loss: 0.4658 - acc: 0.9219\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 250us/sample - loss: 0.1483 - acc: 0.9208 - val_loss: 0.2289 - val_acc: 0.8889\n",
      "Epoch 522\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 301us/sample - loss: 1.0444\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 321us/sample - loss: 1.0511\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 280us/sample - loss: 0.4696 - acc: 0.9375\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 251us/sample - loss: 0.1611 - acc: 0.9174 - val_loss: 0.1644 - val_acc: 0.9306\n",
      "Epoch 523\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 268us/sample - loss: 1.0033\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 353us/sample - loss: 1.0037\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 288us/sample - loss: 0.5422 - acc: 0.8906\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 239us/sample - loss: 0.1400 - acc: 0.9299 - val_loss: 0.1505 - val_acc: 0.9361\n",
      "Epoch 524\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 240us/sample - loss: 1.0323\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 287us/sample - loss: 1.0317\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 338us/sample - loss: 0.5137 - acc: 0.8750\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 276us/sample - loss: 0.1312 - acc: 0.9354 - val_loss: 0.1628 - val_acc: 0.9250\n",
      "Epoch 525\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 325us/sample - loss: 1.0710\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 319us/sample - loss: 1.0621\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 283us/sample - loss: 0.4378 - acc: 0.9531\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 244us/sample - loss: 0.1385 - acc: 0.9306 - val_loss: 0.1530 - val_acc: 0.9222\n",
      "Epoch 526\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 277us/sample - loss: 1.0815\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 240us/sample - loss: 1.0703\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 259us/sample - loss: 0.4424 - acc: 0.9375\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 243us/sample - loss: 0.1563 - acc: 0.9215 - val_loss: 0.1849 - val_acc: 0.9139\n",
      "Epoch 527\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 358us/sample - loss: 0.9620\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 320us/sample - loss: 0.9614\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 352us/sample - loss: 0.5410 - acc: 0.8906\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 280us/sample - loss: 0.1576 - acc: 0.9181 - val_loss: 0.1742 - val_acc: 0.8944\n",
      "Epoch 528\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 270us/sample - loss: 1.1343\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 213us/sample - loss: 1.1228\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 232us/sample - loss: 0.4539 - acc: 0.9531\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 259us/sample - loss: 0.1445 - acc: 0.9278 - val_loss: 0.2096 - val_acc: 0.8778\n",
      "Epoch 529\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 215us/sample - loss: 1.0273\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 291us/sample - loss: 1.0171\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 283us/sample - loss: 0.4838 - acc: 0.9062\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 248us/sample - loss: 0.1544 - acc: 0.9187 - val_loss: 0.1586 - val_acc: 0.9361\n",
      "Epoch 530\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 247us/sample - loss: 1.0148\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 270us/sample - loss: 1.0057\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 354us/sample - loss: 0.5220 - acc: 0.9062\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 278us/sample - loss: 0.1494 - acc: 0.9125 - val_loss: 0.1532 - val_acc: 0.9389\n",
      "Epoch 531\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 291us/sample - loss: 0.9725\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 260us/sample - loss: 0.9677\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 257us/sample - loss: 0.5408 - acc: 0.9219\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 284us/sample - loss: 0.1415 - acc: 0.9257 - val_loss: 0.1833 - val_acc: 0.9167\n",
      "Epoch 532\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 358us/sample - loss: 1.0475\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 292us/sample - loss: 1.0514\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 303us/sample - loss: 0.4910 - acc: 0.9375\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 257us/sample - loss: 0.1413 - acc: 0.9278 - val_loss: 0.1759 - val_acc: 0.9306\n",
      "Epoch 533\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 230us/sample - loss: 1.1191\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 266us/sample - loss: 1.1134\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 369us/sample - loss: 0.4317 - acc: 0.9219\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 269us/sample - loss: 0.1487 - acc: 0.9236 - val_loss: 0.1803 - val_acc: 0.9250\n",
      "Epoch 534\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 268us/sample - loss: 1.1534\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 317us/sample - loss: 1.1487\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 340us/sample - loss: 0.4884 - acc: 0.8906\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 260us/sample - loss: 0.1397 - acc: 0.9340 - val_loss: 0.1683 - val_acc: 0.8806\n",
      "Epoch 535\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 229us/sample - loss: 1.0543\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 269us/sample - loss: 1.0517\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 278us/sample - loss: 0.4938 - acc: 0.9375\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 263us/sample - loss: 0.1576 - acc: 0.9201 - val_loss: 0.2061 - val_acc: 0.8694\n",
      "Epoch 536\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 275us/sample - loss: 1.1034\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 369us/sample - loss: 1.1004\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 261us/sample - loss: 0.4579 - acc: 0.9219\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 254us/sample - loss: 0.1769 - acc: 0.9083 - val_loss: 0.1635 - val_acc: 0.8917\n",
      "Epoch 537\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 251us/sample - loss: 1.0130\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 452us/sample - loss: 1.0112\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 242us/sample - loss: 0.5197 - acc: 0.9375\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 271us/sample - loss: 0.1415 - acc: 0.9299 - val_loss: 0.1505 - val_acc: 0.9333\n",
      "Epoch 538\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 293us/sample - loss: 1.0008\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 273us/sample - loss: 0.9982\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 244us/sample - loss: 0.5141 - acc: 0.9219\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 251us/sample - loss: 0.1433 - acc: 0.9215 - val_loss: 0.1682 - val_acc: 0.9222\n",
      "Epoch 539\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 199us/sample - loss: 0.9972\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 399us/sample - loss: 0.9964\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 299us/sample - loss: 0.4877 - acc: 0.9531\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 251us/sample - loss: 0.1521 - acc: 0.9243 - val_loss: 0.2055 - val_acc: 0.8639\n",
      "Epoch 540\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 243us/sample - loss: 1.0986\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 310us/sample - loss: 1.0929\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 374us/sample - loss: 0.4299 - acc: 0.9531\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 245us/sample - loss: 0.1749 - acc: 0.9139 - val_loss: 0.1598 - val_acc: 0.9028\n",
      "Epoch 541\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - ETA: 0s - loss: 1.002 - 0s 246us/sample - loss: 1.0355\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 470us/sample - loss: 1.0321\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 216us/sample - loss: 0.4683 - acc: 0.9375\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 255us/sample - loss: 0.1497 - acc: 0.9194 - val_loss: 0.2044 - val_acc: 0.9000\n",
      "Epoch 542\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 372us/sample - loss: 0.9679\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 362us/sample - loss: 0.9646\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 436us/sample - loss: 0.5458 - acc: 0.8750\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 241us/sample - loss: 0.1367 - acc: 0.9312 - val_loss: 0.1650 - val_acc: 0.9278\n",
      "Epoch 543\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 351us/sample - loss: 1.0005\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 399us/sample - loss: 0.9994\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 394us/sample - loss: 0.4924 - acc: 0.9375\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 241us/sample - loss: 0.1440 - acc: 0.9264 - val_loss: 0.1788 - val_acc: 0.8806\n",
      "Epoch 544\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 245us/sample - loss: 1.0804\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 364us/sample - loss: 1.0719\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 305us/sample - loss: 0.4490 - acc: 0.9531\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 286us/sample - loss: 0.1403 - acc: 0.9285 - val_loss: 0.1791 - val_acc: 0.9167\n",
      "Epoch 545\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 226us/sample - loss: 1.0886\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 343us/sample - loss: 1.0874\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 319us/sample - loss: 0.4449 - acc: 0.9531\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 277us/sample - loss: 0.1510 - acc: 0.9208 - val_loss: 0.1525 - val_acc: 0.9444\n",
      "Epoch 546\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 342us/sample - loss: 0.9923\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 299us/sample - loss: 0.9872\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 399us/sample - loss: 0.5092 - acc: 0.8906\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 232us/sample - loss: 0.1482 - acc: 0.9264 - val_loss: 0.1784 - val_acc: 0.8778\n",
      "Epoch 547\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 215us/sample - loss: 1.0792\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 226us/sample - loss: 1.0774\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 308us/sample - loss: 0.4665 - acc: 0.9531\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 275us/sample - loss: 0.1394 - acc: 0.9208 - val_loss: 0.2042 - val_acc: 0.9000\n",
      "Epoch 548\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 328us/sample - loss: 1.0533\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 325us/sample - loss: 1.0419\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 307us/sample - loss: 0.4607 - acc: 0.9219\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 259us/sample - loss: 0.1521 - acc: 0.9201 - val_loss: 0.1556 - val_acc: 0.9194\n",
      "Epoch 549\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 317us/sample - loss: 1.0339\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 380us/sample - loss: 1.0385\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 333us/sample - loss: 0.4793 - acc: 0.9375\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 252us/sample - loss: 0.1441 - acc: 0.9257 - val_loss: 0.1596 - val_acc: 0.9417\n",
      "Epoch 550\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 210us/sample - loss: 1.0347\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 430us/sample - loss: 1.0315\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 295us/sample - loss: 0.4805 - acc: 0.9219\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 288us/sample - loss: 0.1493 - acc: 0.9264 - val_loss: 0.1619 - val_acc: 0.9333\n",
      "Epoch 551\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 256us/sample - loss: 1.0088\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 310us/sample - loss: 0.9991\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 341us/sample - loss: 0.4754 - acc: 0.9688\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 245us/sample - loss: 0.1546 - acc: 0.9194 - val_loss: 0.1704 - val_acc: 0.8750\n",
      "Epoch 552\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 284us/sample - loss: 1.0871\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 397us/sample - loss: 1.0812\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 262us/sample - loss: 0.4556 - acc: 0.9531\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 244us/sample - loss: 0.1545 - acc: 0.9201 - val_loss: 0.2172 - val_acc: 0.8611\n",
      "Epoch 553\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 219us/sample - loss: 1.0617\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 305us/sample - loss: 1.0636\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 302us/sample - loss: 0.4535 - acc: 0.9688\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 247us/sample - loss: 0.1507 - acc: 0.9215 - val_loss: 0.1852 - val_acc: 0.9028\n",
      "Epoch 554\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 283us/sample - loss: 1.0480\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 311us/sample - loss: 1.0413\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 245us/sample - loss: 0.4734 - acc: 0.9375\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 262us/sample - loss: 0.1516 - acc: 0.9181 - val_loss: 0.1641 - val_acc: 0.9333\n",
      "Epoch 555\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 284us/sample - loss: 1.0871\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 368us/sample - loss: 1.0842\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 323us/sample - loss: 0.4688 - acc: 0.9062\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 247us/sample - loss: 0.1363 - acc: 0.9299 - val_loss: 0.1553 - val_acc: 0.9083\n",
      "Epoch 556\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 247us/sample - loss: 1.1665\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 250us/sample - loss: 1.1488\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 284us/sample - loss: 0.4296 - acc: 0.9375\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 229us/sample - loss: 0.1341 - acc: 0.9312 - val_loss: 0.1780 - val_acc: 0.8944\n",
      "Epoch 557\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 242us/sample - loss: 1.0868\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 383us/sample - loss: 1.0906\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 271us/sample - loss: 0.4770 - acc: 0.9062\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 229us/sample - loss: 0.1511 - acc: 0.9208 - val_loss: 0.1749 - val_acc: 0.9222\n",
      "Epoch 558\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 226us/sample - loss: 0.9839\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 255us/sample - loss: 0.9852\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 256us/sample - loss: 0.5312 - acc: 0.8750\n",
      "Train on 1440 samples, validate on 360 samples\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1440/1440 [==============================] - 0s 248us/sample - loss: 0.1494 - acc: 0.9236 - val_loss: 0.1494 - val_acc: 0.9417\n",
      "Epoch 559\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 227us/sample - loss: 1.1044\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 345us/sample - loss: 1.0965\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 330us/sample - loss: 0.4176 - acc: 0.9844\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 282us/sample - loss: 0.1432 - acc: 0.9257 - val_loss: 0.1527 - val_acc: 0.9389\n",
      "Epoch 560\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 183us/sample - loss: 1.0415\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 323us/sample - loss: 1.0413\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 334us/sample - loss: 0.4917 - acc: 0.9531\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 257us/sample - loss: 0.1358 - acc: 0.9243 - val_loss: 0.1669 - val_acc: 0.9250\n",
      "Epoch 561\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 296us/sample - loss: 1.0246\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 373us/sample - loss: 1.0193\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 321us/sample - loss: 0.4633 - acc: 0.9688\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 247us/sample - loss: 0.1438 - acc: 0.9257 - val_loss: 0.1582 - val_acc: 0.8944\n",
      "Epoch 562\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 351us/sample - loss: 1.0725\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 370us/sample - loss: 1.0754\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 304us/sample - loss: 0.4633 - acc: 0.9688\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 271us/sample - loss: 0.1455 - acc: 0.9250 - val_loss: 0.1850 - val_acc: 0.8694\n",
      "Epoch 563\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 270us/sample - loss: 1.0452\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 368us/sample - loss: 1.0439\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 303us/sample - loss: 0.4589 - acc: 0.9375\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 233us/sample - loss: 0.1854 - acc: 0.9104 - val_loss: 0.1881 - val_acc: 0.9028\n",
      "Epoch 564\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 289us/sample - loss: 0.9957\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 260us/sample - loss: 0.9921\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 293us/sample - loss: 0.5166 - acc: 0.8906\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 250us/sample - loss: 0.1640 - acc: 0.9174 - val_loss: 0.2433 - val_acc: 0.9056\n",
      "Epoch 565\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 226us/sample - loss: 1.0434\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 343us/sample - loss: 1.0346\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 365us/sample - loss: 0.4640 - acc: 0.9531\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 233us/sample - loss: 0.1682 - acc: 0.9118 - val_loss: 0.1563 - val_acc: 0.9194\n",
      "Epoch 566\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 190us/sample - loss: 1.1316\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 329us/sample - loss: 1.1122\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 275us/sample - loss: 0.4302 - acc: 0.9688\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 249us/sample - loss: 0.1392 - acc: 0.9306 - val_loss: 0.1535 - val_acc: 0.9222\n",
      "Epoch 567\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 221us/sample - loss: 1.0096\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 293us/sample - loss: 1.0138\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 302us/sample - loss: 0.4892 - acc: 0.9062\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 255us/sample - loss: 0.1579 - acc: 0.9299 - val_loss: 0.2906 - val_acc: 0.8611\n",
      "Epoch 568\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 275us/sample - loss: 1.2785\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 291us/sample - loss: 1.2510\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 240us/sample - loss: 0.3680 - acc: 0.9844\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 237us/sample - loss: 0.1823 - acc: 0.9062 - val_loss: 0.1774 - val_acc: 0.8778\n",
      "Epoch 569\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 275us/sample - loss: 1.0572\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 333us/sample - loss: 1.0588\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 226us/sample - loss: 0.4724 - acc: 0.9219\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 245us/sample - loss: 0.1821 - acc: 0.9069 - val_loss: 0.2417 - val_acc: 0.8972\n",
      "Epoch 570\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 267us/sample - loss: 0.8852\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 280us/sample - loss: 0.8827\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 291us/sample - loss: 0.6249 - acc: 0.8125\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 259us/sample - loss: 0.1495 - acc: 0.9187 - val_loss: 0.1553 - val_acc: 0.9417\n",
      "Epoch 571\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 288us/sample - loss: 1.0115\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 259us/sample - loss: 1.0050\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 245us/sample - loss: 0.5164 - acc: 0.9219\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 238us/sample - loss: 0.1438 - acc: 0.9257 - val_loss: 0.1600 - val_acc: 0.9333\n",
      "Epoch 572\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 258us/sample - loss: 1.0196\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 288us/sample - loss: 1.0145\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 303us/sample - loss: 0.5122 - acc: 0.9219\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 277us/sample - loss: 0.1578 - acc: 0.9229 - val_loss: 0.1610 - val_acc: 0.9167\n",
      "Epoch 573\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 213us/sample - loss: 1.0123\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 268us/sample - loss: 1.0093\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 283us/sample - loss: 0.5232 - acc: 0.8906\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 238us/sample - loss: 0.1556 - acc: 0.9236 - val_loss: 0.1614 - val_acc: 0.9333\n",
      "Epoch 574\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 224us/sample - loss: 0.8832\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 223us/sample - loss: 0.8804\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 327us/sample - loss: 0.5916 - acc: 0.8281\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 238us/sample - loss: 0.1502 - acc: 0.9243 - val_loss: 0.1583 - val_acc: 0.9278\n",
      "Epoch 575\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 191us/sample - loss: 1.0206\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 224us/sample - loss: 1.0186\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 302us/sample - loss: 0.4680 - acc: 0.9375\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 242us/sample - loss: 0.1375 - acc: 0.9299 - val_loss: 0.1576 - val_acc: 0.9139\n",
      "Epoch 576\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 294us/sample - loss: 0.9944\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 239us/sample - loss: 0.9905\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 287us/sample - loss: 0.5373 - acc: 0.8750\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 240us/sample - loss: 0.1499 - acc: 0.9167 - val_loss: 0.1951 - val_acc: 0.9250\n",
      "Epoch 577\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 406us/sample - loss: 0.9976\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 193us/sample - loss: 0.9893\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 280us/sample - loss: 0.4976 - acc: 0.9531\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 254us/sample - loss: 0.1393 - acc: 0.9292 - val_loss: 0.1825 - val_acc: 0.9167\n",
      "Epoch 578\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 194us/sample - loss: 1.1074\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 374us/sample - loss: 1.0814\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 318us/sample - loss: 0.4424 - acc: 0.9375\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 252us/sample - loss: 0.1478 - acc: 0.9243 - val_loss: 0.1608 - val_acc: 0.9306\n",
      "Epoch 579\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 223us/sample - loss: 1.0132\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 282us/sample - loss: 0.9947\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 425us/sample - loss: 0.5103 - acc: 0.9375\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 250us/sample - loss: 0.1335 - acc: 0.9333 - val_loss: 0.1617 - val_acc: 0.9056\n",
      "Epoch 580\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 194us/sample - loss: 1.0247\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 268us/sample - loss: 1.0271\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 303us/sample - loss: 0.4805 - acc: 0.9375\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 282us/sample - loss: 0.1474 - acc: 0.9243 - val_loss: 0.1567 - val_acc: 0.9389\n",
      "Epoch 581\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 334us/sample - loss: 0.9909\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 351us/sample - loss: 0.9927\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 300us/sample - loss: 0.4986 - acc: 0.9531\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 288us/sample - loss: 0.1430 - acc: 0.9243 - val_loss: 0.2493 - val_acc: 0.9167\n",
      "Epoch 582\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 304us/sample - loss: 1.1159\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 224us/sample - loss: 1.1112\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 306us/sample - loss: 0.4186 - acc: 0.9688\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 258us/sample - loss: 0.1431 - acc: 0.9333 - val_loss: 0.1529 - val_acc: 0.9333\n",
      "Epoch 583\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 224us/sample - loss: 0.9753\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 346us/sample - loss: 0.9641\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 288us/sample - loss: 0.6028 - acc: 0.9062\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 244us/sample - loss: 0.1566 - acc: 0.9194 - val_loss: 0.1783 - val_acc: 0.8833\n",
      "Epoch 584\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 329us/sample - loss: 1.1037\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 247us/sample - loss: 1.0982\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 235us/sample - loss: 0.4211 - acc: 0.9688\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 250us/sample - loss: 0.1410 - acc: 0.9271 - val_loss: 0.1548 - val_acc: 0.9389\n",
      "Epoch 585\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 257us/sample - loss: 1.0737\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 347us/sample - loss: 1.0696\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 326us/sample - loss: 0.4438 - acc: 0.9688\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 242us/sample - loss: 0.1434 - acc: 0.9243 - val_loss: 0.1555 - val_acc: 0.9389\n",
      "Epoch 586\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 273us/sample - loss: 0.9546\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 326us/sample - loss: 0.9539\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 359us/sample - loss: 0.5420 - acc: 0.9062\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 243us/sample - loss: 0.1437 - acc: 0.9257 - val_loss: 0.1562 - val_acc: 0.9361\n",
      "Epoch 587\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 226us/sample - loss: 1.1086\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 381us/sample - loss: 1.1036\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 268us/sample - loss: 0.4373 - acc: 0.9375\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 255us/sample - loss: 0.1635 - acc: 0.9174 - val_loss: 0.1886 - val_acc: 0.8833\n",
      "Epoch 588\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 265us/sample - loss: 1.1085\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 286us/sample - loss: 1.1049\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 322us/sample - loss: 0.4537 - acc: 0.9531\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 247us/sample - loss: 0.1344 - acc: 0.9375 - val_loss: 0.1532 - val_acc: 0.9444\n",
      "Epoch 589\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 247us/sample - loss: 1.0043\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 330us/sample - loss: 1.0019\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 274us/sample - loss: 0.4998 - acc: 0.9219\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 251us/sample - loss: 0.1412 - acc: 0.9292 - val_loss: 0.1566 - val_acc: 0.9194\n",
      "Epoch 590\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 164us/sample - loss: 0.9753\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 176us/sample - loss: 0.9729\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 232us/sample - loss: 0.5428 - acc: 0.9062\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 282us/sample - loss: 0.1523 - acc: 0.9222 - val_loss: 0.1642 - val_acc: 0.9306\n",
      "Epoch 591\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 259us/sample - loss: 0.9711\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 224us/sample - loss: 0.9679\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 237us/sample - loss: 0.5684 - acc: 0.8750\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 262us/sample - loss: 0.1641 - acc: 0.9153 - val_loss: 0.2192 - val_acc: 0.8972\n",
      "Epoch 592\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 255us/sample - loss: 0.9997\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 453us/sample - loss: 0.9893\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 330us/sample - loss: 0.5813 - acc: 0.9219\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 236us/sample - loss: 0.1508 - acc: 0.9250 - val_loss: 0.1686 - val_acc: 0.8972\n",
      "Epoch 593\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 382us/sample - loss: 1.0869\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 174us/sample - loss: 1.0885\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 235us/sample - loss: 0.4280 - acc: 0.9531\n",
      "Train on 1440 samples, validate on 360 samples\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1440/1440 [==============================] - 0s 246us/sample - loss: 0.1450 - acc: 0.9278 - val_loss: 0.1945 - val_acc: 0.9250\n",
      "Epoch 594\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 231us/sample - loss: 0.9855\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 363us/sample - loss: 0.9845\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 306us/sample - loss: 0.5349 - acc: 0.8906\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 279us/sample - loss: 0.1435 - acc: 0.9299 - val_loss: 0.1763 - val_acc: 0.9194\n",
      "Epoch 595\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 251us/sample - loss: 1.0725\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 332us/sample - loss: 1.0625\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 429us/sample - loss: 0.4462 - acc: 0.9688\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 237us/sample - loss: 0.1425 - acc: 0.9243 - val_loss: 0.1660 - val_acc: 0.9278\n",
      "Epoch 596\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 421us/sample - loss: 0.9290\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 416us/sample - loss: 0.9276\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 335us/sample - loss: 0.5774 - acc: 0.8594\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 249us/sample - loss: 0.1439 - acc: 0.9264 - val_loss: 0.1620 - val_acc: 0.8806\n",
      "Epoch 597\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 297us/sample - loss: 1.1222\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 289us/sample - loss: 1.1180\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 309us/sample - loss: 0.4587 - acc: 0.9688\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 281us/sample - loss: 0.1455 - acc: 0.9187 - val_loss: 0.2144 - val_acc: 0.9111\n",
      "Epoch 598\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 328us/sample - loss: 0.9668\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 309us/sample - loss: 0.9617\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 327us/sample - loss: 0.5349 - acc: 0.8906\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 249us/sample - loss: 0.1664 - acc: 0.9139 - val_loss: 0.1564 - val_acc: 0.9250\n",
      "Epoch 599\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 270us/sample - loss: 1.0411\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 322us/sample - loss: 1.0397\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 344us/sample - loss: 0.4815 - acc: 0.8906\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 225us/sample - loss: 0.1359 - acc: 0.9306 - val_loss: 0.1540 - val_acc: 0.9139\n",
      "Epoch 600\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 240us/sample - loss: 1.0801\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 451us/sample - loss: 1.0779\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 415us/sample - loss: 0.4315 - acc: 0.9844\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 249us/sample - loss: 0.1349 - acc: 0.9333 - val_loss: 0.1607 - val_acc: 0.9083\n",
      "Epoch 601\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 351us/sample - loss: 1.0494\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 336us/sample - loss: 1.0429\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 348us/sample - loss: 0.4509 - acc: 0.9531\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 240us/sample - loss: 0.1584 - acc: 0.9104 - val_loss: 0.2021 - val_acc: 0.8806\n",
      "Epoch 602\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 243us/sample - loss: 1.0346\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 485us/sample - loss: 1.0260\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 291us/sample - loss: 0.4862 - acc: 0.9375\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 306us/sample - loss: 0.1383 - acc: 0.9354 - val_loss: 0.1593 - val_acc: 0.9278\n",
      "Epoch 603\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 318us/sample - loss: 0.9951\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 251us/sample - loss: 0.9945\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 316us/sample - loss: 0.4910 - acc: 0.9375\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 244us/sample - loss: 0.1345 - acc: 0.9285 - val_loss: 0.1724 - val_acc: 0.9167\n",
      "Epoch 604\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 256us/sample - loss: 1.0992\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 271us/sample - loss: 1.0864\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 309us/sample - loss: 0.5117 - acc: 0.8906\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 279us/sample - loss: 0.1600 - acc: 0.9174 - val_loss: 0.1722 - val_acc: 0.8972\n",
      "Epoch 605\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 252us/sample - loss: 1.4334\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 247us/sample - loss: 1.3920\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 341us/sample - loss: 0.4372 - acc: 0.9531\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 249us/sample - loss: 0.1476 - acc: 0.9257 - val_loss: 0.1547 - val_acc: 0.9417\n",
      "Epoch 606\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 236us/sample - loss: 1.0630\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 250us/sample - loss: 1.0579\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 215us/sample - loss: 0.4832 - acc: 0.9531\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 251us/sample - loss: 0.1387 - acc: 0.9264 - val_loss: 0.1546 - val_acc: 0.9333\n",
      "Epoch 607\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 295us/sample - loss: 1.0650\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 325us/sample - loss: 1.0726\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 301us/sample - loss: 0.4434 - acc: 0.9688\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 238us/sample - loss: 0.1522 - acc: 0.9208 - val_loss: 0.1572 - val_acc: 0.9194\n",
      "Epoch 608\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 300us/sample - loss: 1.0080\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 234us/sample - loss: 1.0054\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 281us/sample - loss: 0.4889 - acc: 0.9219\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 243us/sample - loss: 0.1413 - acc: 0.9257 - val_loss: 0.1882 - val_acc: 0.9222\n",
      "Epoch 609\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 284us/sample - loss: 1.0399\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 308us/sample - loss: 1.0300\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 267us/sample - loss: 0.4463 - acc: 1.0000\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 233us/sample - loss: 0.1448 - acc: 0.9278 - val_loss: 0.1503 - val_acc: 0.9333\n",
      "Epoch 610\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 186us/sample - loss: 1.0684\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 254us/sample - loss: 1.0455\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 286us/sample - loss: 0.5506 - acc: 0.8906\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 232us/sample - loss: 0.1379 - acc: 0.9285 - val_loss: 0.1789 - val_acc: 0.8861\n",
      "Epoch 611\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 285us/sample - loss: 1.4007\n",
      "Epoch 2/2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64/64 [==============================] - 0s 318us/sample - loss: 1.4019\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 237us/sample - loss: 0.4328 - acc: 0.9531\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 260us/sample - loss: 0.1498 - acc: 0.9201 - val_loss: 0.2144 - val_acc: 0.8667\n",
      "Epoch 612\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 391us/sample - loss: 1.0629\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 308us/sample - loss: 1.0596\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 526us/sample - loss: 0.4400 - acc: 1.0000\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 282us/sample - loss: 0.1639 - acc: 0.9187 - val_loss: 0.1593 - val_acc: 0.9250\n",
      "Epoch 613\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 334us/sample - loss: 0.9473\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 305us/sample - loss: 0.9427\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 270us/sample - loss: 0.5307 - acc: 0.9062\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 273us/sample - loss: 0.1590 - acc: 0.9257 - val_loss: 0.1720 - val_acc: 0.9139\n",
      "Epoch 614\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 347us/sample - loss: 1.0456\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 450us/sample - loss: 1.0414\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 268us/sample - loss: 0.4651 - acc: 0.9375\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 227us/sample - loss: 0.1549 - acc: 0.9285 - val_loss: 0.1773 - val_acc: 0.9194\n",
      "Epoch 615\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 319us/sample - loss: 0.9435\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 370us/sample - loss: 0.9394\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 280us/sample - loss: 0.5846 - acc: 0.8750\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 253us/sample - loss: 0.1568 - acc: 0.9194 - val_loss: 0.1679 - val_acc: 0.8972\n",
      "Epoch 616\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 265us/sample - loss: 1.1006\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 302us/sample - loss: 1.0982\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 372us/sample - loss: 0.4358 - acc: 0.9375\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 239us/sample - loss: 0.1429 - acc: 0.9278 - val_loss: 0.1646 - val_acc: 0.9250\n",
      "Epoch 617\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 330us/sample - loss: 1.0780\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 363us/sample - loss: 1.0788\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 278us/sample - loss: 0.4645 - acc: 0.9219\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 249us/sample - loss: 0.1488 - acc: 0.9194 - val_loss: 0.1578 - val_acc: 0.9333\n",
      "Epoch 618\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 269us/sample - loss: 0.9705\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 369us/sample - loss: 0.9585\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 259us/sample - loss: 0.5863 - acc: 0.8438\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 227us/sample - loss: 0.1400 - acc: 0.9278 - val_loss: 0.1624 - val_acc: 0.9278\n",
      "Epoch 619\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 362us/sample - loss: 0.9749\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 397us/sample - loss: 0.9736\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 371us/sample - loss: 0.5513 - acc: 0.8750\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 239us/sample - loss: 0.1346 - acc: 0.9306 - val_loss: 0.1605 - val_acc: 0.9278\n",
      "Epoch 620\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 272us/sample - loss: 0.9287\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 323us/sample - loss: 0.9248\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 364us/sample - loss: 0.5757 - acc: 0.8750\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 276us/sample - loss: 0.1409 - acc: 0.9257 - val_loss: 0.1613 - val_acc: 0.9333\n",
      "Epoch 621\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 284us/sample - loss: 1.0814\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 380us/sample - loss: 1.0774\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 307us/sample - loss: 0.4560 - acc: 0.9375\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 270us/sample - loss: 0.1389 - acc: 0.9292 - val_loss: 0.1515 - val_acc: 0.9444\n",
      "Epoch 622\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 190us/sample - loss: 0.9563\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 219us/sample - loss: 0.9560\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 304us/sample - loss: 0.5277 - acc: 0.8594\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 218us/sample - loss: 0.1365 - acc: 0.9306 - val_loss: 0.1561 - val_acc: 0.9278\n",
      "Epoch 623\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 227us/sample - loss: 1.1117\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 264us/sample - loss: 1.0994\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - ETA: 0s - loss: 0.4669 - acc: 0.906 - 0s 377us/sample - loss: 0.4737 - acc: 0.9062\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 258us/sample - loss: 0.1476 - acc: 0.9250 - val_loss: 0.1540 - val_acc: 0.9306\n",
      "Epoch 624\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 295us/sample - loss: 1.1648\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 325us/sample - loss: 1.1506\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 243us/sample - loss: 0.4720 - acc: 0.9531\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 237us/sample - loss: 0.1422 - acc: 0.9257 - val_loss: 0.1713 - val_acc: 0.8806\n",
      "Epoch 625\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 295us/sample - loss: 1.1163\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 257us/sample - loss: 1.1154\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 345us/sample - loss: 0.4372 - acc: 0.9688\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 259us/sample - loss: 0.1434 - acc: 0.9285 - val_loss: 0.1594 - val_acc: 0.9028\n",
      "Epoch 626\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 215us/sample - loss: 0.9793\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 296us/sample - loss: 0.9800\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 323us/sample - loss: 0.5304 - acc: 0.8906\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 222us/sample - loss: 0.1699 - acc: 0.9111 - val_loss: 0.2360 - val_acc: 0.8778\n",
      "Epoch 627\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 215us/sample - loss: 0.9547\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 217us/sample - loss: 0.9526\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 266us/sample - loss: 0.6228 - acc: 0.9062\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 262us/sample - loss: 0.1583 - acc: 0.9215 - val_loss: 0.1547 - val_acc: 0.9083\n",
      "Epoch 628\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 174us/sample - loss: 1.1289\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 215us/sample - loss: 1.1219\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 239us/sample - loss: 0.4306 - acc: 0.9688\n",
      "Train on 1440 samples, validate on 360 samples\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1440/1440 [==============================] - 0s 246us/sample - loss: 0.1388 - acc: 0.9347 - val_loss: 0.1486 - val_acc: 0.9417\n",
      "Epoch 629\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 325us/sample - loss: 0.9824\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 203us/sample - loss: 0.9825\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 303us/sample - loss: 0.5295 - acc: 0.9062\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 262us/sample - loss: 0.1533 - acc: 0.9208 - val_loss: 0.1611 - val_acc: 0.9056\n",
      "Epoch 630\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 231us/sample - loss: 0.9103\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 341us/sample - loss: 0.9062\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 283us/sample - loss: 0.5814 - acc: 0.8906\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 261us/sample - loss: 0.1592 - acc: 0.9194 - val_loss: 0.1668 - val_acc: 0.8806\n",
      "Epoch 631\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 279us/sample - loss: 1.1097\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 237us/sample - loss: 1.1041\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 278us/sample - loss: 0.4408 - acc: 0.9688\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 252us/sample - loss: 0.1857 - acc: 0.9153 - val_loss: 0.2078 - val_acc: 0.9000\n",
      "Epoch 632\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 333us/sample - loss: 0.9515\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 387us/sample - loss: 0.9466\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 353us/sample - loss: 0.5322 - acc: 0.9219\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 257us/sample - loss: 0.1632 - acc: 0.9146 - val_loss: 0.1691 - val_acc: 0.8944\n",
      "Epoch 633\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 209us/sample - loss: 1.0347\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 281us/sample - loss: 1.0355\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 312us/sample - loss: 0.4603 - acc: 0.9375\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 295us/sample - loss: 0.1466 - acc: 0.9243 - val_loss: 0.1889 - val_acc: 0.8778\n",
      "Epoch 634\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 249us/sample - loss: 1.0388\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 276us/sample - loss: 1.0344\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 309us/sample - loss: 0.4520 - acc: 0.9375\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 244us/sample - loss: 0.1499 - acc: 0.9271 - val_loss: 0.2017 - val_acc: 0.8778\n",
      "Epoch 635\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 237us/sample - loss: 1.1010\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 425us/sample - loss: 1.0890\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 281us/sample - loss: 0.4323 - acc: 0.9688\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 268us/sample - loss: 0.1422 - acc: 0.9264 - val_loss: 0.1606 - val_acc: 0.9278\n",
      "Epoch 636\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 235us/sample - loss: 0.9678\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 315us/sample - loss: 0.9711\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 359us/sample - loss: 0.5034 - acc: 0.9375\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 234us/sample - loss: 0.1348 - acc: 0.9271 - val_loss: 0.1585 - val_acc: 0.9333\n",
      "Epoch 637\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 334us/sample - loss: 1.0201\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 303us/sample - loss: 1.0179\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 311us/sample - loss: 0.5122 - acc: 0.9062\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 255us/sample - loss: 0.1453 - acc: 0.9292 - val_loss: 0.1601 - val_acc: 0.9361\n",
      "Epoch 638\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 251us/sample - loss: 0.9643\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 294us/sample - loss: 0.9500\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 232us/sample - loss: 0.6557 - acc: 0.7656\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 249us/sample - loss: 0.1434 - acc: 0.9222 - val_loss: 0.1673 - val_acc: 0.9194\n",
      "Epoch 639\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 249us/sample - loss: 0.9744\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 382us/sample - loss: 0.9770\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 295us/sample - loss: 0.5266 - acc: 0.9375\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 239us/sample - loss: 0.1480 - acc: 0.9222 - val_loss: 0.1598 - val_acc: 0.9333\n",
      "Epoch 640\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 244us/sample - loss: 1.0552\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 331us/sample - loss: 1.0548\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 327us/sample - loss: 0.4778 - acc: 0.9219\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 249us/sample - loss: 0.1517 - acc: 0.9264 - val_loss: 0.1663 - val_acc: 0.8778\n",
      "Epoch 641\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 231us/sample - loss: 1.0520\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 335us/sample - loss: 1.0343\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 294us/sample - loss: 0.4834 - acc: 0.9219\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 269us/sample - loss: 0.1411 - acc: 0.9243 - val_loss: 0.1529 - val_acc: 0.9389\n",
      "Epoch 642\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 307us/sample - loss: 1.0029\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 301us/sample - loss: 1.0023\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 349us/sample - loss: 0.5220 - acc: 0.9062\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 212us/sample - loss: 0.1417 - acc: 0.9326 - val_loss: 0.1512 - val_acc: 0.9389\n",
      "Epoch 643\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 243us/sample - loss: 1.0019\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 290us/sample - loss: 0.9980\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 298us/sample - loss: 0.5266 - acc: 0.9062\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 241us/sample - loss: 0.1379 - acc: 0.9264 - val_loss: 0.1622 - val_acc: 0.9333\n",
      "Epoch 644\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 245us/sample - loss: 1.1269\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 363us/sample - loss: 1.1142\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 282us/sample - loss: 0.4469 - acc: 0.9531\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 248us/sample - loss: 0.1434 - acc: 0.9326 - val_loss: 0.1944 - val_acc: 0.8778\n",
      "Epoch 645\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 210us/sample - loss: 1.1740\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 198us/sample - loss: 1.1546\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 241us/sample - loss: 0.4284 - acc: 0.9688\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 244us/sample - loss: 0.1530 - acc: 0.9236 - val_loss: 0.2107 - val_acc: 0.8833\n",
      "Epoch 646\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 259us/sample - loss: 1.2242\n",
      "Epoch 2/2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64/64 [==============================] - 0s 432us/sample - loss: 1.1936\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 260us/sample - loss: 0.4676 - acc: 0.9375\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 237us/sample - loss: 0.1457 - acc: 0.9215 - val_loss: 0.2695 - val_acc: 0.8778\n",
      "Epoch 647\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 308us/sample - loss: 1.0548\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 366us/sample - loss: 1.0657\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 343us/sample - loss: 0.4517 - acc: 0.9375\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 268us/sample - loss: 0.1723 - acc: 0.9139 - val_loss: 0.1543 - val_acc: 0.9333\n",
      "Epoch 648\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 239us/sample - loss: 0.9630\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 359us/sample - loss: 0.9627\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 317us/sample - loss: 0.5164 - acc: 0.9375\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 257us/sample - loss: 0.1414 - acc: 0.9236 - val_loss: 0.1696 - val_acc: 0.9000\n",
      "Epoch 649\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 246us/sample - loss: 1.1131\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 324us/sample - loss: 1.1087\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 342us/sample - loss: 0.4330 - acc: 0.9844\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 232us/sample - loss: 0.1462 - acc: 0.9278 - val_loss: 0.1851 - val_acc: 0.8806\n",
      "Epoch 650\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 229us/sample - loss: 1.0525\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 315us/sample - loss: 1.0391\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 316us/sample - loss: 0.4696 - acc: 0.9375\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 253us/sample - loss: 0.1445 - acc: 0.9271 - val_loss: 0.1632 - val_acc: 0.9361\n",
      "Epoch 651\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 221us/sample - loss: 1.0155\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 511us/sample - loss: 1.0063\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 323us/sample - loss: 0.5573 - acc: 0.9062\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 262us/sample - loss: 0.1354 - acc: 0.9306 - val_loss: 0.1532 - val_acc: 0.9306\n",
      "Epoch 652\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 369us/sample - loss: 1.0039\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 338us/sample - loss: 0.9668\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 244us/sample - loss: 0.5256 - acc: 0.8750\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 241us/sample - loss: 0.1388 - acc: 0.9312 - val_loss: 0.1535 - val_acc: 0.9194\n",
      "Epoch 653\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 203us/sample - loss: 1.0458\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 141us/sample - loss: 1.0442\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 369us/sample - loss: 0.4782 - acc: 0.9375\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 252us/sample - loss: 0.1353 - acc: 0.9312 - val_loss: 0.1554 - val_acc: 0.9389\n",
      "Epoch 654\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 280us/sample - loss: 1.0243\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 355us/sample - loss: 1.0240\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 277us/sample - loss: 0.4963 - acc: 0.9375\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 262us/sample - loss: 0.1362 - acc: 0.9347 - val_loss: 0.1519 - val_acc: 0.9417\n",
      "Epoch 655\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 392us/sample - loss: 1.1293\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 304us/sample - loss: 1.1273\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 273us/sample - loss: 0.5047 - acc: 0.9062\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 236us/sample - loss: 0.1619 - acc: 0.9194 - val_loss: 0.1532 - val_acc: 0.9389\n",
      "Epoch 656\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 313us/sample - loss: 1.0522\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 223us/sample - loss: 1.0503\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 301us/sample - loss: 0.5060 - acc: 0.9531\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 251us/sample - loss: 0.1416 - acc: 0.9278 - val_loss: 0.1590 - val_acc: 0.9139\n",
      "Epoch 657\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 226us/sample - loss: 1.1088\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 287us/sample - loss: 1.0767\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 329us/sample - loss: 0.5164 - acc: 0.9219\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 227us/sample - loss: 0.1437 - acc: 0.9285 - val_loss: 0.1800 - val_acc: 0.8833\n",
      "Epoch 658\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 291us/sample - loss: 1.0327\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 324us/sample - loss: 1.0383\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 340us/sample - loss: 0.4736 - acc: 0.9219\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 256us/sample - loss: 0.1500 - acc: 0.9306 - val_loss: 0.2129 - val_acc: 0.9083\n",
      "Epoch 659\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 234us/sample - loss: 0.9821\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 257us/sample - loss: 0.9801\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 284us/sample - loss: 0.5124 - acc: 0.9062\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 244us/sample - loss: 0.1756 - acc: 0.9139 - val_loss: 0.1959 - val_acc: 0.8917\n",
      "Epoch 660\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 288us/sample - loss: 1.0659\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 331us/sample - loss: 1.0602\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 376us/sample - loss: 0.4395 - acc: 0.9844\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 259us/sample - loss: 0.1690 - acc: 0.9201 - val_loss: 0.2265 - val_acc: 0.8639\n",
      "Epoch 661\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 327us/sample - loss: 0.9815\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 257us/sample - loss: 0.9694\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 268us/sample - loss: 0.4983 - acc: 0.9375\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 242us/sample - loss: 0.1870 - acc: 0.9076 - val_loss: 0.1513 - val_acc: 0.9222\n",
      "Epoch 662\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 408us/sample - loss: 1.0291\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 352us/sample - loss: 1.0261\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 299us/sample - loss: 0.5315 - acc: 0.9219\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 223us/sample - loss: 0.1403 - acc: 0.9243 - val_loss: 0.1510 - val_acc: 0.9417\n",
      "Epoch 663\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 302us/sample - loss: 0.9375\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 315us/sample - loss: 0.9359\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 287us/sample - loss: 0.5352 - acc: 0.9219\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 268us/sample - loss: 0.1507 - acc: 0.9208 - val_loss: 0.1820 - val_acc: 0.9111\n",
      "Epoch 664\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 369us/sample - loss: 0.9223\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 323us/sample - loss: 0.9186\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 323us/sample - loss: 0.5867 - acc: 0.8438\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 246us/sample - loss: 0.1435 - acc: 0.9319 - val_loss: 0.1521 - val_acc: 0.9417\n",
      "Epoch 665\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 237us/sample - loss: 1.0665\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 369us/sample - loss: 1.0624\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 307us/sample - loss: 0.4488 - acc: 0.9531\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 215us/sample - loss: 0.1437 - acc: 0.9306 - val_loss: 0.1780 - val_acc: 0.9194\n",
      "Epoch 666\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 287us/sample - loss: 1.0663\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 279us/sample - loss: 1.0338\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 292us/sample - loss: 0.4768 - acc: 0.9219\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 281us/sample - loss: 0.1415 - acc: 0.9292 - val_loss: 0.1479 - val_acc: 0.9417\n",
      "Epoch 667\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 238us/sample - loss: 0.9503\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 270us/sample - loss: 0.9552\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 267us/sample - loss: 0.5245 - acc: 0.8906\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 245us/sample - loss: 0.1441 - acc: 0.9264 - val_loss: 0.1641 - val_acc: 0.9083\n",
      "Epoch 668\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 339us/sample - loss: 0.9832\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 287us/sample - loss: 0.9665\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 305us/sample - loss: 0.5604 - acc: 0.8906\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 256us/sample - loss: 0.1399 - acc: 0.9326 - val_loss: 0.1669 - val_acc: 0.9306\n",
      "Epoch 669\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 218us/sample - loss: 1.0076\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 265us/sample - loss: 1.0091\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 299us/sample - loss: 0.5390 - acc: 0.9219\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 230us/sample - loss: 0.1364 - acc: 0.9257 - val_loss: 0.1858 - val_acc: 0.9083\n",
      "Epoch 670\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 251us/sample - loss: 0.9810\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 489us/sample - loss: 0.9696\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 289us/sample - loss: 0.5986 - acc: 0.8750\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 253us/sample - loss: 0.1579 - acc: 0.9215 - val_loss: 0.1787 - val_acc: 0.9056\n",
      "Epoch 671\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 274us/sample - loss: 1.0648\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 274us/sample - loss: 1.0674\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 316us/sample - loss: 0.4694 - acc: 0.9219\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 260us/sample - loss: 0.1485 - acc: 0.9181 - val_loss: 0.1763 - val_acc: 0.9167\n",
      "Epoch 672\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 344us/sample - loss: 1.0202\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 276us/sample - loss: 1.0150\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 346us/sample - loss: 0.4887 - acc: 0.9375\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 266us/sample - loss: 0.1503 - acc: 0.9201 - val_loss: 0.1502 - val_acc: 0.9361\n",
      "Epoch 673\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 263us/sample - loss: 1.0613\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 344us/sample - loss: 1.0547\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 377us/sample - loss: 0.4405 - acc: 0.9688\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 255us/sample - loss: 0.1433 - acc: 0.9299 - val_loss: 0.1530 - val_acc: 0.9306\n",
      "Epoch 674\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 200us/sample - loss: 1.1174\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 296us/sample - loss: 1.1164\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 373us/sample - loss: 0.4826 - acc: 0.9375\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 256us/sample - loss: 0.1463 - acc: 0.9271 - val_loss: 0.1788 - val_acc: 0.8861\n",
      "Epoch 675\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 248us/sample - loss: 1.0373\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 226us/sample - loss: 1.0377\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 319us/sample - loss: 0.4532 - acc: 0.9688\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 240us/sample - loss: 0.1551 - acc: 0.9187 - val_loss: 0.1541 - val_acc: 0.9222\n",
      "Epoch 676\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 263us/sample - loss: 1.0210\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 322us/sample - loss: 1.0185\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 355us/sample - loss: 0.5386 - acc: 0.8750\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 236us/sample - loss: 0.1371 - acc: 0.9299 - val_loss: 0.1530 - val_acc: 0.9194\n",
      "Epoch 677\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 262us/sample - loss: 0.9968\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 347us/sample - loss: 0.9915\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 301us/sample - loss: 0.5209 - acc: 0.9531\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 240us/sample - loss: 0.1497 - acc: 0.9208 - val_loss: 0.1733 - val_acc: 0.8861\n",
      "Epoch 678\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 196us/sample - loss: 1.1218\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 249us/sample - loss: 1.1073\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 273us/sample - loss: 0.4408 - acc: 0.9531\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 248us/sample - loss: 0.1430 - acc: 0.9278 - val_loss: 0.1609 - val_acc: 0.9278\n",
      "Epoch 679\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 253us/sample - loss: 1.0037\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 341us/sample - loss: 1.0062\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 321us/sample - loss: 0.5050 - acc: 0.9531\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 250us/sample - loss: 0.1404 - acc: 0.9264 - val_loss: 0.1679 - val_acc: 0.8861\n",
      "Epoch 680\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 308us/sample - loss: 1.0439\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 330us/sample - loss: 1.0406\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 437us/sample - loss: 0.4713 - acc: 0.9531\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 260us/sample - loss: 0.1429 - acc: 0.9340 - val_loss: 0.1682 - val_acc: 0.8861\n",
      "Epoch 681\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 229us/sample - loss: 0.9964\n",
      "Epoch 2/2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64/64 [==============================] - 0s 271us/sample - loss: 0.9937\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 227us/sample - loss: 0.4874 - acc: 0.9531\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 220us/sample - loss: 0.1466 - acc: 0.9229 - val_loss: 0.1539 - val_acc: 0.9333\n",
      "Epoch 682\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 354us/sample - loss: 0.9789\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 403us/sample - loss: 0.9718\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 325us/sample - loss: 0.5280 - acc: 0.8750\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 278us/sample - loss: 0.1534 - acc: 0.9215 - val_loss: 0.1615 - val_acc: 0.9333\n",
      "Epoch 683\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 222us/sample - loss: 1.0733\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 272us/sample - loss: 1.0445\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 289us/sample - loss: 0.4563 - acc: 0.9688\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 254us/sample - loss: 0.1393 - acc: 0.9312 - val_loss: 0.1544 - val_acc: 0.9167\n",
      "Epoch 684\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 210us/sample - loss: 1.0127\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 292us/sample - loss: 1.0069\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 449us/sample - loss: 0.4794 - acc: 0.9375\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 254us/sample - loss: 0.1442 - acc: 0.9201 - val_loss: 0.1512 - val_acc: 0.9389\n",
      "Epoch 685\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 257us/sample - loss: 0.9863\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 278us/sample - loss: 0.9849\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 369us/sample - loss: 0.5493 - acc: 0.8594\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 255us/sample - loss: 0.1491 - acc: 0.9278 - val_loss: 0.1549 - val_acc: 0.9111\n",
      "Epoch 686\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 291us/sample - loss: 1.0366\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 316us/sample - loss: 1.0232\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 313us/sample - loss: 0.5097 - acc: 0.9688\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 248us/sample - loss: 0.1602 - acc: 0.9118 - val_loss: 0.1580 - val_acc: 0.9028\n",
      "Epoch 687\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 330us/sample - loss: 1.0992\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 327us/sample - loss: 1.0969\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 297us/sample - loss: 0.4424 - acc: 0.9375\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 237us/sample - loss: 0.1346 - acc: 0.9333 - val_loss: 0.1552 - val_acc: 0.9389\n",
      "Epoch 688\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 330us/sample - loss: 1.0484\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 290us/sample - loss: 1.0437\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 338us/sample - loss: 0.4912 - acc: 0.9219\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 248us/sample - loss: 0.1405 - acc: 0.9257 - val_loss: 0.1518 - val_acc: 0.9361\n",
      "Epoch 689\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 264us/sample - loss: 1.0379\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 340us/sample - loss: 1.0157\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 296us/sample - loss: 0.4910 - acc: 0.9219\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 263us/sample - loss: 0.1376 - acc: 0.9312 - val_loss: 0.1576 - val_acc: 0.9333\n",
      "Epoch 690\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 223us/sample - loss: 1.0409\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 263us/sample - loss: 1.0431\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 249us/sample - loss: 0.4950 - acc: 0.9688\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 260us/sample - loss: 0.1448 - acc: 0.9264 - val_loss: 0.1885 - val_acc: 0.9333\n",
      "Epoch 691\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 281us/sample - loss: 1.0050\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 315us/sample - loss: 0.9986\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 352us/sample - loss: 0.5257 - acc: 0.8750\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 241us/sample - loss: 0.1398 - acc: 0.9292 - val_loss: 0.1711 - val_acc: 0.9028\n",
      "Epoch 692\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 270us/sample - loss: 1.0167\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 256us/sample - loss: 1.0095\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 299us/sample - loss: 0.4918 - acc: 0.9375\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 241us/sample - loss: 0.1446 - acc: 0.9285 - val_loss: 0.1489 - val_acc: 0.9361\n",
      "Epoch 693\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 243us/sample - loss: 1.1693\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 272us/sample - loss: 1.1625\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 356us/sample - loss: 0.4444 - acc: 0.9688\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 211us/sample - loss: 0.1396 - acc: 0.9292 - val_loss: 0.1726 - val_acc: 0.9167\n",
      "Epoch 694\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 268us/sample - loss: 1.0919\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 369us/sample - loss: 1.0888\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 281us/sample - loss: 0.4642 - acc: 0.9688\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 249us/sample - loss: 0.1382 - acc: 0.9299 - val_loss: 0.1661 - val_acc: 0.9306\n",
      "Epoch 695\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 245us/sample - loss: 1.0231\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 196us/sample - loss: 1.0162\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 279us/sample - loss: 0.5006 - acc: 0.9531\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 229us/sample - loss: 0.1324 - acc: 0.9368 - val_loss: 0.1553 - val_acc: 0.9417\n",
      "Epoch 696\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 187us/sample - loss: 1.0284\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 180us/sample - loss: 1.0279\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 266us/sample - loss: 0.4898 - acc: 0.9375\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 236us/sample - loss: 0.1372 - acc: 0.9271 - val_loss: 0.1485 - val_acc: 0.9361\n",
      "Epoch 697\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 283us/sample - loss: 1.0167\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 371us/sample - loss: 1.0111\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 266us/sample - loss: 0.5094 - acc: 0.9219\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 273us/sample - loss: 0.1415 - acc: 0.9299 - val_loss: 0.1585 - val_acc: 0.9250\n",
      "Epoch 698\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 318us/sample - loss: 1.0094\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 412us/sample - loss: 1.0038\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 229us/sample - loss: 0.4956 - acc: 0.9219\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 235us/sample - loss: 0.1584 - acc: 0.9153 - val_loss: 0.1671 - val_acc: 0.9000\n",
      "Epoch 699\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 367us/sample - loss: 1.0054\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 357us/sample - loss: 1.0022\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 209us/sample - loss: 0.4963 - acc: 0.8750\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 256us/sample - loss: 0.1447 - acc: 0.9229 - val_loss: 0.1500 - val_acc: 0.9389\n",
      "Epoch 700\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 402us/sample - loss: 0.9865\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 336us/sample - loss: 0.9785\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 240us/sample - loss: 0.5408 - acc: 0.8906\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 253us/sample - loss: 0.1391 - acc: 0.9382 - val_loss: 0.1631 - val_acc: 0.8944\n",
      "Epoch 701\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 267us/sample - loss: 1.0584\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 340us/sample - loss: 1.0492\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 320us/sample - loss: 0.4613 - acc: 0.9219\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 247us/sample - loss: 0.1482 - acc: 0.9243 - val_loss: 0.1874 - val_acc: 0.8889\n",
      "Epoch 702\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 301us/sample - loss: 0.9726\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 231us/sample - loss: 0.9694\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 381us/sample - loss: 0.5257 - acc: 0.9219\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 246us/sample - loss: 0.1501 - acc: 0.9250 - val_loss: 0.1785 - val_acc: 0.9167\n",
      "Epoch 703\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 235us/sample - loss: 0.9981\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 258us/sample - loss: 0.9971\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 282us/sample - loss: 0.5053 - acc: 0.9062\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 239us/sample - loss: 0.1496 - acc: 0.9208 - val_loss: 0.3581 - val_acc: 0.9000\n",
      "Epoch 704\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 332us/sample - loss: 0.9196\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 189us/sample - loss: 0.9146\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 185us/sample - loss: 0.6018 - acc: 0.8750\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 250us/sample - loss: 0.1609 - acc: 0.9215 - val_loss: 0.1765 - val_acc: 0.8917\n",
      "Epoch 705\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 429us/sample - loss: 1.1143\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 258us/sample - loss: 1.0835\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 301us/sample - loss: 0.4980 - acc: 0.8906\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 233us/sample - loss: 0.1530 - acc: 0.9264 - val_loss: 0.1958 - val_acc: 0.9056\n",
      "Epoch 706\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 301us/sample - loss: 1.0165\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 282us/sample - loss: 1.0189\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 309us/sample - loss: 0.5125 - acc: 0.9219\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 203us/sample - loss: 0.1680 - acc: 0.9146 - val_loss: 0.2230 - val_acc: 0.9111\n",
      "Epoch 707\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 177us/sample - loss: 0.9482\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 283us/sample - loss: 0.9495\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 319us/sample - loss: 0.5557 - acc: 0.8594\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 282us/sample - loss: 0.1439 - acc: 0.9319 - val_loss: 0.1820 - val_acc: 0.9306\n",
      "Epoch 708\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 257us/sample - loss: 1.0319\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 267us/sample - loss: 1.0287\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 335us/sample - loss: 0.5046 - acc: 0.9375\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 242us/sample - loss: 0.1574 - acc: 0.9153 - val_loss: 0.1513 - val_acc: 0.9389\n",
      "Epoch 709\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 291us/sample - loss: 0.9694\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 281us/sample - loss: 0.9608\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 336us/sample - loss: 0.4993 - acc: 0.9062\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 256us/sample - loss: 0.1602 - acc: 0.9160 - val_loss: 0.1912 - val_acc: 0.9111\n",
      "Epoch 710\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 195us/sample - loss: 1.0112\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 255us/sample - loss: 1.0022\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 299us/sample - loss: 0.4971 - acc: 0.9219\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 235us/sample - loss: 0.1717 - acc: 0.9132 - val_loss: 0.1693 - val_acc: 0.8944\n",
      "Epoch 711\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 272us/sample - loss: 1.0878\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 279us/sample - loss: 1.0918\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 347us/sample - loss: 0.4353 - acc: 0.9375\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 253us/sample - loss: 0.1438 - acc: 0.9285 - val_loss: 0.1578 - val_acc: 0.9389\n",
      "Epoch 712\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 341us/sample - loss: 0.9380\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 276us/sample - loss: 0.9362\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 397us/sample - loss: 0.5431 - acc: 0.9062\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 239us/sample - loss: 0.1443 - acc: 0.9222 - val_loss: 0.1863 - val_acc: 0.8833\n",
      "Epoch 713\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 291us/sample - loss: 1.0265\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 392us/sample - loss: 1.0273\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 222us/sample - loss: 0.4747 - acc: 0.9531\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - ETA: 0s - loss: 0.1652 - acc: 0.916 - 0s 245us/sample - loss: 0.1638 - acc: 0.9187 - val_loss: 0.1694 - val_acc: 0.9250\n",
      "Epoch 714\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 379us/sample - loss: 0.9876\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 385us/sample - loss: 0.9855\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 270us/sample - loss: 0.4794 - acc: 0.9531\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 221us/sample - loss: 0.1374 - acc: 0.9306 - val_loss: 0.2116 - val_acc: 0.8944\n",
      "Epoch 715\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 241us/sample - loss: 1.1269\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 273us/sample - loss: 1.1055\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 258us/sample - loss: 0.4174 - acc: 0.9844\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 251us/sample - loss: 0.1354 - acc: 0.9292 - val_loss: 0.1539 - val_acc: 0.9306\n",
      "Epoch 716\n",
      "Fitting GAN\n",
      "Epoch 1/2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64/64 [==============================] - 0s 264us/sample - loss: 0.9826\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 384us/sample - loss: 0.9907\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 317us/sample - loss: 0.5468 - acc: 0.9219\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 239us/sample - loss: 0.1308 - acc: 0.9292 - val_loss: 0.1807 - val_acc: 0.9139\n",
      "Epoch 717\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 334us/sample - loss: 0.9248\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 323us/sample - loss: 0.9226\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 309us/sample - loss: 0.5703 - acc: 0.8906\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 273us/sample - loss: 0.1318 - acc: 0.9347 - val_loss: 0.2171 - val_acc: 0.8889\n",
      "Epoch 718\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 232us/sample - loss: 1.0842\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 300us/sample - loss: 1.0781\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 228us/sample - loss: 0.4774 - acc: 0.9375\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 261us/sample - loss: 0.1520 - acc: 0.9250 - val_loss: 0.1606 - val_acc: 0.8944\n",
      "Epoch 719\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 282us/sample - loss: 1.1134\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 341us/sample - loss: 1.1135\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 320us/sample - loss: 0.4082 - acc: 0.9844\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 247us/sample - loss: 0.1429 - acc: 0.9285 - val_loss: 0.1487 - val_acc: 0.9333\n",
      "Epoch 720\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 197us/sample - loss: 1.0151\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 340us/sample - loss: 1.0087\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 332us/sample - loss: 0.4839 - acc: 0.9219\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 238us/sample - loss: 0.1568 - acc: 0.9194 - val_loss: 0.1858 - val_acc: 0.9111\n",
      "Epoch 721\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 220us/sample - loss: 1.0103\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 296us/sample - loss: 0.9995\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 289us/sample - loss: 0.5423 - acc: 0.9062\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 249us/sample - loss: 0.1520 - acc: 0.9250 - val_loss: 0.1681 - val_acc: 0.9056\n",
      "Epoch 722\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 516us/sample - loss: 1.1123\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 269us/sample - loss: 1.0989\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 334us/sample - loss: 0.4654 - acc: 0.9219\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 243us/sample - loss: 0.1392 - acc: 0.9236 - val_loss: 0.2285 - val_acc: 0.9000\n",
      "Epoch 723\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 305us/sample - loss: 0.9181\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 393us/sample - loss: 0.9125\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 287us/sample - loss: 0.6179 - acc: 0.8438\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 283us/sample - loss: 0.1422 - acc: 0.9292 - val_loss: 0.1491 - val_acc: 0.9417\n",
      "Epoch 724\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 278us/sample - loss: 0.9957\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 292us/sample - loss: 0.9816\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 355us/sample - loss: 0.5349 - acc: 0.8750\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 255us/sample - loss: 0.1460 - acc: 0.9292 - val_loss: 0.1959 - val_acc: 0.9111\n",
      "Epoch 725\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 229us/sample - loss: 1.0727\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 273us/sample - loss: 1.0739\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 322us/sample - loss: 0.4311 - acc: 0.9844\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 275us/sample - loss: 0.1517 - acc: 0.9236 - val_loss: 0.1807 - val_acc: 0.9167\n",
      "Epoch 726\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 270us/sample - loss: 0.9725\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 273us/sample - loss: 0.9711\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 288us/sample - loss: 0.4982 - acc: 0.9531\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 235us/sample - loss: 0.1342 - acc: 0.9340 - val_loss: 0.1815 - val_acc: 0.9139\n",
      "Epoch 727\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 264us/sample - loss: 1.1066\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 314us/sample - loss: 1.0974\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 357us/sample - loss: 0.4616 - acc: 0.9219\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 240us/sample - loss: 0.1432 - acc: 0.9271 - val_loss: 0.1707 - val_acc: 0.9194\n",
      "Epoch 728\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 311us/sample - loss: 0.9841\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 331us/sample - loss: 0.9789\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 387us/sample - loss: 0.5240 - acc: 0.9219\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 233us/sample - loss: 0.1412 - acc: 0.9326 - val_loss: 0.1515 - val_acc: 0.9333\n",
      "Epoch 729\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 265us/sample - loss: 0.9756\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 371us/sample - loss: 0.9679\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 325us/sample - loss: 0.5054 - acc: 0.9531\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 264us/sample - loss: 0.1464 - acc: 0.9215 - val_loss: 0.1663 - val_acc: 0.9028\n",
      "Epoch 730\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 191us/sample - loss: 1.0645\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 256us/sample - loss: 1.0603\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 330us/sample - loss: 0.4672 - acc: 0.9062\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 248us/sample - loss: 0.1397 - acc: 0.9264 - val_loss: 0.1795 - val_acc: 0.9000\n",
      "Epoch 731\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 271us/sample - loss: 0.9060\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 308us/sample - loss: 0.9023\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 242us/sample - loss: 0.5900 - acc: 0.8438\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 254us/sample - loss: 0.1411 - acc: 0.9326 - val_loss: 0.1553 - val_acc: 0.9306\n",
      "Epoch 732\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 272us/sample - loss: 1.1076\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 294us/sample - loss: 1.1090\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 263us/sample - loss: 0.4477 - acc: 0.9375\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 270us/sample - loss: 0.1566 - acc: 0.9215 - val_loss: 0.1884 - val_acc: 0.8944\n",
      "Epoch 733\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 233us/sample - loss: 1.0570\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 252us/sample - loss: 1.0542\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 226us/sample - loss: 0.4648 - acc: 0.9062\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 265us/sample - loss: 0.1409 - acc: 0.9292 - val_loss: 0.1808 - val_acc: 0.9167\n",
      "Epoch 734\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 280us/sample - loss: 0.9707\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 314us/sample - loss: 0.9519\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 278us/sample - loss: 0.5523 - acc: 0.8750\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 239us/sample - loss: 0.1439 - acc: 0.9285 - val_loss: 0.1632 - val_acc: 0.9306\n",
      "Epoch 735\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 228us/sample - loss: 1.0103\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 248us/sample - loss: 0.9985\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 312us/sample - loss: 0.5549 - acc: 0.8906\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 264us/sample - loss: 0.1438 - acc: 0.9271 - val_loss: 0.1765 - val_acc: 0.9139\n",
      "Epoch 736\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 309us/sample - loss: 0.9600\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 208us/sample - loss: 0.9624\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 217us/sample - loss: 0.5695 - acc: 0.8750\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 235us/sample - loss: 0.1412 - acc: 0.9326 - val_loss: 0.1513 - val_acc: 0.9250\n",
      "Epoch 737\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 258us/sample - loss: 0.9630\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 279us/sample - loss: 0.9568\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 553us/sample - loss: 0.5168 - acc: 0.9219\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 248us/sample - loss: 0.1448 - acc: 0.9243 - val_loss: 0.1771 - val_acc: 0.9250\n",
      "Epoch 738\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 206us/sample - loss: 1.0345\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 376us/sample - loss: 1.0257\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 227us/sample - loss: 0.4823 - acc: 0.9531\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 247us/sample - loss: 0.1448 - acc: 0.9271 - val_loss: 0.1626 - val_acc: 0.9111\n",
      "Epoch 739\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 197us/sample - loss: 1.2520\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 205us/sample - loss: 1.2448\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 259us/sample - loss: 0.4752 - acc: 0.9531\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 275us/sample - loss: 0.1453 - acc: 0.9271 - val_loss: 0.2150 - val_acc: 0.9139\n",
      "Epoch 740\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 211us/sample - loss: 0.8786\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 370us/sample - loss: 0.8750\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 335us/sample - loss: 0.6142 - acc: 0.7969\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 213us/sample - loss: 0.1571 - acc: 0.9208 - val_loss: 0.2104 - val_acc: 0.9028\n",
      "Epoch 741\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 199us/sample - loss: 0.9996\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 609us/sample - loss: 0.9837\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 416us/sample - loss: 0.5262 - acc: 0.9219\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 259us/sample - loss: 0.1403 - acc: 0.9312 - val_loss: 0.1700 - val_acc: 0.9000\n",
      "Epoch 742\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 356us/sample - loss: 1.0533\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 307us/sample - loss: 1.0297\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 349us/sample - loss: 0.4699 - acc: 0.9219\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 241us/sample - loss: 0.1542 - acc: 0.9236 - val_loss: 0.1738 - val_acc: 0.9167\n",
      "Epoch 743\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 282us/sample - loss: 1.0145\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 278us/sample - loss: 1.0004\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 338us/sample - loss: 0.5256 - acc: 0.9062\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 266us/sample - loss: 0.1500 - acc: 0.9222 - val_loss: 0.1718 - val_acc: 0.9306\n",
      "Epoch 744\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 242us/sample - loss: 1.0161\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 286us/sample - loss: 1.0155\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 341us/sample - loss: 0.5051 - acc: 0.9531\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 248us/sample - loss: 0.1532 - acc: 0.9243 - val_loss: 0.1738 - val_acc: 0.8972\n",
      "Epoch 745\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 198us/sample - loss: 1.0855\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 318us/sample - loss: 1.0843\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 255us/sample - loss: 0.4591 - acc: 0.9375\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 275us/sample - loss: 0.1539 - acc: 0.9201 - val_loss: 0.1723 - val_acc: 0.9028\n",
      "Epoch 746\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 236us/sample - loss: 1.0390\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 280us/sample - loss: 1.0318\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 366us/sample - loss: 0.5022 - acc: 0.9062\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 238us/sample - loss: 0.1457 - acc: 0.9236 - val_loss: 0.1513 - val_acc: 0.9278\n",
      "Epoch 747\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 205us/sample - loss: 1.0074\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 241us/sample - loss: 0.9947\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 236us/sample - loss: 0.5311 - acc: 0.8750\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 253us/sample - loss: 0.1461 - acc: 0.9208 - val_loss: 0.1660 - val_acc: 0.9278\n",
      "Epoch 748\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 266us/sample - loss: 0.9983\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 430us/sample - loss: 0.9947\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 278us/sample - loss: 0.4941 - acc: 0.9531\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 247us/sample - loss: 0.1450 - acc: 0.9222 - val_loss: 0.1577 - val_acc: 0.9389\n",
      "Epoch 749\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 264us/sample - loss: 1.0419\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 374us/sample - loss: 1.0375\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 281us/sample - loss: 0.5012 - acc: 0.9375\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 231us/sample - loss: 0.1395 - acc: 0.9285 - val_loss: 0.1744 - val_acc: 0.9194\n",
      "Epoch 750\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 248us/sample - loss: 1.0270\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 279us/sample - loss: 1.0181\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 278us/sample - loss: 0.4598 - acc: 0.9844\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 257us/sample - loss: 0.1392 - acc: 0.9333 - val_loss: 0.1627 - val_acc: 0.9278\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 751\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 200us/sample - loss: 0.9516\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 173us/sample - loss: 0.9527\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 310us/sample - loss: 0.5701 - acc: 0.8594\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 252us/sample - loss: 0.1609 - acc: 0.9222 - val_loss: 0.2007 - val_acc: 0.8778\n",
      "Epoch 752\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 531us/sample - loss: 1.0173\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 282us/sample - loss: 1.0127\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 266us/sample - loss: 0.5184 - acc: 0.9219\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 239us/sample - loss: 0.1493 - acc: 0.9292 - val_loss: 0.1580 - val_acc: 0.9083\n",
      "Epoch 753\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 428us/sample - loss: 1.0481\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 335us/sample - loss: 1.0460\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 249us/sample - loss: 0.4880 - acc: 0.9219\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 247us/sample - loss: 0.1473 - acc: 0.9250 - val_loss: 0.1591 - val_acc: 0.9333\n",
      "Epoch 754\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 239us/sample - loss: 1.0271\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 366us/sample - loss: 1.0227\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 501us/sample - loss: 0.4659 - acc: 0.9531\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 261us/sample - loss: 0.1432 - acc: 0.9285 - val_loss: 0.1570 - val_acc: 0.9333\n",
      "Epoch 755\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 291us/sample - loss: 0.8916\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 426us/sample - loss: 0.8896\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 280us/sample - loss: 0.6266 - acc: 0.8281\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 246us/sample - loss: 0.1395 - acc: 0.9299 - val_loss: 0.2381 - val_acc: 0.8861\n",
      "Epoch 756\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 861us/sample - loss: 1.0918\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 266us/sample - loss: 1.0858\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 342us/sample - loss: 0.4302 - acc: 0.9844\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 235us/sample - loss: 0.1447 - acc: 0.9236 - val_loss: 0.1831 - val_acc: 0.8861\n",
      "Epoch 757\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 275us/sample - loss: 1.0936\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 321us/sample - loss: 1.0900\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 300us/sample - loss: 0.5087 - acc: 0.9219\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 247us/sample - loss: 0.1413 - acc: 0.9319 - val_loss: 0.1553 - val_acc: 0.9194\n",
      "Epoch 758\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 203us/sample - loss: 1.1311\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 314us/sample - loss: 1.1176\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 305us/sample - loss: 0.4338 - acc: 0.9375\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 274us/sample - loss: 0.1355 - acc: 0.9306 - val_loss: 0.1782 - val_acc: 0.9056\n",
      "Epoch 759\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 286us/sample - loss: 0.9384\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 310us/sample - loss: 0.9444\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 326us/sample - loss: 0.5555 - acc: 0.8750\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 230us/sample - loss: 0.1463 - acc: 0.9250 - val_loss: 0.1629 - val_acc: 0.9222\n",
      "Epoch 760\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 296us/sample - loss: 1.0232\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 260us/sample - loss: 1.0236\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 392us/sample - loss: 0.4833 - acc: 0.9375\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 267us/sample - loss: 0.1405 - acc: 0.9264 - val_loss: 0.1673 - val_acc: 0.8972\n",
      "Epoch 761\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 288us/sample - loss: 1.1459\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 268us/sample - loss: 1.1361\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 199us/sample - loss: 0.4503 - acc: 0.9531\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - ETA: 0s - loss: 0.1500 - acc: 0.927 - 0s 247us/sample - loss: 0.1464 - acc: 0.9285 - val_loss: 0.1569 - val_acc: 0.9278\n",
      "Epoch 762\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 271us/sample - loss: 1.0081\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 272us/sample - loss: 1.0062\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 281us/sample - loss: 0.4848 - acc: 0.9375\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 237us/sample - loss: 0.1528 - acc: 0.9174 - val_loss: 0.1842 - val_acc: 0.8806\n",
      "Epoch 763\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 268us/sample - loss: 1.0517\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 327us/sample - loss: 1.0507\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 265us/sample - loss: 0.4494 - acc: 0.9531\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 252us/sample - loss: 0.1479 - acc: 0.9222 - val_loss: 0.1557 - val_acc: 0.9250\n",
      "Epoch 764\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 307us/sample - loss: 0.9754\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 315us/sample - loss: 0.9732\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 331us/sample - loss: 0.4950 - acc: 0.9375\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 247us/sample - loss: 0.1370 - acc: 0.9326 - val_loss: 0.1650 - val_acc: 0.9194\n",
      "Epoch 765\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 216us/sample - loss: 1.0795\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 250us/sample - loss: 1.0732\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 351us/sample - loss: 0.4439 - acc: 0.9219\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 258us/sample - loss: 0.1408 - acc: 0.9285 - val_loss: 0.1508 - val_acc: 0.9361\n",
      "Epoch 766\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 304us/sample - loss: 0.9153\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 314us/sample - loss: 0.9105\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 385us/sample - loss: 0.5529 - acc: 0.8750\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 271us/sample - loss: 0.1349 - acc: 0.9306 - val_loss: 0.1651 - val_acc: 0.9333\n",
      "Epoch 767\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 265us/sample - loss: 1.0437\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 294us/sample - loss: 1.0357\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 232us/sample - loss: 0.5225 - acc: 0.9375\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 245us/sample - loss: 0.1487 - acc: 0.9278 - val_loss: 0.2040 - val_acc: 0.8722\n",
      "Epoch 768\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 232us/sample - loss: 1.0261\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 334us/sample - loss: 1.0237\n",
      "Fitting discriminator\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64/64 [==============================] - 0s 262us/sample - loss: 0.5003 - acc: 0.8906\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 249us/sample - loss: 0.1530 - acc: 0.9243 - val_loss: 0.1628 - val_acc: 0.9333\n",
      "Epoch 769\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 305us/sample - loss: 1.0149\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 339us/sample - loss: 1.0130\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 314us/sample - loss: 0.4818 - acc: 0.9688\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 222us/sample - loss: 0.1400 - acc: 0.9319 - val_loss: 0.1619 - val_acc: 0.9167\n",
      "Epoch 770\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 183us/sample - loss: 1.0154\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 256us/sample - loss: 1.0130\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 298us/sample - loss: 0.5040 - acc: 0.8906\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 250us/sample - loss: 0.1461 - acc: 0.9347 - val_loss: 0.1503 - val_acc: 0.9361\n",
      "Epoch 771\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 351us/sample - loss: 0.9098\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 387us/sample - loss: 0.9079\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 299us/sample - loss: 0.5708 - acc: 0.8438\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 240us/sample - loss: 0.1370 - acc: 0.9299 - val_loss: 0.1503 - val_acc: 0.9361\n",
      "Epoch 772\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 289us/sample - loss: 1.0216\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 369us/sample - loss: 1.0181\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 599us/sample - loss: 0.4974 - acc: 0.8906\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 280us/sample - loss: 0.1553 - acc: 0.9229 - val_loss: 0.2089 - val_acc: 0.8833\n",
      "Epoch 773\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 329us/sample - loss: 0.9928\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 309us/sample - loss: 0.9910\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 353us/sample - loss: 0.5218 - acc: 0.9219\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 254us/sample - loss: 0.1539 - acc: 0.9181 - val_loss: 0.1795 - val_acc: 0.9083\n",
      "Epoch 774\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 154us/sample - loss: 0.9803\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 241us/sample - loss: 0.9663\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 381us/sample - loss: 0.5321 - acc: 0.8750\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 251us/sample - loss: 0.1663 - acc: 0.9125 - val_loss: 0.1856 - val_acc: 0.8972\n",
      "Epoch 775\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 230us/sample - loss: 1.2767\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 255us/sample - loss: 1.2677\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 376us/sample - loss: 0.4263 - acc: 0.9688\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 253us/sample - loss: 0.1519 - acc: 0.9250 - val_loss: 0.1712 - val_acc: 0.9167\n",
      "Epoch 776\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 219us/sample - loss: 0.9915\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 348us/sample - loss: 0.9707\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 288us/sample - loss: 0.5580 - acc: 0.7969\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 234us/sample - loss: 0.1481 - acc: 0.9229 - val_loss: 0.1914 - val_acc: 0.9139\n",
      "Epoch 777\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 231us/sample - loss: 0.9637\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 209us/sample - loss: 0.9532\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 298us/sample - loss: 0.5366 - acc: 0.9062\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 226us/sample - loss: 0.1541 - acc: 0.9222 - val_loss: 0.1690 - val_acc: 0.9194\n",
      "Epoch 778\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 240us/sample - loss: 1.0190\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 299us/sample - loss: 1.0155\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 378us/sample - loss: 0.4942 - acc: 0.9219\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 215us/sample - loss: 0.1470 - acc: 0.9167 - val_loss: 0.1689 - val_acc: 0.9250\n",
      "Epoch 779\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 249us/sample - loss: 0.9831\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 256us/sample - loss: 0.9778\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 321us/sample - loss: 0.4864 - acc: 0.9688\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 273us/sample - loss: 0.1583 - acc: 0.9250 - val_loss: 0.1886 - val_acc: 0.9250\n",
      "Epoch 780\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 206us/sample - loss: 0.9959\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 240us/sample - loss: 0.9924\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 332us/sample - loss: 0.5375 - acc: 0.9219\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 271us/sample - loss: 0.1374 - acc: 0.9333 - val_loss: 0.1524 - val_acc: 0.9222\n",
      "Epoch 781\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 225us/sample - loss: 1.0562\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 262us/sample - loss: 1.0551\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 246us/sample - loss: 0.4828 - acc: 0.9375\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 239us/sample - loss: 0.1408 - acc: 0.9292 - val_loss: 0.1558 - val_acc: 0.9056\n",
      "Epoch 782\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 583us/sample - loss: 0.9189\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 303us/sample - loss: 0.9076\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 394us/sample - loss: 0.5690 - acc: 0.8594\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 232us/sample - loss: 0.1382 - acc: 0.9340 - val_loss: 0.1681 - val_acc: 0.9222\n",
      "Epoch 783\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 248us/sample - loss: 1.0073\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 292us/sample - loss: 1.0060\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 283us/sample - loss: 0.5133 - acc: 0.9375\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 213us/sample - loss: 0.1331 - acc: 0.9326 - val_loss: 0.1938 - val_acc: 0.9028\n",
      "Epoch 784\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 244us/sample - loss: 0.8669\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 274us/sample - loss: 0.8650\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 198us/sample - loss: 0.6248 - acc: 0.8594\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 229us/sample - loss: 0.1417 - acc: 0.9292 - val_loss: 0.1691 - val_acc: 0.9028\n",
      "Epoch 785\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 254us/sample - loss: 1.0728\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 245us/sample - loss: 1.0698\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 324us/sample - loss: 0.4390 - acc: 0.9219\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 229us/sample - loss: 0.1532 - acc: 0.9187 - val_loss: 0.1581 - val_acc: 0.9222\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 786\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 230us/sample - loss: 1.0120\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 187us/sample - loss: 1.0105\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 275us/sample - loss: 0.5362 - acc: 0.8750\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 225us/sample - loss: 0.1412 - acc: 0.9306 - val_loss: 0.1659 - val_acc: 0.9278\n",
      "Epoch 787\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 304us/sample - loss: 1.0303\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 260us/sample - loss: 1.0269\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 312us/sample - loss: 0.4669 - acc: 0.9688\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 222us/sample - loss: 0.1369 - acc: 0.9257 - val_loss: 0.1510 - val_acc: 0.9222\n",
      "Epoch 788\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 300us/sample - loss: 1.0004\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 238us/sample - loss: 0.9947\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 325us/sample - loss: 0.4800 - acc: 0.9531\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 218us/sample - loss: 0.1354 - acc: 0.9299 - val_loss: 0.1497 - val_acc: 0.9361\n",
      "Epoch 789\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 312us/sample - loss: 0.9491\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 243us/sample - loss: 0.9495\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 285us/sample - loss: 0.5108 - acc: 0.9219\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 235us/sample - loss: 0.1434 - acc: 0.9257 - val_loss: 0.1490 - val_acc: 0.9361\n",
      "Epoch 790\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 231us/sample - loss: 0.9729\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 320us/sample - loss: 0.9705\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 419us/sample - loss: 0.5363 - acc: 0.9219\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 235us/sample - loss: 0.1521 - acc: 0.9271 - val_loss: 0.1765 - val_acc: 0.9083\n",
      "Epoch 791\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 418us/sample - loss: 0.9777\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 341us/sample - loss: 0.9768\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - ETA: 0s - loss: 0.4775 - acc: 0.937 - 0s 243us/sample - loss: 0.5169 - acc: 0.9219\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 236us/sample - loss: 0.1426 - acc: 0.9285 - val_loss: 0.1588 - val_acc: 0.9056\n",
      "Epoch 792\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 349us/sample - loss: 1.2530\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 360us/sample - loss: 1.2399\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 361us/sample - loss: 0.4743 - acc: 0.9375\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 281us/sample - loss: 0.1396 - acc: 0.9312 - val_loss: 0.1509 - val_acc: 0.9361\n",
      "Epoch 793\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 342us/sample - loss: 0.9976\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 281us/sample - loss: 0.9979\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 349us/sample - loss: 0.5324 - acc: 0.8906\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 262us/sample - loss: 0.1438 - acc: 0.9243 - val_loss: 0.1520 - val_acc: 0.9250\n",
      "Epoch 794\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 3ms/sample - loss: 0.9873\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 173us/sample - loss: 0.9858\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 189us/sample - loss: 0.4984 - acc: 0.9375\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 250us/sample - loss: 0.1365 - acc: 0.9340 - val_loss: 0.1539 - val_acc: 0.9278\n",
      "Epoch 795\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 312us/sample - loss: 1.0048\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 258us/sample - loss: 0.9991\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 403us/sample - loss: 0.4950 - acc: 0.8750\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 236us/sample - loss: 0.1511 - acc: 0.9160 - val_loss: 0.1742 - val_acc: 0.8889\n",
      "Epoch 796\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 306us/sample - loss: 1.0095\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 372us/sample - loss: 1.0049\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 283us/sample - loss: 0.5013 - acc: 0.9219\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 235us/sample - loss: 0.1576 - acc: 0.9215 - val_loss: 0.1771 - val_acc: 0.8833\n",
      "Epoch 797\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 275us/sample - loss: 1.0066\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 334us/sample - loss: 1.0034\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 289us/sample - loss: 0.4868 - acc: 0.9375\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 249us/sample - loss: 0.1454 - acc: 0.9250 - val_loss: 0.1664 - val_acc: 0.9361\n",
      "Epoch 798\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 355us/sample - loss: 1.0021\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 293us/sample - loss: 1.0040\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 358us/sample - loss: 0.4905 - acc: 0.8438\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 270us/sample - loss: 0.1401 - acc: 0.9312 - val_loss: 0.1653 - val_acc: 0.9056\n",
      "Epoch 799\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 222us/sample - loss: 0.9841\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 258us/sample - loss: 0.9726\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 262us/sample - loss: 0.5455 - acc: 0.9062\n",
      "Train on 1440 samples, validate on 360 samples\n",
      "1440/1440 [==============================] - 0s 261us/sample - loss: 0.1451 - acc: 0.9264 - val_loss: 0.1549 - val_acc: 0.9333\n"
     ]
    }
   ],
   "source": [
    "fit_gan(gan, NewData, 800)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "N = 128\n",
    "V = generator.predict(TestData.load_random(n_samples=N))\n",
    "Plot('test').picture(V, discriminator.model.predict(V), alpha=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "gan.save('best_gan.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator.model.save('best_generator.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator.model.save('best_discriminator.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1021 23:20:47.660903 43904 deprecation.py:506] From C:\\Users\\Admin\\.conda\\envs\\neuro\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:97: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "W1021 23:20:47.716973 43904 deprecation.py:506] From C:\\Users\\Admin\\.conda\\envs\\neuro\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:97: calling GlorotUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "W1021 23:20:48.125404 43904 hdf5_format.py:258] Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n"
     ]
    }
   ],
   "source": [
    "d2 = tf.keras.models.load_model('best_discriminator.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "Plot('test2').picture(TestData.x, d2.predict(TestData.x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
