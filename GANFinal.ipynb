{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import imageio\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.layers import Dense, Input, Dropout\n",
    "from tensorflow.keras.models import Sequential, Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Misc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# todo: apply to classes\n",
    "def make_trainable(net, val, lr=0.001):\n",
    "    net.model.trainable = val\n",
    "    for l in net.model.layers:\n",
    "        l.trainable = val\n",
    "    net.cmpile(lr)\n",
    "    \n",
    "def define_gan(generator, discriminator):\n",
    "    # make weights in the discriminator not trainable\n",
    "    discriminator.trainable = False\n",
    "    # connect them\n",
    "    model = Sequential()\n",
    "    # add generator\n",
    "    model.add(generator)\n",
    "    # add the discriminator\n",
    "    model.add(discriminator)\n",
    "    # при замене оптимизатора всё слетает ???\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam')\n",
    "    return model\n",
    "\n",
    "def fit_discriminator(discriminator, Data, epochs, lr=0.001):\n",
    "    make_trainable(discriminator, True, lr=lr)\n",
    "    #discriminator.trainable = True\n",
    "    discriminator.fit(Data.x, Data.y, epochs=epochs, plot=True)\n",
    "    \n",
    "# Training GAN\n",
    "def fit_gan(gan, Data, epochs):\n",
    "    p = Plot('GAN_results')\n",
    "\n",
    "    for i in range(epochs):\n",
    "        V = Data.load_random(n_samples=64)\n",
    "        print(\"Epoch %d\" % i)\n",
    "        generated = generator.predict(V)\n",
    "        if i % 10 == 0:\n",
    "            p.add_to_gif(generated, np.ones(V.shape[0]), title='Epoch %d' % i, alpha=1)\n",
    "        #make_trainable(discriminator, False)\n",
    "        print(\"Fitting GAN\")\n",
    "        gan.fit(V, np.ones(V.shape[0]), epochs=2)\n",
    "        #make_trainable(discriminator, True)\n",
    "        print(\"Fitting discriminator\")\n",
    "        discriminator.fit(generated, np.zeros(V.shape[0]), validation_split=None)\n",
    "        discriminator.fit(Data.x, Data.y, validation_split=0.2)\n",
    "    p.save_gif()\n",
    "    gan.save('gan.h5')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data generation class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To generate data\n",
    "class Dataset():\n",
    "    x = None\n",
    "    y = None\n",
    "    W = None\n",
    "    \n",
    "    def __init__(self):\n",
    "        return\n",
    "    \n",
    "    def load_data(self, data_range=10):\n",
    "        dots_x = []\n",
    "        for i in range(data_range*20):\n",
    "            x = random.uniform(-data_range, data_range)\n",
    "            dots_x.append((x, x**2)) # square\n",
    "            for j in range(5):\n",
    "                dots_x.append((x, random.uniform(-data_range, data_range**2))) # less than square\n",
    "                #dots_x.append((x**r, x**(2*r*(1+random.gauss(0.5, 0.25)/20)))) # more than square\n",
    "        dots_x = np.array(dots_x)\n",
    "        #dots_y = np.array([random.uniform(0.75, 1.2) if x[0]**2 == x[1] else random.uniform(0, 0.3) for x in dots_x])\n",
    "        dots_y = np.array([1 if x[0]**2 == x[1] else 0 for x in dots_x])\n",
    "        self.x, self.y = dots_x, dots_y\n",
    "        return dots_x, dots_y\n",
    "    \n",
    "    def load_weights(self, default_weight=0.12):\n",
    "        W = self.y.copy().astype(float)\n",
    "        W[W == 0] = 0.12\n",
    "        self.W = W\n",
    "        return W\n",
    "        \n",
    "    @staticmethod\n",
    "    def load_random(n_dim=5, n_samples=16):\n",
    "        V = np.random.normal(size=(n_samples, n_dim))\n",
    "        return V\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image plotting class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To plot images\n",
    "class Plot:\n",
    "    name = \"\"\n",
    "    images = []\n",
    "    threshold = 0.0\n",
    "    \n",
    "    def __init__(self, name, threshold=0.6):\n",
    "        self.name = name\n",
    "        self.threshold = threshold\n",
    "        self.images = []\n",
    "    \n",
    "    @staticmethod\n",
    "    def parabola_plot(ax, xrange):\n",
    "        x = np.linspace(xrange, 1)\n",
    "        y = x*x\n",
    "        plt.plot(x, y)\n",
    "    \n",
    "    @staticmethod\n",
    "    def dots_plot(ax, dots_x, dots_y, color):\n",
    "        ax.scatter(dots_x, dots_y, color=color, alpha=0.15)\n",
    "        plt.plot()\n",
    "    \n",
    "    def picture(self, dots, predictions, title='', alpha=0.3):\n",
    "        predictions = predictions.reshape(predictions.shape[0])\n",
    "        dots_x = dots.T[0]\n",
    "        fig = plt.figure()\n",
    "        ax1 = fig.add_subplot(111)\n",
    "        ax1.set(title=title)\n",
    "        #ax2 = ax1.twinx()\n",
    "        plt.grid(axis='both')\n",
    "        xrange = (dots_x.min(), dots_x.max())\n",
    "        self.parabola_plot(ax1, xrange)\n",
    "        ax1.scatter(dots.T[0], dots.T[1], c=predictions, cmap='YlOrRd', alpha=alpha)\n",
    "        \n",
    "    def add_to_gif(self, dots_x, predictions, title='', alpha=0.3):\n",
    "        self.picture(dots_x, predictions, title=title, alpha=alpha)\n",
    "        plt.savefig(self.name+'.png')\n",
    "        plt.close()\n",
    "        image = Image.open(self.name+'.png')\n",
    "        ar = np.asarray(image)\n",
    "        self.images.append(ar)\n",
    "        \n",
    "    def save_gif(self):\n",
    "        kargs = { 'duration': 0.2 }\n",
    "        imageio.mimsave(self.name+'.gif', self.images, None, **kargs)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural networks classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classes for neural networks\n",
    "\n",
    "# Generator\n",
    "class Gen:\n",
    "    model = None\n",
    "    \n",
    "    def __init__(self):\n",
    "        model = Sequential([Dense(15, activation='relu', kernel_initializer='he_uniform', input_dim=5),\n",
    "                            Dense(2, activation='linear')\n",
    "        ])\n",
    "        self.model = model\n",
    "        \n",
    "    def predict(self, dots_x):\n",
    "        return self.model.predict(dots_x)\n",
    "    \n",
    "    def cmpile(self):\n",
    "        return\n",
    "    \n",
    "# Discriminator\n",
    "class Dsc:\n",
    "    model = None\n",
    "    \n",
    "    def __init__(self):\n",
    "        model = Sequential([Dense(25, activation='relu', kernel_initializer='he_uniform', input_dim=2),\n",
    "                            Dense(1, activation='sigmoid')\n",
    "        ])\n",
    "        self.model = model\n",
    "    \n",
    "    def cmpile(self, lr=0.0001):\n",
    "        self.model.compile(loss='binary_crossentropy',\n",
    "                           optimizer=tf.keras.optimizers.Adam(lr),\n",
    "                           metrics=['accuracy'])\n",
    "        \n",
    "    def fit(self, dots_x, dots_y, weights=None, epochs=1, validation_split=0.15, plot=False):\n",
    "        if plot:\n",
    "            img = Plot('discriminator_fit')\n",
    "            for i in range(epochs):\n",
    "                print(\"Epoch %d out of %d\" % (i, epochs))\n",
    "                self.model.fit(dots_x, \n",
    "                               dots_y, \n",
    "                               epochs=10, \n",
    "                               sample_weight=weights,\n",
    "                               validation_split=validation_split)\n",
    "                img.add_to_gif(dots_x, self.model.predict(dots_x), title='Epoch %d' % i)\n",
    "            img.save_gif()                        \n",
    "        else:\n",
    "            self.model.fit(dots_x, \n",
    "                           dots_y, \n",
    "                           epochs=epochs, \n",
    "                           sample_weight=weights, \n",
    "                           validation_split=validation_split)\n",
    "    \n",
    "    def save(self, name='discriminator'):\n",
    "        self.model.save(name+'.h5')\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# # Raw classes, don't work \n",
    "\n",
    "```python\n",
    "class Gan:\n",
    "    gen = None\n",
    "    dsc = None\n",
    "    model = None\n",
    "    \n",
    "    def __init__(self, gen, dsc, n_dim=5):\n",
    "        make_trainable(dsc, False)\n",
    "        self.gen = gen\n",
    "        self.dsc = dsc\n",
    "        # connect them\n",
    "        model = Sequential()\n",
    "        # add generator\n",
    "        model.add(gen.model)\n",
    "        # add the discriminator\n",
    "        model.add(dsc.model)\n",
    "        self.model = model\n",
    "    \n",
    "    # This method doesn't work\n",
    "    # Presumably because of some optimizer issue\n",
    "    def cmpile(self, lr=0.001):\n",
    "        self.model.compile(loss='binary_crossentropy',\n",
    "                           optimizer=tf.keras.optimizers.Adam(lr),\n",
    "                           metrics = ['accuracy'])\n",
    "        \n",
    "    def fit(self, dots_x, dots_y, epochs=1):\n",
    "        self.model.fit(dots_x, dots_y, epochs=epochs)\n",
    "        \n",
    "class Dummy:\n",
    "    model = None\n",
    "    \n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "        \n",
    "    def cmpile(self, lr=0.0001):\n",
    "        self.model.compile(loss='binary_crossentropy',\n",
    "                           optimizer=tf.keras.optimizers.Adam(lr),\n",
    "                           metrics=['accuracy'])\n",
    "    \n",
    "    # todo: remove hardcode\n",
    "    def fit(self, dots_x, dots_y, weights=None, epochs=1, validation_split=0.15, plot=False):\n",
    "        if plot:\n",
    "            img = Plot('discriminator_fit')\n",
    "            for i in range(epochs//25):\n",
    "                print(\"Epoch %d out of %d\" % (i, epochs))\n",
    "                self.model.fit(dots_x, \n",
    "                               dots_y, \n",
    "                               epochs=25, \n",
    "                               sample_weight=weights)\n",
    "                img.add_to_gif(dots_x, self.model.predict(dots_x), title='Epoch %d' % i*25)\n",
    "            img.save_gif()                        \n",
    "        else:\n",
    "            self.model.fit(dots_x, \n",
    "                           dots_y, \n",
    "                           epochs=epochs, \n",
    "                           sample_weight=weights, \n",
    "                           validation_split=validation_split)\n",
    "    \n",
    "    def save(self, name='discriminator'):\n",
    "        self.model.save(name+'.h5')\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#discriminator = tf.keras.models.load_model('discriminator.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start Here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating data\n",
    "Data = Dataset()\n",
    "Data.load_data(data_range=15)\n",
    "weights = Data.load_weights()\n",
    "\n",
    "# Defining neural networks\n",
    "generator = Gen()\n",
    "discriminator = Dsc()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 out of 150\n",
      "Train on 1530 samples, validate on 270 samples\n",
      "Epoch 1/10\n",
      "1530/1530 [==============================] - 1s 585us/sample - loss: 6.8988 - acc: 0.8333 - val_loss: 7.3352 - val_acc: 0.8333\n",
      "Epoch 2/10\n",
      "1530/1530 [==============================] - 0s 192us/sample - loss: 5.4740 - acc: 0.8340 - val_loss: 5.7021 - val_acc: 0.8370\n",
      "Epoch 3/10\n",
      "1530/1530 [==============================] - 0s 264us/sample - loss: 4.1377 - acc: 0.8359 - val_loss: 4.1934 - val_acc: 0.8370\n",
      "Epoch 4/10\n",
      "1530/1530 [==============================] - 0s 232us/sample - loss: 2.8823 - acc: 0.8373 - val_loss: 2.6874 - val_acc: 0.8519\n",
      "Epoch 5/10\n",
      "1530/1530 [==============================] - 0s 180us/sample - loss: 1.7501 - acc: 0.8229 - val_loss: 1.5668 - val_acc: 0.8037\n",
      "Epoch 6/10\n",
      "1530/1530 [==============================] - 0s 212us/sample - loss: 1.0824 - acc: 0.7974 - val_loss: 1.1141 - val_acc: 0.7667\n",
      "Epoch 7/10\n",
      "1530/1530 [==============================] - 0s 198us/sample - loss: 0.8262 - acc: 0.7961 - val_loss: 0.8557 - val_acc: 0.7815\n",
      "Epoch 8/10\n",
      "1530/1530 [==============================] - 0s 182us/sample - loss: 0.6420 - acc: 0.7967 - val_loss: 0.6624 - val_acc: 0.7889\n",
      "Epoch 9/10\n",
      "1530/1530 [==============================] - 0s 190us/sample - loss: 0.5119 - acc: 0.8124 - val_loss: 0.5413 - val_acc: 0.8407\n",
      "Epoch 10/10\n",
      "1530/1530 [==============================] - 0s 188us/sample - loss: 0.4389 - acc: 0.8366 - val_loss: 0.4635 - val_acc: 0.8444\n",
      "Epoch 1 out of 150\n",
      "Train on 1530 samples, validate on 270 samples\n",
      "Epoch 1/10\n",
      "1530/1530 [==============================] - 0s 169us/sample - loss: 0.3970 - acc: 0.8399 - val_loss: 0.4403 - val_acc: 0.8481\n",
      "Epoch 2/10\n",
      "1530/1530 [==============================] - 0s 181us/sample - loss: 0.3895 - acc: 0.8386 - val_loss: 0.4263 - val_acc: 0.8444\n",
      "Epoch 3/10\n",
      "1530/1530 [==============================] - 0s 180us/sample - loss: 0.3906 - acc: 0.8353 - val_loss: 0.4231 - val_acc: 0.8444\n",
      "Epoch 4/10\n",
      "1530/1530 [==============================] - 0s 238us/sample - loss: 0.3923 - acc: 0.8353 - val_loss: 0.4172 - val_acc: 0.8407\n",
      "Epoch 5/10\n",
      "1530/1530 [==============================] - 0s 178us/sample - loss: 0.3921 - acc: 0.8366 - val_loss: 0.4104 - val_acc: 0.8444\n",
      "Epoch 6/10\n",
      "1530/1530 [==============================] - 0s 176us/sample - loss: 0.3804 - acc: 0.8366 - val_loss: 0.4046 - val_acc: 0.8444\n",
      "Epoch 7/10\n",
      "1530/1530 [==============================] - 0s 175us/sample - loss: 0.3767 - acc: 0.8366 - val_loss: 0.4016 - val_acc: 0.8444\n",
      "Epoch 8/10\n",
      "1530/1530 [==============================] - 0s 173us/sample - loss: 0.3749 - acc: 0.8373 - val_loss: 0.4009 - val_acc: 0.8444\n",
      "Epoch 9/10\n",
      "1530/1530 [==============================] - 0s 175us/sample - loss: 0.3750 - acc: 0.8386 - val_loss: 0.3930 - val_acc: 0.8444\n",
      "Epoch 10/10\n",
      "1530/1530 [==============================] - 0s 184us/sample - loss: 0.3734 - acc: 0.8418 - val_loss: 0.3860 - val_acc: 0.8444\n",
      "Epoch 2 out of 150\n",
      "Train on 1530 samples, validate on 270 samples\n",
      "Epoch 1/10\n",
      "1530/1530 [==============================] - 0s 175us/sample - loss: 0.3741 - acc: 0.8399 - val_loss: 0.3863 - val_acc: 0.8444\n",
      "Epoch 2/10\n",
      "1530/1530 [==============================] - 0s 190us/sample - loss: 0.3599 - acc: 0.8412 - val_loss: 0.3821 - val_acc: 0.8481\n",
      "Epoch 3/10\n",
      "1530/1530 [==============================] - 0s 189us/sample - loss: 0.3519 - acc: 0.8412 - val_loss: 0.3740 - val_acc: 0.8444\n",
      "Epoch 4/10\n",
      "1530/1530 [==============================] - 0s 224us/sample - loss: 0.3516 - acc: 0.8431 - val_loss: 0.3703 - val_acc: 0.8407\n",
      "Epoch 5/10\n",
      "1530/1530 [==============================] - 0s 183us/sample - loss: 0.3474 - acc: 0.8451 - val_loss: 0.3734 - val_acc: 0.8481\n",
      "Epoch 6/10\n",
      "1530/1530 [==============================] - 0s 203us/sample - loss: 0.3494 - acc: 0.8464 - val_loss: 0.3682 - val_acc: 0.8333\n",
      "Epoch 7/10\n",
      "1530/1530 [==============================] - 0s 175us/sample - loss: 0.3439 - acc: 0.8438 - val_loss: 0.3650 - val_acc: 0.8370\n",
      "Epoch 8/10\n",
      "1530/1530 [==============================] - 0s 178us/sample - loss: 0.3429 - acc: 0.8458 - val_loss: 0.3613 - val_acc: 0.8481\n",
      "Epoch 9/10\n",
      "1530/1530 [==============================] - 0s 186us/sample - loss: 0.3365 - acc: 0.8471 - val_loss: 0.3695 - val_acc: 0.8481\n",
      "Epoch 10/10\n",
      "1530/1530 [==============================] - 0s 177us/sample - loss: 0.3377 - acc: 0.8484 - val_loss: 0.3566 - val_acc: 0.8407\n",
      "Epoch 3 out of 150\n",
      "Train on 1530 samples, validate on 270 samples\n",
      "Epoch 1/10\n",
      "1530/1530 [==============================] - 0s 181us/sample - loss: 0.3347 - acc: 0.8477 - val_loss: 0.3543 - val_acc: 0.8481\n",
      "Epoch 2/10\n",
      "1530/1530 [==============================] - 0s 186us/sample - loss: 0.3311 - acc: 0.8490 - val_loss: 0.3527 - val_acc: 0.8407\n",
      "Epoch 3/10\n",
      "1530/1530 [==============================] - 0s 213us/sample - loss: 0.3321 - acc: 0.8458 - val_loss: 0.3487 - val_acc: 0.8407\n",
      "Epoch 4/10\n",
      "1530/1530 [==============================] - 0s 231us/sample - loss: 0.3302 - acc: 0.8510 - val_loss: 0.3470 - val_acc: 0.8444\n",
      "Epoch 5/10\n",
      "1530/1530 [==============================] - 0s 222us/sample - loss: 0.3323 - acc: 0.8477 - val_loss: 0.3441 - val_acc: 0.8444\n",
      "Epoch 6/10\n",
      "1530/1530 [==============================] - 0s 214us/sample - loss: 0.3241 - acc: 0.8516 - val_loss: 0.3417 - val_acc: 0.8407\n",
      "Epoch 7/10\n",
      "1530/1530 [==============================] - 0s 267us/sample - loss: 0.3227 - acc: 0.8516 - val_loss: 0.3383 - val_acc: 0.8481\n",
      "Epoch 8/10\n",
      "1530/1530 [==============================] - 0s 222us/sample - loss: 0.3209 - acc: 0.8529 - val_loss: 0.3386 - val_acc: 0.8444\n",
      "Epoch 9/10\n",
      "1530/1530 [==============================] - 0s 237us/sample - loss: 0.3181 - acc: 0.8516 - val_loss: 0.3408 - val_acc: 0.8481\n",
      "Epoch 10/10\n",
      "1530/1530 [==============================] - 0s 237us/sample - loss: 0.3237 - acc: 0.8490 - val_loss: 0.3326 - val_acc: 0.8407\n",
      "Epoch 4 out of 150\n",
      "Train on 1530 samples, validate on 270 samples\n",
      "Epoch 1/10\n",
      "1530/1530 [==============================] - 0s 219us/sample - loss: 0.3178 - acc: 0.8516 - val_loss: 0.3307 - val_acc: 0.8407\n",
      "Epoch 2/10\n",
      "1530/1530 [==============================] - 0s 215us/sample - loss: 0.3156 - acc: 0.8516 - val_loss: 0.3293 - val_acc: 0.8407\n",
      "Epoch 3/10\n",
      "1530/1530 [==============================] - 0s 250us/sample - loss: 0.3130 - acc: 0.8529 - val_loss: 0.3263 - val_acc: 0.8444\n",
      "Epoch 4/10\n",
      "1530/1530 [==============================] - 0s 220us/sample - loss: 0.3149 - acc: 0.8510 - val_loss: 0.3308 - val_acc: 0.8296\n",
      "Epoch 5/10\n",
      "1530/1530 [==============================] - 0s 211us/sample - loss: 0.3147 - acc: 0.8529 - val_loss: 0.3342 - val_acc: 0.8481\n",
      "Epoch 6/10\n",
      "1530/1530 [==============================] - 0s 191us/sample - loss: 0.3119 - acc: 0.8529 - val_loss: 0.3238 - val_acc: 0.8444\n",
      "Epoch 7/10\n",
      "1530/1530 [==============================] - 0s 198us/sample - loss: 0.3089 - acc: 0.8529 - val_loss: 0.3221 - val_acc: 0.8444\n",
      "Epoch 8/10\n",
      "1530/1530 [==============================] - 0s 207us/sample - loss: 0.3098 - acc: 0.8556 - val_loss: 0.3227 - val_acc: 0.8370\n",
      "Epoch 9/10\n",
      "1530/1530 [==============================] - 0s 195us/sample - loss: 0.3116 - acc: 0.8562 - val_loss: 0.3210 - val_acc: 0.8407\n",
      "Epoch 10/10\n",
      "1530/1530 [==============================] - 0s 217us/sample - loss: 0.3093 - acc: 0.8536 - val_loss: 0.3240 - val_acc: 0.8481\n",
      "Epoch 5 out of 150\n",
      "Train on 1530 samples, validate on 270 samples\n",
      "Epoch 1/10\n",
      "1530/1530 [==============================] - 0s 181us/sample - loss: 0.3046 - acc: 0.8556 - val_loss: 0.3226 - val_acc: 0.8444\n",
      "Epoch 2/10\n",
      "1530/1530 [==============================] - 0s 188us/sample - loss: 0.3068 - acc: 0.8556 - val_loss: 0.3219 - val_acc: 0.8370\n",
      "Epoch 3/10\n",
      "1530/1530 [==============================] - 0s 212us/sample - loss: 0.3081 - acc: 0.8523 - val_loss: 0.3193 - val_acc: 0.8444\n",
      "Epoch 4/10\n",
      "1530/1530 [==============================] - 0s 222us/sample - loss: 0.3034 - acc: 0.8556 - val_loss: 0.3395 - val_acc: 0.8222\n",
      "Epoch 5/10\n",
      "1530/1530 [==============================] - 0s 198us/sample - loss: 0.3095 - acc: 0.8523 - val_loss: 0.3196 - val_acc: 0.8407\n",
      "Epoch 6/10\n",
      "1530/1530 [==============================] - 0s 196us/sample - loss: 0.3076 - acc: 0.8569 - val_loss: 0.3166 - val_acc: 0.8407\n",
      "Epoch 7/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1530/1530 [==============================] - 0s 184us/sample - loss: 0.3032 - acc: 0.8529 - val_loss: 0.3155 - val_acc: 0.8407\n",
      "Epoch 8/10\n",
      "1530/1530 [==============================] - 0s 169us/sample - loss: 0.3023 - acc: 0.8556 - val_loss: 0.3158 - val_acc: 0.8407\n",
      "Epoch 9/10\n",
      "1530/1530 [==============================] - 0s 168us/sample - loss: 0.3004 - acc: 0.8536 - val_loss: 0.3284 - val_acc: 0.8259\n",
      "Epoch 10/10\n",
      "1530/1530 [==============================] - 0s 196us/sample - loss: 0.3071 - acc: 0.8556 - val_loss: 0.3146 - val_acc: 0.8444\n",
      "Epoch 6 out of 150\n",
      "Train on 1530 samples, validate on 270 samples\n",
      "Epoch 1/10\n",
      "1530/1530 [==============================] - 0s 168us/sample - loss: 0.3018 - acc: 0.8549 - val_loss: 0.3145 - val_acc: 0.8481\n",
      "Epoch 2/10\n",
      "1530/1530 [==============================] - 0s 175us/sample - loss: 0.3025 - acc: 0.8562 - val_loss: 0.3206 - val_acc: 0.8519\n",
      "Epoch 3/10\n",
      "1530/1530 [==============================] - 0s 166us/sample - loss: 0.3004 - acc: 0.8536 - val_loss: 0.3142 - val_acc: 0.8519\n",
      "Epoch 4/10\n",
      "1530/1530 [==============================] - 0s 214us/sample - loss: 0.2979 - acc: 0.8569 - val_loss: 0.3168 - val_acc: 0.8519\n",
      "Epoch 5/10\n",
      "1530/1530 [==============================] - 0s 175us/sample - loss: 0.2993 - acc: 0.8575 - val_loss: 0.3117 - val_acc: 0.8481\n",
      "Epoch 6/10\n",
      "1530/1530 [==============================] - 0s 173us/sample - loss: 0.2983 - acc: 0.8575 - val_loss: 0.3115 - val_acc: 0.8444\n",
      "Epoch 7/10\n",
      "1530/1530 [==============================] - 0s 172us/sample - loss: 0.2994 - acc: 0.8536 - val_loss: 0.3134 - val_acc: 0.8481\n",
      "Epoch 8/10\n",
      "1530/1530 [==============================] - 0s 194us/sample - loss: 0.2990 - acc: 0.8556 - val_loss: 0.3199 - val_acc: 0.8556\n",
      "Epoch 9/10\n",
      "1530/1530 [==============================] - 0s 183us/sample - loss: 0.2982 - acc: 0.8569 - val_loss: 0.3129 - val_acc: 0.8519\n",
      "Epoch 10/10\n",
      "1530/1530 [==============================] - 0s 173us/sample - loss: 0.2960 - acc: 0.8562 - val_loss: 0.3155 - val_acc: 0.8519\n",
      "Epoch 7 out of 150\n",
      "Train on 1530 samples, validate on 270 samples\n",
      "Epoch 1/10\n",
      "1530/1530 [==============================] - 0s 164us/sample - loss: 0.2958 - acc: 0.8556 - val_loss: 0.3134 - val_acc: 0.8519\n",
      "Epoch 2/10\n",
      "1530/1530 [==============================] - 0s 180us/sample - loss: 0.2959 - acc: 0.8549 - val_loss: 0.3104 - val_acc: 0.8519\n",
      "Epoch 3/10\n",
      "1530/1530 [==============================] - 0s 166us/sample - loss: 0.2984 - acc: 0.8575 - val_loss: 0.3358 - val_acc: 0.8556\n",
      "Epoch 4/10\n",
      "1530/1530 [==============================] - 0s 253us/sample - loss: 0.3101 - acc: 0.8549 - val_loss: 0.3092 - val_acc: 0.8481\n",
      "Epoch 5/10\n",
      "1530/1530 [==============================] - 0s 223us/sample - loss: 0.2970 - acc: 0.8556 - val_loss: 0.3166 - val_acc: 0.8556\n",
      "Epoch 6/10\n",
      "1530/1530 [==============================] - 0s 193us/sample - loss: 0.2962 - acc: 0.8582 - val_loss: 0.3129 - val_acc: 0.8444\n",
      "Epoch 7/10\n",
      "1530/1530 [==============================] - 0s 217us/sample - loss: 0.2961 - acc: 0.8601 - val_loss: 0.3116 - val_acc: 0.8519\n",
      "Epoch 8/10\n",
      "1530/1530 [==============================] - 0s 229us/sample - loss: 0.2933 - acc: 0.8621 - val_loss: 0.3074 - val_acc: 0.8556\n",
      "Epoch 9/10\n",
      "1530/1530 [==============================] - 0s 211us/sample - loss: 0.2932 - acc: 0.8601 - val_loss: 0.3074 - val_acc: 0.8519\n",
      "Epoch 10/10\n",
      "1530/1530 [==============================] - 0s 216us/sample - loss: 0.2955 - acc: 0.8575 - val_loss: 0.3066 - val_acc: 0.8519\n",
      "Epoch 8 out of 150\n",
      "Train on 1530 samples, validate on 270 samples\n",
      "Epoch 1/10\n",
      "1530/1530 [==============================] - 0s 231us/sample - loss: 0.2919 - acc: 0.8595 - val_loss: 0.3071 - val_acc: 0.8519\n",
      "Epoch 2/10\n",
      "1530/1530 [==============================] - 0s 287us/sample - loss: 0.2931 - acc: 0.8588 - val_loss: 0.3176 - val_acc: 0.8185\n",
      "Epoch 3/10\n",
      "1530/1530 [==============================] - 0s 269us/sample - loss: 0.2949 - acc: 0.8627 - val_loss: 0.3074 - val_acc: 0.8556\n",
      "Epoch 4/10\n",
      "1530/1530 [==============================] - 0s 218us/sample - loss: 0.2915 - acc: 0.8608 - val_loss: 0.3065 - val_acc: 0.8481\n",
      "Epoch 5/10\n",
      "1530/1530 [==============================] - 0s 233us/sample - loss: 0.2920 - acc: 0.8562 - val_loss: 0.3068 - val_acc: 0.8556\n",
      "Epoch 6/10\n",
      "1530/1530 [==============================] - 0s 218us/sample - loss: 0.2924 - acc: 0.8569 - val_loss: 0.3073 - val_acc: 0.8259\n",
      "Epoch 7/10\n",
      "1530/1530 [==============================] - 0s 194us/sample - loss: 0.2912 - acc: 0.8601 - val_loss: 0.3057 - val_acc: 0.8593\n",
      "Epoch 8/10\n",
      "1530/1530 [==============================] - 0s 224us/sample - loss: 0.2900 - acc: 0.8621 - val_loss: 0.3090 - val_acc: 0.8593\n",
      "Epoch 9/10\n",
      "1530/1530 [==============================] - 0s 183us/sample - loss: 0.2913 - acc: 0.8608 - val_loss: 0.3107 - val_acc: 0.8185\n",
      "Epoch 10/10\n",
      "1530/1530 [==============================] - 0s 204us/sample - loss: 0.2884 - acc: 0.8654 - val_loss: 0.3040 - val_acc: 0.8556\n",
      "Epoch 9 out of 150\n",
      "Train on 1530 samples, validate on 270 samples\n",
      "Epoch 1/10\n",
      "1530/1530 [==============================] - 0s 173us/sample - loss: 0.2913 - acc: 0.8621 - val_loss: 0.3081 - val_acc: 0.8593\n",
      "Epoch 2/10\n",
      "1530/1530 [==============================] - 0s 174us/sample - loss: 0.2878 - acc: 0.8634 - val_loss: 0.3114 - val_acc: 0.8556\n",
      "Epoch 3/10\n",
      "1530/1530 [==============================] - 0s 177us/sample - loss: 0.2945 - acc: 0.8582 - val_loss: 0.3168 - val_acc: 0.8259\n",
      "Epoch 4/10\n",
      "1530/1530 [==============================] - 0s 242us/sample - loss: 0.2884 - acc: 0.8647 - val_loss: 0.3058 - val_acc: 0.8556\n",
      "Epoch 5/10\n",
      "1530/1530 [==============================] - 0s 189us/sample - loss: 0.2867 - acc: 0.8660 - val_loss: 0.3026 - val_acc: 0.8593\n",
      "Epoch 6/10\n",
      "1530/1530 [==============================] - 0s 201us/sample - loss: 0.2864 - acc: 0.8647 - val_loss: 0.3027 - val_acc: 0.8519\n",
      "Epoch 7/10\n",
      "1530/1530 [==============================] - 0s 189us/sample - loss: 0.2873 - acc: 0.8641 - val_loss: 0.3018 - val_acc: 0.8593\n",
      "Epoch 8/10\n",
      "1530/1530 [==============================] - 0s 192us/sample - loss: 0.2871 - acc: 0.8654 - val_loss: 0.3031 - val_acc: 0.8593\n",
      "Epoch 9/10\n",
      "1530/1530 [==============================] - 0s 184us/sample - loss: 0.2878 - acc: 0.8614 - val_loss: 0.3061 - val_acc: 0.8259\n",
      "Epoch 10/10\n",
      "1530/1530 [==============================] - 0s 200us/sample - loss: 0.2889 - acc: 0.8641 - val_loss: 0.3013 - val_acc: 0.8630\n",
      "Epoch 10 out of 150\n",
      "Train on 1530 samples, validate on 270 samples\n",
      "Epoch 1/10\n",
      "1530/1530 [==============================] - 0s 171us/sample - loss: 0.2884 - acc: 0.8614 - val_loss: 0.3010 - val_acc: 0.8556\n",
      "Epoch 2/10\n",
      "1530/1530 [==============================] - 0s 186us/sample - loss: 0.2864 - acc: 0.8641 - val_loss: 0.3006 - val_acc: 0.8481\n",
      "Epoch 3/10\n",
      "1530/1530 [==============================] - 0s 183us/sample - loss: 0.2850 - acc: 0.8647 - val_loss: 0.3001 - val_acc: 0.8519\n",
      "Epoch 4/10\n",
      "1530/1530 [==============================] - 0s 231us/sample - loss: 0.2836 - acc: 0.8686 - val_loss: 0.2998 - val_acc: 0.8519\n",
      "Epoch 5/10\n",
      "1530/1530 [==============================] - 0s 181us/sample - loss: 0.2877 - acc: 0.8654 - val_loss: 0.2999 - val_acc: 0.8630\n",
      "Epoch 6/10\n",
      "1530/1530 [==============================] - 0s 178us/sample - loss: 0.2860 - acc: 0.8673 - val_loss: 0.3001 - val_acc: 0.8630\n",
      "Epoch 7/10\n",
      "1530/1530 [==============================] - 0s 188us/sample - loss: 0.2832 - acc: 0.8673 - val_loss: 0.3134 - val_acc: 0.8593\n",
      "Epoch 8/10\n",
      "1530/1530 [==============================] - 0s 189us/sample - loss: 0.2946 - acc: 0.8595 - val_loss: 0.3011 - val_acc: 0.8370\n",
      "Epoch 9/10\n",
      "1530/1530 [==============================] - 0s 192us/sample - loss: 0.2823 - acc: 0.8667 - val_loss: 0.3000 - val_acc: 0.8593\n",
      "Epoch 10/10\n",
      "1530/1530 [==============================] - 0s 181us/sample - loss: 0.2866 - acc: 0.8712 - val_loss: 0.3077 - val_acc: 0.8630\n",
      "Epoch 11 out of 150\n",
      "Train on 1530 samples, validate on 270 samples\n",
      "Epoch 1/10\n",
      "1530/1530 [==============================] - 0s 166us/sample - loss: 0.2835 - acc: 0.8686 - val_loss: 0.3008 - val_acc: 0.8630\n",
      "Epoch 2/10\n",
      "1530/1530 [==============================] - 0s 195us/sample - loss: 0.2845 - acc: 0.8660 - val_loss: 0.3002 - val_acc: 0.8481\n",
      "Epoch 3/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1530/1530 [==============================] - 0s 171us/sample - loss: 0.2821 - acc: 0.8680 - val_loss: 0.2981 - val_acc: 0.8593\n",
      "Epoch 4/10\n",
      "1530/1530 [==============================] - 0s 217us/sample - loss: 0.2825 - acc: 0.8686 - val_loss: 0.2967 - val_acc: 0.8556\n",
      "Epoch 5/10\n",
      "1530/1530 [==============================] - 0s 175us/sample - loss: 0.2837 - acc: 0.8693 - val_loss: 0.2967 - val_acc: 0.8630\n",
      "Epoch 6/10\n",
      "1530/1530 [==============================] - 0s 175us/sample - loss: 0.2831 - acc: 0.8699 - val_loss: 0.3072 - val_acc: 0.8630\n",
      "Epoch 7/10\n",
      "1530/1530 [==============================] - 0s 174us/sample - loss: 0.2798 - acc: 0.8660 - val_loss: 0.3074 - val_acc: 0.8630\n",
      "Epoch 8/10\n",
      "1530/1530 [==============================] - 0s 169us/sample - loss: 0.2841 - acc: 0.8660 - val_loss: 0.3053 - val_acc: 0.8333\n",
      "Epoch 9/10\n",
      "1530/1530 [==============================] - 0s 181us/sample - loss: 0.2823 - acc: 0.8686 - val_loss: 0.3060 - val_acc: 0.8630\n",
      "Epoch 10/10\n",
      "1530/1530 [==============================] - 0s 169us/sample - loss: 0.2796 - acc: 0.8686 - val_loss: 0.2965 - val_acc: 0.8519\n",
      "Epoch 12 out of 150\n",
      "Train on 1530 samples, validate on 270 samples\n",
      "Epoch 1/10\n",
      "1530/1530 [==============================] - 0s 166us/sample - loss: 0.2820 - acc: 0.8719 - val_loss: 0.2975 - val_acc: 0.8481\n",
      "Epoch 2/10\n",
      "1530/1530 [==============================] - 0s 179us/sample - loss: 0.2801 - acc: 0.8686 - val_loss: 0.2957 - val_acc: 0.8593\n",
      "Epoch 3/10\n",
      "1530/1530 [==============================] - 0s 163us/sample - loss: 0.2853 - acc: 0.8654 - val_loss: 0.3116 - val_acc: 0.8630\n",
      "Epoch 4/10\n",
      "1530/1530 [==============================] - 0s 218us/sample - loss: 0.2832 - acc: 0.8680 - val_loss: 0.2952 - val_acc: 0.8593\n",
      "Epoch 5/10\n",
      "1530/1530 [==============================] - 0s 179us/sample - loss: 0.2856 - acc: 0.8654 - val_loss: 0.3035 - val_acc: 0.8333\n",
      "Epoch 6/10\n",
      "1530/1530 [==============================] - 0s 171us/sample - loss: 0.2821 - acc: 0.8660 - val_loss: 0.2957 - val_acc: 0.8593\n",
      "Epoch 7/10\n",
      "1530/1530 [==============================] - 0s 172us/sample - loss: 0.2779 - acc: 0.8712 - val_loss: 0.2941 - val_acc: 0.8556\n",
      "Epoch 8/10\n",
      "1530/1530 [==============================] - 0s 169us/sample - loss: 0.2797 - acc: 0.8699 - val_loss: 0.2936 - val_acc: 0.8593\n",
      "Epoch 9/10\n",
      "1530/1530 [==============================] - 0s 173us/sample - loss: 0.2793 - acc: 0.8654 - val_loss: 0.2950 - val_acc: 0.8593\n",
      "Epoch 10/10\n",
      "1530/1530 [==============================] - 0s 209us/sample - loss: 0.2781 - acc: 0.8686 - val_loss: 0.2949 - val_acc: 0.8630\n",
      "Epoch 13 out of 150\n",
      "Train on 1530 samples, validate on 270 samples\n",
      "Epoch 1/10\n",
      "1530/1530 [==============================] - 0s 195us/sample - loss: 0.2783 - acc: 0.8680 - val_loss: 0.2941 - val_acc: 0.8593\n",
      "Epoch 2/10\n",
      "1530/1530 [==============================] - 0s 245us/sample - loss: 0.2811 - acc: 0.8706 - val_loss: 0.2927 - val_acc: 0.8556\n",
      "Epoch 3/10\n",
      "1530/1530 [==============================] - 0s 248us/sample - loss: 0.2774 - acc: 0.8667 - val_loss: 0.2942 - val_acc: 0.8630\n",
      "Epoch 4/10\n",
      "1530/1530 [==============================] - 0s 218us/sample - loss: 0.2775 - acc: 0.8693 - val_loss: 0.2935 - val_acc: 0.8519\n",
      "Epoch 5/10\n",
      "1530/1530 [==============================] - 0s 197us/sample - loss: 0.2778 - acc: 0.8712 - val_loss: 0.2919 - val_acc: 0.8556\n",
      "Epoch 6/10\n",
      "1530/1530 [==============================] - 0s 178us/sample - loss: 0.2797 - acc: 0.8667 - val_loss: 0.2923 - val_acc: 0.8556\n",
      "Epoch 7/10\n",
      "1530/1530 [==============================] - 0s 181us/sample - loss: 0.2799 - acc: 0.8693 - val_loss: 0.2926 - val_acc: 0.8481\n",
      "Epoch 8/10\n",
      "1530/1530 [==============================] - 0s 181us/sample - loss: 0.2768 - acc: 0.8654 - val_loss: 0.2944 - val_acc: 0.8630\n",
      "Epoch 9/10\n",
      "1530/1530 [==============================] - 0s 179us/sample - loss: 0.2777 - acc: 0.8673 - val_loss: 0.2912 - val_acc: 0.8556\n",
      "Epoch 10/10\n",
      "1530/1530 [==============================] - 0s 174us/sample - loss: 0.2762 - acc: 0.8712 - val_loss: 0.3041 - val_acc: 0.8333\n",
      "Epoch 14 out of 150\n",
      "Train on 1530 samples, validate on 270 samples\n",
      "Epoch 1/10\n",
      "1530/1530 [==============================] - 0s 167us/sample - loss: 0.2766 - acc: 0.8660 - val_loss: 0.2949 - val_acc: 0.8519\n",
      "Epoch 2/10\n",
      "1530/1530 [==============================] - 0s 164us/sample - loss: 0.2791 - acc: 0.8680 - val_loss: 0.2927 - val_acc: 0.8630\n",
      "Epoch 3/10\n",
      "1530/1530 [==============================] - 0s 183us/sample - loss: 0.2781 - acc: 0.8739 - val_loss: 0.2915 - val_acc: 0.8556\n",
      "Epoch 4/10\n",
      "1530/1530 [==============================] - 0s 267us/sample - loss: 0.2775 - acc: 0.8680 - val_loss: 0.2902 - val_acc: 0.8556\n",
      "Epoch 5/10\n",
      "1530/1530 [==============================] - 0s 230us/sample - loss: 0.2785 - acc: 0.8667 - val_loss: 0.2910 - val_acc: 0.8593\n",
      "Epoch 6/10\n",
      "1530/1530 [==============================] - 0s 227us/sample - loss: 0.2783 - acc: 0.8752 - val_loss: 0.2973 - val_acc: 0.8667\n",
      "Epoch 7/10\n",
      "1530/1530 [==============================] - 0s 260us/sample - loss: 0.2767 - acc: 0.8699 - val_loss: 0.2899 - val_acc: 0.8556\n",
      "Epoch 8/10\n",
      "1530/1530 [==============================] - 0s 249us/sample - loss: 0.2770 - acc: 0.8686 - val_loss: 0.2914 - val_acc: 0.8593\n",
      "Epoch 9/10\n",
      "1530/1530 [==============================] - 0s 220us/sample - loss: 0.2737 - acc: 0.8699 - val_loss: 0.2913 - val_acc: 0.8593\n",
      "Epoch 10/10\n",
      "1530/1530 [==============================] - 0s 196us/sample - loss: 0.2760 - acc: 0.8627 - val_loss: 0.2894 - val_acc: 0.8556\n",
      "Epoch 15 out of 150\n",
      "Train on 1530 samples, validate on 270 samples\n",
      "Epoch 1/10\n",
      "1530/1530 [==============================] - 0s 171us/sample - loss: 0.2750 - acc: 0.8673 - val_loss: 0.2894 - val_acc: 0.8593\n",
      "Epoch 2/10\n",
      "1530/1530 [==============================] - 0s 182us/sample - loss: 0.2757 - acc: 0.8647 - val_loss: 0.2947 - val_acc: 0.8519\n",
      "Epoch 3/10\n",
      "1530/1530 [==============================] - 0s 183us/sample - loss: 0.2759 - acc: 0.8654 - val_loss: 0.2913 - val_acc: 0.8630\n",
      "Epoch 4/10\n",
      "1530/1530 [==============================] - 0s 254us/sample - loss: 0.2736 - acc: 0.8673 - val_loss: 0.2939 - val_acc: 0.8667\n",
      "Epoch 5/10\n",
      "1530/1530 [==============================] - 0s 192us/sample - loss: 0.2730 - acc: 0.8680 - val_loss: 0.2894 - val_acc: 0.8593\n",
      "Epoch 6/10\n",
      "1530/1530 [==============================] - 0s 194us/sample - loss: 0.2742 - acc: 0.8673 - val_loss: 0.2925 - val_acc: 0.8630\n",
      "Epoch 7/10\n",
      "1530/1530 [==============================] - 0s 205us/sample - loss: 0.2736 - acc: 0.8686 - val_loss: 0.2889 - val_acc: 0.8593\n",
      "Epoch 8/10\n",
      "1530/1530 [==============================] - 0s 174us/sample - loss: 0.2757 - acc: 0.8601 - val_loss: 0.2886 - val_acc: 0.8556\n",
      "Epoch 9/10\n",
      "1530/1530 [==============================] - 0s 175us/sample - loss: 0.2707 - acc: 0.8693 - val_loss: 0.2877 - val_acc: 0.8593\n",
      "Epoch 10/10\n",
      "1530/1530 [==============================] - 0s 187us/sample - loss: 0.2752 - acc: 0.8686 - val_loss: 0.2879 - val_acc: 0.8593\n",
      "Epoch 16 out of 150\n",
      "Train on 1530 samples, validate on 270 samples\n",
      "Epoch 1/10\n",
      "1530/1530 [==============================] - 0s 176us/sample - loss: 0.2752 - acc: 0.8693 - val_loss: 0.2902 - val_acc: 0.8519\n",
      "Epoch 2/10\n",
      "1530/1530 [==============================] - 0s 197us/sample - loss: 0.2736 - acc: 0.8732 - val_loss: 0.2927 - val_acc: 0.8519\n",
      "Epoch 3/10\n",
      "1530/1530 [==============================] - 0s 237us/sample - loss: 0.2716 - acc: 0.8667 - val_loss: 0.2863 - val_acc: 0.8556\n",
      "Epoch 4/10\n",
      "1530/1530 [==============================] - 0s 248us/sample - loss: 0.2731 - acc: 0.8660 - val_loss: 0.2929 - val_acc: 0.8593\n",
      "Epoch 5/10\n",
      "1530/1530 [==============================] - 0s 234us/sample - loss: 0.2722 - acc: 0.8693 - val_loss: 0.2916 - val_acc: 0.8630\n",
      "Epoch 6/10\n",
      "1530/1530 [==============================] - 0s 227us/sample - loss: 0.2708 - acc: 0.8699 - val_loss: 0.2936 - val_acc: 0.8667\n",
      "Epoch 7/10\n",
      "1530/1530 [==============================] - 0s 231us/sample - loss: 0.2773 - acc: 0.8699 - val_loss: 0.2866 - val_acc: 0.8593\n",
      "Epoch 8/10\n",
      "1530/1530 [==============================] - 0s 231us/sample - loss: 0.2696 - acc: 0.8719 - val_loss: 0.2863 - val_acc: 0.8593\n",
      "Epoch 9/10\n",
      "1530/1530 [==============================] - 0s 222us/sample - loss: 0.2705 - acc: 0.8680 - val_loss: 0.2891 - val_acc: 0.8519\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/10\n",
      "1530/1530 [==============================] - 0s 201us/sample - loss: 0.2719 - acc: 0.8680 - val_loss: 0.2975 - val_acc: 0.8667\n",
      "Epoch 17 out of 150\n",
      "Train on 1530 samples, validate on 270 samples\n",
      "Epoch 1/10\n",
      "1530/1530 [==============================] - 0s 173us/sample - loss: 0.2702 - acc: 0.8693 - val_loss: 0.2867 - val_acc: 0.8593\n",
      "Epoch 2/10\n",
      "1530/1530 [==============================] - 0s 199us/sample - loss: 0.2710 - acc: 0.8627 - val_loss: 0.3012 - val_acc: 0.8667\n",
      "Epoch 3/10\n",
      "1530/1530 [==============================] - 0s 180us/sample - loss: 0.2715 - acc: 0.8712 - val_loss: 0.2873 - val_acc: 0.8593\n",
      "Epoch 4/10\n",
      "1530/1530 [==============================] - 0s 229us/sample - loss: 0.2697 - acc: 0.8699 - val_loss: 0.2850 - val_acc: 0.8519\n",
      "Epoch 5/10\n",
      "1530/1530 [==============================] - 0s 214us/sample - loss: 0.2699 - acc: 0.8660 - val_loss: 0.2889 - val_acc: 0.8593\n",
      "Epoch 6/10\n",
      "1530/1530 [==============================] - 0s 231us/sample - loss: 0.2705 - acc: 0.8725 - val_loss: 0.2863 - val_acc: 0.8593\n",
      "Epoch 7/10\n",
      "1530/1530 [==============================] - 0s 216us/sample - loss: 0.2705 - acc: 0.8693 - val_loss: 0.2874 - val_acc: 0.8630\n",
      "Epoch 8/10\n",
      "1530/1530 [==============================] - 0s 235us/sample - loss: 0.2684 - acc: 0.8706 - val_loss: 0.2858 - val_acc: 0.8593\n",
      "Epoch 9/10\n",
      "1530/1530 [==============================] - 0s 215us/sample - loss: 0.2684 - acc: 0.8693 - val_loss: 0.2848 - val_acc: 0.8556\n",
      "Epoch 10/10\n",
      "1530/1530 [==============================] - 0s 211us/sample - loss: 0.2687 - acc: 0.8654 - val_loss: 0.2838 - val_acc: 0.8556\n",
      "Epoch 18 out of 150\n",
      "Train on 1530 samples, validate on 270 samples\n",
      "Epoch 1/10\n",
      "1530/1530 [==============================] - 0s 169us/sample - loss: 0.2691 - acc: 0.8680 - val_loss: 0.2928 - val_acc: 0.8667\n",
      "Epoch 2/10\n",
      "1530/1530 [==============================] - 0s 175us/sample - loss: 0.2729 - acc: 0.8654 - val_loss: 0.2895 - val_acc: 0.8667\n",
      "Epoch 3/10\n",
      "1530/1530 [==============================] - 0s 172us/sample - loss: 0.2697 - acc: 0.8621 - val_loss: 0.2829 - val_acc: 0.8556\n",
      "Epoch 4/10\n",
      "1530/1530 [==============================] - 0s 218us/sample - loss: 0.2696 - acc: 0.8673 - val_loss: 0.2926 - val_acc: 0.8519\n",
      "Epoch 5/10\n",
      "1530/1530 [==============================] - 0s 180us/sample - loss: 0.2696 - acc: 0.8719 - val_loss: 0.2837 - val_acc: 0.8593\n",
      "Epoch 6/10\n",
      "1530/1530 [==============================] - 0s 169us/sample - loss: 0.2710 - acc: 0.8667 - val_loss: 0.2840 - val_acc: 0.8667\n",
      "Epoch 7/10\n",
      "1530/1530 [==============================] - 0s 173us/sample - loss: 0.2657 - acc: 0.8673 - val_loss: 0.2897 - val_acc: 0.8667\n",
      "Epoch 8/10\n",
      "1530/1530 [==============================] - 0s 177us/sample - loss: 0.2675 - acc: 0.8699 - val_loss: 0.2820 - val_acc: 0.8556\n",
      "Epoch 9/10\n",
      "1530/1530 [==============================] - 0s 183us/sample - loss: 0.2674 - acc: 0.8712 - val_loss: 0.2998 - val_acc: 0.8667\n",
      "Epoch 10/10\n",
      "1530/1530 [==============================] - 0s 173us/sample - loss: 0.2696 - acc: 0.8739 - val_loss: 0.2864 - val_acc: 0.8630\n",
      "Epoch 19 out of 150\n",
      "Train on 1530 samples, validate on 270 samples\n",
      "Epoch 1/10\n",
      "1530/1530 [==============================] - 0s 173us/sample - loss: 0.2684 - acc: 0.8712 - val_loss: 0.2833 - val_acc: 0.8630\n",
      "Epoch 2/10\n",
      "1530/1530 [==============================] - 0s 170us/sample - loss: 0.2677 - acc: 0.8725 - val_loss: 0.2816 - val_acc: 0.8593\n",
      "Epoch 3/10\n",
      "1530/1530 [==============================] - 0s 166us/sample - loss: 0.2659 - acc: 0.8719 - val_loss: 0.2825 - val_acc: 0.8630\n",
      "Epoch 4/10\n",
      "1530/1530 [==============================] - 0s 229us/sample - loss: 0.2684 - acc: 0.8712 - val_loss: 0.2850 - val_acc: 0.8593\n",
      "Epoch 5/10\n",
      "1530/1530 [==============================] - 0s 183us/sample - loss: 0.2675 - acc: 0.8693 - val_loss: 0.2819 - val_acc: 0.8630\n",
      "Epoch 6/10\n",
      "1530/1530 [==============================] - 0s 169us/sample - loss: 0.2653 - acc: 0.8706 - val_loss: 0.2911 - val_acc: 0.8667\n",
      "Epoch 7/10\n",
      "1530/1530 [==============================] - 0s 176us/sample - loss: 0.2664 - acc: 0.8752 - val_loss: 0.2820 - val_acc: 0.8630\n",
      "Epoch 8/10\n",
      "1530/1530 [==============================] - 0s 181us/sample - loss: 0.2658 - acc: 0.8712 - val_loss: 0.2821 - val_acc: 0.8741\n",
      "Epoch 9/10\n",
      "1530/1530 [==============================] - 0s 173us/sample - loss: 0.2671 - acc: 0.8693 - val_loss: 0.2810 - val_acc: 0.8630\n",
      "Epoch 10/10\n",
      "1530/1530 [==============================] - 0s 171us/sample - loss: 0.2697 - acc: 0.8712 - val_loss: 0.2808 - val_acc: 0.8630\n",
      "Epoch 20 out of 150\n",
      "Train on 1530 samples, validate on 270 samples\n",
      "Epoch 1/10\n",
      "1530/1530 [==============================] - 0s 179us/sample - loss: 0.2673 - acc: 0.8752 - val_loss: 0.2794 - val_acc: 0.8556\n",
      "Epoch 2/10\n",
      "1530/1530 [==============================] - 0s 217us/sample - loss: 0.2657 - acc: 0.8667 - val_loss: 0.2800 - val_acc: 0.8630\n",
      "Epoch 3/10\n",
      "1530/1530 [==============================] - 0s 188us/sample - loss: 0.2647 - acc: 0.8712 - val_loss: 0.2787 - val_acc: 0.8556\n",
      "Epoch 4/10\n",
      "1530/1530 [==============================] - 0s 321us/sample - loss: 0.2630 - acc: 0.8693 - val_loss: 0.2812 - val_acc: 0.8630\n",
      "Epoch 5/10\n",
      "1530/1530 [==============================] - 0s 192us/sample - loss: 0.2650 - acc: 0.8725 - val_loss: 0.2801 - val_acc: 0.8630\n",
      "Epoch 6/10\n",
      "1530/1530 [==============================] - 0s 189us/sample - loss: 0.2652 - acc: 0.8673 - val_loss: 0.2789 - val_acc: 0.8556\n",
      "Epoch 7/10\n",
      "1530/1530 [==============================] - 0s 203us/sample - loss: 0.2668 - acc: 0.8732 - val_loss: 0.2794 - val_acc: 0.8593\n",
      "Epoch 8/10\n",
      "1530/1530 [==============================] - 0s 220us/sample - loss: 0.2625 - acc: 0.8765 - val_loss: 0.2795 - val_acc: 0.8593\n",
      "Epoch 9/10\n",
      "1530/1530 [==============================] - 0s 172us/sample - loss: 0.2648 - acc: 0.8732 - val_loss: 0.2794 - val_acc: 0.8556\n",
      "Epoch 10/10\n",
      "1530/1530 [==============================] - 0s 213us/sample - loss: 0.2651 - acc: 0.8680 - val_loss: 0.2798 - val_acc: 0.8630\n",
      "Epoch 21 out of 150\n",
      "Train on 1530 samples, validate on 270 samples\n",
      "Epoch 1/10\n",
      "1530/1530 [==============================] - 0s 168us/sample - loss: 0.2632 - acc: 0.8719 - val_loss: 0.2775 - val_acc: 0.8593\n",
      "Epoch 2/10\n",
      "1530/1530 [==============================] - 0s 227us/sample - loss: 0.2623 - acc: 0.8699 - val_loss: 0.2774 - val_acc: 0.8556\n",
      "Epoch 3/10\n",
      "1530/1530 [==============================] - 0s 188us/sample - loss: 0.2623 - acc: 0.8686 - val_loss: 0.2930 - val_acc: 0.8704\n",
      "Epoch 4/10\n",
      "1530/1530 [==============================] - 0s 196us/sample - loss: 0.2645 - acc: 0.8712 - val_loss: 0.2786 - val_acc: 0.8593\n",
      "Epoch 5/10\n",
      "1530/1530 [==============================] - 0s 186us/sample - loss: 0.2626 - acc: 0.8680 - val_loss: 0.2797 - val_acc: 0.8593\n",
      "Epoch 6/10\n",
      "1530/1530 [==============================] - 0s 184us/sample - loss: 0.2625 - acc: 0.8699 - val_loss: 0.2885 - val_acc: 0.8704\n",
      "Epoch 7/10\n",
      "1530/1530 [==============================] - 0s 191us/sample - loss: 0.2648 - acc: 0.8732 - val_loss: 0.2772 - val_acc: 0.8556\n",
      "Epoch 8/10\n",
      "1530/1530 [==============================] - 0s 183us/sample - loss: 0.2637 - acc: 0.8732 - val_loss: 0.2877 - val_acc: 0.8741\n",
      "Epoch 9/10\n",
      "1530/1530 [==============================] - 0s 186us/sample - loss: 0.2658 - acc: 0.8706 - val_loss: 0.2747 - val_acc: 0.8556\n",
      "Epoch 10/10\n",
      "1530/1530 [==============================] - 0s 175us/sample - loss: 0.2624 - acc: 0.8680 - val_loss: 0.2802 - val_acc: 0.8556\n",
      "Epoch 22 out of 150\n",
      "Train on 1530 samples, validate on 270 samples\n",
      "Epoch 1/10\n",
      "1530/1530 [==============================] - 0s 179us/sample - loss: 0.2630 - acc: 0.8686 - val_loss: 0.2769 - val_acc: 0.8593\n",
      "Epoch 2/10\n",
      "1530/1530 [==============================] - 0s 199us/sample - loss: 0.2642 - acc: 0.8693 - val_loss: 0.2818 - val_acc: 0.8704\n",
      "Epoch 3/10\n",
      "1530/1530 [==============================] - 0s 231us/sample - loss: 0.2608 - acc: 0.8719 - val_loss: 0.2800 - val_acc: 0.8556\n",
      "Epoch 4/10\n",
      "1530/1530 [==============================] - 0s 261us/sample - loss: 0.2601 - acc: 0.8765 - val_loss: 0.2773 - val_acc: 0.8556\n",
      "Epoch 5/10\n",
      "1530/1530 [==============================] - 0s 213us/sample - loss: 0.2633 - acc: 0.8719 - val_loss: 0.2765 - val_acc: 0.8630\n",
      "Epoch 6/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1530/1530 [==============================] - 0s 223us/sample - loss: 0.2608 - acc: 0.8706 - val_loss: 0.2801 - val_acc: 0.8556\n",
      "Epoch 7/10\n",
      "1530/1530 [==============================] - 0s 220us/sample - loss: 0.2612 - acc: 0.8706 - val_loss: 0.2827 - val_acc: 0.8481\n",
      "Epoch 8/10\n",
      "1530/1530 [==============================] - 0s 198us/sample - loss: 0.2628 - acc: 0.8719 - val_loss: 0.2745 - val_acc: 0.8556\n",
      "Epoch 9/10\n",
      "1530/1530 [==============================] - 0s 203us/sample - loss: 0.2610 - acc: 0.8680 - val_loss: 0.2745 - val_acc: 0.8630\n",
      "Epoch 10/10\n",
      "1530/1530 [==============================] - 0s 176us/sample - loss: 0.2625 - acc: 0.8752 - val_loss: 0.2742 - val_acc: 0.8593\n",
      "Epoch 23 out of 150\n",
      "Train on 1530 samples, validate on 270 samples\n",
      "Epoch 1/10\n",
      "1530/1530 [==============================] - 0s 162us/sample - loss: 0.2627 - acc: 0.8673 - val_loss: 0.2990 - val_acc: 0.8741\n",
      "Epoch 2/10\n",
      "1530/1530 [==============================] - 0s 175us/sample - loss: 0.2641 - acc: 0.8752 - val_loss: 0.2839 - val_acc: 0.8704\n",
      "Epoch 3/10\n",
      "1530/1530 [==============================] - 0s 178us/sample - loss: 0.2585 - acc: 0.8699 - val_loss: 0.2742 - val_acc: 0.8630\n",
      "Epoch 4/10\n",
      "1530/1530 [==============================] - 0s 214us/sample - loss: 0.2585 - acc: 0.8706 - val_loss: 0.2814 - val_acc: 0.8704\n",
      "Epoch 5/10\n",
      "1530/1530 [==============================] - 0s 179us/sample - loss: 0.2592 - acc: 0.8693 - val_loss: 0.2935 - val_acc: 0.8630\n",
      "Epoch 6/10\n",
      "1530/1530 [==============================] - 0s 169us/sample - loss: 0.2629 - acc: 0.8712 - val_loss: 0.2717 - val_acc: 0.8556\n",
      "Epoch 7/10\n",
      "1530/1530 [==============================] - 0s 177us/sample - loss: 0.2553 - acc: 0.8712 - val_loss: 0.2899 - val_acc: 0.8741\n",
      "Epoch 8/10\n",
      "1530/1530 [==============================] - 0s 171us/sample - loss: 0.2603 - acc: 0.8699 - val_loss: 0.2763 - val_acc: 0.8593\n",
      "Epoch 9/10\n",
      "1530/1530 [==============================] - 0s 184us/sample - loss: 0.2562 - acc: 0.8660 - val_loss: 0.2741 - val_acc: 0.8593\n",
      "Epoch 10/10\n",
      "1530/1530 [==============================] - 0s 175us/sample - loss: 0.2576 - acc: 0.8699 - val_loss: 0.2714 - val_acc: 0.8556\n",
      "Epoch 24 out of 150\n",
      "Train on 1530 samples, validate on 270 samples\n",
      "Epoch 1/10\n",
      "1530/1530 [==============================] - 0s 164us/sample - loss: 0.2589 - acc: 0.8706 - val_loss: 0.2721 - val_acc: 0.8556\n",
      "Epoch 2/10\n",
      "1530/1530 [==============================] - 0s 167us/sample - loss: 0.2597 - acc: 0.8660 - val_loss: 0.2731 - val_acc: 0.8593\n",
      "Epoch 3/10\n",
      "1530/1530 [==============================] - 0s 185us/sample - loss: 0.2568 - acc: 0.8719 - val_loss: 0.2723 - val_acc: 0.8593\n",
      "Epoch 4/10\n",
      "1530/1530 [==============================] - 0s 212us/sample - loss: 0.2573 - acc: 0.8712 - val_loss: 0.2791 - val_acc: 0.8704\n",
      "Epoch 5/10\n",
      "1530/1530 [==============================] - 0s 180us/sample - loss: 0.2543 - acc: 0.8712 - val_loss: 0.2785 - val_acc: 0.8704\n",
      "Epoch 6/10\n",
      "1530/1530 [==============================] - 0s 181us/sample - loss: 0.2558 - acc: 0.8765 - val_loss: 0.2730 - val_acc: 0.8556\n",
      "Epoch 7/10\n",
      "1530/1530 [==============================] - 0s 171us/sample - loss: 0.2582 - acc: 0.8719 - val_loss: 0.2706 - val_acc: 0.8630\n",
      "Epoch 8/10\n",
      "1530/1530 [==============================] - 0s 171us/sample - loss: 0.2575 - acc: 0.8739 - val_loss: 0.2692 - val_acc: 0.8556\n",
      "Epoch 9/10\n",
      "1530/1530 [==============================] - 0s 175us/sample - loss: 0.2561 - acc: 0.8712 - val_loss: 0.2690 - val_acc: 0.8556\n",
      "Epoch 10/10\n",
      "1530/1530 [==============================] - 0s 172us/sample - loss: 0.2549 - acc: 0.8725 - val_loss: 0.2765 - val_acc: 0.8704\n",
      "Epoch 25 out of 150\n",
      "Train on 1530 samples, validate on 270 samples\n",
      "Epoch 1/10\n",
      "1530/1530 [==============================] - 0s 181us/sample - loss: 0.2536 - acc: 0.8745 - val_loss: 0.2676 - val_acc: 0.8556\n",
      "Epoch 2/10\n",
      "1530/1530 [==============================] - 0s 199us/sample - loss: 0.2562 - acc: 0.8719 - val_loss: 0.2689 - val_acc: 0.8630\n",
      "Epoch 3/10\n",
      "1530/1530 [==============================] - 0s 213us/sample - loss: 0.2568 - acc: 0.8719 - val_loss: 0.2737 - val_acc: 0.8667\n",
      "Epoch 4/10\n",
      "1530/1530 [==============================] - 0s 272us/sample - loss: 0.2544 - acc: 0.8706 - val_loss: 0.2696 - val_acc: 0.8593\n",
      "Epoch 5/10\n",
      "1530/1530 [==============================] - 0s 223us/sample - loss: 0.2560 - acc: 0.8758 - val_loss: 0.2693 - val_acc: 0.8556\n",
      "Epoch 6/10\n",
      "1530/1530 [==============================] - 0s 244us/sample - loss: 0.2529 - acc: 0.8725 - val_loss: 0.2717 - val_acc: 0.8556\n",
      "Epoch 7/10\n",
      "1530/1530 [==============================] - 0s 220us/sample - loss: 0.2537 - acc: 0.8699 - val_loss: 0.2670 - val_acc: 0.8556\n",
      "Epoch 8/10\n",
      "1530/1530 [==============================] - 0s 220us/sample - loss: 0.2556 - acc: 0.8739 - val_loss: 0.2691 - val_acc: 0.8593\n",
      "Epoch 9/10\n",
      "1530/1530 [==============================] - 0s 211us/sample - loss: 0.2561 - acc: 0.8719 - val_loss: 0.2740 - val_acc: 0.8704\n",
      "Epoch 10/10\n",
      "1530/1530 [==============================] - 0s 224us/sample - loss: 0.2548 - acc: 0.8752 - val_loss: 0.2680 - val_acc: 0.8556\n",
      "Epoch 26 out of 150\n",
      "Train on 1530 samples, validate on 270 samples\n",
      "Epoch 1/10\n",
      "1530/1530 [==============================] - 0s 173us/sample - loss: 0.2526 - acc: 0.8712 - val_loss: 0.2745 - val_acc: 0.8704\n",
      "Epoch 2/10\n",
      "1530/1530 [==============================] - 0s 181us/sample - loss: 0.2556 - acc: 0.8725 - val_loss: 0.2675 - val_acc: 0.8556\n",
      "Epoch 3/10\n",
      "1530/1530 [==============================] - 0s 169us/sample - loss: 0.2511 - acc: 0.8719 - val_loss: 0.2714 - val_acc: 0.8630\n",
      "Epoch 4/10\n",
      "1530/1530 [==============================] - 0s 212us/sample - loss: 0.2543 - acc: 0.8758 - val_loss: 0.2752 - val_acc: 0.8667\n",
      "Epoch 5/10\n",
      "1530/1530 [==============================] - 0s 169us/sample - loss: 0.2576 - acc: 0.8745 - val_loss: 0.2674 - val_acc: 0.8556\n",
      "Epoch 6/10\n",
      "1530/1530 [==============================] - 0s 214us/sample - loss: 0.2535 - acc: 0.8686 - val_loss: 0.2680 - val_acc: 0.8556\n",
      "Epoch 7/10\n",
      "1530/1530 [==============================] - 0s 181us/sample - loss: 0.2516 - acc: 0.8778 - val_loss: 0.2649 - val_acc: 0.8556\n",
      "Epoch 8/10\n",
      "1530/1530 [==============================] - 0s 186us/sample - loss: 0.2495 - acc: 0.8725 - val_loss: 0.2651 - val_acc: 0.8556\n",
      "Epoch 9/10\n",
      "1530/1530 [==============================] - 0s 186us/sample - loss: 0.2497 - acc: 0.8778 - val_loss: 0.2647 - val_acc: 0.8556\n",
      "Epoch 10/10\n",
      "1530/1530 [==============================] - 0s 208us/sample - loss: 0.2498 - acc: 0.8712 - val_loss: 0.2647 - val_acc: 0.8667\n",
      "Epoch 27 out of 150\n",
      "Train on 1530 samples, validate on 270 samples\n",
      "Epoch 1/10\n",
      "1530/1530 [==============================] - 0s 212us/sample - loss: 0.2500 - acc: 0.8765 - val_loss: 0.2680 - val_acc: 0.8630\n",
      "Epoch 2/10\n",
      "1530/1530 [==============================] - 0s 222us/sample - loss: 0.2493 - acc: 0.8778 - val_loss: 0.2672 - val_acc: 0.8667\n",
      "Epoch 3/10\n",
      "1530/1530 [==============================] - 0s 274us/sample - loss: 0.2496 - acc: 0.8739 - val_loss: 0.2641 - val_acc: 0.8556\n",
      "Epoch 4/10\n",
      "1530/1530 [==============================] - 0s 239us/sample - loss: 0.2505 - acc: 0.8784 - val_loss: 0.2728 - val_acc: 0.8704\n",
      "Epoch 5/10\n",
      "1530/1530 [==============================] - 0s 194us/sample - loss: 0.2499 - acc: 0.8771 - val_loss: 0.2631 - val_acc: 0.8556\n",
      "Epoch 6/10\n",
      "1530/1530 [==============================] - 0s 190us/sample - loss: 0.2510 - acc: 0.8752 - val_loss: 0.2639 - val_acc: 0.8556\n",
      "Epoch 7/10\n",
      "1530/1530 [==============================] - 0s 200us/sample - loss: 0.2496 - acc: 0.8758 - val_loss: 0.2705 - val_acc: 0.8704\n",
      "Epoch 8/10\n",
      "1530/1530 [==============================] - 0s 188us/sample - loss: 0.2478 - acc: 0.8732 - val_loss: 0.2654 - val_acc: 0.8667\n",
      "Epoch 9/10\n",
      "1530/1530 [==============================] - 0s 202us/sample - loss: 0.2538 - acc: 0.8771 - val_loss: 0.2728 - val_acc: 0.8593\n",
      "Epoch 10/10\n",
      "1530/1530 [==============================] - 0s 204us/sample - loss: 0.2496 - acc: 0.8739 - val_loss: 0.2623 - val_acc: 0.8667\n",
      "Epoch 28 out of 150\n",
      "Train on 1530 samples, validate on 270 samples\n",
      "Epoch 1/10\n",
      "1530/1530 [==============================] - 0s 170us/sample - loss: 0.2477 - acc: 0.8765 - val_loss: 0.2781 - val_acc: 0.8667\n",
      "Epoch 2/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1530/1530 [==============================] - 0s 203us/sample - loss: 0.2536 - acc: 0.8725 - val_loss: 0.2615 - val_acc: 0.8667\n",
      "Epoch 3/10\n",
      "1530/1530 [==============================] - 0s 177us/sample - loss: 0.2529 - acc: 0.8804 - val_loss: 0.2618 - val_acc: 0.8593\n",
      "Epoch 4/10\n",
      "1530/1530 [==============================] - 0s 223us/sample - loss: 0.2505 - acc: 0.8791 - val_loss: 0.2617 - val_acc: 0.8667\n",
      "Epoch 5/10\n",
      "1530/1530 [==============================] - 0s 177us/sample - loss: 0.2508 - acc: 0.8732 - val_loss: 0.2612 - val_acc: 0.8667\n",
      "Epoch 6/10\n",
      "1530/1530 [==============================] - 0s 177us/sample - loss: 0.2455 - acc: 0.8739 - val_loss: 0.2623 - val_acc: 0.8630\n",
      "Epoch 7/10\n",
      "1530/1530 [==============================] - 0s 168us/sample - loss: 0.2497 - acc: 0.8765 - val_loss: 0.2624 - val_acc: 0.8630\n",
      "Epoch 8/10\n",
      "1530/1530 [==============================] - 0s 165us/sample - loss: 0.2475 - acc: 0.8791 - val_loss: 0.2596 - val_acc: 0.8630\n",
      "Epoch 9/10\n",
      "1530/1530 [==============================] - 0s 174us/sample - loss: 0.2500 - acc: 0.8686 - val_loss: 0.2629 - val_acc: 0.8667\n",
      "Epoch 10/10\n",
      "1530/1530 [==============================] - 0s 173us/sample - loss: 0.2478 - acc: 0.8804 - val_loss: 0.2628 - val_acc: 0.8704\n",
      "Epoch 29 out of 150\n",
      "Train on 1530 samples, validate on 270 samples\n",
      "Epoch 1/10\n",
      "1530/1530 [==============================] - 0s 167us/sample - loss: 0.2433 - acc: 0.8778 - val_loss: 0.2589 - val_acc: 0.8667\n",
      "Epoch 2/10\n",
      "1530/1530 [==============================] - 0s 194us/sample - loss: 0.2470 - acc: 0.8765 - val_loss: 0.2586 - val_acc: 0.8667\n",
      "Epoch 3/10\n",
      "1530/1530 [==============================] - 0s 171us/sample - loss: 0.2436 - acc: 0.8784 - val_loss: 0.2688 - val_acc: 0.8704\n",
      "Epoch 4/10\n",
      "1530/1530 [==============================] - 0s 206us/sample - loss: 0.2482 - acc: 0.8791 - val_loss: 0.2646 - val_acc: 0.8704\n",
      "Epoch 5/10\n",
      "1530/1530 [==============================] - 0s 168us/sample - loss: 0.2449 - acc: 0.8778 - val_loss: 0.2579 - val_acc: 0.8593\n",
      "Epoch 6/10\n",
      "1530/1530 [==============================] - 0s 177us/sample - loss: 0.2456 - acc: 0.8771 - val_loss: 0.2623 - val_acc: 0.8704\n",
      "Epoch 7/10\n",
      "1530/1530 [==============================] - 0s 169us/sample - loss: 0.2448 - acc: 0.8784 - val_loss: 0.2577 - val_acc: 0.8667\n",
      "Epoch 8/10\n",
      "1530/1530 [==============================] - 0s 178us/sample - loss: 0.2503 - acc: 0.8686 - val_loss: 0.2669 - val_acc: 0.8704\n",
      "Epoch 9/10\n",
      "1530/1530 [==============================] - 0s 180us/sample - loss: 0.2469 - acc: 0.8797 - val_loss: 0.2591 - val_acc: 0.8630\n",
      "Epoch 10/10\n",
      "1530/1530 [==============================] - 0s 169us/sample - loss: 0.2437 - acc: 0.8765 - val_loss: 0.2575 - val_acc: 0.8667\n",
      "Epoch 30 out of 150\n",
      "Train on 1530 samples, validate on 270 samples\n",
      "Epoch 1/10\n",
      "1530/1530 [==============================] - 0s 164us/sample - loss: 0.2464 - acc: 0.8739 - val_loss: 0.2622 - val_acc: 0.8667\n",
      "Epoch 2/10\n",
      "1530/1530 [==============================] - 0s 179us/sample - loss: 0.2439 - acc: 0.8778 - val_loss: 0.2586 - val_acc: 0.8667\n",
      "Epoch 3/10\n",
      "1530/1530 [==============================] - 0s 171us/sample - loss: 0.2425 - acc: 0.8797 - val_loss: 0.2560 - val_acc: 0.8630\n",
      "Epoch 4/10\n",
      "1530/1530 [==============================] - 0s 218us/sample - loss: 0.2433 - acc: 0.8791 - val_loss: 0.2564 - val_acc: 0.8630\n",
      "Epoch 5/10\n",
      "1530/1530 [==============================] - 0s 186us/sample - loss: 0.2494 - acc: 0.8778 - val_loss: 0.2683 - val_acc: 0.8667\n",
      "Epoch 6/10\n",
      "1530/1530 [==============================] - 0s 175us/sample - loss: 0.2405 - acc: 0.8797 - val_loss: 0.2605 - val_acc: 0.8667\n",
      "Epoch 7/10\n",
      "1530/1530 [==============================] - 0s 171us/sample - loss: 0.2428 - acc: 0.8791 - val_loss: 0.2636 - val_acc: 0.8667\n",
      "Epoch 8/10\n",
      "1530/1530 [==============================] - 0s 167us/sample - loss: 0.2431 - acc: 0.8804 - val_loss: 0.2570 - val_acc: 0.8667\n",
      "Epoch 9/10\n",
      "1530/1530 [==============================] - 0s 188us/sample - loss: 0.2407 - acc: 0.8765 - val_loss: 0.2559 - val_acc: 0.8667\n",
      "Epoch 10/10\n",
      "1530/1530 [==============================] - 0s 173us/sample - loss: 0.2418 - acc: 0.8765 - val_loss: 0.2897 - val_acc: 0.8556\n",
      "Epoch 31 out of 150\n",
      "Train on 1530 samples, validate on 270 samples\n",
      "Epoch 1/10\n",
      "1530/1530 [==============================] - 0s 170us/sample - loss: 0.2443 - acc: 0.8758 - val_loss: 0.2571 - val_acc: 0.8667\n",
      "Epoch 2/10\n",
      "1530/1530 [==============================] - 0s 177us/sample - loss: 0.2437 - acc: 0.8712 - val_loss: 0.2582 - val_acc: 0.8667\n",
      "Epoch 3/10\n",
      "1530/1530 [==============================] - 0s 176us/sample - loss: 0.2431 - acc: 0.8810 - val_loss: 0.2563 - val_acc: 0.8704\n",
      "Epoch 4/10\n",
      "1530/1530 [==============================] - 0s 222us/sample - loss: 0.2410 - acc: 0.8804 - val_loss: 0.2530 - val_acc: 0.8667\n",
      "Epoch 5/10\n",
      "1530/1530 [==============================] - 0s 194us/sample - loss: 0.2400 - acc: 0.8771 - val_loss: 0.2531 - val_acc: 0.8667\n",
      "Epoch 6/10\n",
      "1530/1530 [==============================] - 0s 170us/sample - loss: 0.2395 - acc: 0.8817 - val_loss: 0.2583 - val_acc: 0.8704\n",
      "Epoch 7/10\n",
      "1530/1530 [==============================] - 0s 180us/sample - loss: 0.2404 - acc: 0.8797 - val_loss: 0.2544 - val_acc: 0.8667\n",
      "Epoch 8/10\n",
      "1530/1530 [==============================] - 0s 175us/sample - loss: 0.2387 - acc: 0.8804 - val_loss: 0.2547 - val_acc: 0.8630\n",
      "Epoch 9/10\n",
      "1530/1530 [==============================] - 0s 191us/sample - loss: 0.2400 - acc: 0.8784 - val_loss: 0.2519 - val_acc: 0.8630\n",
      "Epoch 10/10\n",
      "1530/1530 [==============================] - 0s 220us/sample - loss: 0.2398 - acc: 0.8804 - val_loss: 0.2524 - val_acc: 0.8704\n",
      "Epoch 32 out of 150\n",
      "Train on 1530 samples, validate on 270 samples\n",
      "Epoch 1/10\n",
      "1530/1530 [==============================] - 0s 205us/sample - loss: 0.2393 - acc: 0.8739 - val_loss: 0.2553 - val_acc: 0.8667\n",
      "Epoch 2/10\n",
      "1530/1530 [==============================] - 0s 206us/sample - loss: 0.2393 - acc: 0.8784 - val_loss: 0.2550 - val_acc: 0.8704\n",
      "Epoch 3/10\n",
      "1530/1530 [==============================] - 0s 270us/sample - loss: 0.2420 - acc: 0.8719 - val_loss: 0.2567 - val_acc: 0.8741\n",
      "Epoch 4/10\n",
      "1530/1530 [==============================] - 0s 214us/sample - loss: 0.2399 - acc: 0.8830 - val_loss: 0.2515 - val_acc: 0.8667\n",
      "Epoch 5/10\n",
      "1530/1530 [==============================] - 0s 175us/sample - loss: 0.2381 - acc: 0.8817 - val_loss: 0.2507 - val_acc: 0.8667\n",
      "Epoch 6/10\n",
      "1530/1530 [==============================] - 0s 183us/sample - loss: 0.2425 - acc: 0.8778 - val_loss: 0.2504 - val_acc: 0.8667\n",
      "Epoch 7/10\n",
      "1530/1530 [==============================] - 0s 189us/sample - loss: 0.2391 - acc: 0.8784 - val_loss: 0.2580 - val_acc: 0.8704\n",
      "Epoch 8/10\n",
      "1530/1530 [==============================] - 0s 188us/sample - loss: 0.2408 - acc: 0.8817 - val_loss: 0.2503 - val_acc: 0.8630\n",
      "Epoch 9/10\n",
      "1530/1530 [==============================] - 0s 187us/sample - loss: 0.2384 - acc: 0.8791 - val_loss: 0.2526 - val_acc: 0.8667\n",
      "Epoch 10/10\n",
      "1530/1530 [==============================] - 0s 198us/sample - loss: 0.2410 - acc: 0.8784 - val_loss: 0.2580 - val_acc: 0.8741\n",
      "Epoch 33 out of 150\n",
      "Train on 1530 samples, validate on 270 samples\n",
      "Epoch 1/10\n",
      "1530/1530 [==============================] - 0s 173us/sample - loss: 0.2384 - acc: 0.8791 - val_loss: 0.2497 - val_acc: 0.8630\n",
      "Epoch 2/10\n",
      "1530/1530 [==============================] - 0s 187us/sample - loss: 0.2364 - acc: 0.8797 - val_loss: 0.2504 - val_acc: 0.8667\n",
      "Epoch 3/10\n",
      "1530/1530 [==============================] - 0s 170us/sample - loss: 0.2389 - acc: 0.8837 - val_loss: 0.2493 - val_acc: 0.8630\n",
      "Epoch 4/10\n",
      "1530/1530 [==============================] - ETA: 0s - loss: 0.2375 - acc: 0.876 - 0s 226us/sample - loss: 0.2394 - acc: 0.8771 - val_loss: 0.2583 - val_acc: 0.8704\n",
      "Epoch 5/10\n",
      "1530/1530 [==============================] - 0s 190us/sample - loss: 0.2357 - acc: 0.8837 - val_loss: 0.2483 - val_acc: 0.8630\n",
      "Epoch 6/10\n",
      "1530/1530 [==============================] - 0s 186us/sample - loss: 0.2347 - acc: 0.8797 - val_loss: 0.2497 - val_acc: 0.8667\n",
      "Epoch 7/10\n",
      "1530/1530 [==============================] - 0s 186us/sample - loss: 0.2433 - acc: 0.8719 - val_loss: 0.2482 - val_acc: 0.8630\n",
      "Epoch 8/10\n",
      "1530/1530 [==============================] - 0s 186us/sample - loss: 0.2367 - acc: 0.8771 - val_loss: 0.2652 - val_acc: 0.8852\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/10\n",
      "1530/1530 [==============================] - 0s 192us/sample - loss: 0.2384 - acc: 0.8824 - val_loss: 0.2465 - val_acc: 0.8667\n",
      "Epoch 10/10\n",
      "1530/1530 [==============================] - 0s 170us/sample - loss: 0.2403 - acc: 0.8771 - val_loss: 0.2484 - val_acc: 0.8667\n",
      "Epoch 34 out of 150\n",
      "Train on 1530 samples, validate on 270 samples\n",
      "Epoch 1/10\n",
      "1530/1530 [==============================] - 0s 197us/sample - loss: 0.2341 - acc: 0.8824 - val_loss: 0.2477 - val_acc: 0.8741\n",
      "Epoch 2/10\n",
      "1530/1530 [==============================] - 0s 204us/sample - loss: 0.2411 - acc: 0.8784 - val_loss: 0.2475 - val_acc: 0.8741\n",
      "Epoch 3/10\n",
      "1530/1530 [==============================] - 0s 226us/sample - loss: 0.2332 - acc: 0.8817 - val_loss: 0.2490 - val_acc: 0.8741\n",
      "Epoch 4/10\n",
      "1530/1530 [==============================] - 0s 226us/sample - loss: 0.2344 - acc: 0.8810 - val_loss: 0.2471 - val_acc: 0.8704\n",
      "Epoch 5/10\n",
      "1530/1530 [==============================] - 0s 190us/sample - loss: 0.2347 - acc: 0.8791 - val_loss: 0.2465 - val_acc: 0.8667\n",
      "Epoch 6/10\n",
      "1530/1530 [==============================] - 0s 211us/sample - loss: 0.2331 - acc: 0.8843 - val_loss: 0.2466 - val_acc: 0.8667\n",
      "Epoch 7/10\n",
      "1530/1530 [==============================] - 0s 207us/sample - loss: 0.2333 - acc: 0.8804 - val_loss: 0.2477 - val_acc: 0.8778\n",
      "Epoch 8/10\n",
      "1530/1530 [==============================] - 0s 211us/sample - loss: 0.2331 - acc: 0.8850 - val_loss: 0.2455 - val_acc: 0.8667\n",
      "Epoch 9/10\n",
      "1530/1530 [==============================] - 0s 191us/sample - loss: 0.2346 - acc: 0.8817 - val_loss: 0.2487 - val_acc: 0.8741\n",
      "Epoch 10/10\n",
      "1530/1530 [==============================] - 0s 186us/sample - loss: 0.2360 - acc: 0.8804 - val_loss: 0.2457 - val_acc: 0.8667\n",
      "Epoch 35 out of 150\n",
      "Train on 1530 samples, validate on 270 samples\n",
      "Epoch 1/10\n",
      "1530/1530 [==============================] - 0s 166us/sample - loss: 0.2368 - acc: 0.8784 - val_loss: 0.2631 - val_acc: 0.8815\n",
      "Epoch 2/10\n",
      "1530/1530 [==============================] - 0s 181us/sample - loss: 0.2376 - acc: 0.8752 - val_loss: 0.2483 - val_acc: 0.8667\n",
      "Epoch 3/10\n",
      "1530/1530 [==============================] - 0s 186us/sample - loss: 0.2359 - acc: 0.8797 - val_loss: 0.2441 - val_acc: 0.8704\n",
      "Epoch 4/10\n",
      "1530/1530 [==============================] - 0s 214us/sample - loss: 0.2353 - acc: 0.8686 - val_loss: 0.2462 - val_acc: 0.8704\n",
      "Epoch 5/10\n",
      "1530/1530 [==============================] - 0s 169us/sample - loss: 0.2316 - acc: 0.8895 - val_loss: 0.2596 - val_acc: 0.8778\n",
      "Epoch 6/10\n",
      "1530/1530 [==============================] - 0s 178us/sample - loss: 0.2343 - acc: 0.8797 - val_loss: 0.2461 - val_acc: 0.8778\n",
      "Epoch 7/10\n",
      "1530/1530 [==============================] - 0s 186us/sample - loss: 0.2321 - acc: 0.8830 - val_loss: 0.2435 - val_acc: 0.8667\n",
      "Epoch 8/10\n",
      "1530/1530 [==============================] - 0s 169us/sample - loss: 0.2362 - acc: 0.8837 - val_loss: 0.2495 - val_acc: 0.8778\n",
      "Epoch 9/10\n",
      "1530/1530 [==============================] - 0s 169us/sample - loss: 0.2358 - acc: 0.8824 - val_loss: 0.2423 - val_acc: 0.8704\n",
      "Epoch 10/10\n",
      "1530/1530 [==============================] - 0s 175us/sample - loss: 0.2323 - acc: 0.8804 - val_loss: 0.2427 - val_acc: 0.8704\n",
      "Epoch 36 out of 150\n",
      "Train on 1530 samples, validate on 270 samples\n",
      "Epoch 1/10\n",
      "1530/1530 [==============================] - 0s 164us/sample - loss: 0.2311 - acc: 0.8817 - val_loss: 0.2460 - val_acc: 0.8704\n",
      "Epoch 2/10\n",
      "1530/1530 [==============================] - 0s 179us/sample - loss: 0.2314 - acc: 0.8863 - val_loss: 0.2423 - val_acc: 0.8704\n",
      "Epoch 3/10\n",
      "1530/1530 [==============================] - 0s 183us/sample - loss: 0.2362 - acc: 0.8850 - val_loss: 0.2438 - val_acc: 0.8704\n",
      "Epoch 4/10\n",
      "1530/1530 [==============================] - 0s 241us/sample - loss: 0.2329 - acc: 0.8817 - val_loss: 0.2449 - val_acc: 0.8741\n",
      "Epoch 5/10\n",
      "1530/1530 [==============================] - 0s 175us/sample - loss: 0.2339 - acc: 0.8817 - val_loss: 0.2451 - val_acc: 0.8741\n",
      "Epoch 6/10\n",
      "1530/1530 [==============================] - 0s 183us/sample - loss: 0.2337 - acc: 0.8824 - val_loss: 0.2426 - val_acc: 0.8704\n",
      "Epoch 7/10\n",
      "1530/1530 [==============================] - 0s 197us/sample - loss: 0.2310 - acc: 0.8797 - val_loss: 0.2419 - val_acc: 0.8704\n",
      "Epoch 8/10\n",
      "1530/1530 [==============================] - 0s 217us/sample - loss: 0.2303 - acc: 0.8824 - val_loss: 0.2407 - val_acc: 0.8704\n",
      "Epoch 9/10\n",
      "1530/1530 [==============================] - 0s 222us/sample - loss: 0.2295 - acc: 0.8824 - val_loss: 0.2412 - val_acc: 0.8704\n",
      "Epoch 10/10\n",
      "1530/1530 [==============================] - 0s 217us/sample - loss: 0.2321 - acc: 0.8843 - val_loss: 0.2404 - val_acc: 0.8704\n",
      "Epoch 37 out of 150\n",
      "Train on 1530 samples, validate on 270 samples\n",
      "Epoch 1/10\n",
      "1530/1530 [==============================] - 0s 194us/sample - loss: 0.2284 - acc: 0.8810 - val_loss: 0.2527 - val_acc: 0.8815\n",
      "Epoch 2/10\n",
      "1530/1530 [==============================] - 0s 213us/sample - loss: 0.2322 - acc: 0.8876 - val_loss: 0.2463 - val_acc: 0.8741\n",
      "Epoch 3/10\n",
      "1530/1530 [==============================] - 0s 196us/sample - loss: 0.2294 - acc: 0.8804 - val_loss: 0.2433 - val_acc: 0.8704\n",
      "Epoch 4/10\n",
      "1530/1530 [==============================] - 0s 202us/sample - loss: 0.2307 - acc: 0.8824 - val_loss: 0.2407 - val_acc: 0.8704\n",
      "Epoch 5/10\n",
      "1530/1530 [==============================] - 0s 167us/sample - loss: 0.2286 - acc: 0.8863 - val_loss: 0.2531 - val_acc: 0.8778\n",
      "Epoch 6/10\n",
      "1530/1530 [==============================] - 0s 199us/sample - loss: 0.2319 - acc: 0.8824 - val_loss: 0.2391 - val_acc: 0.8704\n",
      "Epoch 7/10\n",
      "1530/1530 [==============================] - 0s 179us/sample - loss: 0.2301 - acc: 0.8771 - val_loss: 0.2464 - val_acc: 0.8815\n",
      "Epoch 8/10\n",
      "1530/1530 [==============================] - 0s 208us/sample - loss: 0.2294 - acc: 0.8837 - val_loss: 0.2396 - val_acc: 0.8704\n",
      "Epoch 9/10\n",
      "1530/1530 [==============================] - 0s 176us/sample - loss: 0.2276 - acc: 0.8810 - val_loss: 0.2400 - val_acc: 0.8704\n",
      "Epoch 10/10\n",
      "1530/1530 [==============================] - 0s 173us/sample - loss: 0.2300 - acc: 0.8824 - val_loss: 0.2394 - val_acc: 0.8704\n",
      "Epoch 38 out of 150\n",
      "Train on 1530 samples, validate on 270 samples\n",
      "Epoch 1/10\n",
      "1530/1530 [==============================] - 0s 167us/sample - loss: 0.2340 - acc: 0.8863 - val_loss: 0.2387 - val_acc: 0.8704\n",
      "Epoch 2/10\n",
      "1530/1530 [==============================] - 0s 182us/sample - loss: 0.2308 - acc: 0.8850 - val_loss: 0.2408 - val_acc: 0.8778\n",
      "Epoch 3/10\n",
      "1530/1530 [==============================] - 0s 201us/sample - loss: 0.2267 - acc: 0.8830 - val_loss: 0.2408 - val_acc: 0.8778\n",
      "Epoch 4/10\n",
      "1530/1530 [==============================] - 0s 271us/sample - loss: 0.2299 - acc: 0.8850 - val_loss: 0.2380 - val_acc: 0.8741\n",
      "Epoch 5/10\n",
      "1530/1530 [==============================] - 0s 173us/sample - loss: 0.2264 - acc: 0.8817 - val_loss: 0.2392 - val_acc: 0.8667\n",
      "Epoch 6/10\n",
      "1530/1530 [==============================] - 0s 180us/sample - loss: 0.2293 - acc: 0.8817 - val_loss: 0.2533 - val_acc: 0.8778\n",
      "Epoch 7/10\n",
      "1530/1530 [==============================] - 0s 227us/sample - loss: 0.2305 - acc: 0.8850 - val_loss: 0.2372 - val_acc: 0.8704\n",
      "Epoch 8/10\n",
      "1530/1530 [==============================] - 0s 215us/sample - loss: 0.2355 - acc: 0.8804 - val_loss: 0.2366 - val_acc: 0.8704\n",
      "Epoch 9/10\n",
      "1530/1530 [==============================] - 0s 197us/sample - loss: 0.2305 - acc: 0.8791 - val_loss: 0.2389 - val_acc: 0.8778\n",
      "Epoch 10/10\n",
      "1530/1530 [==============================] - 0s 256us/sample - loss: 0.2302 - acc: 0.8856 - val_loss: 0.2360 - val_acc: 0.8741\n",
      "Epoch 39 out of 150\n",
      "Train on 1530 samples, validate on 270 samples\n",
      "Epoch 1/10\n",
      "1530/1530 [==============================] - 0s 232us/sample - loss: 0.2259 - acc: 0.8843 - val_loss: 0.2352 - val_acc: 0.8704\n",
      "Epoch 2/10\n",
      "1530/1530 [==============================] - 0s 216us/sample - loss: 0.2243 - acc: 0.8869 - val_loss: 0.2429 - val_acc: 0.8852\n",
      "Epoch 3/10\n",
      "1530/1530 [==============================] - 0s 273us/sample - loss: 0.2263 - acc: 0.8856 - val_loss: 0.2369 - val_acc: 0.8704\n",
      "Epoch 4/10\n",
      "1530/1530 [==============================] - 0s 214us/sample - loss: 0.2263 - acc: 0.8863 - val_loss: 0.2510 - val_acc: 0.8889\n",
      "Epoch 5/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1530/1530 [==============================] - 0s 206us/sample - loss: 0.2343 - acc: 0.8810 - val_loss: 0.2409 - val_acc: 0.8741\n",
      "Epoch 6/10\n",
      "1530/1530 [==============================] - 0s 214us/sample - loss: 0.2242 - acc: 0.8850 - val_loss: 0.2399 - val_acc: 0.8815\n",
      "Epoch 7/10\n",
      "1530/1530 [==============================] - 0s 182us/sample - loss: 0.2250 - acc: 0.8837 - val_loss: 0.2358 - val_acc: 0.8704\n",
      "Epoch 8/10\n",
      "1530/1530 [==============================] - 0s 213us/sample - loss: 0.2232 - acc: 0.8817 - val_loss: 0.2388 - val_acc: 0.8704\n",
      "Epoch 9/10\n",
      "1530/1530 [==============================] - 0s 187us/sample - loss: 0.2295 - acc: 0.8837 - val_loss: 0.2365 - val_acc: 0.8704\n",
      "Epoch 10/10\n",
      "1530/1530 [==============================] - 0s 192us/sample - loss: 0.2249 - acc: 0.8830 - val_loss: 0.2369 - val_acc: 0.8704\n",
      "Epoch 40 out of 150\n",
      "Train on 1530 samples, validate on 270 samples\n",
      "Epoch 1/10\n",
      "1530/1530 [==============================] - 0s 181us/sample - loss: 0.2251 - acc: 0.8856 - val_loss: 0.2364 - val_acc: 0.8778\n",
      "Epoch 2/10\n",
      "1530/1530 [==============================] - 0s 181us/sample - loss: 0.2241 - acc: 0.8837 - val_loss: 0.2352 - val_acc: 0.8704\n",
      "Epoch 3/10\n",
      "1530/1530 [==============================] - 0s 194us/sample - loss: 0.2271 - acc: 0.8830 - val_loss: 0.2394 - val_acc: 0.8704\n",
      "Epoch 4/10\n",
      "1530/1530 [==============================] - 0s 241us/sample - loss: 0.2264 - acc: 0.8804 - val_loss: 0.2387 - val_acc: 0.8778\n",
      "Epoch 5/10\n",
      "1530/1530 [==============================] - 0s 186us/sample - loss: 0.2234 - acc: 0.8824 - val_loss: 0.2340 - val_acc: 0.8704\n",
      "Epoch 6/10\n",
      "1530/1530 [==============================] - 0s 179us/sample - loss: 0.2233 - acc: 0.8882 - val_loss: 0.2368 - val_acc: 0.8778\n",
      "Epoch 7/10\n",
      "1530/1530 [==============================] - 0s 171us/sample - loss: 0.2246 - acc: 0.8869 - val_loss: 0.2484 - val_acc: 0.8852\n",
      "Epoch 8/10\n",
      "1530/1530 [==============================] - 0s 173us/sample - loss: 0.2276 - acc: 0.8784 - val_loss: 0.2378 - val_acc: 0.8815\n",
      "Epoch 9/10\n",
      "1530/1530 [==============================] - 0s 169us/sample - loss: 0.2233 - acc: 0.8869 - val_loss: 0.2367 - val_acc: 0.8704\n",
      "Epoch 10/10\n",
      "1530/1530 [==============================] - 0s 204us/sample - loss: 0.2229 - acc: 0.8863 - val_loss: 0.2362 - val_acc: 0.8741\n",
      "Epoch 41 out of 150\n",
      "Train on 1530 samples, validate on 270 samples\n",
      "Epoch 1/10\n",
      "1530/1530 [==============================] - 0s 172us/sample - loss: 0.2260 - acc: 0.8830 - val_loss: 0.2376 - val_acc: 0.8741\n",
      "Epoch 2/10\n",
      "1530/1530 [==============================] - 0s 206us/sample - loss: 0.2224 - acc: 0.8850 - val_loss: 0.2331 - val_acc: 0.8704\n",
      "Epoch 3/10\n",
      "1530/1530 [==============================] - 0s 241us/sample - loss: 0.2217 - acc: 0.8863 - val_loss: 0.2350 - val_acc: 0.8778\n",
      "Epoch 4/10\n",
      "1530/1530 [==============================] - 0s 268us/sample - loss: 0.2217 - acc: 0.8843 - val_loss: 0.2359 - val_acc: 0.8852\n",
      "Epoch 5/10\n",
      "1530/1530 [==============================] - 0s 228us/sample - loss: 0.2226 - acc: 0.8850 - val_loss: 0.2326 - val_acc: 0.8704\n",
      "Epoch 6/10\n",
      "1530/1530 [==============================] - 0s 234us/sample - loss: 0.2227 - acc: 0.8850 - val_loss: 0.2386 - val_acc: 0.8778\n",
      "Epoch 7/10\n",
      "1530/1530 [==============================] - 0s 230us/sample - loss: 0.2235 - acc: 0.8817 - val_loss: 0.2461 - val_acc: 0.8852\n",
      "Epoch 8/10\n",
      "1530/1530 [==============================] - 0s 255us/sample - loss: 0.2223 - acc: 0.8830 - val_loss: 0.2334 - val_acc: 0.8741\n",
      "Epoch 9/10\n",
      "1530/1530 [==============================] - 0s 194us/sample - loss: 0.2267 - acc: 0.8804 - val_loss: 0.2351 - val_acc: 0.8778\n",
      "Epoch 10/10\n",
      "1530/1530 [==============================] - 0s 291us/sample - loss: 0.2215 - acc: 0.8843 - val_loss: 0.2327 - val_acc: 0.8704\n",
      "Epoch 42 out of 150\n",
      "Train on 1530 samples, validate on 270 samples\n",
      "Epoch 1/10\n",
      "1530/1530 [==============================] - 0s 272us/sample - loss: 0.2275 - acc: 0.8778 - val_loss: 0.2395 - val_acc: 0.8778\n",
      "Epoch 2/10\n",
      "1530/1530 [==============================] - 0s 218us/sample - loss: 0.2208 - acc: 0.8843 - val_loss: 0.2433 - val_acc: 0.8889\n",
      "Epoch 3/10\n",
      "1530/1530 [==============================] - 0s 248us/sample - loss: 0.2196 - acc: 0.8935 - val_loss: 0.2499 - val_acc: 0.8889\n",
      "Epoch 4/10\n",
      "1530/1530 [==============================] - 0s 215us/sample - loss: 0.2215 - acc: 0.8922 - val_loss: 0.2424 - val_acc: 0.8778\n",
      "Epoch 5/10\n",
      "1530/1530 [==============================] - 0s 225us/sample - loss: 0.2251 - acc: 0.8791 - val_loss: 0.2398 - val_acc: 0.8815\n",
      "Epoch 6/10\n",
      "1530/1530 [==============================] - 0s 233us/sample - loss: 0.2217 - acc: 0.8817 - val_loss: 0.2356 - val_acc: 0.8741\n",
      "Epoch 7/10\n",
      "1530/1530 [==============================] - 0s 261us/sample - loss: 0.2227 - acc: 0.8863 - val_loss: 0.2312 - val_acc: 0.8704\n",
      "Epoch 8/10\n",
      "1530/1530 [==============================] - 0s 246us/sample - loss: 0.2208 - acc: 0.8863 - val_loss: 0.2306 - val_acc: 0.8704\n",
      "Epoch 9/10\n",
      "1530/1530 [==============================] - 0s 207us/sample - loss: 0.2185 - acc: 0.8895 - val_loss: 0.2371 - val_acc: 0.8926\n",
      "Epoch 10/10\n",
      "1530/1530 [==============================] - 0s 258us/sample - loss: 0.2206 - acc: 0.8843 - val_loss: 0.2326 - val_acc: 0.8704\n",
      "Epoch 43 out of 150\n",
      "Train on 1530 samples, validate on 270 samples\n",
      "Epoch 1/10\n",
      "1530/1530 [==============================] - 0s 235us/sample - loss: 0.2203 - acc: 0.8856 - val_loss: 0.2314 - val_acc: 0.8704\n",
      "Epoch 2/10\n",
      "1530/1530 [==============================] - 0s 268us/sample - loss: 0.2206 - acc: 0.8843 - val_loss: 0.2347 - val_acc: 0.8852\n",
      "Epoch 3/10\n",
      "1530/1530 [==============================] - 0s 250us/sample - loss: 0.2202 - acc: 0.8837 - val_loss: 0.2308 - val_acc: 0.8778\n",
      "Epoch 4/10\n",
      "1530/1530 [==============================] - 0s 261us/sample - loss: 0.2197 - acc: 0.8876 - val_loss: 0.2336 - val_acc: 0.8926\n",
      "Epoch 5/10\n",
      "1530/1530 [==============================] - 0s 259us/sample - loss: 0.2197 - acc: 0.8824 - val_loss: 0.2610 - val_acc: 0.8815\n",
      "Epoch 6/10\n",
      "1530/1530 [==============================] - 0s 203us/sample - loss: 0.2204 - acc: 0.8843 - val_loss: 0.2302 - val_acc: 0.8704\n",
      "Epoch 7/10\n",
      "1530/1530 [==============================] - 0s 250us/sample - loss: 0.2174 - acc: 0.8876 - val_loss: 0.2377 - val_acc: 0.8815\n",
      "Epoch 8/10\n",
      "1530/1530 [==============================] - 0s 203us/sample - loss: 0.2193 - acc: 0.8876 - val_loss: 0.2435 - val_acc: 0.8852\n",
      "Epoch 9/10\n",
      "1530/1530 [==============================] - 0s 237us/sample - loss: 0.2215 - acc: 0.8856 - val_loss: 0.2302 - val_acc: 0.8704\n",
      "Epoch 10/10\n",
      "1530/1530 [==============================] - 0s 258us/sample - loss: 0.2185 - acc: 0.8876 - val_loss: 0.2316 - val_acc: 0.8704\n",
      "Epoch 44 out of 150\n",
      "Train on 1530 samples, validate on 270 samples\n",
      "Epoch 1/10\n",
      "1530/1530 [==============================] - 0s 187us/sample - loss: 0.2203 - acc: 0.8843 - val_loss: 0.2342 - val_acc: 0.8852\n",
      "Epoch 2/10\n",
      "1530/1530 [==============================] - 0s 203us/sample - loss: 0.2173 - acc: 0.8863 - val_loss: 0.2287 - val_acc: 0.8704\n",
      "Epoch 3/10\n",
      "1530/1530 [==============================] - 0s 190us/sample - loss: 0.2208 - acc: 0.8830 - val_loss: 0.2315 - val_acc: 0.8815\n",
      "Epoch 4/10\n",
      "1530/1530 [==============================] - 0s 246us/sample - loss: 0.2184 - acc: 0.8869 - val_loss: 0.2288 - val_acc: 0.8704\n",
      "Epoch 5/10\n",
      "1530/1530 [==============================] - 0s 189us/sample - loss: 0.2183 - acc: 0.8850 - val_loss: 0.2301 - val_acc: 0.8741\n",
      "Epoch 6/10\n",
      "1530/1530 [==============================] - 0s 218us/sample - loss: 0.2180 - acc: 0.8843 - val_loss: 0.2335 - val_acc: 0.8815\n",
      "Epoch 7/10\n",
      "1530/1530 [==============================] - 0s 209us/sample - loss: 0.2178 - acc: 0.8824 - val_loss: 0.2289 - val_acc: 0.8704\n",
      "Epoch 8/10\n",
      "1530/1530 [==============================] - 0s 187us/sample - loss: 0.2164 - acc: 0.8837 - val_loss: 0.2425 - val_acc: 0.8815\n",
      "Epoch 9/10\n",
      "1530/1530 [==============================] - 0s 215us/sample - loss: 0.2203 - acc: 0.8876 - val_loss: 0.2298 - val_acc: 0.8741\n",
      "Epoch 10/10\n",
      "1530/1530 [==============================] - 0s 186us/sample - loss: 0.2173 - acc: 0.8850 - val_loss: 0.2293 - val_acc: 0.8704\n",
      "Epoch 45 out of 150\n",
      "Train on 1530 samples, validate on 270 samples\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1530/1530 [==============================] - 0s 183us/sample - loss: 0.2170 - acc: 0.8856 - val_loss: 0.2286 - val_acc: 0.8704\n",
      "Epoch 2/10\n",
      "1530/1530 [==============================] - 0s 178us/sample - loss: 0.2156 - acc: 0.8902 - val_loss: 0.2300 - val_acc: 0.8778\n",
      "Epoch 3/10\n",
      "1530/1530 [==============================] - 0s 183us/sample - loss: 0.2166 - acc: 0.8856 - val_loss: 0.2312 - val_acc: 0.8704\n",
      "Epoch 4/10\n",
      "1530/1530 [==============================] - 0s 258us/sample - loss: 0.2176 - acc: 0.8908 - val_loss: 0.2281 - val_acc: 0.8778\n",
      "Epoch 5/10\n",
      "1530/1530 [==============================] - 0s 224us/sample - loss: 0.2157 - acc: 0.8824 - val_loss: 0.2480 - val_acc: 0.8926\n",
      "Epoch 6/10\n",
      "1530/1530 [==============================] - 0s 234us/sample - loss: 0.2218 - acc: 0.8824 - val_loss: 0.2443 - val_acc: 0.8963\n",
      "Epoch 7/10\n",
      "1530/1530 [==============================] - 0s 218us/sample - loss: 0.2194 - acc: 0.8902 - val_loss: 0.2372 - val_acc: 0.8741\n",
      "Epoch 8/10\n",
      "1530/1530 [==============================] - 0s 231us/sample - loss: 0.2173 - acc: 0.8843 - val_loss: 0.2275 - val_acc: 0.8704\n",
      "Epoch 9/10\n",
      "1530/1530 [==============================] - 0s 242us/sample - loss: 0.2148 - acc: 0.8882 - val_loss: 0.2288 - val_acc: 0.8704\n",
      "Epoch 10/10\n",
      "1530/1530 [==============================] - 0s 194us/sample - loss: 0.2159 - acc: 0.8856 - val_loss: 0.2267 - val_acc: 0.8741\n",
      "Epoch 46 out of 150\n",
      "Train on 1530 samples, validate on 270 samples\n",
      "Epoch 1/10\n",
      "1530/1530 [==============================] - 0s 177us/sample - loss: 0.2162 - acc: 0.8876 - val_loss: 0.2270 - val_acc: 0.8704\n",
      "Epoch 2/10\n",
      "1530/1530 [==============================] - 0s 196us/sample - loss: 0.2157 - acc: 0.8850 - val_loss: 0.2294 - val_acc: 0.8704\n",
      "Epoch 3/10\n",
      "1530/1530 [==============================] - 0s 182us/sample - loss: 0.2150 - acc: 0.8824 - val_loss: 0.2276 - val_acc: 0.8778\n",
      "Epoch 4/10\n",
      "1530/1530 [==============================] - 0s 249us/sample - loss: 0.2160 - acc: 0.8889 - val_loss: 0.2283 - val_acc: 0.8778\n",
      "Epoch 5/10\n",
      "1530/1530 [==============================] - 0s 181us/sample - loss: 0.2201 - acc: 0.8837 - val_loss: 0.2280 - val_acc: 0.8741\n",
      "Epoch 6/10\n",
      "1530/1530 [==============================] - 0s 191us/sample - loss: 0.2140 - acc: 0.8869 - val_loss: 0.2267 - val_acc: 0.8741\n",
      "Epoch 7/10\n",
      "1530/1530 [==============================] - 0s 214us/sample - loss: 0.2133 - acc: 0.8869 - val_loss: 0.2310 - val_acc: 0.8852\n",
      "Epoch 8/10\n",
      "1530/1530 [==============================] - 0s 179us/sample - loss: 0.2150 - acc: 0.8817 - val_loss: 0.2278 - val_acc: 0.8741\n",
      "Epoch 9/10\n",
      "1530/1530 [==============================] - 0s 182us/sample - loss: 0.2163 - acc: 0.8830 - val_loss: 0.2258 - val_acc: 0.8704\n",
      "Epoch 10/10\n",
      "1530/1530 [==============================] - 0s 187us/sample - loss: 0.2146 - acc: 0.8889 - val_loss: 0.2253 - val_acc: 0.8741\n",
      "Epoch 47 out of 150\n",
      "Train on 1530 samples, validate on 270 samples\n",
      "Epoch 1/10\n",
      "1530/1530 [==============================] - 0s 170us/sample - loss: 0.2126 - acc: 0.8882 - val_loss: 0.2265 - val_acc: 0.8704\n",
      "Epoch 2/10\n",
      "1530/1530 [==============================] - 0s 177us/sample - loss: 0.2125 - acc: 0.8889 - val_loss: 0.2286 - val_acc: 0.8741\n",
      "Epoch 3/10\n",
      "1530/1530 [==============================] - 0s 191us/sample - loss: 0.2137 - acc: 0.8856 - val_loss: 0.2271 - val_acc: 0.8741\n",
      "Epoch 4/10\n",
      "1530/1530 [==============================] - 0s 219us/sample - loss: 0.2178 - acc: 0.8876 - val_loss: 0.2288 - val_acc: 0.8741\n",
      "Epoch 5/10\n",
      "1530/1530 [==============================] - 0s 183us/sample - loss: 0.2154 - acc: 0.8843 - val_loss: 0.2342 - val_acc: 0.8926\n",
      "Epoch 6/10\n",
      "1530/1530 [==============================] - 0s 205us/sample - loss: 0.2147 - acc: 0.8882 - val_loss: 0.2254 - val_acc: 0.8741\n",
      "Epoch 7/10\n",
      "1530/1530 [==============================] - 0s 184us/sample - loss: 0.2146 - acc: 0.8850 - val_loss: 0.2277 - val_acc: 0.8815\n",
      "Epoch 8/10\n",
      "1530/1530 [==============================] - 0s 197us/sample - loss: 0.2114 - acc: 0.8850 - val_loss: 0.2307 - val_acc: 0.8815\n",
      "Epoch 9/10\n",
      "1530/1530 [==============================] - 0s 207us/sample - loss: 0.2140 - acc: 0.8837 - val_loss: 0.2302 - val_acc: 0.8815\n",
      "Epoch 10/10\n",
      "1530/1530 [==============================] - 0s 182us/sample - loss: 0.2188 - acc: 0.8876 - val_loss: 0.2262 - val_acc: 0.8778\n",
      "Epoch 48 out of 150\n",
      "Train on 1530 samples, validate on 270 samples\n",
      "Epoch 1/10\n",
      "1530/1530 [==============================] - 0s 178us/sample - loss: 0.2120 - acc: 0.8889 - val_loss: 0.2234 - val_acc: 0.8741\n",
      "Epoch 2/10\n",
      "1530/1530 [==============================] - 0s 205us/sample - loss: 0.2150 - acc: 0.8863 - val_loss: 0.2231 - val_acc: 0.8741\n",
      "Epoch 3/10\n",
      "1530/1530 [==============================] - 0s 181us/sample - loss: 0.2094 - acc: 0.8908 - val_loss: 0.2236 - val_acc: 0.8815\n",
      "Epoch 4/10\n",
      "1530/1530 [==============================] - 0s 214us/sample - loss: 0.2138 - acc: 0.8902 - val_loss: 0.2229 - val_acc: 0.8741\n",
      "Epoch 5/10\n",
      "1530/1530 [==============================] - 0s 189us/sample - loss: 0.2082 - acc: 0.8876 - val_loss: 0.2219 - val_acc: 0.8704\n",
      "Epoch 6/10\n",
      "1530/1530 [==============================] - 0s 182us/sample - loss: 0.2088 - acc: 0.8882 - val_loss: 0.2307 - val_acc: 0.8815\n",
      "Epoch 7/10\n",
      "1530/1530 [==============================] - 0s 209us/sample - loss: 0.2111 - acc: 0.8856 - val_loss: 0.2260 - val_acc: 0.8889\n",
      "Epoch 8/10\n",
      "1530/1530 [==============================] - 0s 188us/sample - loss: 0.2103 - acc: 0.8869 - val_loss: 0.2259 - val_acc: 0.8741\n",
      "Epoch 9/10\n",
      "1530/1530 [==============================] - 0s 204us/sample - loss: 0.2103 - acc: 0.8869 - val_loss: 0.2377 - val_acc: 0.8852\n",
      "Epoch 10/10\n",
      "1530/1530 [==============================] - 0s 176us/sample - loss: 0.2140 - acc: 0.8889 - val_loss: 0.2233 - val_acc: 0.8741\n",
      "Epoch 49 out of 150\n",
      "Train on 1530 samples, validate on 270 samples\n",
      "Epoch 1/10\n",
      "1530/1530 [==============================] - 0s 183us/sample - loss: 0.2085 - acc: 0.8895 - val_loss: 0.2411 - val_acc: 0.9000\n",
      "Epoch 2/10\n",
      "1530/1530 [==============================] - 0s 191us/sample - loss: 0.2198 - acc: 0.8830 - val_loss: 0.2309 - val_acc: 0.8815\n",
      "Epoch 3/10\n",
      "1530/1530 [==============================] - 0s 211us/sample - loss: 0.2145 - acc: 0.8850 - val_loss: 0.2213 - val_acc: 0.8778\n",
      "Epoch 4/10\n",
      "1530/1530 [==============================] - 0s 226us/sample - loss: 0.2207 - acc: 0.8824 - val_loss: 0.2235 - val_acc: 0.8778\n",
      "Epoch 5/10\n",
      "1530/1530 [==============================] - 0s 186us/sample - loss: 0.2121 - acc: 0.8948 - val_loss: 0.2213 - val_acc: 0.8778\n",
      "Epoch 6/10\n",
      "1530/1530 [==============================] - 0s 186us/sample - loss: 0.2096 - acc: 0.8837 - val_loss: 0.2251 - val_acc: 0.8778\n",
      "Epoch 7/10\n",
      "1530/1530 [==============================] - 0s 198us/sample - loss: 0.2090 - acc: 0.8889 - val_loss: 0.2203 - val_acc: 0.8741\n",
      "Epoch 8/10\n",
      "1530/1530 [==============================] - 0s 188us/sample - loss: 0.2106 - acc: 0.8863 - val_loss: 0.2227 - val_acc: 0.8926\n",
      "Epoch 9/10\n",
      "1530/1530 [==============================] - 0s 219us/sample - loss: 0.2106 - acc: 0.8889 - val_loss: 0.2205 - val_acc: 0.8741\n",
      "Epoch 10/10\n",
      "1530/1530 [==============================] - 0s 225us/sample - loss: 0.2100 - acc: 0.8856 - val_loss: 0.2221 - val_acc: 0.8741\n",
      "Epoch 50 out of 150\n",
      "Train on 1530 samples, validate on 270 samples\n",
      "Epoch 1/10\n",
      "1530/1530 [==============================] - 0s 204us/sample - loss: 0.2091 - acc: 0.8908 - val_loss: 0.2290 - val_acc: 0.8815\n",
      "Epoch 2/10\n",
      "1530/1530 [==============================] - 0s 258us/sample - loss: 0.2084 - acc: 0.8889 - val_loss: 0.2229 - val_acc: 0.8926\n",
      "Epoch 3/10\n",
      "1530/1530 [==============================] - 0s 304us/sample - loss: 0.2080 - acc: 0.8941 - val_loss: 0.2184 - val_acc: 0.8741\n",
      "Epoch 4/10\n",
      "1530/1530 [==============================] - 0s 250us/sample - loss: 0.2063 - acc: 0.8882 - val_loss: 0.2203 - val_acc: 0.8741\n",
      "Epoch 5/10\n",
      "1530/1530 [==============================] - 0s 227us/sample - loss: 0.2073 - acc: 0.8928 - val_loss: 0.2220 - val_acc: 0.8741\n",
      "Epoch 6/10\n",
      "1530/1530 [==============================] - 0s 225us/sample - loss: 0.2083 - acc: 0.8869 - val_loss: 0.2176 - val_acc: 0.8741\n",
      "Epoch 7/10\n",
      "1530/1530 [==============================] - 0s 214us/sample - loss: 0.2077 - acc: 0.8824 - val_loss: 0.2182 - val_acc: 0.8741\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/10\n",
      "1530/1530 [==============================] - 0s 197us/sample - loss: 0.2057 - acc: 0.8902 - val_loss: 0.2199 - val_acc: 0.8889\n",
      "Epoch 9/10\n",
      "1530/1530 [==============================] - 0s 188us/sample - loss: 0.2079 - acc: 0.8902 - val_loss: 0.2186 - val_acc: 0.8741\n",
      "Epoch 10/10\n",
      "1530/1530 [==============================] - 0s 217us/sample - loss: 0.2066 - acc: 0.8889 - val_loss: 0.2190 - val_acc: 0.8741\n",
      "Epoch 51 out of 150\n",
      "Train on 1530 samples, validate on 270 samples\n",
      "Epoch 1/10\n",
      "1530/1530 [==============================] - 0s 194us/sample - loss: 0.2059 - acc: 0.8948 - val_loss: 0.2163 - val_acc: 0.8741\n",
      "Epoch 2/10\n",
      "1530/1530 [==============================] - 0s 215us/sample - loss: 0.2041 - acc: 0.8882 - val_loss: 0.2303 - val_acc: 0.8815\n",
      "Epoch 3/10\n",
      "1530/1530 [==============================] - 0s 265us/sample - loss: 0.2056 - acc: 0.8869 - val_loss: 0.2199 - val_acc: 0.8778\n",
      "Epoch 4/10\n",
      "1530/1530 [==============================] - 0s 250us/sample - loss: 0.2042 - acc: 0.8908 - val_loss: 0.2215 - val_acc: 0.8815\n",
      "Epoch 5/10\n",
      "1530/1530 [==============================] - 0s 221us/sample - loss: 0.2047 - acc: 0.8915 - val_loss: 0.2543 - val_acc: 0.8852\n",
      "Epoch 6/10\n",
      "1530/1530 [==============================] - 0s 216us/sample - loss: 0.2083 - acc: 0.8915 - val_loss: 0.2177 - val_acc: 0.8778\n",
      "Epoch 7/10\n",
      "1530/1530 [==============================] - 0s 213us/sample - loss: 0.2053 - acc: 0.8856 - val_loss: 0.2336 - val_acc: 0.8815\n",
      "Epoch 8/10\n",
      "1530/1530 [==============================] - 0s 215us/sample - loss: 0.2046 - acc: 0.8922 - val_loss: 0.2174 - val_acc: 0.8778\n",
      "Epoch 9/10\n",
      "1530/1530 [==============================] - 0s 169us/sample - loss: 0.2052 - acc: 0.8895 - val_loss: 0.2176 - val_acc: 0.8741\n",
      "Epoch 10/10\n",
      "1530/1530 [==============================] - 0s 173us/sample - loss: 0.2050 - acc: 0.8863 - val_loss: 0.2193 - val_acc: 0.8778\n",
      "Epoch 52 out of 150\n",
      "Train on 1530 samples, validate on 270 samples\n",
      "Epoch 1/10\n",
      "1530/1530 [==============================] - 0s 180us/sample - loss: 0.2035 - acc: 0.8889 - val_loss: 0.2175 - val_acc: 0.8778\n",
      "Epoch 2/10\n",
      "1530/1530 [==============================] - 0s 187us/sample - loss: 0.2057 - acc: 0.8928 - val_loss: 0.2159 - val_acc: 0.8778\n",
      "Epoch 3/10\n",
      "1530/1530 [==============================] - 0s 199us/sample - loss: 0.2039 - acc: 0.8889 - val_loss: 0.2159 - val_acc: 0.8778\n",
      "Epoch 4/10\n",
      "1530/1530 [==============================] - 0s 254us/sample - loss: 0.2031 - acc: 0.8869 - val_loss: 0.2167 - val_acc: 0.8815\n",
      "Epoch 5/10\n",
      "1530/1530 [==============================] - 0s 181us/sample - loss: 0.2061 - acc: 0.8889 - val_loss: 0.2252 - val_acc: 0.8815\n",
      "Epoch 6/10\n",
      "1530/1530 [==============================] - 0s 204us/sample - loss: 0.2026 - acc: 0.8830 - val_loss: 0.2164 - val_acc: 0.8852\n",
      "Epoch 7/10\n",
      "1530/1530 [==============================] - 0s 187us/sample - loss: 0.2027 - acc: 0.8889 - val_loss: 0.2160 - val_acc: 0.8741\n",
      "Epoch 8/10\n",
      "1530/1530 [==============================] - 0s 190us/sample - loss: 0.2031 - acc: 0.8882 - val_loss: 0.2160 - val_acc: 0.8815\n",
      "Epoch 9/10\n",
      "1530/1530 [==============================] - 0s 196us/sample - loss: 0.2015 - acc: 0.8895 - val_loss: 0.2150 - val_acc: 0.8778\n",
      "Epoch 10/10\n",
      "1530/1530 [==============================] - 0s 185us/sample - loss: 0.2071 - acc: 0.8876 - val_loss: 0.2156 - val_acc: 0.8778\n",
      "Epoch 53 out of 150\n",
      "Train on 1530 samples, validate on 270 samples\n",
      "Epoch 1/10\n",
      "1530/1530 [==============================] - 0s 176us/sample - loss: 0.2055 - acc: 0.8902 - val_loss: 0.2211 - val_acc: 0.8852\n",
      "Epoch 2/10\n",
      "1530/1530 [==============================] - 0s 191us/sample - loss: 0.2048 - acc: 0.8908 - val_loss: 0.2139 - val_acc: 0.8778\n",
      "Epoch 3/10\n",
      "1530/1530 [==============================] - 0s 215us/sample - loss: 0.2008 - acc: 0.8869 - val_loss: 0.2227 - val_acc: 0.8778\n",
      "Epoch 4/10\n",
      "1530/1530 [==============================] - 0s 225us/sample - loss: 0.2113 - acc: 0.8889 - val_loss: 0.2197 - val_acc: 0.8889\n",
      "Epoch 5/10\n",
      "1530/1530 [==============================] - 0s 205us/sample - loss: 0.2051 - acc: 0.8889 - val_loss: 0.2180 - val_acc: 0.8815\n",
      "Epoch 6/10\n",
      "1530/1530 [==============================] - 0s 190us/sample - loss: 0.2030 - acc: 0.8954 - val_loss: 0.2133 - val_acc: 0.8778\n",
      "Epoch 7/10\n",
      "1530/1530 [==============================] - 0s 205us/sample - loss: 0.2026 - acc: 0.8843 - val_loss: 0.2144 - val_acc: 0.8778\n",
      "Epoch 8/10\n",
      "1530/1530 [==============================] - 0s 196us/sample - loss: 0.1996 - acc: 0.8850 - val_loss: 0.2234 - val_acc: 0.9074\n",
      "Epoch 9/10\n",
      "1530/1530 [==============================] - 0s 221us/sample - loss: 0.2024 - acc: 0.8863 - val_loss: 0.2180 - val_acc: 0.8741\n",
      "Epoch 10/10\n",
      "1530/1530 [==============================] - 0s 181us/sample - loss: 0.2016 - acc: 0.8856 - val_loss: 0.2163 - val_acc: 0.8852\n",
      "Epoch 54 out of 150\n",
      "Train on 1530 samples, validate on 270 samples\n",
      "Epoch 1/10\n",
      "1530/1530 [==============================] - 0s 181us/sample - loss: 0.2001 - acc: 0.8895 - val_loss: 0.2112 - val_acc: 0.8778\n",
      "Epoch 2/10\n",
      "1530/1530 [==============================] - 0s 199us/sample - loss: 0.1997 - acc: 0.8889 - val_loss: 0.2193 - val_acc: 0.8778\n",
      "Epoch 3/10\n",
      "1530/1530 [==============================] - 0s 187us/sample - loss: 0.1991 - acc: 0.8908 - val_loss: 0.2133 - val_acc: 0.8778\n",
      "Epoch 4/10\n",
      "1530/1530 [==============================] - 0s 224us/sample - loss: 0.1987 - acc: 0.8889 - val_loss: 0.2129 - val_acc: 0.8741\n",
      "Epoch 5/10\n",
      "1530/1530 [==============================] - 0s 217us/sample - loss: 0.1986 - acc: 0.8915 - val_loss: 0.2163 - val_acc: 0.8778\n",
      "Epoch 6/10\n",
      "1530/1530 [==============================] - 0s 221us/sample - loss: 0.2006 - acc: 0.8876 - val_loss: 0.2229 - val_acc: 0.8852\n",
      "Epoch 7/10\n",
      "1530/1530 [==============================] - 0s 231us/sample - loss: 0.2009 - acc: 0.8876 - val_loss: 0.2143 - val_acc: 0.8815\n",
      "Epoch 8/10\n",
      "1530/1530 [==============================] - 0s 254us/sample - loss: 0.2013 - acc: 0.8915 - val_loss: 0.2442 - val_acc: 0.8852\n",
      "Epoch 9/10\n",
      "1530/1530 [==============================] - 0s 241us/sample - loss: 0.2041 - acc: 0.8961 - val_loss: 0.2191 - val_acc: 0.8815\n",
      "Epoch 10/10\n",
      "1530/1530 [==============================] - 0s 228us/sample - loss: 0.2024 - acc: 0.8902 - val_loss: 0.2174 - val_acc: 0.9111\n",
      "Epoch 55 out of 150\n",
      "Train on 1530 samples, validate on 270 samples\n",
      "Epoch 1/10\n",
      "1530/1530 [==============================] - 0s 225us/sample - loss: 0.1989 - acc: 0.8895 - val_loss: 0.2282 - val_acc: 0.9037\n",
      "Epoch 2/10\n",
      "1530/1530 [==============================] - 0s 226us/sample - loss: 0.1991 - acc: 0.8948 - val_loss: 0.2148 - val_acc: 0.8815\n",
      "Epoch 3/10\n",
      "1530/1530 [==============================] - 0s 221us/sample - loss: 0.1972 - acc: 0.8902 - val_loss: 0.2150 - val_acc: 0.8741\n",
      "Epoch 4/10\n",
      "1530/1530 [==============================] - ETA: 0s - loss: 0.2038 - acc: 0.892 - 0s 227us/sample - loss: 0.2022 - acc: 0.8908 - val_loss: 0.2144 - val_acc: 0.8741\n",
      "Epoch 5/10\n",
      "1530/1530 [==============================] - 0s 200us/sample - loss: 0.1968 - acc: 0.8915 - val_loss: 0.2178 - val_acc: 0.9074\n",
      "Epoch 6/10\n",
      "1530/1530 [==============================] - 0s 190us/sample - loss: 0.1970 - acc: 0.8941 - val_loss: 0.2104 - val_acc: 0.8778\n",
      "Epoch 7/10\n",
      "1530/1530 [==============================] - 0s 205us/sample - loss: 0.1951 - acc: 0.8922 - val_loss: 0.2207 - val_acc: 0.9185\n",
      "Epoch 8/10\n",
      "1530/1530 [==============================] - 0s 192us/sample - loss: 0.2022 - acc: 0.8948 - val_loss: 0.2107 - val_acc: 0.8815\n",
      "Epoch 9/10\n",
      "1530/1530 [==============================] - 0s 200us/sample - loss: 0.1998 - acc: 0.8856 - val_loss: 0.2152 - val_acc: 0.8815\n",
      "Epoch 10/10\n",
      "1530/1530 [==============================] - 0s 205us/sample - loss: 0.2028 - acc: 0.8935 - val_loss: 0.2121 - val_acc: 0.8852\n",
      "Epoch 56 out of 150\n",
      "Train on 1530 samples, validate on 270 samples\n",
      "Epoch 1/10\n",
      "1530/1530 [==============================] - 0s 175us/sample - loss: 0.1945 - acc: 0.8928 - val_loss: 0.2121 - val_acc: 0.9000\n",
      "Epoch 2/10\n",
      "1530/1530 [==============================] - 0s 190us/sample - loss: 0.1958 - acc: 0.8961 - val_loss: 0.2094 - val_acc: 0.8815\n",
      "Epoch 3/10\n",
      "1530/1530 [==============================] - 0s 187us/sample - loss: 0.1968 - acc: 0.8935 - val_loss: 0.2142 - val_acc: 0.8852\n",
      "Epoch 4/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1530/1530 [==============================] - 0s 242us/sample - loss: 0.1960 - acc: 0.8974 - val_loss: 0.2255 - val_acc: 0.9148\n",
      "Epoch 5/10\n",
      "1530/1530 [==============================] - 0s 183us/sample - loss: 0.1955 - acc: 0.8908 - val_loss: 0.2134 - val_acc: 0.8778\n",
      "Epoch 6/10\n",
      "1530/1530 [==============================] - 0s 179us/sample - loss: 0.1977 - acc: 0.8902 - val_loss: 0.2118 - val_acc: 0.9037\n",
      "Epoch 7/10\n",
      "1530/1530 [==============================] - 0s 218us/sample - loss: 0.1935 - acc: 0.8941 - val_loss: 0.2093 - val_acc: 0.8778\n",
      "Epoch 8/10\n",
      "1530/1530 [==============================] - 0s 179us/sample - loss: 0.1980 - acc: 0.8915 - val_loss: 0.2102 - val_acc: 0.8741\n",
      "Epoch 9/10\n",
      "1530/1530 [==============================] - 0s 179us/sample - loss: 0.1987 - acc: 0.8967 - val_loss: 0.2294 - val_acc: 0.8852\n",
      "Epoch 10/10\n",
      "1530/1530 [==============================] - 0s 186us/sample - loss: 0.1990 - acc: 0.8935 - val_loss: 0.2089 - val_acc: 0.8852\n",
      "Epoch 57 out of 150\n",
      "Train on 1530 samples, validate on 270 samples\n",
      "Epoch 1/10\n",
      "1530/1530 [==============================] - 0s 174us/sample - loss: 0.1971 - acc: 0.8961 - val_loss: 0.2099 - val_acc: 0.8815\n",
      "Epoch 2/10\n",
      "1530/1530 [==============================] - 0s 183us/sample - loss: 0.1968 - acc: 0.8928 - val_loss: 0.2068 - val_acc: 0.8815\n",
      "Epoch 3/10\n",
      "1530/1530 [==============================] - 0s 178us/sample - loss: 0.1929 - acc: 0.8915 - val_loss: 0.2066 - val_acc: 0.8815\n",
      "Epoch 4/10\n",
      "1530/1530 [==============================] - 0s 299us/sample - loss: 0.1916 - acc: 0.8987 - val_loss: 0.2087 - val_acc: 0.8815\n",
      "Epoch 5/10\n",
      "1530/1530 [==============================] - 0s 225us/sample - loss: 0.1946 - acc: 0.8961 - val_loss: 0.2087 - val_acc: 0.9000\n",
      "Epoch 6/10\n",
      "1530/1530 [==============================] - 0s 246us/sample - loss: 0.1962 - acc: 0.8980 - val_loss: 0.2115 - val_acc: 0.9111\n",
      "Epoch 7/10\n",
      "1530/1530 [==============================] - 0s 199us/sample - loss: 0.1936 - acc: 0.9007 - val_loss: 0.2076 - val_acc: 0.8778\n",
      "Epoch 8/10\n",
      "1530/1530 [==============================] - 1s 329us/sample - loss: 0.1917 - acc: 0.8954 - val_loss: 0.2042 - val_acc: 0.8815\n",
      "Epoch 9/10\n",
      "1530/1530 [==============================] - 0s 203us/sample - loss: 0.1899 - acc: 0.8961 - val_loss: 0.2065 - val_acc: 0.8815\n",
      "Epoch 10/10\n",
      "1530/1530 [==============================] - 0s 136us/sample - loss: 0.1929 - acc: 0.8980 - val_loss: 0.2060 - val_acc: 0.9037\n",
      "Epoch 58 out of 150\n",
      "Train on 1530 samples, validate on 270 samples\n",
      "Epoch 1/10\n",
      "1530/1530 [==============================] - 0s 172us/sample - loss: 0.1925 - acc: 0.8954 - val_loss: 0.2045 - val_acc: 0.8815\n",
      "Epoch 2/10\n",
      "1530/1530 [==============================] - 0s 141us/sample - loss: 0.1916 - acc: 0.8980 - val_loss: 0.2053 - val_acc: 0.8778\n",
      "Epoch 3/10\n",
      "1530/1530 [==============================] - 0s 164us/sample - loss: 0.1901 - acc: 0.8974 - val_loss: 0.2187 - val_acc: 0.9000\n",
      "Epoch 4/10\n",
      "1530/1530 [==============================] - 0s 186us/sample - loss: 0.1913 - acc: 0.8967 - val_loss: 0.2064 - val_acc: 0.9111\n",
      "Epoch 5/10\n",
      "1530/1530 [==============================] - 0s 147us/sample - loss: 0.1913 - acc: 0.9026 - val_loss: 0.2075 - val_acc: 0.8741\n",
      "Epoch 6/10\n",
      "1530/1530 [==============================] - 0s 157us/sample - loss: 0.1951 - acc: 0.8941 - val_loss: 0.2054 - val_acc: 0.8926\n",
      "Epoch 7/10\n",
      "1530/1530 [==============================] - 0s 154us/sample - loss: 0.1927 - acc: 0.8954 - val_loss: 0.2061 - val_acc: 0.9074\n",
      "Epoch 8/10\n",
      "1530/1530 [==============================] - 0s 164us/sample - loss: 0.1896 - acc: 0.8987 - val_loss: 0.2078 - val_acc: 0.9185\n",
      "Epoch 9/10\n",
      "1530/1530 [==============================] - 0s 269us/sample - loss: 0.1872 - acc: 0.9046 - val_loss: 0.2093 - val_acc: 0.8778\n",
      "Epoch 10/10\n",
      "1530/1530 [==============================] - 1s 428us/sample - loss: 0.1905 - acc: 0.8967 - val_loss: 0.2071 - val_acc: 0.9000\n",
      "Epoch 59 out of 150\n",
      "Train on 1530 samples, validate on 270 samples\n",
      "Epoch 1/10\n",
      "1530/1530 [==============================] - 0s 298us/sample - loss: 0.1936 - acc: 0.9000 - val_loss: 0.2062 - val_acc: 0.8778\n",
      "Epoch 2/10\n",
      "1530/1530 [==============================] - 1s 368us/sample - loss: 0.1904 - acc: 0.9007 - val_loss: 0.2055 - val_acc: 0.8926\n",
      "Epoch 3/10\n",
      "1530/1530 [==============================] - 1s 424us/sample - loss: 0.1884 - acc: 0.9046 - val_loss: 0.2050 - val_acc: 0.8815\n",
      "Epoch 4/10\n",
      "1530/1530 [==============================] - 1s 374us/sample - loss: 0.1868 - acc: 0.9007 - val_loss: 0.2048 - val_acc: 0.9111\n",
      "Epoch 5/10\n",
      "1530/1530 [==============================] - 0s 205us/sample - loss: 0.1963 - acc: 0.8954 - val_loss: 0.2063 - val_acc: 0.9074\n",
      "Epoch 6/10\n",
      "1530/1530 [==============================] - 0s 202us/sample - loss: 0.1953 - acc: 0.8928 - val_loss: 0.2160 - val_acc: 0.8815\n",
      "Epoch 7/10\n",
      "1530/1530 [==============================] - 0s 188us/sample - loss: 0.1878 - acc: 0.9033 - val_loss: 0.2066 - val_acc: 0.8926\n",
      "Epoch 8/10\n",
      "1530/1530 [==============================] - 1s 348us/sample - loss: 0.1898 - acc: 0.8993 - val_loss: 0.2036 - val_acc: 0.9111\n",
      "Epoch 9/10\n",
      "1530/1530 [==============================] - 1s 379us/sample - loss: 0.1937 - acc: 0.9000 - val_loss: 0.2107 - val_acc: 0.8778\n",
      "Epoch 10/10\n",
      "1530/1530 [==============================] - 1s 357us/sample - loss: 0.1919 - acc: 0.8974 - val_loss: 0.2075 - val_acc: 0.9222\n",
      "Epoch 60 out of 150\n",
      "Train on 1530 samples, validate on 270 samples\n",
      "Epoch 1/10\n",
      "1530/1530 [==============================] - 0s 243us/sample - loss: 0.1870 - acc: 0.8967 - val_loss: 0.2024 - val_acc: 0.9185\n",
      "Epoch 2/10\n",
      "1530/1530 [==============================] - 0s 308us/sample - loss: 0.1862 - acc: 0.9033 - val_loss: 0.2075 - val_acc: 0.9185\n",
      "Epoch 3/10\n",
      "1530/1530 [==============================] - 0s 283us/sample - loss: 0.1898 - acc: 0.9105 - val_loss: 0.2163 - val_acc: 0.8741\n",
      "Epoch 4/10\n",
      "1530/1530 [==============================] - 0s 263us/sample - loss: 0.1901 - acc: 0.9026 - val_loss: 0.2044 - val_acc: 0.9074\n",
      "Epoch 5/10\n",
      "1530/1530 [==============================] - 0s 221us/sample - loss: 0.1875 - acc: 0.9085 - val_loss: 0.2067 - val_acc: 0.8778\n",
      "Epoch 6/10\n",
      "1530/1530 [==============================] - 0s 217us/sample - loss: 0.1871 - acc: 0.9007 - val_loss: 0.2006 - val_acc: 0.8815\n",
      "Epoch 7/10\n",
      "1530/1530 [==============================] - 0s 217us/sample - loss: 0.1875 - acc: 0.8908 - val_loss: 0.2015 - val_acc: 0.8852\n",
      "Epoch 8/10\n",
      "1530/1530 [==============================] - 0s 214us/sample - loss: 0.1929 - acc: 0.9039 - val_loss: 0.2001 - val_acc: 0.8815\n",
      "Epoch 9/10\n",
      "1530/1530 [==============================] - 0s 216us/sample - loss: 0.1863 - acc: 0.9039 - val_loss: 0.2001 - val_acc: 0.8852\n",
      "Epoch 10/10\n",
      "1530/1530 [==============================] - 0s 209us/sample - loss: 0.1884 - acc: 0.9020 - val_loss: 0.2073 - val_acc: 0.8741\n",
      "Epoch 61 out of 150\n",
      "Train on 1530 samples, validate on 270 samples\n",
      "Epoch 1/10\n",
      "1530/1530 [==============================] - 0s 237us/sample - loss: 0.1863 - acc: 0.8993 - val_loss: 0.2023 - val_acc: 0.8778\n",
      "Epoch 2/10\n",
      "1530/1530 [==============================] - 0s 243us/sample - loss: 0.1864 - acc: 0.9013 - val_loss: 0.2078 - val_acc: 0.8778\n",
      "Epoch 3/10\n",
      "1530/1530 [==============================] - 0s 282us/sample - loss: 0.1891 - acc: 0.9007 - val_loss: 0.2014 - val_acc: 0.9148\n",
      "Epoch 4/10\n",
      "1530/1530 [==============================] - 0s 323us/sample - loss: 0.1852 - acc: 0.9039 - val_loss: 0.2035 - val_acc: 0.8778\n",
      "Epoch 5/10\n",
      "1530/1530 [==============================] - 0s 254us/sample - loss: 0.1879 - acc: 0.8961 - val_loss: 0.1987 - val_acc: 0.8815\n",
      "Epoch 6/10\n",
      "1530/1530 [==============================] - 0s 224us/sample - loss: 0.1832 - acc: 0.9065 - val_loss: 0.1993 - val_acc: 0.8852\n",
      "Epoch 7/10\n",
      "1530/1530 [==============================] - 0s 238us/sample - loss: 0.1837 - acc: 0.9033 - val_loss: 0.2021 - val_acc: 0.9222\n",
      "Epoch 8/10\n",
      "1530/1530 [==============================] - 0s 213us/sample - loss: 0.1875 - acc: 0.9033 - val_loss: 0.1980 - val_acc: 0.8778\n",
      "Epoch 9/10\n",
      "1530/1530 [==============================] - ETA: 0s - loss: 0.1792 - acc: 0.8935- ETA: 0s - loss: 0.1825 - acc: 0.8 - 0s 224us/sample - loss: 0.1851 - acc: 0.8935 - val_loss: 0.2013 - val_acc: 0.9111\n",
      "Epoch 10/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1530/1530 [==============================] - 0s 279us/sample - loss: 0.1884 - acc: 0.9026 - val_loss: 0.2041 - val_acc: 0.8778\n",
      "Epoch 62 out of 150\n",
      "Train on 1530 samples, validate on 270 samples\n",
      "Epoch 1/10\n",
      "1530/1530 [==============================] - 0s 224us/sample - loss: 0.1834 - acc: 0.9039 - val_loss: 0.1973 - val_acc: 0.8852\n",
      "Epoch 2/10\n",
      "1530/1530 [==============================] - 0s 237us/sample - loss: 0.1858 - acc: 0.8974 - val_loss: 0.2009 - val_acc: 0.9185\n",
      "Epoch 3/10\n",
      "1530/1530 [==============================] - 0s 267us/sample - loss: 0.1854 - acc: 0.9092 - val_loss: 0.1966 - val_acc: 0.9111\n",
      "Epoch 4/10\n",
      "1530/1530 [==============================] - 0s 241us/sample - loss: 0.1842 - acc: 0.9098 - val_loss: 0.2019 - val_acc: 0.8778\n",
      "Epoch 5/10\n",
      "1530/1530 [==============================] - 0s 280us/sample - loss: 0.1857 - acc: 0.8974 - val_loss: 0.1963 - val_acc: 0.8852\n",
      "Epoch 6/10\n",
      "1530/1530 [==============================] - 0s 253us/sample - loss: 0.1823 - acc: 0.9039 - val_loss: 0.1954 - val_acc: 0.8778\n",
      "Epoch 7/10\n",
      "1530/1530 [==============================] - 0s 221us/sample - loss: 0.1863 - acc: 0.9007 - val_loss: 0.1965 - val_acc: 0.8852\n",
      "Epoch 8/10\n",
      "1530/1530 [==============================] - 0s 290us/sample - loss: 0.1819 - acc: 0.8993 - val_loss: 0.1992 - val_acc: 0.9074\n",
      "Epoch 9/10\n",
      "1530/1530 [==============================] - 0s 249us/sample - loss: 0.1892 - acc: 0.9007 - val_loss: 0.1961 - val_acc: 0.8889\n",
      "Epoch 10/10\n",
      "1530/1530 [==============================] - 0s 222us/sample - loss: 0.1860 - acc: 0.9092 - val_loss: 0.1978 - val_acc: 0.8778\n",
      "Epoch 63 out of 150\n",
      "Train on 1530 samples, validate on 270 samples\n",
      "Epoch 1/10\n",
      "1530/1530 [==============================] - 0s 194us/sample - loss: 0.1822 - acc: 0.9026 - val_loss: 0.1976 - val_acc: 0.8778\n",
      "Epoch 2/10\n",
      "1530/1530 [==============================] - 0s 190us/sample - loss: 0.1822 - acc: 0.9118 - val_loss: 0.1947 - val_acc: 0.8852\n",
      "Epoch 3/10\n",
      "1530/1530 [==============================] - 0s 229us/sample - loss: 0.1829 - acc: 0.9052 - val_loss: 0.2009 - val_acc: 0.8852\n",
      "Epoch 4/10\n",
      "1530/1530 [==============================] - 0s 157us/sample - loss: 0.1827 - acc: 0.9137 - val_loss: 0.1963 - val_acc: 0.8963\n",
      "Epoch 5/10\n",
      "1530/1530 [==============================] - 0s 155us/sample - loss: 0.1809 - acc: 0.9013 - val_loss: 0.2100 - val_acc: 0.9370\n",
      "Epoch 6/10\n",
      "1530/1530 [==============================] - 0s 154us/sample - loss: 0.1864 - acc: 0.9118 - val_loss: 0.1961 - val_acc: 0.9000\n",
      "Epoch 7/10\n",
      "1530/1530 [==============================] - 0s 183us/sample - loss: 0.1806 - acc: 0.9033 - val_loss: 0.2066 - val_acc: 0.9296\n",
      "Epoch 8/10\n",
      "1530/1530 [==============================] - 1s 334us/sample - loss: 0.1817 - acc: 0.9026 - val_loss: 0.1946 - val_acc: 0.8926\n",
      "Epoch 9/10\n",
      "1530/1530 [==============================] - 0s 158us/sample - loss: 0.1859 - acc: 0.9039 - val_loss: 0.2100 - val_acc: 0.8815\n",
      "Epoch 10/10\n",
      "1530/1530 [==============================] - 0s 169us/sample - loss: 0.1835 - acc: 0.9092 - val_loss: 0.1946 - val_acc: 0.8889\n",
      "Epoch 64 out of 150\n",
      "Train on 1530 samples, validate on 270 samples\n",
      "Epoch 1/10\n",
      "1530/1530 [==============================] - 0s 218us/sample - loss: 0.1834 - acc: 0.9020 - val_loss: 0.1937 - val_acc: 0.8889\n",
      "Epoch 2/10\n",
      "1530/1530 [==============================] - 0s 200us/sample - loss: 0.1817 - acc: 0.9007 - val_loss: 0.1926 - val_acc: 0.8963\n",
      "Epoch 3/10\n",
      "1530/1530 [==============================] - 0s 224us/sample - loss: 0.1811 - acc: 0.9033 - val_loss: 0.1943 - val_acc: 0.9259\n",
      "Epoch 4/10\n",
      "1530/1530 [==============================] - 0s 173us/sample - loss: 0.1818 - acc: 0.9072 - val_loss: 0.1928 - val_acc: 0.8963\n",
      "Epoch 5/10\n",
      "1530/1530 [==============================] - 0s 201us/sample - loss: 0.1784 - acc: 0.9190 - val_loss: 0.1996 - val_acc: 0.8741\n",
      "Epoch 6/10\n",
      "1530/1530 [==============================] - 0s 158us/sample - loss: 0.1781 - acc: 0.9033 - val_loss: 0.1986 - val_acc: 0.9222\n",
      "Epoch 7/10\n",
      "1530/1530 [==============================] - 0s 160us/sample - loss: 0.1785 - acc: 0.9105 - val_loss: 0.2021 - val_acc: 0.8852\n",
      "Epoch 8/10\n",
      "1530/1530 [==============================] - 0s 168us/sample - loss: 0.1816 - acc: 0.9007 - val_loss: 0.1931 - val_acc: 0.8778\n",
      "Epoch 9/10\n",
      "1530/1530 [==============================] - 0s 220us/sample - loss: 0.1869 - acc: 0.9000 - val_loss: 0.2104 - val_acc: 0.9148\n",
      "Epoch 10/10\n",
      "1530/1530 [==============================] - 0s 248us/sample - loss: 0.1797 - acc: 0.9098 - val_loss: 0.1924 - val_acc: 0.8963\n",
      "Epoch 65 out of 150\n",
      "Train on 1530 samples, validate on 270 samples\n",
      "Epoch 1/10\n",
      "1530/1530 [==============================] - 0s 151us/sample - loss: 0.1804 - acc: 0.9007 - val_loss: 0.1938 - val_acc: 0.9074\n",
      "Epoch 2/10\n",
      "1530/1530 [==============================] - 0s 140us/sample - loss: 0.1796 - acc: 0.9131 - val_loss: 0.1967 - val_acc: 0.9111\n",
      "Epoch 3/10\n",
      "1530/1530 [==============================] - 0s 141us/sample - loss: 0.1797 - acc: 0.9026 - val_loss: 0.1925 - val_acc: 0.8889\n",
      "Epoch 4/10\n",
      "1530/1530 [==============================] - 0s 139us/sample - loss: 0.1801 - acc: 0.9065 - val_loss: 0.1942 - val_acc: 0.8778\n",
      "Epoch 5/10\n",
      "1530/1530 [==============================] - 0s 208us/sample - loss: 0.1804 - acc: 0.9111 - val_loss: 0.1926 - val_acc: 0.9185\n",
      "Epoch 6/10\n",
      "1530/1530 [==============================] - 0s 154us/sample - loss: 0.1779 - acc: 0.9105 - val_loss: 0.1925 - val_acc: 0.8889\n",
      "Epoch 7/10\n",
      "1530/1530 [==============================] - 0s 222us/sample - loss: 0.1776 - acc: 0.9105 - val_loss: 0.1949 - val_acc: 0.8815\n",
      "Epoch 8/10\n",
      "1530/1530 [==============================] - 0s 189us/sample - loss: 0.1756 - acc: 0.9046 - val_loss: 0.1984 - val_acc: 0.8778\n",
      "Epoch 9/10\n",
      "1530/1530 [==============================] - 0s 278us/sample - loss: 0.1778 - acc: 0.9026 - val_loss: 0.1977 - val_acc: 0.9296\n",
      "Epoch 10/10\n",
      "1530/1530 [==============================] - 0s 181us/sample - loss: 0.1788 - acc: 0.9111 - val_loss: 0.2112 - val_acc: 0.9148\n",
      "Epoch 66 out of 150\n",
      "Train on 1530 samples, validate on 270 samples\n",
      "Epoch 1/10\n",
      "1530/1530 [==============================] - 0s 181us/sample - loss: 0.1787 - acc: 0.9085 - val_loss: 0.1914 - val_acc: 0.9111\n",
      "Epoch 2/10\n",
      "1530/1530 [==============================] - 0s 211us/sample - loss: 0.1801 - acc: 0.9046 - val_loss: 0.1919 - val_acc: 0.9000\n",
      "Epoch 3/10\n",
      "1530/1530 [==============================] - 0s 325us/sample - loss: 0.1811 - acc: 0.9092 - val_loss: 0.1917 - val_acc: 0.8889\n",
      "Epoch 4/10\n",
      "1530/1530 [==============================] - 0s 260us/sample - loss: 0.1780 - acc: 0.9092 - val_loss: 0.1934 - val_acc: 0.9037\n",
      "Epoch 5/10\n",
      "1530/1530 [==============================] - 0s 198us/sample - loss: 0.1777 - acc: 0.9157 - val_loss: 0.1912 - val_acc: 0.8852\n",
      "Epoch 6/10\n",
      "1530/1530 [==============================] - 0s 272us/sample - loss: 0.1758 - acc: 0.9072 - val_loss: 0.1900 - val_acc: 0.9111\n",
      "Epoch 7/10\n",
      "1530/1530 [==============================] - 0s 212us/sample - loss: 0.1761 - acc: 0.9124 - val_loss: 0.1947 - val_acc: 0.9222\n",
      "Epoch 8/10\n",
      "1530/1530 [==============================] - 0s 251us/sample - loss: 0.1782 - acc: 0.9118 - val_loss: 0.1922 - val_acc: 0.8815\n",
      "Epoch 9/10\n",
      "1530/1530 [==============================] - 0s 247us/sample - loss: 0.1804 - acc: 0.9020 - val_loss: 0.1938 - val_acc: 0.9000\n",
      "Epoch 10/10\n",
      "1530/1530 [==============================] - 0s 243us/sample - loss: 0.1760 - acc: 0.9170 - val_loss: 0.1918 - val_acc: 0.8852\n",
      "Epoch 67 out of 150\n",
      "Train on 1530 samples, validate on 270 samples\n",
      "Epoch 1/10\n",
      "1530/1530 [==============================] - 0s 282us/sample - loss: 0.1790 - acc: 0.9052 - val_loss: 0.1916 - val_acc: 0.9222\n",
      "Epoch 2/10\n",
      "1530/1530 [==============================] - 0s 284us/sample - loss: 0.1767 - acc: 0.9131 - val_loss: 0.1906 - val_acc: 0.9185\n",
      "Epoch 3/10\n",
      "1530/1530 [==============================] - 0s 233us/sample - loss: 0.1752 - acc: 0.9098 - val_loss: 0.1892 - val_acc: 0.9111\n",
      "Epoch 4/10\n",
      "1530/1530 [==============================] - 0s 228us/sample - loss: 0.1750 - acc: 0.9150 - val_loss: 0.1910 - val_acc: 0.8778\n",
      "Epoch 5/10\n",
      "1530/1530 [==============================] - 0s 216us/sample - loss: 0.1780 - acc: 0.9072 - val_loss: 0.2005 - val_acc: 0.8778\n",
      "Epoch 6/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1530/1530 [==============================] - 1s 343us/sample - loss: 0.1795 - acc: 0.9078 - val_loss: 0.1898 - val_acc: 0.9148\n",
      "Epoch 7/10\n",
      "1530/1530 [==============================] - 0s 253us/sample - loss: 0.1748 - acc: 0.9229 - val_loss: 0.1929 - val_acc: 0.8778\n",
      "Epoch 8/10\n",
      "1530/1530 [==============================] - 0s 208us/sample - loss: 0.1750 - acc: 0.9144 - val_loss: 0.2014 - val_acc: 0.8778\n",
      "Epoch 9/10\n",
      "1530/1530 [==============================] - 0s 211us/sample - loss: 0.1820 - acc: 0.9020 - val_loss: 0.1892 - val_acc: 0.9111\n",
      "Epoch 10/10\n",
      "1530/1530 [==============================] - 0s 179us/sample - loss: 0.1740 - acc: 0.9072 - val_loss: 0.1879 - val_acc: 0.9074\n",
      "Epoch 68 out of 150\n",
      "Train on 1530 samples, validate on 270 samples\n",
      "Epoch 1/10\n",
      "1530/1530 [==============================] - 0s 202us/sample - loss: 0.1771 - acc: 0.9098 - val_loss: 0.1941 - val_acc: 0.8889\n",
      "Epoch 2/10\n",
      "1530/1530 [==============================] - 0s 182us/sample - loss: 0.1749 - acc: 0.9157 - val_loss: 0.1886 - val_acc: 0.8889\n",
      "Epoch 3/10\n",
      "1530/1530 [==============================] - 0s 156us/sample - loss: 0.1746 - acc: 0.9092 - val_loss: 0.1885 - val_acc: 0.9148\n",
      "Epoch 4/10\n",
      "1530/1530 [==============================] - 0s 275us/sample - loss: 0.1748 - acc: 0.9124 - val_loss: 0.1924 - val_acc: 0.8889\n",
      "Epoch 5/10\n",
      "1530/1530 [==============================] - 0s 175us/sample - loss: 0.1826 - acc: 0.9092 - val_loss: 0.1932 - val_acc: 0.8741\n",
      "Epoch 6/10\n",
      "1530/1530 [==============================] - 0s 163us/sample - loss: 0.1750 - acc: 0.9124 - val_loss: 0.1939 - val_acc: 0.8852\n",
      "Epoch 7/10\n",
      "1530/1530 [==============================] - 0s 142us/sample - loss: 0.1760 - acc: 0.9072 - val_loss: 0.1934 - val_acc: 0.8889\n",
      "Epoch 8/10\n",
      "1530/1530 [==============================] - 0s 213us/sample - loss: 0.1744 - acc: 0.9118 - val_loss: 0.1891 - val_acc: 0.8926\n",
      "Epoch 9/10\n",
      "1530/1530 [==============================] - 0s 177us/sample - loss: 0.1732 - acc: 0.9137 - val_loss: 0.2033 - val_acc: 0.8741\n",
      "Epoch 10/10\n",
      "1530/1530 [==============================] - 0s 139us/sample - loss: 0.1773 - acc: 0.9105 - val_loss: 0.1890 - val_acc: 0.9000\n",
      "Epoch 69 out of 150\n",
      "Train on 1530 samples, validate on 270 samples\n",
      "Epoch 1/10\n",
      "1530/1530 [==============================] - 0s 153us/sample - loss: 0.1772 - acc: 0.9059 - val_loss: 0.1988 - val_acc: 0.8741\n",
      "Epoch 2/10\n",
      "1530/1530 [==============================] - 0s 147us/sample - loss: 0.1758 - acc: 0.9118 - val_loss: 0.1930 - val_acc: 0.8852\n",
      "Epoch 3/10\n",
      "1530/1530 [==============================] - 0s 166us/sample - loss: 0.1768 - acc: 0.9183 - val_loss: 0.1878 - val_acc: 0.8963\n",
      "Epoch 4/10\n",
      "1530/1530 [==============================] - 0s 213us/sample - loss: 0.1745 - acc: 0.9092 - val_loss: 0.1890 - val_acc: 0.9222\n",
      "Epoch 5/10\n",
      "1530/1530 [==============================] - 0s 175us/sample - loss: 0.1749 - acc: 0.9248 - val_loss: 0.1931 - val_acc: 0.8815\n",
      "Epoch 6/10\n",
      "1530/1530 [==============================] - 0s 159us/sample - loss: 0.1734 - acc: 0.9124 - val_loss: 0.1915 - val_acc: 0.9148\n",
      "Epoch 7/10\n",
      "1530/1530 [==============================] - 0s 164us/sample - loss: 0.1705 - acc: 0.9190 - val_loss: 0.1926 - val_acc: 0.8778\n",
      "Epoch 8/10\n",
      "1530/1530 [==============================] - 0s 147us/sample - loss: 0.1754 - acc: 0.9111 - val_loss: 0.1921 - val_acc: 0.9037\n",
      "Epoch 9/10\n",
      "1530/1530 [==============================] - 0s 286us/sample - loss: 0.1723 - acc: 0.9144 - val_loss: 0.1867 - val_acc: 0.9074\n",
      "Epoch 10/10\n",
      "1530/1530 [==============================] - 0s 254us/sample - loss: 0.1738 - acc: 0.9150 - val_loss: 0.1912 - val_acc: 0.8852\n",
      "Epoch 70 out of 150\n",
      "Train on 1530 samples, validate on 270 samples\n",
      "Epoch 1/10\n",
      "1530/1530 [==============================] - 0s 153us/sample - loss: 0.1738 - acc: 0.9072 - val_loss: 0.1883 - val_acc: 0.9222\n",
      "Epoch 2/10\n",
      "1530/1530 [==============================] - 0s 197us/sample - loss: 0.1738 - acc: 0.9157 - val_loss: 0.1914 - val_acc: 0.9259\n",
      "Epoch 3/10\n",
      "1530/1530 [==============================] - 0s 170us/sample - loss: 0.1727 - acc: 0.9209 - val_loss: 0.1901 - val_acc: 0.8815\n",
      "Epoch 4/10\n",
      "1530/1530 [==============================] - 0s 235us/sample - loss: 0.1738 - acc: 0.9105 - val_loss: 0.1885 - val_acc: 0.8852\n",
      "Epoch 5/10\n",
      "1530/1530 [==============================] - 0s 240us/sample - loss: 0.1729 - acc: 0.9052 - val_loss: 0.1896 - val_acc: 0.9222\n",
      "Epoch 6/10\n",
      "1530/1530 [==============================] - 1s 373us/sample - loss: 0.1722 - acc: 0.9203 - val_loss: 0.1860 - val_acc: 0.9148\n",
      "Epoch 7/10\n",
      "1530/1530 [==============================] - 1s 379us/sample - loss: 0.1737 - acc: 0.9190 - val_loss: 0.1925 - val_acc: 0.9407\n",
      "Epoch 8/10\n",
      "1530/1530 [==============================] - 0s 222us/sample - loss: 0.1746 - acc: 0.9288 - val_loss: 0.1867 - val_acc: 0.8926\n",
      "Epoch 9/10\n",
      "1530/1530 [==============================] - 0s 174us/sample - loss: 0.1719 - acc: 0.9131 - val_loss: 0.1871 - val_acc: 0.9074\n",
      "Epoch 10/10\n",
      "1530/1530 [==============================] - 0s 267us/sample - loss: 0.1722 - acc: 0.9111 - val_loss: 0.1864 - val_acc: 0.8926\n",
      "Epoch 71 out of 150\n",
      "Train on 1530 samples, validate on 270 samples\n",
      "Epoch 1/10\n",
      "1530/1530 [==============================] - 0s 214us/sample - loss: 0.1731 - acc: 0.9098 - val_loss: 0.1869 - val_acc: 0.9148\n",
      "Epoch 2/10\n",
      "1530/1530 [==============================] - 0s 304us/sample - loss: 0.1730 - acc: 0.9131 - val_loss: 0.1909 - val_acc: 0.8778\n",
      "Epoch 3/10\n",
      "1530/1530 [==============================] - 0s 252us/sample - loss: 0.1693 - acc: 0.9176 - val_loss: 0.1912 - val_acc: 0.8889\n",
      "Epoch 4/10\n",
      "1530/1530 [==============================] - 0s 141us/sample - loss: 0.1705 - acc: 0.9203 - val_loss: 0.1891 - val_acc: 0.8852\n",
      "Epoch 5/10\n",
      "1530/1530 [==============================] - 0s 144us/sample - loss: 0.1706 - acc: 0.9131 - val_loss: 0.1849 - val_acc: 0.9148\n",
      "Epoch 6/10\n",
      "1530/1530 [==============================] - 0s 159us/sample - loss: 0.1697 - acc: 0.9229 - val_loss: 0.1878 - val_acc: 0.8852\n",
      "Epoch 7/10\n",
      "1530/1530 [==============================] - 0s 145us/sample - loss: 0.1761 - acc: 0.9176 - val_loss: 0.1851 - val_acc: 0.8926\n",
      "Epoch 8/10\n",
      "1530/1530 [==============================] - 0s 142us/sample - loss: 0.1701 - acc: 0.9170 - val_loss: 0.1846 - val_acc: 0.9222\n",
      "Epoch 9/10\n",
      "1530/1530 [==============================] - 0s 156us/sample - loss: 0.1769 - acc: 0.9033 - val_loss: 0.1949 - val_acc: 0.8926\n",
      "Epoch 10/10\n",
      "1530/1530 [==============================] - 0s 159us/sample - loss: 0.1754 - acc: 0.9144 - val_loss: 0.1874 - val_acc: 0.9296\n",
      "Epoch 72 out of 150\n",
      "Train on 1530 samples, validate on 270 samples\n",
      "Epoch 1/10\n",
      "1530/1530 [==============================] - 0s 196us/sample - loss: 0.1706 - acc: 0.9157 - val_loss: 0.1846 - val_acc: 0.9111\n",
      "Epoch 2/10\n",
      "1530/1530 [==============================] - 0s 240us/sample - loss: 0.1711 - acc: 0.9235 - val_loss: 0.1839 - val_acc: 0.9185\n",
      "Epoch 3/10\n",
      "1530/1530 [==============================] - 0s 302us/sample - loss: 0.1695 - acc: 0.9229 - val_loss: 0.1987 - val_acc: 0.8778\n",
      "Epoch 4/10\n",
      "1530/1530 [==============================] - 0s 215us/sample - loss: 0.1718 - acc: 0.9183 - val_loss: 0.1851 - val_acc: 0.9148\n",
      "Epoch 5/10\n",
      "1530/1530 [==============================] - 1s 386us/sample - loss: 0.1681 - acc: 0.9176 - val_loss: 0.1897 - val_acc: 0.8852\n",
      "Epoch 6/10\n",
      "1530/1530 [==============================] - 0s 257us/sample - loss: 0.1698 - acc: 0.9196 - val_loss: 0.2086 - val_acc: 0.8852\n",
      "Epoch 7/10\n",
      "1530/1530 [==============================] - 1s 399us/sample - loss: 0.1733 - acc: 0.9118 - val_loss: 0.1901 - val_acc: 0.8852\n",
      "Epoch 8/10\n",
      "1530/1530 [==============================] - 0s 280us/sample - loss: 0.1710 - acc: 0.9176 - val_loss: 0.1944 - val_acc: 0.8852\n",
      "Epoch 9/10\n",
      "1530/1530 [==============================] - 0s 295us/sample - loss: 0.1679 - acc: 0.9268 - val_loss: 0.1862 - val_acc: 0.9259\n",
      "Epoch 10/10\n",
      "1530/1530 [==============================] - 0s 230us/sample - loss: 0.1711 - acc: 0.9209 - val_loss: 0.1837 - val_acc: 0.8926\n",
      "Epoch 73 out of 150\n",
      "Train on 1530 samples, validate on 270 samples\n",
      "Epoch 1/10\n",
      "1530/1530 [==============================] - 0s 282us/sample - loss: 0.1705 - acc: 0.9203 - val_loss: 0.1848 - val_acc: 0.9111\n",
      "Epoch 2/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1530/1530 [==============================] - 0s 224us/sample - loss: 0.1699 - acc: 0.9157 - val_loss: 0.1829 - val_acc: 0.9148\n",
      "Epoch 3/10\n",
      "1530/1530 [==============================] - 0s 153us/sample - loss: 0.1689 - acc: 0.9150 - val_loss: 0.1867 - val_acc: 0.9296\n",
      "Epoch 4/10\n",
      "1530/1530 [==============================] - 0s 154us/sample - loss: 0.1696 - acc: 0.9242 - val_loss: 0.1854 - val_acc: 0.9222\n",
      "Epoch 5/10\n",
      "1530/1530 [==============================] - 0s 164us/sample - loss: 0.1686 - acc: 0.9190 - val_loss: 0.1855 - val_acc: 0.8963\n",
      "Epoch 6/10\n",
      "1530/1530 [==============================] - 0s 213us/sample - loss: 0.1688 - acc: 0.9216 - val_loss: 0.1854 - val_acc: 0.9037\n",
      "Epoch 7/10\n",
      "1530/1530 [==============================] - 0s 199us/sample - loss: 0.1664 - acc: 0.9255 - val_loss: 0.1835 - val_acc: 0.9074\n",
      "Epoch 8/10\n",
      "1530/1530 [==============================] - 0s 154us/sample - loss: 0.1673 - acc: 0.9216 - val_loss: 0.1853 - val_acc: 0.8926\n",
      "Epoch 9/10\n",
      "1530/1530 [==============================] - 0s 147us/sample - loss: 0.1696 - acc: 0.9190 - val_loss: 0.1918 - val_acc: 0.8852\n",
      "Epoch 10/10\n",
      "1530/1530 [==============================] - 0s 138us/sample - loss: 0.1732 - acc: 0.9118 - val_loss: 0.1921 - val_acc: 0.9370\n",
      "Epoch 74 out of 150\n",
      "Train on 1530 samples, validate on 270 samples\n",
      "Epoch 1/10\n",
      "1530/1530 [==============================] - 0s 194us/sample - loss: 0.1699 - acc: 0.9248 - val_loss: 0.1966 - val_acc: 0.8852\n",
      "Epoch 2/10\n",
      "1530/1530 [==============================] - 0s 186us/sample - loss: 0.1711 - acc: 0.9163 - val_loss: 0.1926 - val_acc: 0.8815\n",
      "Epoch 3/10\n",
      "1530/1530 [==============================] - 0s 281us/sample - loss: 0.1691 - acc: 0.9137 - val_loss: 0.1832 - val_acc: 0.8852\n",
      "Epoch 4/10\n",
      "1530/1530 [==============================] - 0s 220us/sample - loss: 0.1655 - acc: 0.9190 - val_loss: 0.1852 - val_acc: 0.9000\n",
      "Epoch 5/10\n",
      "1530/1530 [==============================] - 0s 176us/sample - loss: 0.1667 - acc: 0.9209 - val_loss: 0.1819 - val_acc: 0.9111\n",
      "Epoch 6/10\n",
      "1530/1530 [==============================] - 0s 185us/sample - loss: 0.1702 - acc: 0.9209 - val_loss: 0.1821 - val_acc: 0.9185\n",
      "Epoch 7/10\n",
      "1530/1530 [==============================] - 1s 341us/sample - loss: 0.1714 - acc: 0.9183 - val_loss: 0.1821 - val_acc: 0.9037\n",
      "Epoch 8/10\n",
      "1530/1530 [==============================] - 0s 308us/sample - loss: 0.1688 - acc: 0.9235 - val_loss: 0.1884 - val_acc: 0.9370\n",
      "Epoch 9/10\n",
      "1530/1530 [==============================] - 0s 250us/sample - loss: 0.1692 - acc: 0.9268 - val_loss: 0.2111 - val_acc: 0.8889\n",
      "Epoch 10/10\n",
      "1530/1530 [==============================] - 0s 180us/sample - loss: 0.1683 - acc: 0.9216 - val_loss: 0.1880 - val_acc: 0.8889\n",
      "Epoch 75 out of 150\n",
      "Train on 1530 samples, validate on 270 samples\n",
      "Epoch 1/10\n",
      "1530/1530 [==============================] - 0s 167us/sample - loss: 0.1691 - acc: 0.9190 - val_loss: 0.1821 - val_acc: 0.9148\n",
      "Epoch 2/10\n",
      "1530/1530 [==============================] - 0s 155us/sample - loss: 0.1666 - acc: 0.9176 - val_loss: 0.1831 - val_acc: 0.9111\n",
      "Epoch 3/10\n",
      "1530/1530 [==============================] - 0s 138us/sample - loss: 0.1660 - acc: 0.9209 - val_loss: 0.1863 - val_acc: 0.9296\n",
      "Epoch 4/10\n",
      "1530/1530 [==============================] - 0s 155us/sample - loss: 0.1675 - acc: 0.9222 - val_loss: 0.1818 - val_acc: 0.9074\n",
      "Epoch 5/10\n",
      "1530/1530 [==============================] - 0s 152us/sample - loss: 0.1742 - acc: 0.9196 - val_loss: 0.1830 - val_acc: 0.8926\n",
      "Epoch 6/10\n",
      "1530/1530 [==============================] - 0s 136us/sample - loss: 0.1692 - acc: 0.9111 - val_loss: 0.1844 - val_acc: 0.8926\n",
      "Epoch 7/10\n",
      "1530/1530 [==============================] - 0s 133us/sample - loss: 0.1646 - acc: 0.9203 - val_loss: 0.1837 - val_acc: 0.9296\n",
      "Epoch 8/10\n",
      "1530/1530 [==============================] - 0s 139us/sample - loss: 0.1698 - acc: 0.9196 - val_loss: 0.1813 - val_acc: 0.9111\n",
      "Epoch 9/10\n",
      "1530/1530 [==============================] - 0s 142us/sample - loss: 0.1661 - acc: 0.9255 - val_loss: 0.1818 - val_acc: 0.9259\n",
      "Epoch 10/10\n",
      "1530/1530 [==============================] - 0s 312us/sample - loss: 0.1670 - acc: 0.9209 - val_loss: 0.1820 - val_acc: 0.9185\n",
      "Epoch 76 out of 150\n",
      "Train on 1530 samples, validate on 270 samples\n",
      "Epoch 1/10\n",
      "1530/1530 [==============================] - 0s 169us/sample - loss: 0.1645 - acc: 0.9229 - val_loss: 0.1859 - val_acc: 0.8889\n",
      "Epoch 2/10\n",
      "1530/1530 [==============================] - 0s 169us/sample - loss: 0.1681 - acc: 0.9118 - val_loss: 0.1855 - val_acc: 0.9333\n",
      "Epoch 3/10\n",
      "1530/1530 [==============================] - 0s 140us/sample - loss: 0.1672 - acc: 0.9216 - val_loss: 0.1825 - val_acc: 0.8963\n",
      "Epoch 4/10\n",
      "1530/1530 [==============================] - 0s 192us/sample - loss: 0.1667 - acc: 0.9176 - val_loss: 0.1863 - val_acc: 0.9074\n",
      "Epoch 5/10\n",
      "1530/1530 [==============================] - 0s 171us/sample - loss: 0.1695 - acc: 0.9163 - val_loss: 0.1868 - val_acc: 0.9037\n",
      "Epoch 6/10\n",
      "1530/1530 [==============================] - 0s 145us/sample - loss: 0.1665 - acc: 0.9209 - val_loss: 0.1871 - val_acc: 0.9185\n",
      "Epoch 7/10\n",
      "1530/1530 [==============================] - 0s 145us/sample - loss: 0.1665 - acc: 0.9190 - val_loss: 0.1887 - val_acc: 0.9000\n",
      "Epoch 8/10\n",
      "1530/1530 [==============================] - 0s 141us/sample - loss: 0.1647 - acc: 0.9275 - val_loss: 0.1922 - val_acc: 0.8815\n",
      "Epoch 9/10\n",
      "1530/1530 [==============================] - 0s 169us/sample - loss: 0.1646 - acc: 0.9229 - val_loss: 0.1913 - val_acc: 0.9296\n",
      "Epoch 10/10\n",
      "1530/1530 [==============================] - 0s 177us/sample - loss: 0.1663 - acc: 0.9255 - val_loss: 0.1816 - val_acc: 0.9111\n",
      "Epoch 77 out of 150\n",
      "Train on 1530 samples, validate on 270 samples\n",
      "Epoch 1/10\n",
      "1530/1530 [==============================] - 0s 166us/sample - loss: 0.1646 - acc: 0.9261 - val_loss: 0.1807 - val_acc: 0.9111\n",
      "Epoch 2/10\n",
      "1530/1530 [==============================] - 0s 166us/sample - loss: 0.1656 - acc: 0.9209 - val_loss: 0.1811 - val_acc: 0.9111\n",
      "Epoch 3/10\n",
      "1530/1530 [==============================] - 0s 188us/sample - loss: 0.1659 - acc: 0.9268 - val_loss: 0.1852 - val_acc: 0.9037\n",
      "Epoch 4/10\n",
      "1530/1530 [==============================] - 0s 155us/sample - loss: 0.1676 - acc: 0.9248 - val_loss: 0.1822 - val_acc: 0.9111\n",
      "Epoch 5/10\n",
      "1530/1530 [==============================] - 0s 166us/sample - loss: 0.1690 - acc: 0.9222 - val_loss: 0.1831 - val_acc: 0.8852\n",
      "Epoch 6/10\n",
      "1530/1530 [==============================] - 0s 186us/sample - loss: 0.1662 - acc: 0.9229 - val_loss: 0.1850 - val_acc: 0.8815\n",
      "Epoch 7/10\n",
      "1530/1530 [==============================] - 0s 289us/sample - loss: 0.1726 - acc: 0.9144 - val_loss: 0.1840 - val_acc: 0.9222\n",
      "Epoch 8/10\n",
      "1530/1530 [==============================] - 0s 167us/sample - loss: 0.1687 - acc: 0.9216 - val_loss: 0.1946 - val_acc: 0.9148\n",
      "Epoch 9/10\n",
      "1530/1530 [==============================] - 0s 175us/sample - loss: 0.1672 - acc: 0.9268 - val_loss: 0.2195 - val_acc: 0.8815\n",
      "Epoch 10/10\n",
      "1530/1530 [==============================] - 0s 135us/sample - loss: 0.1680 - acc: 0.9229 - val_loss: 0.1833 - val_acc: 0.9296\n",
      "Epoch 78 out of 150\n",
      "Train on 1530 samples, validate on 270 samples\n",
      "Epoch 1/10\n",
      "1530/1530 [==============================] - 0s 172us/sample - loss: 0.1635 - acc: 0.9268 - val_loss: 0.1846 - val_acc: 0.8889\n",
      "Epoch 2/10\n",
      "1530/1530 [==============================] - 0s 274us/sample - loss: 0.1679 - acc: 0.9190 - val_loss: 0.1895 - val_acc: 0.9370\n",
      "Epoch 3/10\n",
      "1530/1530 [==============================] - 0s 181us/sample - loss: 0.1641 - acc: 0.9255 - val_loss: 0.1804 - val_acc: 0.9185\n",
      "Epoch 4/10\n",
      "1530/1530 [==============================] - 0s 140us/sample - loss: 0.1649 - acc: 0.9216 - val_loss: 0.1822 - val_acc: 0.8852\n",
      "Epoch 5/10\n",
      "1530/1530 [==============================] - 0s 255us/sample - loss: 0.1647 - acc: 0.9196 - val_loss: 0.1802 - val_acc: 0.9222\n",
      "Epoch 6/10\n",
      "1530/1530 [==============================] - 0s 315us/sample - loss: 0.1642 - acc: 0.9248 - val_loss: 0.1864 - val_acc: 0.9000\n",
      "Epoch 7/10\n",
      "1530/1530 [==============================] - 0s 187us/sample - loss: 0.1666 - acc: 0.9216 - val_loss: 0.1923 - val_acc: 0.8778\n",
      "Epoch 8/10\n",
      "1530/1530 [==============================] - 0s 151us/sample - loss: 0.1653 - acc: 0.9183 - val_loss: 0.1803 - val_acc: 0.9111\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/10\n",
      "1530/1530 [==============================] - 0s 151us/sample - loss: 0.1683 - acc: 0.9248 - val_loss: 0.1871 - val_acc: 0.9259\n",
      "Epoch 10/10\n",
      "1530/1530 [==============================] - 0s 140us/sample - loss: 0.1638 - acc: 0.9190 - val_loss: 0.1814 - val_acc: 0.8889\n",
      "Epoch 79 out of 150\n",
      "Train on 1530 samples, validate on 270 samples\n",
      "Epoch 1/10\n",
      "1530/1530 [==============================] - 0s 136us/sample - loss: 0.1614 - acc: 0.9248 - val_loss: 0.1804 - val_acc: 0.9111\n",
      "Epoch 2/10\n",
      "1530/1530 [==============================] - 0s 134us/sample - loss: 0.1620 - acc: 0.9261 - val_loss: 0.1855 - val_acc: 0.9148\n",
      "Epoch 3/10\n",
      "1530/1530 [==============================] - 0s 145us/sample - loss: 0.1670 - acc: 0.9229 - val_loss: 0.1807 - val_acc: 0.9185\n",
      "Epoch 4/10\n",
      "1530/1530 [==============================] - 0s 136us/sample - loss: 0.1633 - acc: 0.9235 - val_loss: 0.1818 - val_acc: 0.9111\n",
      "Epoch 5/10\n",
      "1530/1530 [==============================] - 0s 167us/sample - loss: 0.1632 - acc: 0.9320 - val_loss: 0.1853 - val_acc: 0.9074\n",
      "Epoch 6/10\n",
      "1530/1530 [==============================] - 0s 139us/sample - loss: 0.1691 - acc: 0.9137 - val_loss: 0.2262 - val_acc: 0.8852\n",
      "Epoch 7/10\n",
      "1530/1530 [==============================] - 0s 141us/sample - loss: 0.1648 - acc: 0.9216 - val_loss: 0.1840 - val_acc: 0.9185\n",
      "Epoch 8/10\n",
      "1530/1530 [==============================] - 0s 151us/sample - loss: 0.1618 - acc: 0.9235 - val_loss: 0.1818 - val_acc: 0.9185\n",
      "Epoch 9/10\n",
      "1530/1530 [==============================] - 0s 168us/sample - loss: 0.1700 - acc: 0.9190 - val_loss: 0.1838 - val_acc: 0.9259\n",
      "Epoch 10/10\n",
      "1530/1530 [==============================] - 0s 169us/sample - loss: 0.1653 - acc: 0.9216 - val_loss: 0.1862 - val_acc: 0.8815\n",
      "Epoch 80 out of 150\n",
      "Train on 1530 samples, validate on 270 samples\n",
      "Epoch 1/10\n",
      "1530/1530 [==============================] - 0s 174us/sample - loss: 0.1631 - acc: 0.9255 - val_loss: 0.1818 - val_acc: 0.9185\n",
      "Epoch 2/10\n",
      "1530/1530 [==============================] - 0s 167us/sample - loss: 0.1633 - acc: 0.9229 - val_loss: 0.1801 - val_acc: 0.9148\n",
      "Epoch 3/10\n",
      "1530/1530 [==============================] - 0s 153us/sample - loss: 0.1608 - acc: 0.9216 - val_loss: 0.1828 - val_acc: 0.9037\n",
      "Epoch 4/10\n",
      "1530/1530 [==============================] - 0s 169us/sample - loss: 0.1634 - acc: 0.9183 - val_loss: 0.1955 - val_acc: 0.8889\n",
      "Epoch 5/10\n",
      "1530/1530 [==============================] - 0s 136us/sample - loss: 0.1622 - acc: 0.9307 - val_loss: 0.1834 - val_acc: 0.8815\n",
      "Epoch 6/10\n",
      "1530/1530 [==============================] - 0s 160us/sample - loss: 0.1628 - acc: 0.9222 - val_loss: 0.1852 - val_acc: 0.8889\n",
      "Epoch 7/10\n",
      "1530/1530 [==============================] - 0s 155us/sample - loss: 0.1590 - acc: 0.9255 - val_loss: 0.1846 - val_acc: 0.9185\n",
      "Epoch 8/10\n",
      "1530/1530 [==============================] - 0s 154us/sample - loss: 0.1627 - acc: 0.9196 - val_loss: 0.1863 - val_acc: 0.9000\n",
      "Epoch 9/10\n",
      "1530/1530 [==============================] - 0s 144us/sample - loss: 0.1638 - acc: 0.9235 - val_loss: 0.1808 - val_acc: 0.9000\n",
      "Epoch 10/10\n",
      "1530/1530 [==============================] - 0s 156us/sample - loss: 0.1605 - acc: 0.9235 - val_loss: 0.1840 - val_acc: 0.9074\n",
      "Epoch 81 out of 150\n",
      "Train on 1530 samples, validate on 270 samples\n",
      "Epoch 1/10\n",
      "1530/1530 [==============================] - 0s 153us/sample - loss: 0.1604 - acc: 0.9333 - val_loss: 0.1805 - val_acc: 0.9222\n",
      "Epoch 2/10\n",
      "1530/1530 [==============================] - 0s 154us/sample - loss: 0.1596 - acc: 0.9281 - val_loss: 0.1882 - val_acc: 0.9333\n",
      "Epoch 3/10\n",
      "1530/1530 [==============================] - 0s 147us/sample - loss: 0.1590 - acc: 0.9268 - val_loss: 0.1816 - val_acc: 0.9222\n",
      "Epoch 4/10\n",
      "1530/1530 [==============================] - 0s 165us/sample - loss: 0.1618 - acc: 0.9261 - val_loss: 0.1836 - val_acc: 0.8852\n",
      "Epoch 5/10\n",
      "1530/1530 [==============================] - 0s 146us/sample - loss: 0.1620 - acc: 0.9209 - val_loss: 0.1863 - val_acc: 0.9333\n",
      "Epoch 6/10\n",
      "1530/1530 [==============================] - 0s 160us/sample - loss: 0.1588 - acc: 0.9320 - val_loss: 0.1841 - val_acc: 0.9074\n",
      "Epoch 7/10\n",
      "1530/1530 [==============================] - 0s 149us/sample - loss: 0.1670 - acc: 0.9261 - val_loss: 0.1811 - val_acc: 0.9111\n",
      "Epoch 8/10\n",
      "1530/1530 [==============================] - 0s 145us/sample - loss: 0.1595 - acc: 0.9261 - val_loss: 0.1802 - val_acc: 0.9185\n",
      "Epoch 9/10\n",
      "1530/1530 [==============================] - 0s 138us/sample - loss: 0.1612 - acc: 0.9235 - val_loss: 0.1844 - val_acc: 0.8852\n",
      "Epoch 10/10\n",
      "1530/1530 [==============================] - 0s 141us/sample - loss: 0.1615 - acc: 0.9248 - val_loss: 0.1896 - val_acc: 0.9259\n",
      "Epoch 82 out of 150\n",
      "Train on 1530 samples, validate on 270 samples\n",
      "Epoch 1/10\n",
      "1530/1530 [==============================] - 0s 151us/sample - loss: 0.1604 - acc: 0.9216 - val_loss: 0.2023 - val_acc: 0.9259\n",
      "Epoch 2/10\n",
      "1530/1530 [==============================] - 0s 225us/sample - loss: 0.1613 - acc: 0.9275 - val_loss: 0.1789 - val_acc: 0.9111\n",
      "Epoch 3/10\n",
      "1530/1530 [==============================] - 0s 160us/sample - loss: 0.1646 - acc: 0.9235 - val_loss: 0.1823 - val_acc: 0.9185\n",
      "Epoch 4/10\n",
      "1530/1530 [==============================] - 0s 210us/sample - loss: 0.1607 - acc: 0.9261 - val_loss: 0.1856 - val_acc: 0.9222\n",
      "Epoch 5/10\n",
      "1530/1530 [==============================] - 0s 160us/sample - loss: 0.1627 - acc: 0.9261 - val_loss: 0.1800 - val_acc: 0.9148\n",
      "Epoch 6/10\n",
      "1530/1530 [==============================] - 0s 148us/sample - loss: 0.1606 - acc: 0.9294 - val_loss: 0.1863 - val_acc: 0.8889\n",
      "Epoch 7/10\n",
      "1530/1530 [==============================] - 0s 165us/sample - loss: 0.1587 - acc: 0.9301 - val_loss: 0.1822 - val_acc: 0.9296\n",
      "Epoch 8/10\n",
      "1530/1530 [==============================] - 0s 173us/sample - loss: 0.1569 - acc: 0.9346 - val_loss: 0.1926 - val_acc: 0.9333\n",
      "Epoch 9/10\n",
      "1530/1530 [==============================] - 0s 155us/sample - loss: 0.1629 - acc: 0.9203 - val_loss: 0.1877 - val_acc: 0.9296\n",
      "Epoch 10/10\n",
      "1530/1530 [==============================] - 0s 191us/sample - loss: 0.1596 - acc: 0.9255 - val_loss: 0.1834 - val_acc: 0.8889\n",
      "Epoch 83 out of 150\n",
      "Train on 1530 samples, validate on 270 samples\n",
      "Epoch 1/10\n",
      "1530/1530 [==============================] - 0s 138us/sample - loss: 0.1594 - acc: 0.9203 - val_loss: 0.1922 - val_acc: 0.8815\n",
      "Epoch 2/10\n",
      "1530/1530 [==============================] - 0s 139us/sample - loss: 0.1623 - acc: 0.9183 - val_loss: 0.1786 - val_acc: 0.9222\n",
      "Epoch 3/10\n",
      "1530/1530 [==============================] - 0s 138us/sample - loss: 0.1610 - acc: 0.9307 - val_loss: 0.1793 - val_acc: 0.9296\n",
      "Epoch 4/10\n",
      "1530/1530 [==============================] - 0s 150us/sample - loss: 0.1571 - acc: 0.9281 - val_loss: 0.1795 - val_acc: 0.9037\n",
      "Epoch 5/10\n",
      "1530/1530 [==============================] - 0s 220us/sample - loss: 0.1578 - acc: 0.9353 - val_loss: 0.1781 - val_acc: 0.9074\n",
      "Epoch 6/10\n",
      "1530/1530 [==============================] - 0s 186us/sample - loss: 0.1591 - acc: 0.9268 - val_loss: 0.1776 - val_acc: 0.9111\n",
      "Epoch 7/10\n",
      "1530/1530 [==============================] - 0s 232us/sample - loss: 0.1581 - acc: 0.9314 - val_loss: 0.1779 - val_acc: 0.9185\n",
      "Epoch 8/10\n",
      "1530/1530 [==============================] - 0s 210us/sample - loss: 0.1601 - acc: 0.9222 - val_loss: 0.1840 - val_acc: 0.9296\n",
      "Epoch 9/10\n",
      "1530/1530 [==============================] - 0s 190us/sample - loss: 0.1602 - acc: 0.9261 - val_loss: 0.1777 - val_acc: 0.9148\n",
      "Epoch 10/10\n",
      "1530/1530 [==============================] - 0s 171us/sample - loss: 0.1606 - acc: 0.9275 - val_loss: 0.1844 - val_acc: 0.9148\n",
      "Epoch 84 out of 150\n",
      "Train on 1530 samples, validate on 270 samples\n",
      "Epoch 1/10\n",
      "1530/1530 [==============================] - 0s 177us/sample - loss: 0.1583 - acc: 0.9301 - val_loss: 0.1799 - val_acc: 0.9222\n",
      "Epoch 2/10\n",
      "1530/1530 [==============================] - 0s 180us/sample - loss: 0.1584 - acc: 0.9261 - val_loss: 0.1855 - val_acc: 0.9111\n",
      "Epoch 3/10\n",
      "1530/1530 [==============================] - 0s 184us/sample - loss: 0.1584 - acc: 0.9248 - val_loss: 0.1906 - val_acc: 0.8889\n",
      "Epoch 4/10\n",
      "1530/1530 [==============================] - 0s 244us/sample - loss: 0.1580 - acc: 0.9196 - val_loss: 0.1836 - val_acc: 0.9037\n",
      "Epoch 5/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1530/1530 [==============================] - 0s 163us/sample - loss: 0.1572 - acc: 0.9294 - val_loss: 0.1789 - val_acc: 0.9222\n",
      "Epoch 6/10\n",
      "1530/1530 [==============================] - 0s 216us/sample - loss: 0.1554 - acc: 0.9346 - val_loss: 0.1978 - val_acc: 0.8852\n",
      "Epoch 7/10\n",
      "1530/1530 [==============================] - 0s 166us/sample - loss: 0.1587 - acc: 0.9275 - val_loss: 0.1838 - val_acc: 0.8852\n",
      "Epoch 8/10\n",
      "1530/1530 [==============================] - 0s 207us/sample - loss: 0.1628 - acc: 0.9294 - val_loss: 0.1838 - val_acc: 0.8889\n",
      "Epoch 9/10\n",
      "1530/1530 [==============================] - 0s 203us/sample - loss: 0.1605 - acc: 0.9242 - val_loss: 0.1869 - val_acc: 0.9222\n",
      "Epoch 10/10\n",
      "1530/1530 [==============================] - 1s 574us/sample - loss: 0.1618 - acc: 0.9248 - val_loss: 0.1778 - val_acc: 0.9037\n",
      "Epoch 85 out of 150\n",
      "Train on 1530 samples, validate on 270 samples\n",
      "Epoch 1/10\n",
      "1530/1530 [==============================] - 0s 184us/sample - loss: 0.1591 - acc: 0.9333 - val_loss: 0.1926 - val_acc: 0.9259\n",
      "Epoch 2/10\n",
      "1530/1530 [==============================] - 0s 177us/sample - loss: 0.1603 - acc: 0.9327 - val_loss: 0.1808 - val_acc: 0.8889\n",
      "Epoch 3/10\n",
      "1530/1530 [==============================] - 0s 166us/sample - loss: 0.1618 - acc: 0.9248 - val_loss: 0.1879 - val_acc: 0.9037\n",
      "Epoch 4/10\n",
      "1530/1530 [==============================] - 0s 217us/sample - loss: 0.1624 - acc: 0.9209 - val_loss: 0.1812 - val_acc: 0.9222\n",
      "Epoch 5/10\n",
      "1530/1530 [==============================] - 0s 171us/sample - loss: 0.1570 - acc: 0.9327 - val_loss: 0.1815 - val_acc: 0.9037\n",
      "Epoch 6/10\n",
      "1530/1530 [==============================] - 0s 145us/sample - loss: 0.1588 - acc: 0.9261 - val_loss: 0.1813 - val_acc: 0.8926\n",
      "Epoch 7/10\n",
      "1530/1530 [==============================] - 0s 138us/sample - loss: 0.1556 - acc: 0.9268 - val_loss: 0.1787 - val_acc: 0.9222\n",
      "Epoch 8/10\n",
      "1530/1530 [==============================] - 0s 142us/sample - loss: 0.1558 - acc: 0.9327 - val_loss: 0.1900 - val_acc: 0.8889\n",
      "Epoch 9/10\n",
      "1530/1530 [==============================] - 0s 156us/sample - loss: 0.1545 - acc: 0.9373 - val_loss: 0.1784 - val_acc: 0.9111\n",
      "Epoch 10/10\n",
      "1530/1530 [==============================] - 0s 151us/sample - loss: 0.1592 - acc: 0.9222 - val_loss: 0.1751 - val_acc: 0.9074\n",
      "Epoch 86 out of 150\n",
      "Train on 1530 samples, validate on 270 samples\n",
      "Epoch 1/10\n",
      "1530/1530 [==============================] - 0s 143us/sample - loss: 0.1556 - acc: 0.9359 - val_loss: 0.1771 - val_acc: 0.9074\n",
      "Epoch 2/10\n",
      "1530/1530 [==============================] - 0s 154us/sample - loss: 0.1559 - acc: 0.9346 - val_loss: 0.1762 - val_acc: 0.9222\n",
      "Epoch 3/10\n",
      "1530/1530 [==============================] - 0s 238us/sample - loss: 0.1566 - acc: 0.9288 - val_loss: 0.1777 - val_acc: 0.9222\n",
      "Epoch 4/10\n",
      "1530/1530 [==============================] - 0s 207us/sample - loss: 0.1564 - acc: 0.9268 - val_loss: 0.1890 - val_acc: 0.9259\n",
      "Epoch 5/10\n",
      "1530/1530 [==============================] - 0s 147us/sample - loss: 0.1580 - acc: 0.9307 - val_loss: 0.1764 - val_acc: 0.9185\n",
      "Epoch 6/10\n",
      "1530/1530 [==============================] - 0s 176us/sample - loss: 0.1552 - acc: 0.9320 - val_loss: 0.1721 - val_acc: 0.9185\n",
      "Epoch 7/10\n",
      "1530/1530 [==============================] - 0s 180us/sample - loss: 0.1611 - acc: 0.9190 - val_loss: 0.1790 - val_acc: 0.8963\n",
      "Epoch 8/10\n",
      "1530/1530 [==============================] - 0s 158us/sample - loss: 0.1544 - acc: 0.9399 - val_loss: 0.1801 - val_acc: 0.9148\n",
      "Epoch 9/10\n",
      "1530/1530 [==============================] - 0s 140us/sample - loss: 0.1599 - acc: 0.9170 - val_loss: 0.1970 - val_acc: 0.8889\n",
      "Epoch 10/10\n",
      "1530/1530 [==============================] - 0s 149us/sample - loss: 0.1587 - acc: 0.9222 - val_loss: 0.1788 - val_acc: 0.9111\n",
      "Epoch 87 out of 150\n",
      "Train on 1530 samples, validate on 270 samples\n",
      "Epoch 1/10\n",
      "1530/1530 [==============================] - 0s 154us/sample - loss: 0.1643 - acc: 0.9203 - val_loss: 0.1912 - val_acc: 0.8963\n",
      "Epoch 2/10\n",
      "1530/1530 [==============================] - 0s 151us/sample - loss: 0.1541 - acc: 0.9353 - val_loss: 0.1782 - val_acc: 0.9111\n",
      "Epoch 3/10\n",
      "1530/1530 [==============================] - 0s 149us/sample - loss: 0.1559 - acc: 0.9314 - val_loss: 0.1959 - val_acc: 0.8889\n",
      "Epoch 4/10\n",
      "1530/1530 [==============================] - 0s 156us/sample - loss: 0.1562 - acc: 0.9301 - val_loss: 0.1850 - val_acc: 0.9333\n",
      "Epoch 5/10\n",
      "1530/1530 [==============================] - 0s 157us/sample - loss: 0.1561 - acc: 0.9288 - val_loss: 0.1824 - val_acc: 0.9370\n",
      "Epoch 6/10\n",
      "1530/1530 [==============================] - 0s 139us/sample - loss: 0.1615 - acc: 0.9268 - val_loss: 0.1779 - val_acc: 0.9148\n",
      "Epoch 7/10\n",
      "1530/1530 [==============================] - 0s 139us/sample - loss: 0.1557 - acc: 0.9346 - val_loss: 0.1799 - val_acc: 0.9185\n",
      "Epoch 8/10\n",
      "1530/1530 [==============================] - 0s 150us/sample - loss: 0.1560 - acc: 0.9301 - val_loss: 0.1938 - val_acc: 0.8889\n",
      "Epoch 9/10\n",
      "1530/1530 [==============================] - 0s 166us/sample - loss: 0.1544 - acc: 0.9307 - val_loss: 0.1757 - val_acc: 0.9259\n",
      "Epoch 10/10\n",
      "1530/1530 [==============================] - 0s 226us/sample - loss: 0.1549 - acc: 0.9307 - val_loss: 0.1770 - val_acc: 0.9074\n",
      "Epoch 88 out of 150\n",
      "Train on 1530 samples, validate on 270 samples\n",
      "Epoch 1/10\n",
      "1530/1530 [==============================] - 1s 336us/sample - loss: 0.1545 - acc: 0.9320 - val_loss: 0.1812 - val_acc: 0.9296\n",
      "Epoch 2/10\n",
      "1530/1530 [==============================] - 0s 222us/sample - loss: 0.1546 - acc: 0.9353 - val_loss: 0.1903 - val_acc: 0.9259\n",
      "Epoch 3/10\n",
      "1530/1530 [==============================] - 0s 188us/sample - loss: 0.1580 - acc: 0.9294 - val_loss: 0.1793 - val_acc: 0.9259\n",
      "Epoch 4/10\n",
      "1530/1530 [==============================] - 0s 164us/sample - loss: 0.1553 - acc: 0.9294 - val_loss: 0.1809 - val_acc: 0.9259\n",
      "Epoch 5/10\n",
      "1530/1530 [==============================] - 0s 203us/sample - loss: 0.1585 - acc: 0.9268 - val_loss: 0.1883 - val_acc: 0.9296\n",
      "Epoch 6/10\n",
      "1530/1530 [==============================] - 0s 144us/sample - loss: 0.1551 - acc: 0.9346 - val_loss: 0.1762 - val_acc: 0.9148\n",
      "Epoch 7/10\n",
      "1530/1530 [==============================] - 0s 138us/sample - loss: 0.1562 - acc: 0.9327 - val_loss: 0.1746 - val_acc: 0.9296\n",
      "Epoch 8/10\n",
      "1530/1530 [==============================] - 0s 132us/sample - loss: 0.1574 - acc: 0.9268 - val_loss: 0.1817 - val_acc: 0.8778\n",
      "Epoch 9/10\n",
      "1530/1530 [==============================] - 0s 145us/sample - loss: 0.1559 - acc: 0.9320 - val_loss: 0.1762 - val_acc: 0.9259\n",
      "Epoch 10/10\n",
      "1530/1530 [==============================] - 0s 135us/sample - loss: 0.1533 - acc: 0.9314 - val_loss: 0.1769 - val_acc: 0.8963\n",
      "Epoch 89 out of 150\n",
      "Train on 1530 samples, validate on 270 samples\n",
      "Epoch 1/10\n",
      "1530/1530 [==============================] - 0s 154us/sample - loss: 0.1535 - acc: 0.9268 - val_loss: 0.1837 - val_acc: 0.9296\n",
      "Epoch 2/10\n",
      "1530/1530 [==============================] - 0s 182us/sample - loss: 0.1546 - acc: 0.9294 - val_loss: 0.1884 - val_acc: 0.9222\n",
      "Epoch 3/10\n",
      "1530/1530 [==============================] - 0s 140us/sample - loss: 0.1513 - acc: 0.9392 - val_loss: 0.1777 - val_acc: 0.9148\n",
      "Epoch 4/10\n",
      "1530/1530 [==============================] - 0s 163us/sample - loss: 0.1547 - acc: 0.9275 - val_loss: 0.1728 - val_acc: 0.9370\n",
      "Epoch 5/10\n",
      "1530/1530 [==============================] - 0s 160us/sample - loss: 0.1546 - acc: 0.9320 - val_loss: 0.1767 - val_acc: 0.9111\n",
      "Epoch 6/10\n",
      "1530/1530 [==============================] - 0s 141us/sample - loss: 0.1568 - acc: 0.9248 - val_loss: 0.1768 - val_acc: 0.9296\n",
      "Epoch 7/10\n",
      "1530/1530 [==============================] - 0s 138us/sample - loss: 0.1533 - acc: 0.9353 - val_loss: 0.1747 - val_acc: 0.9074\n",
      "Epoch 8/10\n",
      "1530/1530 [==============================] - 0s 158us/sample - loss: 0.1537 - acc: 0.9301 - val_loss: 0.1761 - val_acc: 0.9185\n",
      "Epoch 9/10\n",
      "1530/1530 [==============================] - 0s 164us/sample - loss: 0.1582 - acc: 0.9242 - val_loss: 0.1828 - val_acc: 0.9296\n",
      "Epoch 10/10\n",
      "1530/1530 [==============================] - 0s 145us/sample - loss: 0.1552 - acc: 0.9268 - val_loss: 0.1734 - val_acc: 0.9222\n",
      "Epoch 90 out of 150\n",
      "Train on 1530 samples, validate on 270 samples\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1530/1530 [==============================] - 0s 224us/sample - loss: 0.1536 - acc: 0.9294 - val_loss: 0.1729 - val_acc: 0.9222\n",
      "Epoch 2/10\n",
      "1530/1530 [==============================] - 0s 177us/sample - loss: 0.1541 - acc: 0.9268 - val_loss: 0.1763 - val_acc: 0.9148\n",
      "Epoch 3/10\n",
      "1530/1530 [==============================] - 0s 198us/sample - loss: 0.1565 - acc: 0.9301 - val_loss: 0.1748 - val_acc: 0.9148\n",
      "Epoch 4/10\n",
      "1530/1530 [==============================] - 0s 234us/sample - loss: 0.1533 - acc: 0.9333 - val_loss: 0.1729 - val_acc: 0.9222\n",
      "Epoch 5/10\n",
      "1530/1530 [==============================] - 0s 184us/sample - loss: 0.1544 - acc: 0.9294 - val_loss: 0.1833 - val_acc: 0.9296\n",
      "Epoch 6/10\n",
      "1530/1530 [==============================] - 0s 191us/sample - loss: 0.1586 - acc: 0.9261 - val_loss: 0.1786 - val_acc: 0.8889\n",
      "Epoch 7/10\n",
      "1530/1530 [==============================] - 0s 188us/sample - loss: 0.1540 - acc: 0.9320 - val_loss: 0.1806 - val_acc: 0.8852\n",
      "Epoch 8/10\n",
      "1530/1530 [==============================] - 0s 146us/sample - loss: 0.1545 - acc: 0.9294 - val_loss: 0.1720 - val_acc: 0.9000\n",
      "Epoch 9/10\n",
      "1530/1530 [==============================] - 0s 149us/sample - loss: 0.1518 - acc: 0.9301 - val_loss: 0.2529 - val_acc: 0.8889\n",
      "Epoch 10/10\n",
      "1530/1530 [==============================] - 0s 143us/sample - loss: 0.1565 - acc: 0.9255 - val_loss: 0.1756 - val_acc: 0.9111\n",
      "Epoch 91 out of 150\n",
      "Train on 1530 samples, validate on 270 samples\n",
      "Epoch 1/10\n",
      "1530/1530 [==============================] - 0s 179us/sample - loss: 0.1561 - acc: 0.9327 - val_loss: 0.1750 - val_acc: 0.9222\n",
      "Epoch 2/10\n",
      "1530/1530 [==============================] - 0s 184us/sample - loss: 0.1529 - acc: 0.9314 - val_loss: 0.1798 - val_acc: 0.9296\n",
      "Epoch 3/10\n",
      "1530/1530 [==============================] - 0s 186us/sample - loss: 0.1527 - acc: 0.9333 - val_loss: 0.1757 - val_acc: 0.9296\n",
      "Epoch 4/10\n",
      "1530/1530 [==============================] - 0s 196us/sample - loss: 0.1544 - acc: 0.9327 - val_loss: 0.1790 - val_acc: 0.9222\n",
      "Epoch 5/10\n",
      "1530/1530 [==============================] - 0s 248us/sample - loss: 0.1538 - acc: 0.9281 - val_loss: 0.1824 - val_acc: 0.9407\n",
      "Epoch 6/10\n",
      "1530/1530 [==============================] - 0s 144us/sample - loss: 0.1530 - acc: 0.9275 - val_loss: 0.1828 - val_acc: 0.8815\n",
      "Epoch 7/10\n",
      "1530/1530 [==============================] - 0s 168us/sample - loss: 0.1583 - acc: 0.9268 - val_loss: 0.1853 - val_acc: 0.9333\n",
      "Epoch 8/10\n",
      "1530/1530 [==============================] - 0s 156us/sample - loss: 0.1604 - acc: 0.9248 - val_loss: 0.1891 - val_acc: 0.9333\n",
      "Epoch 9/10\n",
      "1530/1530 [==============================] - 0s 157us/sample - loss: 0.1513 - acc: 0.9373 - val_loss: 0.1762 - val_acc: 0.9222\n",
      "Epoch 10/10\n",
      "1530/1530 [==============================] - 0s 141us/sample - loss: 0.1520 - acc: 0.9438 - val_loss: 0.1733 - val_acc: 0.9333\n",
      "Epoch 92 out of 150\n",
      "Train on 1530 samples, validate on 270 samples\n",
      "Epoch 1/10\n",
      "1530/1530 [==============================] - 0s 280us/sample - loss: 0.1529 - acc: 0.9288 - val_loss: 0.1757 - val_acc: 0.9222\n",
      "Epoch 2/10\n",
      "1530/1530 [==============================] - 0s 198us/sample - loss: 0.1553 - acc: 0.9301 - val_loss: 0.1807 - val_acc: 0.9407\n",
      "Epoch 3/10\n",
      "1530/1530 [==============================] - 0s 197us/sample - loss: 0.1559 - acc: 0.9275 - val_loss: 0.1811 - val_acc: 0.9370\n",
      "Epoch 4/10\n",
      "1530/1530 [==============================] - 0s 145us/sample - loss: 0.1541 - acc: 0.9281 - val_loss: 0.1857 - val_acc: 0.8815\n",
      "Epoch 5/10\n",
      "1530/1530 [==============================] - 0s 147us/sample - loss: 0.1569 - acc: 0.9340 - val_loss: 0.1730 - val_acc: 0.9296\n",
      "Epoch 6/10\n",
      "1530/1530 [==============================] - 0s 138us/sample - loss: 0.1513 - acc: 0.9301 - val_loss: 0.1841 - val_acc: 0.8852\n",
      "Epoch 7/10\n",
      "1530/1530 [==============================] - 0s 144us/sample - loss: 0.1545 - acc: 0.9320 - val_loss: 0.1872 - val_acc: 0.8926\n",
      "Epoch 8/10\n",
      "1530/1530 [==============================] - 0s 148us/sample - loss: 0.1544 - acc: 0.9275 - val_loss: 0.1788 - val_acc: 0.9407\n",
      "Epoch 9/10\n",
      "1530/1530 [==============================] - 0s 143us/sample - loss: 0.1524 - acc: 0.9366 - val_loss: 0.1958 - val_acc: 0.8889\n",
      "Epoch 10/10\n",
      "1530/1530 [==============================] - 0s 142us/sample - loss: 0.1599 - acc: 0.9294 - val_loss: 0.1795 - val_acc: 0.9407\n",
      "Epoch 93 out of 150\n",
      "Train on 1530 samples, validate on 270 samples\n",
      "Epoch 1/10\n",
      "1530/1530 [==============================] - 0s 179us/sample - loss: 0.1545 - acc: 0.9281 - val_loss: 0.1841 - val_acc: 0.9000\n",
      "Epoch 2/10\n",
      "1530/1530 [==============================] - 0s 177us/sample - loss: 0.1559 - acc: 0.9268 - val_loss: 0.1739 - val_acc: 0.9222\n",
      "Epoch 3/10\n",
      "1530/1530 [==============================] - 0s 166us/sample - loss: 0.1510 - acc: 0.9327 - val_loss: 0.1757 - val_acc: 0.9259\n",
      "Epoch 4/10\n",
      "1530/1530 [==============================] - 0s 242us/sample - loss: 0.1559 - acc: 0.9320 - val_loss: 0.1777 - val_acc: 0.9037\n",
      "Epoch 5/10\n",
      "1530/1530 [==============================] - 0s 198us/sample - loss: 0.1521 - acc: 0.9301 - val_loss: 0.1785 - val_acc: 0.9074\n",
      "Epoch 6/10\n",
      "1530/1530 [==============================] - 0s 315us/sample - loss: 0.1536 - acc: 0.9288 - val_loss: 0.1817 - val_acc: 0.9333\n",
      "Epoch 7/10\n",
      "1530/1530 [==============================] - 0s 279us/sample - loss: 0.1506 - acc: 0.9366 - val_loss: 0.1709 - val_acc: 0.9259\n",
      "Epoch 8/10\n",
      "1530/1530 [==============================] - 0s 317us/sample - loss: 0.1563 - acc: 0.9314 - val_loss: 0.1760 - val_acc: 0.9296\n",
      "Epoch 9/10\n",
      "1530/1530 [==============================] - 1s 508us/sample - loss: 0.1505 - acc: 0.9353 - val_loss: 0.1759 - val_acc: 0.9185\n",
      "Epoch 10/10\n",
      "1530/1530 [==============================] - 1s 419us/sample - loss: 0.1526 - acc: 0.9353 - val_loss: 0.1743 - val_acc: 0.9222\n",
      "Epoch 94 out of 150\n",
      "Train on 1530 samples, validate on 270 samples\n",
      "Epoch 1/10\n",
      "1530/1530 [==============================] - 0s 163us/sample - loss: 0.1555 - acc: 0.9281 - val_loss: 0.1746 - val_acc: 0.9259\n",
      "Epoch 2/10\n",
      "1530/1530 [==============================] - 0s 169us/sample - loss: 0.1522 - acc: 0.9261 - val_loss: 0.1911 - val_acc: 0.9111\n",
      "Epoch 3/10\n",
      "1530/1530 [==============================] - 0s 180us/sample - loss: 0.1538 - acc: 0.9353 - val_loss: 0.1902 - val_acc: 0.9222\n",
      "Epoch 4/10\n",
      "1530/1530 [==============================] - 0s 219us/sample - loss: 0.1511 - acc: 0.9333 - val_loss: 0.1809 - val_acc: 0.8926\n",
      "Epoch 5/10\n",
      "1530/1530 [==============================] - 0s 165us/sample - loss: 0.1524 - acc: 0.9366 - val_loss: 0.1746 - val_acc: 0.9370\n",
      "Epoch 6/10\n",
      "1530/1530 [==============================] - 0s 308us/sample - loss: 0.1533 - acc: 0.9366 - val_loss: 0.1755 - val_acc: 0.8926\n",
      "Epoch 7/10\n",
      "1530/1530 [==============================] - 0s 181us/sample - loss: 0.1530 - acc: 0.9307 - val_loss: 0.1779 - val_acc: 0.9296\n",
      "Epoch 8/10\n",
      "1530/1530 [==============================] - 0s 203us/sample - loss: 0.1530 - acc: 0.9327 - val_loss: 0.1865 - val_acc: 0.9148\n",
      "Epoch 9/10\n",
      "1530/1530 [==============================] - 0s 182us/sample - loss: 0.1507 - acc: 0.9379 - val_loss: 0.1732 - val_acc: 0.9259\n",
      "Epoch 10/10\n",
      "1530/1530 [==============================] - 0s 196us/sample - loss: 0.1538 - acc: 0.9320 - val_loss: 0.1743 - val_acc: 0.8963\n",
      "Epoch 95 out of 150\n",
      "Train on 1530 samples, validate on 270 samples\n",
      "Epoch 1/10\n",
      "1530/1530 [==============================] - 0s 153us/sample - loss: 0.1524 - acc: 0.9340 - val_loss: 0.1809 - val_acc: 0.9333\n",
      "Epoch 2/10\n",
      "1530/1530 [==============================] - 0s 156us/sample - loss: 0.1540 - acc: 0.9346 - val_loss: 0.1696 - val_acc: 0.9185\n",
      "Epoch 3/10\n",
      "1530/1530 [==============================] - 0s 160us/sample - loss: 0.1505 - acc: 0.9327 - val_loss: 0.1673 - val_acc: 0.9148\n",
      "Epoch 4/10\n",
      "1530/1530 [==============================] - 0s 182us/sample - loss: 0.1522 - acc: 0.9275 - val_loss: 0.1753 - val_acc: 0.9222\n",
      "Epoch 5/10\n",
      "1530/1530 [==============================] - 0s 171us/sample - loss: 0.1498 - acc: 0.9379 - val_loss: 0.1729 - val_acc: 0.9370\n",
      "Epoch 6/10\n",
      "1530/1530 [==============================] - 0s 261us/sample - loss: 0.1518 - acc: 0.9373 - val_loss: 0.1756 - val_acc: 0.8889\n",
      "Epoch 7/10\n",
      "1530/1530 [==============================] - 0s 153us/sample - loss: 0.1510 - acc: 0.9268 - val_loss: 0.1662 - val_acc: 0.9333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/10\n",
      "1530/1530 [==============================] - 0s 144us/sample - loss: 0.1518 - acc: 0.9301 - val_loss: 0.1702 - val_acc: 0.9148\n",
      "Epoch 9/10\n",
      "1530/1530 [==============================] - 0s 158us/sample - loss: 0.1566 - acc: 0.9294 - val_loss: 0.1737 - val_acc: 0.9185\n",
      "Epoch 10/10\n",
      "1530/1530 [==============================] - 0s 168us/sample - loss: 0.1494 - acc: 0.9307 - val_loss: 0.1696 - val_acc: 0.9296\n",
      "Epoch 96 out of 150\n",
      "Train on 1530 samples, validate on 270 samples\n",
      "Epoch 1/10\n",
      "1530/1530 [==============================] - 0s 150us/sample - loss: 0.1505 - acc: 0.9346 - val_loss: 0.1691 - val_acc: 0.9148\n",
      "Epoch 2/10\n",
      "1530/1530 [==============================] - 0s 200us/sample - loss: 0.1550 - acc: 0.9288 - val_loss: 0.1755 - val_acc: 0.9148\n",
      "Epoch 3/10\n",
      "1530/1530 [==============================] - 0s 143us/sample - loss: 0.1517 - acc: 0.9255 - val_loss: 0.1743 - val_acc: 0.9111\n",
      "Epoch 4/10\n",
      "1530/1530 [==============================] - 0s 172us/sample - loss: 0.1568 - acc: 0.9353 - val_loss: 0.1735 - val_acc: 0.9148\n",
      "Epoch 5/10\n",
      "1530/1530 [==============================] - 0s 140us/sample - loss: 0.1527 - acc: 0.9399 - val_loss: 0.1779 - val_acc: 0.9185\n",
      "Epoch 6/10\n",
      "1530/1530 [==============================] - 0s 190us/sample - loss: 0.1507 - acc: 0.9294 - val_loss: 0.1683 - val_acc: 0.9407\n",
      "Epoch 7/10\n",
      "1530/1530 [==============================] - 0s 175us/sample - loss: 0.1536 - acc: 0.9366 - val_loss: 0.1716 - val_acc: 0.9222\n",
      "Epoch 8/10\n",
      "1530/1530 [==============================] - 0s 141us/sample - loss: 0.1507 - acc: 0.9366 - val_loss: 0.1735 - val_acc: 0.9111\n",
      "Epoch 9/10\n",
      "1530/1530 [==============================] - 0s 180us/sample - loss: 0.1560 - acc: 0.9294 - val_loss: 0.1985 - val_acc: 0.8852\n",
      "Epoch 10/10\n",
      "1530/1530 [==============================] - 0s 172us/sample - loss: 0.1492 - acc: 0.9314 - val_loss: 0.1682 - val_acc: 0.9259\n",
      "Epoch 97 out of 150\n",
      "Train on 1530 samples, validate on 270 samples\n",
      "Epoch 1/10\n",
      "1530/1530 [==============================] - 0s 145us/sample - loss: 0.1496 - acc: 0.9333 - val_loss: 0.1730 - val_acc: 0.9296\n",
      "Epoch 2/10\n",
      "1530/1530 [==============================] - 0s 138us/sample - loss: 0.1535 - acc: 0.9307 - val_loss: 0.1791 - val_acc: 0.9296\n",
      "Epoch 3/10\n",
      "1530/1530 [==============================] - 0s 139us/sample - loss: 0.1521 - acc: 0.9333 - val_loss: 0.1706 - val_acc: 0.8926\n",
      "Epoch 4/10\n",
      "1530/1530 [==============================] - 0s 151us/sample - loss: 0.1516 - acc: 0.9320 - val_loss: 0.1672 - val_acc: 0.9296\n",
      "Epoch 5/10\n",
      "1530/1530 [==============================] - 0s 168us/sample - loss: 0.1492 - acc: 0.9333 - val_loss: 0.1716 - val_acc: 0.9185\n",
      "Epoch 6/10\n",
      "1530/1530 [==============================] - 0s 148us/sample - loss: 0.1488 - acc: 0.9314 - val_loss: 0.1741 - val_acc: 0.9370\n",
      "Epoch 7/10\n",
      "1530/1530 [==============================] - 0s 163us/sample - loss: 0.1487 - acc: 0.9327 - val_loss: 0.1717 - val_acc: 0.9222\n",
      "Epoch 8/10\n",
      "1530/1530 [==============================] - ETA: 0s - loss: 0.1466 - acc: 0.935 - 0s 155us/sample - loss: 0.1506 - acc: 0.9366 - val_loss: 0.1853 - val_acc: 0.9259\n",
      "Epoch 9/10\n",
      "1530/1530 [==============================] - 0s 143us/sample - loss: 0.1520 - acc: 0.9281 - val_loss: 0.1744 - val_acc: 0.9148\n",
      "Epoch 10/10\n",
      "1530/1530 [==============================] - 0s 141us/sample - loss: 0.1490 - acc: 0.9366 - val_loss: 0.1898 - val_acc: 0.9000\n",
      "Epoch 98 out of 150\n",
      "Train on 1530 samples, validate on 270 samples\n",
      "Epoch 1/10\n",
      "1530/1530 [==============================] - 0s 182us/sample - loss: 0.1514 - acc: 0.9379 - val_loss: 0.1706 - val_acc: 0.9333\n",
      "Epoch 2/10\n",
      "1530/1530 [==============================] - 0s 173us/sample - loss: 0.1521 - acc: 0.9281 - val_loss: 0.1782 - val_acc: 0.9333\n",
      "Epoch 3/10\n",
      "1530/1530 [==============================] - 0s 144us/sample - loss: 0.1578 - acc: 0.9281 - val_loss: 0.1774 - val_acc: 0.9148\n",
      "Epoch 4/10\n",
      "1530/1530 [==============================] - 0s 214us/sample - loss: 0.1484 - acc: 0.9366 - val_loss: 0.1731 - val_acc: 0.9259\n",
      "Epoch 5/10\n",
      "1530/1530 [==============================] - ETA: 0s - loss: 0.1492 - acc: 0.938 - 0s 150us/sample - loss: 0.1482 - acc: 0.9418 - val_loss: 0.1795 - val_acc: 0.9333\n",
      "Epoch 6/10\n",
      "1530/1530 [==============================] - 0s 182us/sample - loss: 0.1525 - acc: 0.9333 - val_loss: 0.1760 - val_acc: 0.9074\n",
      "Epoch 7/10\n",
      "1530/1530 [==============================] - 0s 160us/sample - loss: 0.1546 - acc: 0.9268 - val_loss: 0.1724 - val_acc: 0.9407\n",
      "Epoch 8/10\n",
      "1530/1530 [==============================] - 0s 139us/sample - loss: 0.1482 - acc: 0.9353 - val_loss: 0.1703 - val_acc: 0.9333\n",
      "Epoch 9/10\n",
      "1530/1530 [==============================] - 0s 155us/sample - loss: 0.1503 - acc: 0.9386 - val_loss: 0.1732 - val_acc: 0.9185\n",
      "Epoch 10/10\n",
      "1530/1530 [==============================] - 0s 164us/sample - loss: 0.1499 - acc: 0.9346 - val_loss: 0.1675 - val_acc: 0.9370\n",
      "Epoch 99 out of 150\n",
      "Train on 1530 samples, validate on 270 samples\n",
      "Epoch 1/10\n",
      "1530/1530 [==============================] - 0s 175us/sample - loss: 0.1517 - acc: 0.9301 - val_loss: 0.1696 - val_acc: 0.9259\n",
      "Epoch 2/10\n",
      "1530/1530 [==============================] - 0s 163us/sample - loss: 0.1500 - acc: 0.9346 - val_loss: 0.1749 - val_acc: 0.9111\n",
      "Epoch 3/10\n",
      "1530/1530 [==============================] - 0s 153us/sample - loss: 0.1493 - acc: 0.9307 - val_loss: 0.1694 - val_acc: 0.9037\n",
      "Epoch 4/10\n",
      "1530/1530 [==============================] - 0s 195us/sample - loss: 0.1476 - acc: 0.9333 - val_loss: 0.1697 - val_acc: 0.9296\n",
      "Epoch 5/10\n",
      "1530/1530 [==============================] - 0s 147us/sample - loss: 0.1530 - acc: 0.9327 - val_loss: 0.1732 - val_acc: 0.9185\n",
      "Epoch 6/10\n",
      "1530/1530 [==============================] - 0s 144us/sample - loss: 0.1487 - acc: 0.9346 - val_loss: 0.1679 - val_acc: 0.9296\n",
      "Epoch 7/10\n",
      "1530/1530 [==============================] - 0s 195us/sample - loss: 0.1503 - acc: 0.9333 - val_loss: 0.1702 - val_acc: 0.9185\n",
      "Epoch 8/10\n",
      "1530/1530 [==============================] - 0s 166us/sample - loss: 0.1493 - acc: 0.9320 - val_loss: 0.1737 - val_acc: 0.9000\n",
      "Epoch 9/10\n",
      "1530/1530 [==============================] - 0s 207us/sample - loss: 0.1497 - acc: 0.9346 - val_loss: 0.1821 - val_acc: 0.9333\n",
      "Epoch 10/10\n",
      "1530/1530 [==============================] - 0s 221us/sample - loss: 0.1511 - acc: 0.9307 - val_loss: 0.1855 - val_acc: 0.9259\n",
      "Epoch 100 out of 150\n",
      "Train on 1530 samples, validate on 270 samples\n",
      "Epoch 1/10\n",
      "1530/1530 [==============================] - 0s 193us/sample - loss: 0.1507 - acc: 0.9301 - val_loss: 0.1771 - val_acc: 0.9407\n",
      "Epoch 2/10\n",
      "1530/1530 [==============================] - 0s 228us/sample - loss: 0.1497 - acc: 0.9353 - val_loss: 0.1656 - val_acc: 0.9333\n",
      "Epoch 3/10\n",
      "1530/1530 [==============================] - 0s 250us/sample - loss: 0.1492 - acc: 0.9288 - val_loss: 0.1826 - val_acc: 0.8852\n",
      "Epoch 4/10\n",
      "1530/1530 [==============================] - 0s 218us/sample - loss: 0.1472 - acc: 0.9320 - val_loss: 0.1671 - val_acc: 0.9222\n",
      "Epoch 5/10\n",
      "1530/1530 [==============================] - 0s 266us/sample - loss: 0.1546 - acc: 0.9255 - val_loss: 0.1716 - val_acc: 0.9222\n",
      "Epoch 6/10\n",
      "1530/1530 [==============================] - 0s 169us/sample - loss: 0.1496 - acc: 0.9366 - val_loss: 0.1654 - val_acc: 0.9222\n",
      "Epoch 7/10\n",
      "1530/1530 [==============================] - 0s 185us/sample - loss: 0.1493 - acc: 0.9314 - val_loss: 0.1758 - val_acc: 0.9074\n",
      "Epoch 8/10\n",
      "1530/1530 [==============================] - 0s 211us/sample - loss: 0.1530 - acc: 0.9288 - val_loss: 0.1797 - val_acc: 0.9074\n",
      "Epoch 9/10\n",
      "1530/1530 [==============================] - 0s 188us/sample - loss: 0.1530 - acc: 0.9353 - val_loss: 0.1661 - val_acc: 0.9259\n",
      "Epoch 10/10\n",
      "1530/1530 [==============================] - 0s 184us/sample - loss: 0.1526 - acc: 0.9255 - val_loss: 0.1673 - val_acc: 0.9185\n",
      "Epoch 101 out of 150\n",
      "Train on 1530 samples, validate on 270 samples\n",
      "Epoch 1/10\n",
      "1530/1530 [==============================] - 0s 141us/sample - loss: 0.1535 - acc: 0.9275 - val_loss: 0.1829 - val_acc: 0.9333\n",
      "Epoch 2/10\n",
      "1530/1530 [==============================] - 0s 141us/sample - loss: 0.1490 - acc: 0.9333 - val_loss: 0.1798 - val_acc: 0.9111\n",
      "Epoch 3/10\n",
      "1530/1530 [==============================] - 0s 214us/sample - loss: 0.1496 - acc: 0.9399 - val_loss: 0.1762 - val_acc: 0.8852\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/10\n",
      "1530/1530 [==============================] - 0s 184us/sample - loss: 0.1478 - acc: 0.9307 - val_loss: 0.1678 - val_acc: 0.9333\n",
      "Epoch 5/10\n",
      "1530/1530 [==============================] - 0s 185us/sample - loss: 0.1461 - acc: 0.9392 - val_loss: 0.1731 - val_acc: 0.9185\n",
      "Epoch 6/10\n",
      "1530/1530 [==============================] - 0s 156us/sample - loss: 0.1505 - acc: 0.9353 - val_loss: 0.1785 - val_acc: 0.9148\n",
      "Epoch 7/10\n",
      "1530/1530 [==============================] - 0s 159us/sample - loss: 0.1489 - acc: 0.9314 - val_loss: 0.1738 - val_acc: 0.9185\n",
      "Epoch 8/10\n",
      "1530/1530 [==============================] - 0s 166us/sample - loss: 0.1515 - acc: 0.9294 - val_loss: 0.1698 - val_acc: 0.9407\n",
      "Epoch 9/10\n",
      "1530/1530 [==============================] - 0s 159us/sample - loss: 0.1515 - acc: 0.9301 - val_loss: 0.1738 - val_acc: 0.8889\n",
      "Epoch 10/10\n",
      "1530/1530 [==============================] - 0s 145us/sample - loss: 0.1541 - acc: 0.9288 - val_loss: 0.1996 - val_acc: 0.9111\n",
      "Epoch 102 out of 150\n",
      "Train on 1530 samples, validate on 270 samples\n",
      "Epoch 1/10\n",
      "1530/1530 [==============================] - 0s 137us/sample - loss: 0.1574 - acc: 0.9281 - val_loss: 0.1857 - val_acc: 0.9185\n",
      "Epoch 2/10\n",
      "1530/1530 [==============================] - 0s 151us/sample - loss: 0.1560 - acc: 0.9294 - val_loss: 0.1703 - val_acc: 0.9185\n",
      "Epoch 3/10\n",
      "1530/1530 [==============================] - 0s 168us/sample - loss: 0.1526 - acc: 0.9288 - val_loss: 0.1674 - val_acc: 0.9259\n",
      "Epoch 4/10\n",
      "1530/1530 [==============================] - 0s 181us/sample - loss: 0.1492 - acc: 0.9333 - val_loss: 0.1726 - val_acc: 0.9259\n",
      "Epoch 5/10\n",
      "1530/1530 [==============================] - 0s 180us/sample - loss: 0.1474 - acc: 0.9320 - val_loss: 0.1675 - val_acc: 0.9370\n",
      "Epoch 6/10\n",
      "1530/1530 [==============================] - 0s 159us/sample - loss: 0.1480 - acc: 0.9373 - val_loss: 0.1896 - val_acc: 0.9074\n",
      "Epoch 7/10\n",
      "1530/1530 [==============================] - 0s 171us/sample - loss: 0.1499 - acc: 0.9333 - val_loss: 0.1679 - val_acc: 0.9370\n",
      "Epoch 8/10\n",
      "1530/1530 [==============================] - 0s 164us/sample - loss: 0.1487 - acc: 0.9320 - val_loss: 0.1767 - val_acc: 0.8926\n",
      "Epoch 9/10\n",
      "1530/1530 [==============================] - 0s 164us/sample - loss: 0.1506 - acc: 0.9314 - val_loss: 0.1868 - val_acc: 0.9037\n",
      "Epoch 10/10\n",
      "1530/1530 [==============================] - 0s 168us/sample - loss: 0.1527 - acc: 0.9281 - val_loss: 0.1746 - val_acc: 0.9185\n",
      "Epoch 103 out of 150\n",
      "Train on 1530 samples, validate on 270 samples\n",
      "Epoch 1/10\n",
      "1530/1530 [==============================] - 0s 135us/sample - loss: 0.1481 - acc: 0.9386 - val_loss: 0.1781 - val_acc: 0.8926\n",
      "Epoch 2/10\n",
      "1530/1530 [==============================] - 0s 137us/sample - loss: 0.1535 - acc: 0.9301 - val_loss: 0.1783 - val_acc: 0.9000\n",
      "Epoch 3/10\n",
      "1530/1530 [==============================] - 0s 138us/sample - loss: 0.1480 - acc: 0.9314 - val_loss: 0.1646 - val_acc: 0.9185\n",
      "Epoch 4/10\n",
      "1530/1530 [==============================] - 0s 140us/sample - loss: 0.1471 - acc: 0.9353 - val_loss: 0.1705 - val_acc: 0.9037\n",
      "Epoch 5/10\n",
      "1530/1530 [==============================] - 0s 168us/sample - loss: 0.1478 - acc: 0.9294 - val_loss: 0.1676 - val_acc: 0.9259\n",
      "Epoch 6/10\n",
      "1530/1530 [==============================] - 0s 136us/sample - loss: 0.1512 - acc: 0.9327 - val_loss: 0.1820 - val_acc: 0.9296\n",
      "Epoch 7/10\n",
      "1530/1530 [==============================] - 0s 154us/sample - loss: 0.1471 - acc: 0.9399 - val_loss: 0.1871 - val_acc: 0.8963\n",
      "Epoch 8/10\n",
      "1530/1530 [==============================] - 0s 142us/sample - loss: 0.1546 - acc: 0.9307 - val_loss: 0.1739 - val_acc: 0.9296\n",
      "Epoch 9/10\n",
      "1530/1530 [==============================] - 0s 139us/sample - loss: 0.1484 - acc: 0.9281 - val_loss: 0.1720 - val_acc: 0.9185\n",
      "Epoch 10/10\n",
      "1530/1530 [==============================] - 0s 138us/sample - loss: 0.1491 - acc: 0.9333 - val_loss: 0.1704 - val_acc: 0.9148\n",
      "Epoch 104 out of 150\n",
      "Train on 1530 samples, validate on 270 samples\n",
      "Epoch 1/10\n",
      "1530/1530 [==============================] - 0s 165us/sample - loss: 0.1478 - acc: 0.9333 - val_loss: 0.1749 - val_acc: 0.9296\n",
      "Epoch 2/10\n",
      "1530/1530 [==============================] - 0s 162us/sample - loss: 0.1477 - acc: 0.9346 - val_loss: 0.1794 - val_acc: 0.9259\n",
      "Epoch 3/10\n",
      "1530/1530 [==============================] - 0s 136us/sample - loss: 0.1470 - acc: 0.9353 - val_loss: 0.1653 - val_acc: 0.9222\n",
      "Epoch 4/10\n",
      "1530/1530 [==============================] - 0s 172us/sample - loss: 0.1501 - acc: 0.9320 - val_loss: 0.1723 - val_acc: 0.9370\n",
      "Epoch 5/10\n",
      "1530/1530 [==============================] - 0s 136us/sample - loss: 0.1479 - acc: 0.9340 - val_loss: 0.1674 - val_acc: 0.9296\n",
      "Epoch 6/10\n",
      "1530/1530 [==============================] - 0s 141us/sample - loss: 0.1463 - acc: 0.9379 - val_loss: 0.1752 - val_acc: 0.9222\n",
      "Epoch 7/10\n",
      "1530/1530 [==============================] - 0s 134us/sample - loss: 0.1488 - acc: 0.9320 - val_loss: 0.1764 - val_acc: 0.8926\n",
      "Epoch 8/10\n",
      "1530/1530 [==============================] - 0s 134us/sample - loss: 0.1476 - acc: 0.9333 - val_loss: 0.1765 - val_acc: 0.9148\n",
      "Epoch 9/10\n",
      "1530/1530 [==============================] - 0s 134us/sample - loss: 0.1529 - acc: 0.9301 - val_loss: 0.1693 - val_acc: 0.9185\n",
      "Epoch 10/10\n",
      "1530/1530 [==============================] - 0s 139us/sample - loss: 0.1506 - acc: 0.9340 - val_loss: 0.1730 - val_acc: 0.9037\n",
      "Epoch 105 out of 150\n",
      "Train on 1530 samples, validate on 270 samples\n",
      "Epoch 1/10\n",
      "1530/1530 [==============================] - 0s 137us/sample - loss: 0.1480 - acc: 0.9320 - val_loss: 0.1685 - val_acc: 0.9185\n",
      "Epoch 2/10\n",
      "1530/1530 [==============================] - 0s 145us/sample - loss: 0.1469 - acc: 0.9281 - val_loss: 0.1735 - val_acc: 0.8889\n",
      "Epoch 3/10\n",
      "1530/1530 [==============================] - 0s 136us/sample - loss: 0.1455 - acc: 0.9340 - val_loss: 0.1702 - val_acc: 0.9407\n",
      "Epoch 4/10\n",
      "1530/1530 [==============================] - 0s 145us/sample - loss: 0.1492 - acc: 0.9346 - val_loss: 0.1664 - val_acc: 0.9185\n",
      "Epoch 5/10\n",
      "1530/1530 [==============================] - 0s 210us/sample - loss: 0.1465 - acc: 0.9359 - val_loss: 0.1754 - val_acc: 0.9296\n",
      "Epoch 6/10\n",
      "1530/1530 [==============================] - 0s 167us/sample - loss: 0.1476 - acc: 0.9359 - val_loss: 0.1692 - val_acc: 0.9000\n",
      "Epoch 7/10\n",
      "1530/1530 [==============================] - 0s 172us/sample - loss: 0.1494 - acc: 0.9307 - val_loss: 0.1828 - val_acc: 0.9111\n",
      "Epoch 8/10\n",
      "1530/1530 [==============================] - 0s 168us/sample - loss: 0.1489 - acc: 0.9307 - val_loss: 0.1696 - val_acc: 0.9259\n",
      "Epoch 9/10\n",
      "1530/1530 [==============================] - 0s 162us/sample - loss: 0.1467 - acc: 0.9366 - val_loss: 0.1636 - val_acc: 0.9370\n",
      "Epoch 10/10\n",
      "1530/1530 [==============================] - 0s 162us/sample - loss: 0.1459 - acc: 0.9340 - val_loss: 0.1876 - val_acc: 0.9185\n",
      "Epoch 106 out of 150\n",
      "Train on 1530 samples, validate on 270 samples\n",
      "Epoch 1/10\n",
      "1530/1530 [==============================] - 0s 138us/sample - loss: 0.1534 - acc: 0.9333 - val_loss: 0.1714 - val_acc: 0.9222\n",
      "Epoch 2/10\n",
      "1530/1530 [==============================] - 0s 135us/sample - loss: 0.1462 - acc: 0.9379 - val_loss: 0.1717 - val_acc: 0.9000\n",
      "Epoch 3/10\n",
      "1530/1530 [==============================] - 0s 132us/sample - loss: 0.1494 - acc: 0.9327 - val_loss: 0.1669 - val_acc: 0.9296\n",
      "Epoch 4/10\n",
      "1530/1530 [==============================] - 0s 134us/sample - loss: 0.1455 - acc: 0.9359 - val_loss: 0.1638 - val_acc: 0.9370\n",
      "Epoch 5/10\n",
      "1530/1530 [==============================] - 0s 175us/sample - loss: 0.1456 - acc: 0.9314 - val_loss: 0.1860 - val_acc: 0.9000\n",
      "Epoch 6/10\n",
      "1530/1530 [==============================] - 0s 136us/sample - loss: 0.1504 - acc: 0.9242 - val_loss: 0.1675 - val_acc: 0.9185\n",
      "Epoch 7/10\n",
      "1530/1530 [==============================] - 0s 138us/sample - loss: 0.1487 - acc: 0.9307 - val_loss: 0.1691 - val_acc: 0.8926\n",
      "Epoch 8/10\n",
      "1530/1530 [==============================] - 0s 135us/sample - loss: 0.1478 - acc: 0.9307 - val_loss: 0.1852 - val_acc: 0.8778\n",
      "Epoch 9/10\n",
      "1530/1530 [==============================] - 0s 143us/sample - loss: 0.1469 - acc: 0.9320 - val_loss: 0.1757 - val_acc: 0.9185\n",
      "Epoch 10/10\n",
      "1530/1530 [==============================] - 0s 134us/sample - loss: 0.1486 - acc: 0.9340 - val_loss: 0.1718 - val_acc: 0.9407\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 107 out of 150\n",
      "Train on 1530 samples, validate on 270 samples\n",
      "Epoch 1/10\n",
      "1530/1530 [==============================] - 0s 136us/sample - loss: 0.1501 - acc: 0.9268 - val_loss: 0.1636 - val_acc: 0.9296\n",
      "Epoch 2/10\n",
      "1530/1530 [==============================] - 0s 140us/sample - loss: 0.1449 - acc: 0.9346 - val_loss: 0.1668 - val_acc: 0.9222\n",
      "Epoch 3/10\n",
      "1530/1530 [==============================] - 0s 136us/sample - loss: 0.1458 - acc: 0.9359 - val_loss: 0.1653 - val_acc: 0.9519\n",
      "Epoch 4/10\n",
      "1530/1530 [==============================] - 0s 135us/sample - loss: 0.1472 - acc: 0.9346 - val_loss: 0.1715 - val_acc: 0.8926\n",
      "Epoch 5/10\n",
      "1530/1530 [==============================] - 0s 169us/sample - loss: 0.1454 - acc: 0.9333 - val_loss: 0.1751 - val_acc: 0.9148\n",
      "Epoch 6/10\n",
      "1530/1530 [==============================] - 0s 134us/sample - loss: 0.1420 - acc: 0.9425 - val_loss: 0.1970 - val_acc: 0.8926\n",
      "Epoch 7/10\n",
      "1530/1530 [==============================] - 0s 143us/sample - loss: 0.1568 - acc: 0.9261 - val_loss: 0.1726 - val_acc: 0.9259\n",
      "Epoch 8/10\n",
      "1530/1530 [==============================] - 0s 133us/sample - loss: 0.1485 - acc: 0.9366 - val_loss: 0.1725 - val_acc: 0.9185\n",
      "Epoch 9/10\n",
      "1530/1530 [==============================] - 0s 135us/sample - loss: 0.1465 - acc: 0.9327 - val_loss: 0.1682 - val_acc: 0.9296\n",
      "Epoch 10/10\n",
      "1530/1530 [==============================] - 0s 136us/sample - loss: 0.1465 - acc: 0.9301 - val_loss: 0.1643 - val_acc: 0.9259\n",
      "Epoch 108 out of 150\n",
      "Train on 1530 samples, validate on 270 samples\n",
      "Epoch 1/10\n",
      "1530/1530 [==============================] - 0s 138us/sample - loss: 0.1498 - acc: 0.9340 - val_loss: 0.1880 - val_acc: 0.9111\n",
      "Epoch 2/10\n",
      "1530/1530 [==============================] - 0s 138us/sample - loss: 0.1456 - acc: 0.9327 - val_loss: 0.1790 - val_acc: 0.9148\n",
      "Epoch 3/10\n",
      "1530/1530 [==============================] - 0s 145us/sample - loss: 0.1490 - acc: 0.9307 - val_loss: 0.1750 - val_acc: 0.9000\n",
      "Epoch 4/10\n",
      "1530/1530 [==============================] - 0s 141us/sample - loss: 0.1482 - acc: 0.9340 - val_loss: 0.1764 - val_acc: 0.9111\n",
      "Epoch 5/10\n",
      "1530/1530 [==============================] - 0s 171us/sample - loss: 0.1456 - acc: 0.9373 - val_loss: 0.1996 - val_acc: 0.8889\n",
      "Epoch 6/10\n",
      "1530/1530 [==============================] - 0s 134us/sample - loss: 0.1536 - acc: 0.9288 - val_loss: 0.1678 - val_acc: 0.9333\n",
      "Epoch 7/10\n",
      "1530/1530 [==============================] - 0s 137us/sample - loss: 0.1460 - acc: 0.9314 - val_loss: 0.1671 - val_acc: 0.9222\n",
      "Epoch 8/10\n",
      "1530/1530 [==============================] - 0s 138us/sample - loss: 0.1454 - acc: 0.9327 - val_loss: 0.1688 - val_acc: 0.9111\n",
      "Epoch 9/10\n",
      "1530/1530 [==============================] - 0s 143us/sample - loss: 0.1448 - acc: 0.9320 - val_loss: 0.1679 - val_acc: 0.9222\n",
      "Epoch 10/10\n",
      "1530/1530 [==============================] - 0s 136us/sample - loss: 0.1451 - acc: 0.9333 - val_loss: 0.1785 - val_acc: 0.9296\n",
      "Epoch 109 out of 150\n",
      "Train on 1530 samples, validate on 270 samples\n",
      "Epoch 1/10\n",
      "1530/1530 [==============================] - 0s 147us/sample - loss: 0.1450 - acc: 0.9366 - val_loss: 0.1643 - val_acc: 0.9333\n",
      "Epoch 2/10\n",
      "1530/1530 [==============================] - 0s 141us/sample - loss: 0.1469 - acc: 0.9314 - val_loss: 0.1692 - val_acc: 0.9333\n",
      "Epoch 3/10\n",
      "1530/1530 [==============================] - 0s 140us/sample - loss: 0.1434 - acc: 0.9333 - val_loss: 0.1656 - val_acc: 0.9185\n",
      "Epoch 4/10\n",
      "1530/1530 [==============================] - 0s 134us/sample - loss: 0.1483 - acc: 0.9431 - val_loss: 0.1715 - val_acc: 0.9259\n",
      "Epoch 5/10\n",
      "1530/1530 [==============================] - 0s 163us/sample - loss: 0.1465 - acc: 0.9307 - val_loss: 0.1787 - val_acc: 0.8926\n",
      "Epoch 6/10\n",
      "1530/1530 [==============================] - 0s 132us/sample - loss: 0.1483 - acc: 0.9294 - val_loss: 0.1758 - val_acc: 0.8963\n",
      "Epoch 7/10\n",
      "1530/1530 [==============================] - 0s 141us/sample - loss: 0.1466 - acc: 0.9340 - val_loss: 0.1751 - val_acc: 0.8852\n",
      "Epoch 8/10\n",
      "1530/1530 [==============================] - 0s 134us/sample - loss: 0.1457 - acc: 0.9366 - val_loss: 0.1645 - val_acc: 0.9259\n",
      "Epoch 9/10\n",
      "1530/1530 [==============================] - 0s 132us/sample - loss: 0.1425 - acc: 0.9386 - val_loss: 0.1766 - val_acc: 0.9111\n",
      "Epoch 10/10\n",
      "1530/1530 [==============================] - 0s 142us/sample - loss: 0.1455 - acc: 0.9366 - val_loss: 0.1771 - val_acc: 0.9185\n",
      "Epoch 110 out of 150\n",
      "Train on 1530 samples, validate on 270 samples\n",
      "Epoch 1/10\n",
      "1530/1530 [==============================] - 0s 142us/sample - loss: 0.1474 - acc: 0.9340 - val_loss: 0.1611 - val_acc: 0.9333\n",
      "Epoch 2/10\n",
      "1530/1530 [==============================] - 0s 135us/sample - loss: 0.1469 - acc: 0.9340 - val_loss: 0.1703 - val_acc: 0.9148\n",
      "Epoch 3/10\n",
      "1530/1530 [==============================] - 0s 135us/sample - loss: 0.1473 - acc: 0.9333 - val_loss: 0.1710 - val_acc: 0.9407\n",
      "Epoch 4/10\n",
      "1530/1530 [==============================] - 0s 133us/sample - loss: 0.1449 - acc: 0.9346 - val_loss: 0.1771 - val_acc: 0.8926\n",
      "Epoch 5/10\n",
      "1530/1530 [==============================] - 0s 178us/sample - loss: 0.1486 - acc: 0.9333 - val_loss: 0.1718 - val_acc: 0.9333\n",
      "Epoch 6/10\n",
      "1530/1530 [==============================] - 0s 138us/sample - loss: 0.1440 - acc: 0.9307 - val_loss: 0.1645 - val_acc: 0.9185\n",
      "Epoch 7/10\n",
      "1530/1530 [==============================] - 0s 134us/sample - loss: 0.1499 - acc: 0.9301 - val_loss: 0.1665 - val_acc: 0.9259\n",
      "Epoch 8/10\n",
      "1530/1530 [==============================] - ETA: 0s - loss: 0.1482 - acc: 0.932 - 0s 152us/sample - loss: 0.1489 - acc: 0.9281 - val_loss: 0.1761 - val_acc: 0.9370\n",
      "Epoch 9/10\n",
      "1530/1530 [==============================] - 0s 140us/sample - loss: 0.1449 - acc: 0.9320 - val_loss: 0.1672 - val_acc: 0.9148\n",
      "Epoch 10/10\n",
      "1530/1530 [==============================] - 0s 139us/sample - loss: 0.1449 - acc: 0.9340 - val_loss: 0.1828 - val_acc: 0.9000\n",
      "Epoch 111 out of 150\n",
      "Train on 1530 samples, validate on 270 samples\n",
      "Epoch 1/10\n",
      "1530/1530 [==============================] - 0s 135us/sample - loss: 0.1494 - acc: 0.9261 - val_loss: 0.1667 - val_acc: 0.9259\n",
      "Epoch 2/10\n",
      "1530/1530 [==============================] - 0s 136us/sample - loss: 0.1433 - acc: 0.9359 - val_loss: 0.1621 - val_acc: 0.9370\n",
      "Epoch 3/10\n",
      "1530/1530 [==============================] - 0s 143us/sample - loss: 0.1456 - acc: 0.9320 - val_loss: 0.1791 - val_acc: 0.9333\n",
      "Epoch 4/10\n",
      "1530/1530 [==============================] - 0s 134us/sample - loss: 0.1488 - acc: 0.9320 - val_loss: 0.1758 - val_acc: 0.9222\n",
      "Epoch 5/10\n",
      "1530/1530 [==============================] - 0s 181us/sample - loss: 0.1434 - acc: 0.9405 - val_loss: 0.1691 - val_acc: 0.9185\n",
      "Epoch 6/10\n",
      "1530/1530 [==============================] - 0s 138us/sample - loss: 0.1437 - acc: 0.9314 - val_loss: 0.1692 - val_acc: 0.9407\n",
      "Epoch 7/10\n",
      "1530/1530 [==============================] - 0s 143us/sample - loss: 0.1477 - acc: 0.9320 - val_loss: 0.1688 - val_acc: 0.9296\n",
      "Epoch 8/10\n",
      "1530/1530 [==============================] - 0s 153us/sample - loss: 0.1447 - acc: 0.9412 - val_loss: 0.1682 - val_acc: 0.9407\n",
      "Epoch 9/10\n",
      "1530/1530 [==============================] - 0s 167us/sample - loss: 0.1445 - acc: 0.9386 - val_loss: 0.1646 - val_acc: 0.9407\n",
      "Epoch 10/10\n",
      "1530/1530 [==============================] - 0s 168us/sample - loss: 0.1460 - acc: 0.9340 - val_loss: 0.1621 - val_acc: 0.9296\n",
      "Epoch 112 out of 150\n",
      "Train on 1530 samples, validate on 270 samples\n",
      "Epoch 1/10\n",
      "1530/1530 [==============================] - 0s 159us/sample - loss: 0.1440 - acc: 0.9320 - val_loss: 0.1766 - val_acc: 0.9074\n",
      "Epoch 2/10\n",
      "1530/1530 [==============================] - 0s 169us/sample - loss: 0.1477 - acc: 0.9281 - val_loss: 0.1696 - val_acc: 0.9333\n",
      "Epoch 3/10\n",
      "1530/1530 [==============================] - 0s 145us/sample - loss: 0.1439 - acc: 0.9333 - val_loss: 0.1847 - val_acc: 0.9074\n",
      "Epoch 4/10\n",
      "1530/1530 [==============================] - 0s 169us/sample - loss: 0.1473 - acc: 0.9353 - val_loss: 0.1709 - val_acc: 0.8963\n",
      "Epoch 5/10\n",
      "1530/1530 [==============================] - 0s 136us/sample - loss: 0.1464 - acc: 0.9320 - val_loss: 0.1690 - val_acc: 0.9296\n",
      "Epoch 6/10\n",
      "1530/1530 [==============================] - 0s 134us/sample - loss: 0.1452 - acc: 0.9333 - val_loss: 0.1620 - val_acc: 0.9296\n",
      "Epoch 7/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1530/1530 [==============================] - 0s 136us/sample - loss: 0.1426 - acc: 0.9346 - val_loss: 0.1696 - val_acc: 0.9259\n",
      "Epoch 8/10\n",
      "1530/1530 [==============================] - 0s 142us/sample - loss: 0.1447 - acc: 0.9359 - val_loss: 0.1635 - val_acc: 0.9370\n",
      "Epoch 9/10\n",
      "1530/1530 [==============================] - 0s 138us/sample - loss: 0.1461 - acc: 0.9327 - val_loss: 0.1680 - val_acc: 0.9222\n",
      "Epoch 10/10\n",
      "1530/1530 [==============================] - 0s 135us/sample - loss: 0.1426 - acc: 0.9359 - val_loss: 0.1730 - val_acc: 0.9370\n",
      "Epoch 113 out of 150\n",
      "Train on 1530 samples, validate on 270 samples\n",
      "Epoch 1/10\n",
      "1530/1530 [==============================] - 0s 146us/sample - loss: 0.1498 - acc: 0.9346 - val_loss: 0.1686 - val_acc: 0.9148\n",
      "Epoch 2/10\n",
      "1530/1530 [==============================] - 0s 135us/sample - loss: 0.1473 - acc: 0.9320 - val_loss: 0.1666 - val_acc: 0.9222\n",
      "Epoch 3/10\n",
      "1530/1530 [==============================] - 0s 136us/sample - loss: 0.1446 - acc: 0.9346 - val_loss: 0.1756 - val_acc: 0.9074\n",
      "Epoch 4/10\n",
      "1530/1530 [==============================] - 0s 134us/sample - loss: 0.1424 - acc: 0.9392 - val_loss: 0.1700 - val_acc: 0.9000\n",
      "Epoch 5/10\n",
      "1530/1530 [==============================] - 0s 166us/sample - loss: 0.1478 - acc: 0.9301 - val_loss: 0.1752 - val_acc: 0.9222\n",
      "Epoch 6/10\n",
      "1530/1530 [==============================] - 0s 143us/sample - loss: 0.1464 - acc: 0.9353 - val_loss: 0.1702 - val_acc: 0.9407\n",
      "Epoch 7/10\n",
      "1530/1530 [==============================] - 0s 134us/sample - loss: 0.1452 - acc: 0.9340 - val_loss: 0.1770 - val_acc: 0.8852\n",
      "Epoch 8/10\n",
      "1530/1530 [==============================] - 0s 137us/sample - loss: 0.1482 - acc: 0.9314 - val_loss: 0.1662 - val_acc: 0.9185\n",
      "Epoch 9/10\n",
      "1530/1530 [==============================] - 0s 168us/sample - loss: 0.1429 - acc: 0.9314 - val_loss: 0.1643 - val_acc: 0.9333\n",
      "Epoch 10/10\n",
      "1530/1530 [==============================] - 0s 172us/sample - loss: 0.1487 - acc: 0.9320 - val_loss: 0.1722 - val_acc: 0.9185\n",
      "Epoch 114 out of 150\n",
      "Train on 1530 samples, validate on 270 samples\n",
      "Epoch 1/10\n",
      "1530/1530 [==============================] - 0s 158us/sample - loss: 0.1456 - acc: 0.9261 - val_loss: 0.1778 - val_acc: 0.9185\n",
      "Epoch 2/10\n",
      "1530/1530 [==============================] - 0s 158us/sample - loss: 0.1441 - acc: 0.9373 - val_loss: 0.1624 - val_acc: 0.9296\n",
      "Epoch 3/10\n",
      "1530/1530 [==============================] - 0s 171us/sample - loss: 0.1496 - acc: 0.9333 - val_loss: 0.1695 - val_acc: 0.9370\n",
      "Epoch 4/10\n",
      "1530/1530 [==============================] - 0s 188us/sample - loss: 0.1441 - acc: 0.9346 - val_loss: 0.1611 - val_acc: 0.9296\n",
      "Epoch 5/10\n",
      "1530/1530 [==============================] - 0s 170us/sample - loss: 0.1453 - acc: 0.9359 - val_loss: 0.1723 - val_acc: 0.8926\n",
      "Epoch 6/10\n",
      "1530/1530 [==============================] - 0s 168us/sample - loss: 0.1434 - acc: 0.9359 - val_loss: 0.1650 - val_acc: 0.9296\n",
      "Epoch 7/10\n",
      "1530/1530 [==============================] - 0s 137us/sample - loss: 0.1429 - acc: 0.9353 - val_loss: 0.1752 - val_acc: 0.9407\n",
      "Epoch 8/10\n",
      "1530/1530 [==============================] - 0s 134us/sample - loss: 0.1440 - acc: 0.9340 - val_loss: 0.1689 - val_acc: 0.9222\n",
      "Epoch 9/10\n",
      "1530/1530 [==============================] - 0s 138us/sample - loss: 0.1483 - acc: 0.9366 - val_loss: 0.1712 - val_acc: 0.9222\n",
      "Epoch 10/10\n",
      "1530/1530 [==============================] - 0s 133us/sample - loss: 0.1513 - acc: 0.9301 - val_loss: 0.1761 - val_acc: 0.9148\n",
      "Epoch 115 out of 150\n",
      "Train on 1530 samples, validate on 270 samples\n",
      "Epoch 1/10\n",
      "1530/1530 [==============================] - 0s 135us/sample - loss: 0.1512 - acc: 0.9346 - val_loss: 0.1656 - val_acc: 0.9222\n",
      "Epoch 2/10\n",
      "1530/1530 [==============================] - 0s 135us/sample - loss: 0.1428 - acc: 0.9399 - val_loss: 0.1640 - val_acc: 0.9296\n",
      "Epoch 3/10\n",
      "1530/1530 [==============================] - 0s 141us/sample - loss: 0.1457 - acc: 0.9366 - val_loss: 0.1694 - val_acc: 0.9444\n",
      "Epoch 4/10\n",
      "1530/1530 [==============================] - 0s 139us/sample - loss: 0.1425 - acc: 0.9373 - val_loss: 0.1750 - val_acc: 0.9333\n",
      "Epoch 5/10\n",
      "1530/1530 [==============================] - 0s 164us/sample - loss: 0.1460 - acc: 0.9379 - val_loss: 0.1834 - val_acc: 0.8926\n",
      "Epoch 6/10\n",
      "1530/1530 [==============================] - 0s 134us/sample - loss: 0.1453 - acc: 0.9327 - val_loss: 0.1813 - val_acc: 0.9000\n",
      "Epoch 7/10\n",
      "1530/1530 [==============================] - 0s 138us/sample - loss: 0.1453 - acc: 0.9307 - val_loss: 0.1662 - val_acc: 0.9185\n",
      "Epoch 8/10\n",
      "1530/1530 [==============================] - 0s 134us/sample - loss: 0.1450 - acc: 0.9340 - val_loss: 0.1607 - val_acc: 0.9370\n",
      "Epoch 9/10\n",
      "1530/1530 [==============================] - 0s 143us/sample - loss: 0.1484 - acc: 0.9431 - val_loss: 0.1629 - val_acc: 0.9222\n",
      "Epoch 10/10\n",
      "1530/1530 [==============================] - 0s 136us/sample - loss: 0.1455 - acc: 0.9307 - val_loss: 0.1803 - val_acc: 0.9333\n",
      "Epoch 116 out of 150\n",
      "Train on 1530 samples, validate on 270 samples\n",
      "Epoch 1/10\n",
      "1530/1530 [==============================] - 0s 154us/sample - loss: 0.1465 - acc: 0.9307 - val_loss: 0.1649 - val_acc: 0.9259\n",
      "Epoch 2/10\n",
      "1530/1530 [==============================] - 0s 147us/sample - loss: 0.1422 - acc: 0.9399 - val_loss: 0.1661 - val_acc: 0.9370\n",
      "Epoch 3/10\n",
      "1530/1530 [==============================] - 0s 136us/sample - loss: 0.1444 - acc: 0.9327 - val_loss: 0.1680 - val_acc: 0.9148\n",
      "Epoch 4/10\n",
      "1530/1530 [==============================] - 0s 134us/sample - loss: 0.1487 - acc: 0.9294 - val_loss: 0.1733 - val_acc: 0.9333\n",
      "Epoch 5/10\n",
      "1530/1530 [==============================] - 0s 164us/sample - loss: 0.1487 - acc: 0.9320 - val_loss: 0.1630 - val_acc: 0.9185\n",
      "Epoch 6/10\n",
      "1530/1530 [==============================] - 0s 139us/sample - loss: 0.1457 - acc: 0.9333 - val_loss: 0.1645 - val_acc: 0.9407\n",
      "Epoch 7/10\n",
      "1530/1530 [==============================] - 0s 135us/sample - loss: 0.1429 - acc: 0.9379 - val_loss: 0.1642 - val_acc: 0.9259\n",
      "Epoch 8/10\n",
      "1530/1530 [==============================] - 0s 139us/sample - loss: 0.1427 - acc: 0.9444 - val_loss: 0.1665 - val_acc: 0.9370\n",
      "Epoch 9/10\n",
      "1530/1530 [==============================] - 0s 134us/sample - loss: 0.1416 - acc: 0.9444 - val_loss: 0.1656 - val_acc: 0.9333\n",
      "Epoch 10/10\n",
      "1530/1530 [==============================] - 0s 147us/sample - loss: 0.1420 - acc: 0.9359 - val_loss: 0.1615 - val_acc: 0.9370\n",
      "Epoch 117 out of 150\n",
      "Train on 1530 samples, validate on 270 samples\n",
      "Epoch 1/10\n",
      "1530/1530 [==============================] - 0s 138us/sample - loss: 0.1450 - acc: 0.9320 - val_loss: 0.1907 - val_acc: 0.9333\n",
      "Epoch 2/10\n",
      "1530/1530 [==============================] - 0s 135us/sample - loss: 0.1462 - acc: 0.9307 - val_loss: 0.1708 - val_acc: 0.9222\n",
      "Epoch 3/10\n",
      "1530/1530 [==============================] - 0s 137us/sample - loss: 0.1495 - acc: 0.9275 - val_loss: 0.1741 - val_acc: 0.9148\n",
      "Epoch 4/10\n",
      "1530/1530 [==============================] - 0s 145us/sample - loss: 0.1462 - acc: 0.9288 - val_loss: 0.1689 - val_acc: 0.9185\n",
      "Epoch 5/10\n",
      "1530/1530 [==============================] - 0s 164us/sample - loss: 0.1416 - acc: 0.9366 - val_loss: 0.1707 - val_acc: 0.9370\n",
      "Epoch 6/10\n",
      "1530/1530 [==============================] - 0s 133us/sample - loss: 0.1435 - acc: 0.9386 - val_loss: 0.1826 - val_acc: 0.9111\n",
      "Epoch 7/10\n",
      "1530/1530 [==============================] - 0s 143us/sample - loss: 0.1439 - acc: 0.9340 - val_loss: 0.1614 - val_acc: 0.9333\n",
      "Epoch 8/10\n",
      "1530/1530 [==============================] - 0s 135us/sample - loss: 0.1412 - acc: 0.9340 - val_loss: 0.1647 - val_acc: 0.9222\n",
      "Epoch 9/10\n",
      "1530/1530 [==============================] - 0s 141us/sample - loss: 0.1452 - acc: 0.9314 - val_loss: 0.1629 - val_acc: 0.9296\n",
      "Epoch 10/10\n",
      "1530/1530 [==============================] - 0s 154us/sample - loss: 0.1418 - acc: 0.9346 - val_loss: 0.1651 - val_acc: 0.9370\n",
      "Epoch 118 out of 150\n",
      "Train on 1530 samples, validate on 270 samples\n",
      "Epoch 1/10\n",
      "1530/1530 [==============================] - 0s 170us/sample - loss: 0.1462 - acc: 0.9268 - val_loss: 0.1674 - val_acc: 0.9222\n",
      "Epoch 2/10\n",
      "1530/1530 [==============================] - 0s 168us/sample - loss: 0.1445 - acc: 0.9366 - val_loss: 0.1665 - val_acc: 0.9370\n",
      "Epoch 3/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1530/1530 [==============================] - 0s 162us/sample - loss: 0.1421 - acc: 0.9405 - val_loss: 0.1701 - val_acc: 0.8889\n",
      "Epoch 4/10\n",
      "1530/1530 [==============================] - 0s 194us/sample - loss: 0.1443 - acc: 0.9346 - val_loss: 0.1671 - val_acc: 0.9407\n",
      "Epoch 5/10\n",
      "1530/1530 [==============================] - 0s 152us/sample - loss: 0.1410 - acc: 0.9386 - val_loss: 0.1800 - val_acc: 0.9074\n",
      "Epoch 6/10\n",
      "1530/1530 [==============================] - 0s 134us/sample - loss: 0.1430 - acc: 0.9307 - val_loss: 0.1602 - val_acc: 0.9444\n",
      "Epoch 7/10\n",
      "1530/1530 [==============================] - 0s 136us/sample - loss: 0.1410 - acc: 0.9346 - val_loss: 0.1777 - val_acc: 0.9370\n",
      "Epoch 8/10\n",
      "1530/1530 [==============================] - 0s 133us/sample - loss: 0.1470 - acc: 0.9281 - val_loss: 0.1621 - val_acc: 0.9259\n",
      "Epoch 9/10\n",
      "1530/1530 [==============================] - 0s 134us/sample - loss: 0.1470 - acc: 0.9353 - val_loss: 0.1714 - val_acc: 0.8889\n",
      "Epoch 10/10\n",
      "1530/1530 [==============================] - 0s 142us/sample - loss: 0.1426 - acc: 0.9386 - val_loss: 0.1659 - val_acc: 0.9407\n",
      "Epoch 119 out of 150\n",
      "Train on 1530 samples, validate on 270 samples\n",
      "Epoch 1/10\n",
      "1530/1530 [==============================] - 0s 136us/sample - loss: 0.1412 - acc: 0.9366 - val_loss: 0.1663 - val_acc: 0.9296\n",
      "Epoch 2/10\n",
      "1530/1530 [==============================] - 0s 147us/sample - loss: 0.1411 - acc: 0.9386 - val_loss: 0.1687 - val_acc: 0.9333\n",
      "Epoch 3/10\n",
      "1530/1530 [==============================] - 0s 143us/sample - loss: 0.1456 - acc: 0.9405 - val_loss: 0.1693 - val_acc: 0.9296\n",
      "Epoch 4/10\n",
      "1530/1530 [==============================] - 0s 133us/sample - loss: 0.1432 - acc: 0.9392 - val_loss: 0.1668 - val_acc: 0.9259\n",
      "Epoch 5/10\n",
      "1530/1530 [==============================] - 0s 166us/sample - loss: 0.1400 - acc: 0.9366 - val_loss: 0.1632 - val_acc: 0.9444\n",
      "Epoch 6/10\n",
      "1530/1530 [==============================] - 0s 134us/sample - loss: 0.1421 - acc: 0.9327 - val_loss: 0.1618 - val_acc: 0.9259\n",
      "Epoch 7/10\n",
      "1530/1530 [==============================] - 0s 137us/sample - loss: 0.1436 - acc: 0.9340 - val_loss: 0.1684 - val_acc: 0.9148\n",
      "Epoch 8/10\n",
      "1530/1530 [==============================] - 0s 138us/sample - loss: 0.1449 - acc: 0.9346 - val_loss: 0.1689 - val_acc: 0.8963\n",
      "Epoch 9/10\n",
      "1530/1530 [==============================] - 0s 136us/sample - loss: 0.1439 - acc: 0.9314 - val_loss: 0.1665 - val_acc: 0.9148\n",
      "Epoch 10/10\n",
      "1530/1530 [==============================] - 0s 137us/sample - loss: 0.1466 - acc: 0.9353 - val_loss: 0.1667 - val_acc: 0.9222\n",
      "Epoch 120 out of 150\n",
      "Train on 1530 samples, validate on 270 samples\n",
      "Epoch 1/10\n",
      "1530/1530 [==============================] - 0s 168us/sample - loss: 0.1407 - acc: 0.9359 - val_loss: 0.1614 - val_acc: 0.9296\n",
      "Epoch 2/10\n",
      "1530/1530 [==============================] - 0s 134us/sample - loss: 0.1436 - acc: 0.9320 - val_loss: 0.1693 - val_acc: 0.8926\n",
      "Epoch 3/10\n",
      "1530/1530 [==============================] - 0s 133us/sample - loss: 0.1423 - acc: 0.9353 - val_loss: 0.1695 - val_acc: 0.9148\n",
      "Epoch 4/10\n",
      "1530/1530 [==============================] - 0s 133us/sample - loss: 0.1451 - acc: 0.9366 - val_loss: 0.1624 - val_acc: 0.9333\n",
      "Epoch 5/10\n",
      "1530/1530 [==============================] - 0s 173us/sample - loss: 0.1400 - acc: 0.9412 - val_loss: 0.1626 - val_acc: 0.9148\n",
      "Epoch 6/10\n",
      "1530/1530 [==============================] - 0s 133us/sample - loss: 0.1474 - acc: 0.9359 - val_loss: 0.1724 - val_acc: 0.9333\n",
      "Epoch 7/10\n",
      "1530/1530 [==============================] - 0s 136us/sample - loss: 0.1439 - acc: 0.9333 - val_loss: 0.1728 - val_acc: 0.8889\n",
      "Epoch 8/10\n",
      "1530/1530 [==============================] - 0s 153us/sample - loss: 0.1406 - acc: 0.9359 - val_loss: 0.1606 - val_acc: 0.9222\n",
      "Epoch 9/10\n",
      "1530/1530 [==============================] - 0s 136us/sample - loss: 0.1423 - acc: 0.9353 - val_loss: 0.1618 - val_acc: 0.9333\n",
      "Epoch 10/10\n",
      "1530/1530 [==============================] - 0s 143us/sample - loss: 0.1446 - acc: 0.9386 - val_loss: 0.1694 - val_acc: 0.8963\n",
      "Epoch 121 out of 150\n",
      "Train on 1530 samples, validate on 270 samples\n",
      "Epoch 1/10\n",
      "1530/1530 [==============================] - 0s 137us/sample - loss: 0.1468 - acc: 0.9281 - val_loss: 0.1659 - val_acc: 0.9222\n",
      "Epoch 2/10\n",
      "1530/1530 [==============================] - 0s 137us/sample - loss: 0.1419 - acc: 0.9359 - val_loss: 0.1750 - val_acc: 0.9148\n",
      "Epoch 3/10\n",
      "1530/1530 [==============================] - 0s 141us/sample - loss: 0.1455 - acc: 0.9346 - val_loss: 0.1682 - val_acc: 0.9296\n",
      "Epoch 4/10\n",
      "1530/1530 [==============================] - 0s 134us/sample - loss: 0.1460 - acc: 0.9346 - val_loss: 0.1663 - val_acc: 0.9407\n",
      "Epoch 5/10\n",
      "1530/1530 [==============================] - 0s 163us/sample - loss: 0.1423 - acc: 0.9392 - val_loss: 0.1828 - val_acc: 0.8889\n",
      "Epoch 6/10\n",
      "1530/1530 [==============================] - 0s 143us/sample - loss: 0.1436 - acc: 0.9366 - val_loss: 0.1621 - val_acc: 0.9222\n",
      "Epoch 7/10\n",
      "1530/1530 [==============================] - 0s 140us/sample - loss: 0.1427 - acc: 0.9366 - val_loss: 0.1807 - val_acc: 0.9111\n",
      "Epoch 8/10\n",
      "1530/1530 [==============================] - 0s 136us/sample - loss: 0.1436 - acc: 0.9366 - val_loss: 0.1691 - val_acc: 0.9259\n",
      "Epoch 9/10\n",
      "1530/1530 [==============================] - 0s 132us/sample - loss: 0.1479 - acc: 0.9340 - val_loss: 0.1666 - val_acc: 0.9222\n",
      "Epoch 10/10\n",
      "1530/1530 [==============================] - 0s 138us/sample - loss: 0.1422 - acc: 0.9359 - val_loss: 0.1635 - val_acc: 0.9259\n",
      "Epoch 122 out of 150\n",
      "Train on 1530 samples, validate on 270 samples\n",
      "Epoch 1/10\n",
      "1530/1530 [==============================] - 0s 142us/sample - loss: 0.1513 - acc: 0.9275 - val_loss: 0.1656 - val_acc: 0.9037\n",
      "Epoch 2/10\n",
      "1530/1530 [==============================] - 0s 138us/sample - loss: 0.1425 - acc: 0.9392 - val_loss: 0.1832 - val_acc: 0.8963\n",
      "Epoch 3/10\n",
      "1530/1530 [==============================] - 0s 143us/sample - loss: 0.1447 - acc: 0.9314 - val_loss: 0.1941 - val_acc: 0.8852\n",
      "Epoch 4/10\n",
      "1530/1530 [==============================] - 0s 139us/sample - loss: 0.1413 - acc: 0.9392 - val_loss: 0.1648 - val_acc: 0.9222\n",
      "Epoch 5/10\n",
      "1530/1530 [==============================] - 0s 176us/sample - loss: 0.1451 - acc: 0.9314 - val_loss: 0.1655 - val_acc: 0.9185\n",
      "Epoch 6/10\n",
      "1530/1530 [==============================] - 0s 175us/sample - loss: 0.1427 - acc: 0.9320 - val_loss: 0.1863 - val_acc: 0.9222\n",
      "Epoch 7/10\n",
      "1530/1530 [==============================] - 0s 205us/sample - loss: 0.1455 - acc: 0.9359 - val_loss: 0.1599 - val_acc: 0.9259\n",
      "Epoch 8/10\n",
      "1530/1530 [==============================] - 0s 235us/sample - loss: 0.1408 - acc: 0.9412 - val_loss: 0.1740 - val_acc: 0.9074\n",
      "Epoch 9/10\n",
      "1530/1530 [==============================] - 0s 166us/sample - loss: 0.1465 - acc: 0.9307 - val_loss: 0.1677 - val_acc: 0.9259\n",
      "Epoch 10/10\n",
      "1530/1530 [==============================] - 0s 176us/sample - loss: 0.1445 - acc: 0.9359 - val_loss: 0.1687 - val_acc: 0.9037\n",
      "Epoch 123 out of 150\n",
      "Train on 1530 samples, validate on 270 samples\n",
      "Epoch 1/10\n",
      "1530/1530 [==============================] - 0s 193us/sample - loss: 0.1450 - acc: 0.9314 - val_loss: 0.1762 - val_acc: 0.9111\n",
      "Epoch 2/10\n",
      "1530/1530 [==============================] - 1s 386us/sample - loss: 0.1427 - acc: 0.9307 - val_loss: 0.1704 - val_acc: 0.9370\n",
      "Epoch 3/10\n",
      "1530/1530 [==============================] - 1s 484us/sample - loss: 0.1428 - acc: 0.9340 - val_loss: 0.1656 - val_acc: 0.9370\n",
      "Epoch 4/10\n",
      "1530/1530 [==============================] - 0s 213us/sample - loss: 0.1447 - acc: 0.9288 - val_loss: 0.1771 - val_acc: 0.9259\n",
      "Epoch 5/10\n",
      "1530/1530 [==============================] - 1s 408us/sample - loss: 0.1432 - acc: 0.9359 - val_loss: 0.1664 - val_acc: 0.9185\n",
      "Epoch 6/10\n",
      "1530/1530 [==============================] - 0s 261us/sample - loss: 0.1443 - acc: 0.9346 - val_loss: 0.1731 - val_acc: 0.9185\n",
      "Epoch 7/10\n",
      "1530/1530 [==============================] - 0s 202us/sample - loss: 0.1491 - acc: 0.9366 - val_loss: 0.1679 - val_acc: 0.9333\n",
      "Epoch 8/10\n",
      "1530/1530 [==============================] - 0s 179us/sample - loss: 0.1458 - acc: 0.9346 - val_loss: 0.1671 - val_acc: 0.9333\n",
      "Epoch 9/10\n",
      "1530/1530 [==============================] - 0s 162us/sample - loss: 0.1414 - acc: 0.9301 - val_loss: 0.1711 - val_acc: 0.9407\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/10\n",
      "1530/1530 [==============================] - 0s 186us/sample - loss: 0.1400 - acc: 0.9359 - val_loss: 0.1652 - val_acc: 0.9185\n",
      "Epoch 124 out of 150\n",
      "Train on 1530 samples, validate on 270 samples\n",
      "Epoch 1/10\n",
      "1530/1530 [==============================] - 0s 134us/sample - loss: 0.1411 - acc: 0.9353 - val_loss: 0.1623 - val_acc: 0.9407\n",
      "Epoch 2/10\n",
      "1530/1530 [==============================] - 0s 142us/sample - loss: 0.1406 - acc: 0.9359 - val_loss: 0.1605 - val_acc: 0.9259\n",
      "Epoch 3/10\n",
      "1530/1530 [==============================] - 0s 153us/sample - loss: 0.1460 - acc: 0.9320 - val_loss: 0.1612 - val_acc: 0.9222\n",
      "Epoch 4/10\n",
      "1530/1530 [==============================] - 0s 173us/sample - loss: 0.1427 - acc: 0.9405 - val_loss: 0.1610 - val_acc: 0.9407\n",
      "Epoch 5/10\n",
      "1530/1530 [==============================] - 0s 185us/sample - loss: 0.1420 - acc: 0.9379 - val_loss: 0.1592 - val_acc: 0.9370\n",
      "Epoch 6/10\n",
      "1530/1530 [==============================] - 0s 197us/sample - loss: 0.1409 - acc: 0.9340 - val_loss: 0.1673 - val_acc: 0.9333\n",
      "Epoch 7/10\n",
      "1530/1530 [==============================] - 0s 204us/sample - loss: 0.1489 - acc: 0.9359 - val_loss: 0.1656 - val_acc: 0.9185\n",
      "Epoch 8/10\n",
      "1530/1530 [==============================] - 0s 183us/sample - loss: 0.1479 - acc: 0.9301 - val_loss: 0.1655 - val_acc: 0.9222\n",
      "Epoch 9/10\n",
      "1530/1530 [==============================] - 1s 515us/sample - loss: 0.1468 - acc: 0.9314 - val_loss: 0.1695 - val_acc: 0.9111\n",
      "Epoch 10/10\n",
      "1530/1530 [==============================] - 1s 383us/sample - loss: 0.1434 - acc: 0.9327 - val_loss: 0.1772 - val_acc: 0.9185\n",
      "Epoch 125 out of 150\n",
      "Train on 1530 samples, validate on 270 samples\n",
      "Epoch 1/10\n",
      "1530/1530 [==============================] - 0s 190us/sample - loss: 0.1422 - acc: 0.9386 - val_loss: 0.1733 - val_acc: 0.9370\n",
      "Epoch 2/10\n",
      "1530/1530 [==============================] - 0s 164us/sample - loss: 0.1445 - acc: 0.9320 - val_loss: 0.1619 - val_acc: 0.9444\n",
      "Epoch 3/10\n",
      "1530/1530 [==============================] - 0s 173us/sample - loss: 0.1399 - acc: 0.9373 - val_loss: 0.1643 - val_acc: 0.9296\n",
      "Epoch 4/10\n",
      "1530/1530 [==============================] - 0s 145us/sample - loss: 0.1401 - acc: 0.9353 - val_loss: 0.1703 - val_acc: 0.9333\n",
      "Epoch 5/10\n",
      "1530/1530 [==============================] - 0s 155us/sample - loss: 0.1422 - acc: 0.9353 - val_loss: 0.1647 - val_acc: 0.9259\n",
      "Epoch 6/10\n",
      "1530/1530 [==============================] - 0s 154us/sample - loss: 0.1434 - acc: 0.9327 - val_loss: 0.1647 - val_acc: 0.9296\n",
      "Epoch 7/10\n",
      "1530/1530 [==============================] - 0s 179us/sample - loss: 0.1438 - acc: 0.9327 - val_loss: 0.1614 - val_acc: 0.9333\n",
      "Epoch 8/10\n",
      "1530/1530 [==============================] - 0s 300us/sample - loss: 0.1408 - acc: 0.9353 - val_loss: 0.1652 - val_acc: 0.9333\n",
      "Epoch 9/10\n",
      "1530/1530 [==============================] - 1s 349us/sample - loss: 0.1443 - acc: 0.9327 - val_loss: 0.1702 - val_acc: 0.9185\n",
      "Epoch 10/10\n",
      "1530/1530 [==============================] - 0s 326us/sample - loss: 0.1360 - acc: 0.9444 - val_loss: 0.1662 - val_acc: 0.9185\n",
      "Epoch 126 out of 150\n",
      "Train on 1530 samples, validate on 270 samples\n",
      "Epoch 1/10\n",
      "1530/1530 [==============================] - 0s 159us/sample - loss: 0.1413 - acc: 0.9366 - val_loss: 0.1696 - val_acc: 0.9111\n",
      "Epoch 2/10\n",
      "1530/1530 [==============================] - 0s 147us/sample - loss: 0.1436 - acc: 0.9346 - val_loss: 0.1596 - val_acc: 0.9222\n",
      "Epoch 3/10\n",
      "1530/1530 [==============================] - 0s 142us/sample - loss: 0.1436 - acc: 0.9379 - val_loss: 0.1719 - val_acc: 0.8926\n",
      "Epoch 4/10\n",
      "1530/1530 [==============================] - 0s 176us/sample - loss: 0.1407 - acc: 0.9340 - val_loss: 0.1627 - val_acc: 0.9259\n",
      "Epoch 5/10\n",
      "1530/1530 [==============================] - 0s 250us/sample - loss: 0.1394 - acc: 0.9373 - val_loss: 0.1606 - val_acc: 0.9222\n",
      "Epoch 6/10\n",
      "1530/1530 [==============================] - 0s 295us/sample - loss: 0.1397 - acc: 0.9366 - val_loss: 0.1781 - val_acc: 0.9111\n",
      "Epoch 7/10\n",
      "1530/1530 [==============================] - 0s 155us/sample - loss: 0.1472 - acc: 0.9366 - val_loss: 0.1608 - val_acc: 0.9407\n",
      "Epoch 8/10\n",
      "1530/1530 [==============================] - 0s 169us/sample - loss: 0.1409 - acc: 0.9379 - val_loss: 0.1638 - val_acc: 0.9148\n",
      "Epoch 9/10\n",
      "1530/1530 [==============================] - 0s 156us/sample - loss: 0.1401 - acc: 0.9340 - val_loss: 0.1678 - val_acc: 0.9185\n",
      "Epoch 10/10\n",
      "1530/1530 [==============================] - 0s 150us/sample - loss: 0.1396 - acc: 0.9399 - val_loss: 0.1662 - val_acc: 0.9000\n",
      "Epoch 127 out of 150\n",
      "Train on 1530 samples, validate on 270 samples\n",
      "Epoch 1/10\n",
      "1530/1530 [==============================] - 0s 297us/sample - loss: 0.1406 - acc: 0.9379 - val_loss: 0.1691 - val_acc: 0.9185\n",
      "Epoch 2/10\n",
      "1530/1530 [==============================] - 1s 445us/sample - loss: 0.1426 - acc: 0.9333 - val_loss: 0.1653 - val_acc: 0.9333\n",
      "Epoch 3/10\n",
      "1530/1530 [==============================] - 0s 249us/sample - loss: 0.1396 - acc: 0.9379 - val_loss: 0.1651 - val_acc: 0.9259\n",
      "Epoch 4/10\n",
      "1530/1530 [==============================] - 0s 304us/sample - loss: 0.1402 - acc: 0.9346 - val_loss: 0.1581 - val_acc: 0.9407\n",
      "Epoch 5/10\n",
      "1530/1530 [==============================] - 0s 257us/sample - loss: 0.1471 - acc: 0.9340 - val_loss: 0.1682 - val_acc: 0.9000\n",
      "Epoch 6/10\n",
      "1530/1530 [==============================] - 1s 609us/sample - loss: 0.1405 - acc: 0.9346 - val_loss: 0.1690 - val_acc: 0.9370\n",
      "Epoch 7/10\n",
      "1530/1530 [==============================] - 1s 492us/sample - loss: 0.1425 - acc: 0.9333 - val_loss: 0.1701 - val_acc: 0.9000\n",
      "Epoch 8/10\n",
      "1530/1530 [==============================] - 1s 394us/sample - loss: 0.1431 - acc: 0.9353 - val_loss: 0.1597 - val_acc: 0.9296\n",
      "Epoch 9/10\n",
      "1530/1530 [==============================] - 0s 248us/sample - loss: 0.1382 - acc: 0.9451 - val_loss: 0.1715 - val_acc: 0.9185\n",
      "Epoch 10/10\n",
      "1530/1530 [==============================] - 0s 217us/sample - loss: 0.1394 - acc: 0.9379 - val_loss: 0.1630 - val_acc: 0.9148\n",
      "Epoch 128 out of 150\n",
      "Train on 1530 samples, validate on 270 samples\n",
      "Epoch 1/10\n",
      "1530/1530 [==============================] - 0s 186us/sample - loss: 0.1391 - acc: 0.9386 - val_loss: 0.1599 - val_acc: 0.9370\n",
      "Epoch 2/10\n",
      "1530/1530 [==============================] - 0s 184us/sample - loss: 0.1389 - acc: 0.9386 - val_loss: 0.1590 - val_acc: 0.9370\n",
      "Epoch 3/10\n",
      "1530/1530 [==============================] - 0s 201us/sample - loss: 0.1403 - acc: 0.9373 - val_loss: 0.1610 - val_acc: 0.9407\n",
      "Epoch 4/10\n",
      "1530/1530 [==============================] - ETA: 0s - loss: 0.1460 - acc: 0.931 - 0s 232us/sample - loss: 0.1413 - acc: 0.9333 - val_loss: 0.1634 - val_acc: 0.9259\n",
      "Epoch 5/10\n",
      "1530/1530 [==============================] - 0s 189us/sample - loss: 0.1409 - acc: 0.9340 - val_loss: 0.1674 - val_acc: 0.9333\n",
      "Epoch 6/10\n",
      "1530/1530 [==============================] - 0s 196us/sample - loss: 0.1400 - acc: 0.9301 - val_loss: 0.1645 - val_acc: 0.9259\n",
      "Epoch 7/10\n",
      "1530/1530 [==============================] - 0s 196us/sample - loss: 0.1393 - acc: 0.9412 - val_loss: 0.1752 - val_acc: 0.9259\n",
      "Epoch 8/10\n",
      "1530/1530 [==============================] - 0s 198us/sample - loss: 0.1440 - acc: 0.9314 - val_loss: 0.1620 - val_acc: 0.9296\n",
      "Epoch 9/10\n",
      "1530/1530 [==============================] - 0s 213us/sample - loss: 0.1400 - acc: 0.9373 - val_loss: 0.1664 - val_acc: 0.9148\n",
      "Epoch 10/10\n",
      "1530/1530 [==============================] - 0s 196us/sample - loss: 0.1426 - acc: 0.9405 - val_loss: 0.1621 - val_acc: 0.9259\n",
      "Epoch 129 out of 150\n",
      "Train on 1530 samples, validate on 270 samples\n",
      "Epoch 1/10\n",
      "1530/1530 [==============================] - 0s 160us/sample - loss: 0.1429 - acc: 0.9366 - val_loss: 0.1678 - val_acc: 0.9296\n",
      "Epoch 2/10\n",
      "1530/1530 [==============================] - 0s 169us/sample - loss: 0.1403 - acc: 0.9359 - val_loss: 0.1640 - val_acc: 0.9296\n",
      "Epoch 3/10\n",
      "1530/1530 [==============================] - 0s 207us/sample - loss: 0.1411 - acc: 0.9333 - val_loss: 0.1586 - val_acc: 0.9296\n",
      "Epoch 4/10\n",
      "1530/1530 [==============================] - 0s 169us/sample - loss: 0.1381 - acc: 0.9373 - val_loss: 0.1680 - val_acc: 0.9259\n",
      "Epoch 5/10\n",
      "1530/1530 [==============================] - 0s 182us/sample - loss: 0.1404 - acc: 0.9379 - val_loss: 0.1585 - val_acc: 0.9370\n",
      "Epoch 6/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1530/1530 [==============================] - 0s 166us/sample - loss: 0.1407 - acc: 0.9379 - val_loss: 0.1618 - val_acc: 0.9296\n",
      "Epoch 7/10\n",
      "1530/1530 [==============================] - 0s 154us/sample - loss: 0.1386 - acc: 0.9386 - val_loss: 0.1720 - val_acc: 0.9185\n",
      "Epoch 8/10\n",
      "1530/1530 [==============================] - 0s 176us/sample - loss: 0.1430 - acc: 0.9346 - val_loss: 0.1647 - val_acc: 0.9370\n",
      "Epoch 9/10\n",
      "1530/1530 [==============================] - 0s 178us/sample - loss: 0.1387 - acc: 0.9346 - val_loss: 0.1661 - val_acc: 0.9222\n",
      "Epoch 10/10\n",
      "1530/1530 [==============================] - 0s 163us/sample - loss: 0.1419 - acc: 0.9399 - val_loss: 0.1806 - val_acc: 0.9370\n",
      "Epoch 130 out of 150\n",
      "Train on 1530 samples, validate on 270 samples\n",
      "Epoch 1/10\n",
      "1530/1530 [==============================] - 0s 207us/sample - loss: 0.1406 - acc: 0.9373 - val_loss: 0.1614 - val_acc: 0.9333\n",
      "Epoch 2/10\n",
      "1530/1530 [==============================] - 0s 194us/sample - loss: 0.1526 - acc: 0.9294 - val_loss: 0.1802 - val_acc: 0.9370\n",
      "Epoch 3/10\n",
      "1530/1530 [==============================] - 0s 183us/sample - loss: 0.1476 - acc: 0.9359 - val_loss: 0.1600 - val_acc: 0.9444\n",
      "Epoch 4/10\n",
      "1530/1530 [==============================] - 0s 176us/sample - loss: 0.1393 - acc: 0.9464 - val_loss: 0.1617 - val_acc: 0.9407\n",
      "Epoch 5/10\n",
      "1530/1530 [==============================] - 0s 166us/sample - loss: 0.1406 - acc: 0.9346 - val_loss: 0.1718 - val_acc: 0.8926\n",
      "Epoch 6/10\n",
      "1530/1530 [==============================] - 0s 165us/sample - loss: 0.1392 - acc: 0.9366 - val_loss: 0.1669 - val_acc: 0.9333\n",
      "Epoch 7/10\n",
      "1530/1530 [==============================] - 0s 155us/sample - loss: 0.1413 - acc: 0.9405 - val_loss: 0.1708 - val_acc: 0.9222\n",
      "Epoch 8/10\n",
      "1530/1530 [==============================] - 0s 177us/sample - loss: 0.1387 - acc: 0.9314 - val_loss: 0.1591 - val_acc: 0.9259\n",
      "Epoch 9/10\n",
      "1530/1530 [==============================] - 0s 188us/sample - loss: 0.1392 - acc: 0.9405 - val_loss: 0.1584 - val_acc: 0.9333\n",
      "Epoch 10/10\n",
      "1530/1530 [==============================] - 0s 157us/sample - loss: 0.1368 - acc: 0.9458 - val_loss: 0.1673 - val_acc: 0.9148\n",
      "Epoch 131 out of 150\n",
      "Train on 1530 samples, validate on 270 samples\n",
      "Epoch 1/10\n",
      "1530/1530 [==============================] - 0s 175us/sample - loss: 0.1400 - acc: 0.9366 - val_loss: 0.1743 - val_acc: 0.9111\n",
      "Epoch 2/10\n",
      "1530/1530 [==============================] - 0s 175us/sample - loss: 0.1527 - acc: 0.9353 - val_loss: 0.1938 - val_acc: 0.9148\n",
      "Epoch 3/10\n",
      "1530/1530 [==============================] - 0s 160us/sample - loss: 0.1462 - acc: 0.9314 - val_loss: 0.1686 - val_acc: 0.9407\n",
      "Epoch 4/10\n",
      "1530/1530 [==============================] - 0s 187us/sample - loss: 0.1401 - acc: 0.9366 - val_loss: 0.1620 - val_acc: 0.9222\n",
      "Epoch 5/10\n",
      "1530/1530 [==============================] - 0s 172us/sample - loss: 0.1386 - acc: 0.9333 - val_loss: 0.1719 - val_acc: 0.9111\n",
      "Epoch 6/10\n",
      "1530/1530 [==============================] - 0s 169us/sample - loss: 0.1408 - acc: 0.9320 - val_loss: 0.1760 - val_acc: 0.8926\n",
      "Epoch 7/10\n",
      "1530/1530 [==============================] - 0s 186us/sample - loss: 0.1398 - acc: 0.9366 - val_loss: 0.1654 - val_acc: 0.9185\n",
      "Epoch 8/10\n",
      "1530/1530 [==============================] - 0s 162us/sample - loss: 0.1392 - acc: 0.9386 - val_loss: 0.1640 - val_acc: 0.9185\n",
      "Epoch 9/10\n",
      "1530/1530 [==============================] - 0s 192us/sample - loss: 0.1416 - acc: 0.9353 - val_loss: 0.1708 - val_acc: 0.9148\n",
      "Epoch 10/10\n",
      "1530/1530 [==============================] - 0s 191us/sample - loss: 0.1392 - acc: 0.9346 - val_loss: 0.1593 - val_acc: 0.9444\n",
      "Epoch 132 out of 150\n",
      "Train on 1530 samples, validate on 270 samples\n",
      "Epoch 1/10\n",
      "1530/1530 [==============================] - 0s 221us/sample - loss: 0.1399 - acc: 0.9366 - val_loss: 0.1675 - val_acc: 0.9222\n",
      "Epoch 2/10\n",
      "1530/1530 [==============================] - 0s 215us/sample - loss: 0.1409 - acc: 0.9320 - val_loss: 0.1605 - val_acc: 0.9407\n",
      "Epoch 3/10\n",
      "1530/1530 [==============================] - 0s 247us/sample - loss: 0.1409 - acc: 0.9373 - val_loss: 0.1611 - val_acc: 0.9444\n",
      "Epoch 4/10\n",
      "1530/1530 [==============================] - 0s 203us/sample - loss: 0.1392 - acc: 0.9386 - val_loss: 0.1642 - val_acc: 0.9333\n",
      "Epoch 5/10\n",
      "1530/1530 [==============================] - 0s 180us/sample - loss: 0.1402 - acc: 0.9373 - val_loss: 0.1820 - val_acc: 0.8963\n",
      "Epoch 6/10\n",
      "1530/1530 [==============================] - 0s 176us/sample - loss: 0.1447 - acc: 0.9333 - val_loss: 0.1708 - val_acc: 0.9370\n",
      "Epoch 7/10\n",
      "1530/1530 [==============================] - 0s 180us/sample - loss: 0.1415 - acc: 0.9340 - val_loss: 0.1603 - val_acc: 0.9370\n",
      "Epoch 8/10\n",
      "1530/1530 [==============================] - 0s 176us/sample - loss: 0.1368 - acc: 0.9438 - val_loss: 0.1591 - val_acc: 0.9370\n",
      "Epoch 9/10\n",
      "1530/1530 [==============================] - 0s 182us/sample - loss: 0.1396 - acc: 0.9425 - val_loss: 0.1836 - val_acc: 0.9370\n",
      "Epoch 10/10\n",
      "1530/1530 [==============================] - 0s 189us/sample - loss: 0.1434 - acc: 0.9307 - val_loss: 0.1823 - val_acc: 0.9000\n",
      "Epoch 133 out of 150\n",
      "Train on 1530 samples, validate on 270 samples\n",
      "Epoch 1/10\n",
      "1530/1530 [==============================] - 0s 148us/sample - loss: 0.1407 - acc: 0.9425 - val_loss: 0.1602 - val_acc: 0.9333\n",
      "Epoch 2/10\n",
      "1530/1530 [==============================] - 0s 160us/sample - loss: 0.1369 - acc: 0.9379 - val_loss: 0.1845 - val_acc: 0.8926\n",
      "Epoch 3/10\n",
      "1530/1530 [==============================] - 0s 152us/sample - loss: 0.1441 - acc: 0.9340 - val_loss: 0.1657 - val_acc: 0.9407\n",
      "Epoch 4/10\n",
      "1530/1530 [==============================] - 0s 171us/sample - loss: 0.1408 - acc: 0.9327 - val_loss: 0.1680 - val_acc: 0.9370\n",
      "Epoch 5/10\n",
      "1530/1530 [==============================] - 0s 171us/sample - loss: 0.1385 - acc: 0.9307 - val_loss: 0.1642 - val_acc: 0.9185\n",
      "Epoch 6/10\n",
      "1530/1530 [==============================] - 0s 169us/sample - loss: 0.1389 - acc: 0.9386 - val_loss: 0.1634 - val_acc: 0.9296\n",
      "Epoch 7/10\n",
      "1530/1530 [==============================] - 0s 173us/sample - loss: 0.1373 - acc: 0.9392 - val_loss: 0.1598 - val_acc: 0.9185\n",
      "Epoch 8/10\n",
      "1530/1530 [==============================] - 0s 250us/sample - loss: 0.1403 - acc: 0.9386 - val_loss: 0.1574 - val_acc: 0.9296\n",
      "Epoch 9/10\n",
      "1530/1530 [==============================] - 0s 190us/sample - loss: 0.1439 - acc: 0.9261 - val_loss: 0.1680 - val_acc: 0.9370\n",
      "Epoch 10/10\n",
      "1530/1530 [==============================] - 0s 168us/sample - loss: 0.1398 - acc: 0.9399 - val_loss: 0.1589 - val_acc: 0.9333\n",
      "Epoch 134 out of 150\n",
      "Train on 1530 samples, validate on 270 samples\n",
      "Epoch 1/10\n",
      "1530/1530 [==============================] - 0s 185us/sample - loss: 0.1378 - acc: 0.9392 - val_loss: 0.1594 - val_acc: 0.9444\n",
      "Epoch 2/10\n",
      "1530/1530 [==============================] - 0s 184us/sample - loss: 0.1378 - acc: 0.9379 - val_loss: 0.1582 - val_acc: 0.9370\n",
      "Epoch 3/10\n",
      "1530/1530 [==============================] - 0s 183us/sample - loss: 0.1387 - acc: 0.9379 - val_loss: 0.1757 - val_acc: 0.9333\n",
      "Epoch 4/10\n",
      "1530/1530 [==============================] - 0s 184us/sample - loss: 0.1475 - acc: 0.9346 - val_loss: 0.2099 - val_acc: 0.8889\n",
      "Epoch 5/10\n",
      "1530/1530 [==============================] - 0s 173us/sample - loss: 0.1502 - acc: 0.9288 - val_loss: 0.1646 - val_acc: 0.9000\n",
      "Epoch 6/10\n",
      "1530/1530 [==============================] - 0s 179us/sample - loss: 0.1409 - acc: 0.9320 - val_loss: 0.1651 - val_acc: 0.9333\n",
      "Epoch 7/10\n",
      "1530/1530 [==============================] - 0s 162us/sample - loss: 0.1382 - acc: 0.9412 - val_loss: 0.1605 - val_acc: 0.9407\n",
      "Epoch 8/10\n",
      "1530/1530 [==============================] - 0s 169us/sample - loss: 0.1399 - acc: 0.9366 - val_loss: 0.1703 - val_acc: 0.9259\n",
      "Epoch 9/10\n",
      "1530/1530 [==============================] - 0s 166us/sample - loss: 0.1363 - acc: 0.9399 - val_loss: 0.1805 - val_acc: 0.9333\n",
      "Epoch 10/10\n",
      "1530/1530 [==============================] - 0s 161us/sample - loss: 0.1414 - acc: 0.9386 - val_loss: 0.1771 - val_acc: 0.9148\n",
      "Epoch 135 out of 150\n",
      "Train on 1530 samples, validate on 270 samples\n",
      "Epoch 1/10\n",
      "1530/1530 [==============================] - 0s 166us/sample - loss: 0.1395 - acc: 0.9418 - val_loss: 0.1614 - val_acc: 0.9222\n",
      "Epoch 2/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1530/1530 [==============================] - 0s 173us/sample - loss: 0.1381 - acc: 0.9314 - val_loss: 0.1633 - val_acc: 0.9296\n",
      "Epoch 3/10\n",
      "1530/1530 [==============================] - 0s 165us/sample - loss: 0.1371 - acc: 0.9431 - val_loss: 0.1769 - val_acc: 0.9333\n",
      "Epoch 4/10\n",
      "1530/1530 [==============================] - 0s 147us/sample - loss: 0.1404 - acc: 0.9379 - val_loss: 0.1651 - val_acc: 0.9185\n",
      "Epoch 5/10\n",
      "1530/1530 [==============================] - 0s 145us/sample - loss: 0.1379 - acc: 0.9405 - val_loss: 0.1617 - val_acc: 0.9370\n",
      "Epoch 6/10\n",
      "1530/1530 [==============================] - 0s 138us/sample - loss: 0.1435 - acc: 0.9359 - val_loss: 0.1718 - val_acc: 0.9370\n",
      "Epoch 7/10\n",
      "1530/1530 [==============================] - 0s 138us/sample - loss: 0.1428 - acc: 0.9379 - val_loss: 0.1727 - val_acc: 0.9074\n",
      "Epoch 8/10\n",
      "1530/1530 [==============================] - 0s 148us/sample - loss: 0.1391 - acc: 0.9373 - val_loss: 0.1589 - val_acc: 0.9333\n",
      "Epoch 9/10\n",
      "1530/1530 [==============================] - 0s 137us/sample - loss: 0.1374 - acc: 0.9399 - val_loss: 0.1617 - val_acc: 0.9296\n",
      "Epoch 10/10\n",
      "1530/1530 [==============================] - 0s 138us/sample - loss: 0.1377 - acc: 0.9405 - val_loss: 0.1622 - val_acc: 0.9370\n",
      "Epoch 136 out of 150\n",
      "Train on 1530 samples, validate on 270 samples\n",
      "Epoch 1/10\n",
      "1530/1530 [==============================] - 0s 147us/sample - loss: 0.1353 - acc: 0.9431 - val_loss: 0.1602 - val_acc: 0.9407\n",
      "Epoch 2/10\n",
      "1530/1530 [==============================] - 0s 135us/sample - loss: 0.1364 - acc: 0.9431 - val_loss: 0.1730 - val_acc: 0.9074\n",
      "Epoch 3/10\n",
      "1530/1530 [==============================] - 0s 136us/sample - loss: 0.1392 - acc: 0.9307 - val_loss: 0.1641 - val_acc: 0.9444\n",
      "Epoch 4/10\n",
      "1530/1530 [==============================] - 0s 134us/sample - loss: 0.1399 - acc: 0.9405 - val_loss: 0.1641 - val_acc: 0.9111\n",
      "Epoch 5/10\n",
      "1530/1530 [==============================] - 0s 170us/sample - loss: 0.1414 - acc: 0.9366 - val_loss: 0.1640 - val_acc: 0.9222\n",
      "Epoch 6/10\n",
      "1530/1530 [==============================] - 0s 140us/sample - loss: 0.1372 - acc: 0.9386 - val_loss: 0.1698 - val_acc: 0.9370\n",
      "Epoch 7/10\n",
      "1530/1530 [==============================] - 0s 136us/sample - loss: 0.1387 - acc: 0.9386 - val_loss: 0.1625 - val_acc: 0.9333\n",
      "Epoch 8/10\n",
      "1530/1530 [==============================] - 0s 137us/sample - loss: 0.1401 - acc: 0.9320 - val_loss: 0.1640 - val_acc: 0.9407\n",
      "Epoch 9/10\n",
      "1530/1530 [==============================] - 0s 143us/sample - loss: 0.1357 - acc: 0.9399 - val_loss: 0.1590 - val_acc: 0.9370\n",
      "Epoch 10/10\n",
      "1530/1530 [==============================] - 0s 151us/sample - loss: 0.1411 - acc: 0.9294 - val_loss: 0.1617 - val_acc: 0.9407\n",
      "Epoch 137 out of 150\n",
      "Train on 1530 samples, validate on 270 samples\n",
      "Epoch 1/10\n",
      "1530/1530 [==============================] - 0s 183us/sample - loss: 0.1389 - acc: 0.9405 - val_loss: 0.1669 - val_acc: 0.9259\n",
      "Epoch 2/10\n",
      "1530/1530 [==============================] - 0s 183us/sample - loss: 0.1360 - acc: 0.9366 - val_loss: 0.1665 - val_acc: 0.9444\n",
      "Epoch 3/10\n",
      "1530/1530 [==============================] - 0s 174us/sample - loss: 0.1440 - acc: 0.9307 - val_loss: 0.1678 - val_acc: 0.9333\n",
      "Epoch 4/10\n",
      "1530/1530 [==============================] - 0s 186us/sample - loss: 0.1421 - acc: 0.9314 - val_loss: 0.1635 - val_acc: 0.9333\n",
      "Epoch 5/10\n",
      "1530/1530 [==============================] - 0s 181us/sample - loss: 0.1424 - acc: 0.9320 - val_loss: 0.1757 - val_acc: 0.9370\n",
      "Epoch 6/10\n",
      "1530/1530 [==============================] - 0s 175us/sample - loss: 0.1384 - acc: 0.9366 - val_loss: 0.1617 - val_acc: 0.9259\n",
      "Epoch 7/10\n",
      "1530/1530 [==============================] - 0s 145us/sample - loss: 0.1355 - acc: 0.9471 - val_loss: 0.1699 - val_acc: 0.9222\n",
      "Epoch 8/10\n",
      "1530/1530 [==============================] - 0s 192us/sample - loss: 0.1401 - acc: 0.9392 - val_loss: 0.1614 - val_acc: 0.9407\n",
      "Epoch 9/10\n",
      "1530/1530 [==============================] - 0s 180us/sample - loss: 0.1379 - acc: 0.9405 - val_loss: 0.1606 - val_acc: 0.9407\n",
      "Epoch 10/10\n",
      "1530/1530 [==============================] - 0s 173us/sample - loss: 0.1377 - acc: 0.9412 - val_loss: 0.1622 - val_acc: 0.9370\n",
      "Epoch 138 out of 150\n",
      "Train on 1530 samples, validate on 270 samples\n",
      "Epoch 1/10\n",
      "1530/1530 [==============================] - 1s 366us/sample - loss: 0.1404 - acc: 0.9294 - val_loss: 0.1569 - val_acc: 0.9370\n",
      "Epoch 2/10\n",
      "1530/1530 [==============================] - 1s 344us/sample - loss: 0.1394 - acc: 0.9405 - val_loss: 0.1624 - val_acc: 0.9407\n",
      "Epoch 3/10\n",
      "1530/1530 [==============================] - 0s 174us/sample - loss: 0.1359 - acc: 0.9373 - val_loss: 0.1663 - val_acc: 0.9185\n",
      "Epoch 4/10\n",
      "1530/1530 [==============================] - 0s 177us/sample - loss: 0.1370 - acc: 0.9386 - val_loss: 0.1623 - val_acc: 0.9333\n",
      "Epoch 5/10\n",
      "1530/1530 [==============================] - 0s 226us/sample - loss: 0.1363 - acc: 0.9379 - val_loss: 0.1617 - val_acc: 0.9296\n",
      "Epoch 6/10\n",
      "1530/1530 [==============================] - 0s 195us/sample - loss: 0.1372 - acc: 0.9346 - val_loss: 0.1708 - val_acc: 0.9296\n",
      "Epoch 7/10\n",
      "1530/1530 [==============================] - 0s 144us/sample - loss: 0.1399 - acc: 0.9405 - val_loss: 0.1714 - val_acc: 0.9333\n",
      "Epoch 8/10\n",
      "1530/1530 [==============================] - 0s 154us/sample - loss: 0.1391 - acc: 0.9373 - val_loss: 0.1661 - val_acc: 0.9333\n",
      "Epoch 9/10\n",
      "1530/1530 [==============================] - 0s 139us/sample - loss: 0.1380 - acc: 0.9379 - val_loss: 0.1761 - val_acc: 0.8889\n",
      "Epoch 10/10\n",
      "1530/1530 [==============================] - 0s 245us/sample - loss: 0.1417 - acc: 0.9359 - val_loss: 0.1654 - val_acc: 0.9407\n",
      "Epoch 139 out of 150\n",
      "Train on 1530 samples, validate on 270 samples\n",
      "Epoch 1/10\n",
      "1530/1530 [==============================] - 0s 311us/sample - loss: 0.1453 - acc: 0.9353 - val_loss: 0.1728 - val_acc: 0.9148\n",
      "Epoch 2/10\n",
      "1530/1530 [==============================] - 1s 345us/sample - loss: 0.1343 - acc: 0.9346 - val_loss: 0.1688 - val_acc: 0.9074\n",
      "Epoch 3/10\n",
      "1530/1530 [==============================] - 1s 360us/sample - loss: 0.1382 - acc: 0.9405 - val_loss: 0.1600 - val_acc: 0.9407\n",
      "Epoch 4/10\n",
      "1530/1530 [==============================] - 0s 276us/sample - loss: 0.1388 - acc: 0.9314 - val_loss: 0.1613 - val_acc: 0.9333\n",
      "Epoch 5/10\n",
      "1530/1530 [==============================] - 0s 145us/sample - loss: 0.1351 - acc: 0.9366 - val_loss: 0.1584 - val_acc: 0.9333\n",
      "Epoch 6/10\n",
      "1530/1530 [==============================] - 0s 147us/sample - loss: 0.1378 - acc: 0.9359 - val_loss: 0.1728 - val_acc: 0.9185\n",
      "Epoch 7/10\n",
      "1530/1530 [==============================] - 0s 137us/sample - loss: 0.1391 - acc: 0.9418 - val_loss: 0.1709 - val_acc: 0.9407\n",
      "Epoch 8/10\n",
      "1530/1530 [==============================] - 0s 135us/sample - loss: 0.1389 - acc: 0.9340 - val_loss: 0.1624 - val_acc: 0.9222\n",
      "Epoch 9/10\n",
      "1530/1530 [==============================] - 0s 138us/sample - loss: 0.1384 - acc: 0.9333 - val_loss: 0.1657 - val_acc: 0.9407\n",
      "Epoch 10/10\n",
      "1530/1530 [==============================] - 0s 143us/sample - loss: 0.1400 - acc: 0.9346 - val_loss: 0.1815 - val_acc: 0.9259\n",
      "Epoch 140 out of 150\n",
      "Train on 1530 samples, validate on 270 samples\n",
      "Epoch 1/10\n",
      "1530/1530 [==============================] - 0s 131us/sample - loss: 0.1370 - acc: 0.9438 - val_loss: 0.1922 - val_acc: 0.8926\n",
      "Epoch 2/10\n",
      "1530/1530 [==============================] - 0s 150us/sample - loss: 0.1497 - acc: 0.9281 - val_loss: 0.1855 - val_acc: 0.9259\n",
      "Epoch 3/10\n",
      "1530/1530 [==============================] - 0s 147us/sample - loss: 0.1420 - acc: 0.9373 - val_loss: 0.1696 - val_acc: 0.9185\n",
      "Epoch 4/10\n",
      "1530/1530 [==============================] - 0s 135us/sample - loss: 0.1416 - acc: 0.9340 - val_loss: 0.1608 - val_acc: 0.9185\n",
      "Epoch 5/10\n",
      "1530/1530 [==============================] - 0s 163us/sample - loss: 0.1360 - acc: 0.9301 - val_loss: 0.1730 - val_acc: 0.9333\n",
      "Epoch 6/10\n",
      "1530/1530 [==============================] - 0s 138us/sample - loss: 0.1382 - acc: 0.9405 - val_loss: 0.1703 - val_acc: 0.9333\n",
      "Epoch 7/10\n",
      "1530/1530 [==============================] - 0s 139us/sample - loss: 0.1390 - acc: 0.9333 - val_loss: 0.1670 - val_acc: 0.9148\n",
      "Epoch 8/10\n",
      "1530/1530 [==============================] - 0s 143us/sample - loss: 0.1376 - acc: 0.9307 - val_loss: 0.1666 - val_acc: 0.9148\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/10\n",
      "1530/1530 [==============================] - 0s 136us/sample - loss: 0.1352 - acc: 0.9451 - val_loss: 0.1631 - val_acc: 0.9259\n",
      "Epoch 10/10\n",
      "1530/1530 [==============================] - 0s 140us/sample - loss: 0.1362 - acc: 0.9431 - val_loss: 0.1605 - val_acc: 0.9222\n",
      "Epoch 141 out of 150\n",
      "Train on 1530 samples, validate on 270 samples\n",
      "Epoch 1/10\n",
      "1530/1530 [==============================] - 0s 168us/sample - loss: 0.1347 - acc: 0.9346 - val_loss: 0.1662 - val_acc: 0.9444\n",
      "Epoch 2/10\n",
      "1530/1530 [==============================] - 0s 146us/sample - loss: 0.1361 - acc: 0.9399 - val_loss: 0.1869 - val_acc: 0.9185\n",
      "Epoch 3/10\n",
      "1530/1530 [==============================] - 0s 152us/sample - loss: 0.1451 - acc: 0.9275 - val_loss: 0.1701 - val_acc: 0.9259\n",
      "Epoch 4/10\n",
      "1530/1530 [==============================] - 0s 171us/sample - loss: 0.1391 - acc: 0.9379 - val_loss: 0.1789 - val_acc: 0.8889\n",
      "Epoch 5/10\n",
      "1530/1530 [==============================] - 0s 153us/sample - loss: 0.1372 - acc: 0.9425 - val_loss: 0.1616 - val_acc: 0.9148\n",
      "Epoch 6/10\n",
      "1530/1530 [==============================] - 0s 308us/sample - loss: 0.1376 - acc: 0.9294 - val_loss: 0.1825 - val_acc: 0.8889\n",
      "Epoch 7/10\n",
      "1530/1530 [==============================] - 1s 458us/sample - loss: 0.1424 - acc: 0.9366 - val_loss: 0.1651 - val_acc: 0.9407\n",
      "Epoch 8/10\n",
      "1530/1530 [==============================] - 1s 468us/sample - loss: 0.1400 - acc: 0.9314 - val_loss: 0.1716 - val_acc: 0.9370\n",
      "Epoch 9/10\n",
      "1530/1530 [==============================] - 1s 336us/sample - loss: 0.1386 - acc: 0.9373 - val_loss: 0.1623 - val_acc: 0.9259\n",
      "Epoch 10/10\n",
      "1530/1530 [==============================] - 1s 364us/sample - loss: 0.1401 - acc: 0.9294 - val_loss: 0.1672 - val_acc: 0.9370\n",
      "Epoch 142 out of 150\n",
      "Train on 1530 samples, validate on 270 samples\n",
      "Epoch 1/10\n",
      "1530/1530 [==============================] - 0s 320us/sample - loss: 0.1387 - acc: 0.9412 - val_loss: 0.1682 - val_acc: 0.9000\n",
      "Epoch 2/10\n",
      "1530/1530 [==============================] - 1s 574us/sample - loss: 0.1362 - acc: 0.9412 - val_loss: 0.1597 - val_acc: 0.9370 loss: 0.1356 - acc: 0.937 - ETA: 0s - loss: 0.1356 - acc: 0.940\n",
      "Epoch 3/10\n",
      "1530/1530 [==============================] - 1s 374us/sample - loss: 0.1364 - acc: 0.9425 - val_loss: 0.1599 - val_acc: 0.9333\n",
      "Epoch 4/10\n",
      "1530/1530 [==============================] - 1s 377us/sample - loss: 0.1367 - acc: 0.9327 - val_loss: 0.1600 - val_acc: 0.9296\n",
      "Epoch 5/10\n",
      "1530/1530 [==============================] - 1s 342us/sample - loss: 0.1355 - acc: 0.9373 - val_loss: 0.1663 - val_acc: 0.8963\n",
      "Epoch 6/10\n",
      "1530/1530 [==============================] - 0s 325us/sample - loss: 0.1387 - acc: 0.9327 - val_loss: 0.1722 - val_acc: 0.9370\n",
      "Epoch 7/10\n",
      "1530/1530 [==============================] - 1s 488us/sample - loss: 0.1363 - acc: 0.9431 - val_loss: 0.1724 - val_acc: 0.9111\n",
      "Epoch 8/10\n",
      "1530/1530 [==============================] - 1s 331us/sample - loss: 0.1419 - acc: 0.9386 - val_loss: 0.1706 - val_acc: 0.9407\n",
      "Epoch 9/10\n",
      "1530/1530 [==============================] - 0s 324us/sample - loss: 0.1353 - acc: 0.9392 - val_loss: 0.1879 - val_acc: 0.9185\n",
      "Epoch 10/10\n",
      "1530/1530 [==============================] - 0s 221us/sample - loss: 0.1388 - acc: 0.9346 - val_loss: 0.1689 - val_acc: 0.9000\n",
      "Epoch 143 out of 150\n",
      "Train on 1530 samples, validate on 270 samples\n",
      "Epoch 1/10\n",
      "1530/1530 [==============================] - 0s 243us/sample - loss: 0.1393 - acc: 0.9327 - val_loss: 0.1641 - val_acc: 0.9333\n",
      "Epoch 2/10\n",
      "1530/1530 [==============================] - 0s 248us/sample - loss: 0.1347 - acc: 0.9379 - val_loss: 0.1723 - val_acc: 0.9407\n",
      "Epoch 3/10\n",
      "1530/1530 [==============================] - 0s 228us/sample - loss: 0.1350 - acc: 0.9438 - val_loss: 0.1663 - val_acc: 0.9333\n",
      "Epoch 4/10\n",
      "1530/1530 [==============================] - 0s 230us/sample - loss: 0.1366 - acc: 0.9373 - val_loss: 0.1593 - val_acc: 0.9444\n",
      "Epoch 5/10\n",
      "1530/1530 [==============================] - 0s 229us/sample - loss: 0.1368 - acc: 0.9431 - val_loss: 0.1664 - val_acc: 0.9148\n",
      "Epoch 6/10\n",
      "1530/1530 [==============================] - 0s 218us/sample - loss: 0.1348 - acc: 0.9392 - val_loss: 0.1691 - val_acc: 0.8926\n",
      "Epoch 7/10\n",
      "1530/1530 [==============================] - 0s 222us/sample - loss: 0.1366 - acc: 0.9353 - val_loss: 0.1683 - val_acc: 0.9407\n",
      "Epoch 8/10\n",
      "1530/1530 [==============================] - 0s 194us/sample - loss: 0.1354 - acc: 0.9418 - val_loss: 0.1660 - val_acc: 0.9444\n",
      "Epoch 9/10\n",
      "1530/1530 [==============================] - 0s 280us/sample - loss: 0.1448 - acc: 0.9275 - val_loss: 0.1995 - val_acc: 0.9148\n",
      "Epoch 10/10\n",
      "1530/1530 [==============================] - 0s 260us/sample - loss: 0.1405 - acc: 0.9379 - val_loss: 0.1627 - val_acc: 0.9370\n",
      "Epoch 144 out of 150\n",
      "Train on 1530 samples, validate on 270 samples\n",
      "Epoch 1/10\n",
      "1530/1530 [==============================] - 0s 216us/sample - loss: 0.1379 - acc: 0.9366 - val_loss: 0.1673 - val_acc: 0.9333\n",
      "Epoch 2/10\n",
      "1530/1530 [==============================] - 0s 237us/sample - loss: 0.1376 - acc: 0.9366 - val_loss: 0.1765 - val_acc: 0.9333\n",
      "Epoch 3/10\n",
      "1530/1530 [==============================] - 0s 280us/sample - loss: 0.1364 - acc: 0.9412 - val_loss: 0.1635 - val_acc: 0.9259\n",
      "Epoch 4/10\n",
      "1530/1530 [==============================] - 0s 228us/sample - loss: 0.1341 - acc: 0.9405 - val_loss: 0.1676 - val_acc: 0.9407\n",
      "Epoch 5/10\n",
      "1530/1530 [==============================] - 0s 191us/sample - loss: 0.1376 - acc: 0.9294 - val_loss: 0.1697 - val_acc: 0.8926\n",
      "Epoch 6/10\n",
      "1530/1530 [==============================] - 1s 387us/sample - loss: 0.1406 - acc: 0.9333 - val_loss: 0.1613 - val_acc: 0.9148\n",
      "Epoch 7/10\n",
      "1530/1530 [==============================] - 0s 321us/sample - loss: 0.1390 - acc: 0.9366 - val_loss: 0.1650 - val_acc: 0.9370\n",
      "Epoch 8/10\n",
      "1530/1530 [==============================] - 0s 263us/sample - loss: 0.1322 - acc: 0.9405 - val_loss: 0.1830 - val_acc: 0.8889\n",
      "Epoch 9/10\n",
      "1530/1530 [==============================] - 0s 262us/sample - loss: 0.1403 - acc: 0.9314 - val_loss: 0.1667 - val_acc: 0.9370\n",
      "Epoch 10/10\n",
      "1530/1530 [==============================] - 0s 298us/sample - loss: 0.1397 - acc: 0.9320 - val_loss: 0.1657 - val_acc: 0.8963\n",
      "Epoch 145 out of 150\n",
      "Train on 1530 samples, validate on 270 samples\n",
      "Epoch 1/10\n",
      "1530/1530 [==============================] - 1s 375us/sample - loss: 0.1348 - acc: 0.9386 - val_loss: 0.1694 - val_acc: 0.9111\n",
      "Epoch 2/10\n",
      "1530/1530 [==============================] - 0s 236us/sample - loss: 0.1361 - acc: 0.9373 - val_loss: 0.1671 - val_acc: 0.9370\n",
      "Epoch 3/10\n",
      "1530/1530 [==============================] - 0s 177us/sample - loss: 0.1360 - acc: 0.9392 - val_loss: 0.1841 - val_acc: 0.8889\n",
      "Epoch 4/10\n",
      "1530/1530 [==============================] - 0s 261us/sample - loss: 0.1345 - acc: 0.9392 - val_loss: 0.1605 - val_acc: 0.9148\n",
      "Epoch 5/10\n",
      "1530/1530 [==============================] - 0s 312us/sample - loss: 0.1369 - acc: 0.9359 - val_loss: 0.1611 - val_acc: 0.9407\n",
      "Epoch 6/10\n",
      "1530/1530 [==============================] - 0s 196us/sample - loss: 0.1373 - acc: 0.9340 - val_loss: 0.1687 - val_acc: 0.9333\n",
      "Epoch 7/10\n",
      "1530/1530 [==============================] - 0s 201us/sample - loss: 0.1353 - acc: 0.9379 - val_loss: 0.1579 - val_acc: 0.9407\n",
      "Epoch 8/10\n",
      "1530/1530 [==============================] - 0s 292us/sample - loss: 0.1345 - acc: 0.9392 - val_loss: 0.1639 - val_acc: 0.9185\n",
      "Epoch 9/10\n",
      "1530/1530 [==============================] - 0s 278us/sample - loss: 0.1339 - acc: 0.9399 - val_loss: 0.1593 - val_acc: 0.9407\n",
      "Epoch 10/10\n",
      "1530/1530 [==============================] - 0s 177us/sample - loss: 0.1344 - acc: 0.9399 - val_loss: 0.1724 - val_acc: 0.9222\n",
      "Epoch 146 out of 150\n",
      "Train on 1530 samples, validate on 270 samples\n",
      "Epoch 1/10\n",
      "1530/1530 [==============================] - 0s 151us/sample - loss: 0.1381 - acc: 0.9340 - val_loss: 0.1632 - val_acc: 0.9222\n",
      "Epoch 2/10\n",
      "1530/1530 [==============================] - 0s 170us/sample - loss: 0.1405 - acc: 0.9379 - val_loss: 0.1862 - val_acc: 0.8852\n",
      "Epoch 3/10\n",
      "1530/1530 [==============================] - 0s 214us/sample - loss: 0.1372 - acc: 0.9412 - val_loss: 0.1583 - val_acc: 0.9370\n",
      "Epoch 4/10\n",
      "1530/1530 [==============================] - 0s 278us/sample - loss: 0.1354 - acc: 0.9359 - val_loss: 0.1627 - val_acc: 0.9259\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/10\n",
      "1530/1530 [==============================] - 0s 282us/sample - loss: 0.1363 - acc: 0.9418 - val_loss: 0.1630 - val_acc: 0.9407\n",
      "Epoch 6/10\n",
      "1530/1530 [==============================] - 0s 272us/sample - loss: 0.1360 - acc: 0.9353 - val_loss: 0.1617 - val_acc: 0.9370\n",
      "Epoch 7/10\n",
      "1530/1530 [==============================] - 1s 390us/sample - loss: 0.1371 - acc: 0.9366 - val_loss: 0.1637 - val_acc: 0.9074\n",
      "Epoch 8/10\n",
      "1530/1530 [==============================] - 1s 727us/sample - loss: 0.1379 - acc: 0.9333 - val_loss: 0.1718 - val_acc: 0.9333\n",
      "Epoch 9/10\n",
      "1530/1530 [==============================] - 1s 338us/sample - loss: 0.1360 - acc: 0.9399 - val_loss: 0.1767 - val_acc: 0.9074\n",
      "Epoch 10/10\n",
      "1530/1530 [==============================] - 0s 210us/sample - loss: 0.1447 - acc: 0.9301 - val_loss: 0.1703 - val_acc: 0.9259\n",
      "Epoch 147 out of 150\n",
      "Train on 1530 samples, validate on 270 samples\n",
      "Epoch 1/10\n",
      "1530/1530 [==============================] - 0s 234us/sample - loss: 0.1358 - acc: 0.9373 - val_loss: 0.1585 - val_acc: 0.9444\n",
      "Epoch 2/10\n",
      "1530/1530 [==============================] - 0s 181us/sample - loss: 0.1479 - acc: 0.9386 - val_loss: 0.1939 - val_acc: 0.9185\n",
      "Epoch 3/10\n",
      "1530/1530 [==============================] - 0s 226us/sample - loss: 0.1421 - acc: 0.9353 - val_loss: 0.1668 - val_acc: 0.9407\n",
      "Epoch 4/10\n",
      "1530/1530 [==============================] - 0s 207us/sample - loss: 0.1350 - acc: 0.9379 - val_loss: 0.1670 - val_acc: 0.9111\n",
      "Epoch 5/10\n",
      "1530/1530 [==============================] - 0s 224us/sample - loss: 0.1363 - acc: 0.9405 - val_loss: 0.1613 - val_acc: 0.9407\n",
      "Epoch 6/10\n",
      "1530/1530 [==============================] - 1s 373us/sample - loss: 0.1376 - acc: 0.9294 - val_loss: 0.1588 - val_acc: 0.9296\n",
      "Epoch 7/10\n",
      "1530/1530 [==============================] - 0s 305us/sample - loss: 0.1331 - acc: 0.9412 - val_loss: 0.1590 - val_acc: 0.9407\n",
      "Epoch 8/10\n",
      "1530/1530 [==============================] - 0s 302us/sample - loss: 0.1346 - acc: 0.9444 - val_loss: 0.1684 - val_acc: 0.9370\n",
      "Epoch 9/10\n",
      "1530/1530 [==============================] - 0s 195us/sample - loss: 0.1356 - acc: 0.9458 - val_loss: 0.1584 - val_acc: 0.9259\n",
      "Epoch 10/10\n",
      "1530/1530 [==============================] - 0s 242us/sample - loss: 0.1411 - acc: 0.9314 - val_loss: 0.1566 - val_acc: 0.9333\n",
      "Epoch 148 out of 150\n",
      "Train on 1530 samples, validate on 270 samples\n",
      "Epoch 1/10\n",
      "1530/1530 [==============================] - 1s 344us/sample - loss: 0.1348 - acc: 0.9379 - val_loss: 0.1627 - val_acc: 0.9148\n",
      "Epoch 2/10\n",
      "1530/1530 [==============================] - 1s 538us/sample - loss: 0.1350 - acc: 0.9333 - val_loss: 0.1631 - val_acc: 0.9222\n",
      "Epoch 3/10\n",
      "1530/1530 [==============================] - 0s 306us/sample - loss: 0.1344 - acc: 0.9353 - val_loss: 0.1638 - val_acc: 0.9074\n",
      "Epoch 4/10\n",
      "1530/1530 [==============================] - 1s 359us/sample - loss: 0.1357 - acc: 0.9399 - val_loss: 0.1735 - val_acc: 0.9333\n",
      "Epoch 5/10\n",
      "1530/1530 [==============================] - 0s 209us/sample - loss: 0.1344 - acc: 0.9392 - val_loss: 0.1565 - val_acc: 0.9370\n",
      "Epoch 6/10\n",
      "1530/1530 [==============================] - 0s 220us/sample - loss: 0.1367 - acc: 0.9359 - val_loss: 0.1631 - val_acc: 0.9333\n",
      "Epoch 7/10\n",
      "1530/1530 [==============================] - 0s 183us/sample - loss: 0.1406 - acc: 0.9359 - val_loss: 0.1864 - val_acc: 0.8889\n",
      "Epoch 8/10\n",
      "1530/1530 [==============================] - 0s 137us/sample - loss: 0.1348 - acc: 0.9418 - val_loss: 0.1615 - val_acc: 0.9185\n",
      "Epoch 9/10\n",
      "1530/1530 [==============================] - 0s 169us/sample - loss: 0.1340 - acc: 0.9418 - val_loss: 0.1617 - val_acc: 0.9148\n",
      "Epoch 10/10\n",
      "1530/1530 [==============================] - 0s 272us/sample - loss: 0.1328 - acc: 0.9353 - val_loss: 0.1635 - val_acc: 0.9259\n",
      "Epoch 149 out of 150\n",
      "Train on 1530 samples, validate on 270 samples\n",
      "Epoch 1/10\n",
      "1530/1530 [==============================] - 0s 146us/sample - loss: 0.1333 - acc: 0.9438 - val_loss: 0.1713 - val_acc: 0.8926\n",
      "Epoch 2/10\n",
      "1530/1530 [==============================] - 0s 207us/sample - loss: 0.1381 - acc: 0.9379 - val_loss: 0.1733 - val_acc: 0.9185\n",
      "Epoch 3/10\n",
      "1530/1530 [==============================] - 0s 149us/sample - loss: 0.1377 - acc: 0.9294 - val_loss: 0.1609 - val_acc: 0.9333\n",
      "Epoch 4/10\n",
      "1530/1530 [==============================] - 0s 190us/sample - loss: 0.1345 - acc: 0.9444 - val_loss: 0.1605 - val_acc: 0.9222\n",
      "Epoch 5/10\n",
      "1530/1530 [==============================] - 0s 179us/sample - loss: 0.1332 - acc: 0.9333 - val_loss: 0.1659 - val_acc: 0.9148\n",
      "Epoch 6/10\n",
      "1530/1530 [==============================] - 0s 146us/sample - loss: 0.1356 - acc: 0.9353 - val_loss: 0.1613 - val_acc: 0.9296\n",
      "Epoch 7/10\n",
      "1530/1530 [==============================] - 0s 138us/sample - loss: 0.1394 - acc: 0.9320 - val_loss: 0.1705 - val_acc: 0.9074\n",
      "Epoch 8/10\n",
      "1530/1530 [==============================] - 0s 135us/sample - loss: 0.1396 - acc: 0.9288 - val_loss: 0.1655 - val_acc: 0.9296\n",
      "Epoch 9/10\n",
      "1530/1530 [==============================] - 0s 142us/sample - loss: 0.1393 - acc: 0.9340 - val_loss: 0.1642 - val_acc: 0.9185\n",
      "Epoch 10/10\n",
      "1530/1530 [==============================] - 0s 190us/sample - loss: 0.1343 - acc: 0.9425 - val_loss: 0.1590 - val_acc: 0.9333\n"
     ]
    }
   ],
   "source": [
    "fit_discriminator(discriminator, Data, 150, lr=0.0005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1800/1800 [==============================] - 0s 99us/sample - loss: 0.1643 - acc: 0.9344\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.16432734880182479, 0.9344444]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TestData = Dataset()\n",
    "TestData.load_data(data_range=15)\n",
    "discriminator.model.evaluate(TestData.x, TestData.y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "Plot('test2').picture(TestData.x, discriminator.model.predict(TestData.x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[  6.25208647,  39.08858529],\n",
       "        [  6.25208647,  -8.30056238],\n",
       "        [  6.25208647,  53.16194665],\n",
       "        ...,\n",
       "        [  8.21697349,  75.31942414],\n",
       "        [  8.21697349,  -8.30596556],\n",
       "        [  8.21697349, -11.68603093]]), array([1, 0, 0, ..., 0, 0, 0]))"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NewData = Dataset()\n",
    "NewData.load_data(data_range=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 156us/sample - loss: 1.3295\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 187us/sample - loss: 1.3120\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 265us/sample - loss: 0.5578 - acc: 0.7812\n",
      "Train on 1152 samples, validate on 288 samples\n",
      "1152/1152 [==============================] - 0s 230us/sample - loss: 0.1279 - acc: 0.9384 - val_loss: 0.1726 - val_acc: 0.9306\n",
      "Epoch 1\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 265us/sample - loss: 1.2143\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 218us/sample - loss: 1.2142\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 249us/sample - loss: 0.6271 - acc: 0.8281\n",
      "Train on 1152 samples, validate on 288 samples\n",
      "1152/1152 [==============================] - 0s 234us/sample - loss: 0.1272 - acc: 0.9444 - val_loss: 0.1715 - val_acc: 0.9306\n",
      "Epoch 2\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 171us/sample - loss: 1.2817\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 234us/sample - loss: 1.2769\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 265us/sample - loss: 0.5810 - acc: 0.8125\n",
      "Train on 1152 samples, validate on 288 samples\n",
      "1152/1152 [==============================] - 0s 409us/sample - loss: 0.1277 - acc: 0.9436 - val_loss: 0.1717 - val_acc: 0.9201\n",
      "Epoch 3\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 265us/sample - loss: 1.2927\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 234us/sample - loss: 1.2724\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 327us/sample - loss: 0.8348 - acc: 0.7500\n",
      "Train on 1152 samples, validate on 288 samples\n",
      "1152/1152 [==============================] - 0s 228us/sample - loss: 0.1265 - acc: 0.9444 - val_loss: 0.1661 - val_acc: 0.9340\n",
      "Epoch 4\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 265us/sample - loss: 1.1522\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 171us/sample - loss: 1.1562\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 187us/sample - loss: 0.6501 - acc: 0.7500\n",
      "Train on 1152 samples, validate on 288 samples\n",
      "1152/1152 [==============================] - 0s 219us/sample - loss: 0.1341 - acc: 0.9349 - val_loss: 0.1589 - val_acc: 0.9375\n",
      "Epoch 5\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 265us/sample - loss: 1.2051\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 218us/sample - loss: 1.1990\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 234us/sample - loss: 0.8384 - acc: 0.7812\n",
      "Train on 1152 samples, validate on 288 samples\n",
      "1152/1152 [==============================] - 0s 227us/sample - loss: 0.1240 - acc: 0.9470 - val_loss: 0.1661 - val_acc: 0.9306\n",
      "Epoch 6\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 171us/sample - loss: 1.2109\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 281us/sample - loss: 1.2008\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 187us/sample - loss: 0.6937 - acc: 0.7656\n",
      "Train on 1152 samples, validate on 288 samples\n",
      "1152/1152 [==============================] - 0s 207us/sample - loss: 0.1232 - acc: 0.9497 - val_loss: 0.1641 - val_acc: 0.9201\n",
      "Epoch 7\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 171us/sample - loss: 1.3265\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 280us/sample - loss: 1.3210\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 171us/sample - loss: 0.7275 - acc: 0.7969\n",
      "Train on 1152 samples, validate on 288 samples\n",
      "1152/1152 [==============================] - 0s 222us/sample - loss: 0.1257 - acc: 0.9392 - val_loss: 0.1775 - val_acc: 0.9132\n",
      "Epoch 8\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 171us/sample - loss: 1.2246\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 187us/sample - loss: 1.2213\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 187us/sample - loss: 0.7816 - acc: 0.7500\n",
      "Train on 1152 samples, validate on 288 samples\n",
      "1152/1152 [==============================] - 0s 222us/sample - loss: 0.1318 - acc: 0.9462 - val_loss: 0.1605 - val_acc: 0.9340\n",
      "Epoch 9\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 250us/sample - loss: 1.1611\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 203us/sample - loss: 1.1472\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 218us/sample - loss: 0.6883 - acc: 0.7031\n",
      "Train on 1152 samples, validate on 288 samples\n",
      "1152/1152 [==============================] - 0s 205us/sample - loss: 0.1234 - acc: 0.9427 - val_loss: 0.1634 - val_acc: 0.9340\n",
      "Epoch 10\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 156us/sample - loss: 1.1764\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 171us/sample - loss: 1.1683\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 296us/sample - loss: 0.7526 - acc: 0.7344\n",
      "Train on 1152 samples, validate on 288 samples\n",
      "1152/1152 [==============================] - 0s 212us/sample - loss: 0.1281 - acc: 0.9427 - val_loss: 0.1574 - val_acc: 0.9375\n",
      "Epoch 11\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 187us/sample - loss: 1.2858\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 265us/sample - loss: 1.2832\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 265us/sample - loss: 0.7455 - acc: 0.7812\n",
      "Train on 1152 samples, validate on 288 samples\n",
      "1152/1152 [==============================] - 0s 235us/sample - loss: 0.1243 - acc: 0.9418 - val_loss: 0.1602 - val_acc: 0.9375\n",
      "Epoch 12\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 187us/sample - loss: 1.4128\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 249us/sample - loss: 1.4026\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 281us/sample - loss: 0.7111 - acc: 0.7812\n",
      "Train on 1152 samples, validate on 288 samples\n",
      "1152/1152 [==============================] - 0s 228us/sample - loss: 0.1259 - acc: 0.9410 - val_loss: 0.1611 - val_acc: 0.9375\n",
      "Epoch 13\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 280us/sample - loss: 1.1718\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 234us/sample - loss: 1.1649\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 390us/sample - loss: 0.6997 - acc: 0.7344\n",
      "Train on 1152 samples, validate on 288 samples\n",
      "1152/1152 [==============================] - 0s 248us/sample - loss: 0.1271 - acc: 0.9410 - val_loss: 0.1604 - val_acc: 0.9375\n",
      "Epoch 14\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 249us/sample - loss: 1.3383\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 249us/sample - loss: 1.3320\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 249us/sample - loss: 0.7648 - acc: 0.7656\n",
      "Train on 1152 samples, validate on 288 samples\n",
      "1152/1152 [==============================] - 0s 228us/sample - loss: 0.1266 - acc: 0.9444 - val_loss: 0.1726 - val_acc: 0.9062\n",
      "Epoch 15\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 171us/sample - loss: 1.3721\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 203us/sample - loss: 1.3674\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 312us/sample - loss: 0.7376 - acc: 0.7656\n",
      "Train on 1152 samples, validate on 288 samples\n",
      "1152/1152 [==============================] - 0s 209us/sample - loss: 0.1316 - acc: 0.9366 - val_loss: 0.1641 - val_acc: 0.9375\n",
      "Epoch 16\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 187us/sample - loss: 1.6956\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 203us/sample - loss: 1.6766\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 312us/sample - loss: 0.6856 - acc: 0.7500\n",
      "Train on 1152 samples, validate on 288 samples\n",
      "1152/1152 [==============================] - ETA: 0s - loss: 0.1241 - acc: 0.947 - 0s 263us/sample - loss: 0.1248 - acc: 0.9462 - val_loss: 0.1610 - val_acc: 0.9340\n",
      "Epoch 17\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 249us/sample - loss: 1.1169\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 327us/sample - loss: 1.1137\n",
      "Fitting discriminator\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64/64 [==============================] - 0s 218us/sample - loss: 1.0005 - acc: 0.6562\n",
      "Train on 1152 samples, validate on 288 samples\n",
      "1152/1152 [==============================] - 0s 231us/sample - loss: 0.1235 - acc: 0.9470 - val_loss: 0.1738 - val_acc: 0.9306\n",
      "Epoch 18\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 203us/sample - loss: 1.4724\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 234us/sample - loss: 1.4592\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 312us/sample - loss: 0.4880 - acc: 0.7969\n",
      "Train on 1152 samples, validate on 288 samples\n",
      "1152/1152 [==============================] - 0s 226us/sample - loss: 0.1248 - acc: 0.9470 - val_loss: 0.1650 - val_acc: 0.9236\n",
      "Epoch 19\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 187us/sample - loss: 1.3930\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 265us/sample - loss: 1.3690\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 265us/sample - loss: 0.5014 - acc: 0.8750\n",
      "Train on 1152 samples, validate on 288 samples\n",
      "1152/1152 [==============================] - 0s 247us/sample - loss: 0.1238 - acc: 0.9444 - val_loss: 0.1694 - val_acc: 0.9306\n",
      "Epoch 20\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 187us/sample - loss: 1.1572\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 218us/sample - loss: 1.1606\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 358us/sample - loss: 0.9347 - acc: 0.7188\n",
      "Train on 1152 samples, validate on 288 samples\n",
      "1152/1152 [==============================] - 0s 241us/sample - loss: 0.1230 - acc: 0.9505 - val_loss: 0.1602 - val_acc: 0.9340\n",
      "Epoch 21\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 203us/sample - loss: 1.2806\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 281us/sample - loss: 1.2734\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 218us/sample - loss: 0.5981 - acc: 0.7812\n",
      "Train on 1152 samples, validate on 288 samples\n",
      "1152/1152 [==============================] - 0s 202us/sample - loss: 0.1245 - acc: 0.9444 - val_loss: 0.1578 - val_acc: 0.9375\n",
      "Epoch 22\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 156us/sample - loss: 1.1352\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 203us/sample - loss: 1.1284\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 312us/sample - loss: 0.8763 - acc: 0.7188\n",
      "Train on 1152 samples, validate on 288 samples\n",
      "1152/1152 [==============================] - 0s 221us/sample - loss: 0.1255 - acc: 0.9444 - val_loss: 0.1591 - val_acc: 0.9375\n",
      "Epoch 23\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 296us/sample - loss: 1.4808\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 296us/sample - loss: 1.4688\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 218us/sample - loss: 0.6744 - acc: 0.7188\n",
      "Train on 1152 samples, validate on 288 samples\n",
      "1152/1152 [==============================] - 0s 194us/sample - loss: 0.1228 - acc: 0.9505 - val_loss: 0.1619 - val_acc: 0.9375\n",
      "Epoch 24\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 218us/sample - loss: 1.2494\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 296us/sample - loss: 1.2502\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 296us/sample - loss: 0.6898 - acc: 0.7188\n",
      "Train on 1152 samples, validate on 288 samples\n",
      "1152/1152 [==============================] - 0s 198us/sample - loss: 0.1230 - acc: 0.9444 - val_loss: 0.1722 - val_acc: 0.9236\n",
      "Epoch 25\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 187us/sample - loss: 1.2561\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 374us/sample - loss: 1.2436\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 249us/sample - loss: 0.5685 - acc: 0.7812\n",
      "Train on 1152 samples, validate on 288 samples\n",
      "1152/1152 [==============================] - 0s 232us/sample - loss: 0.1220 - acc: 0.9497 - val_loss: 0.1609 - val_acc: 0.9375\n",
      "Epoch 26\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - ETA: 0s - loss: 1.297 - 0s 171us/sample - loss: 1.1898\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 156us/sample - loss: 1.1830\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 265us/sample - loss: 0.6198 - acc: 0.7500\n",
      "Train on 1152 samples, validate on 288 samples\n",
      "1152/1152 [==============================] - 0s 209us/sample - loss: 0.1257 - acc: 0.9427 - val_loss: 0.1581 - val_acc: 0.9375\n",
      "Epoch 27\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 187us/sample - loss: 1.2762\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 203us/sample - loss: 1.2785\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 265us/sample - loss: 0.6125 - acc: 0.7969\n",
      "Train on 1152 samples, validate on 288 samples\n",
      "1152/1152 [==============================] - 0s 209us/sample - loss: 0.1244 - acc: 0.9462 - val_loss: 0.1593 - val_acc: 0.9375\n",
      "Epoch 28\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 171us/sample - loss: 1.2312\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 218us/sample - loss: 1.2153\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 280us/sample - loss: 0.6754 - acc: 0.7031\n",
      "Train on 1152 samples, validate on 288 samples\n",
      "1152/1152 [==============================] - 0s 202us/sample - loss: 0.1251 - acc: 0.9427 - val_loss: 0.1578 - val_acc: 0.9375\n",
      "Epoch 29\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 171us/sample - loss: 1.1114\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 265us/sample - loss: 1.1169\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 203us/sample - loss: 0.7932 - acc: 0.7188\n",
      "Train on 1152 samples, validate on 288 samples\n",
      "1152/1152 [==============================] - 0s 222us/sample - loss: 0.1270 - acc: 0.9436 - val_loss: 0.1822 - val_acc: 0.9097\n",
      "Epoch 30\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 171us/sample - loss: 1.2569\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 218us/sample - loss: 1.2448\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 234us/sample - loss: 0.5984 - acc: 0.6719\n",
      "Train on 1152 samples, validate on 288 samples\n",
      "1152/1152 [==============================] - 0s 211us/sample - loss: 0.1272 - acc: 0.9462 - val_loss: 0.1620 - val_acc: 0.9340\n",
      "Epoch 31\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 171us/sample - loss: 1.2565\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 234us/sample - loss: 1.2584\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 234us/sample - loss: 0.5445 - acc: 0.7188\n",
      "Train on 1152 samples, validate on 288 samples\n",
      "1152/1152 [==============================] - 0s 213us/sample - loss: 0.1231 - acc: 0.9436 - val_loss: 0.1634 - val_acc: 0.9375\n",
      "Epoch 32\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 156us/sample - loss: 1.2095\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 265us/sample - loss: 1.2030\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 203us/sample - loss: 0.6166 - acc: 0.7188\n",
      "Train on 1152 samples, validate on 288 samples\n",
      "1152/1152 [==============================] - 0s 218us/sample - loss: 0.1255 - acc: 0.9453 - val_loss: 0.1624 - val_acc: 0.9340\n",
      "Epoch 33\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 218us/sample - loss: 1.2933\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 343us/sample - loss: 1.2874\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 327us/sample - loss: 0.4767 - acc: 0.8438\n",
      "Train on 1152 samples, validate on 288 samples\n",
      "1152/1152 [==============================] - 0s 228us/sample - loss: 0.1239 - acc: 0.9427 - val_loss: 0.1619 - val_acc: 0.9340\n",
      "Epoch 34\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 218us/sample - loss: 1.0787\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 218us/sample - loss: 1.0749\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 234us/sample - loss: 0.9457 - acc: 0.6719\n",
      "Train on 1152 samples, validate on 288 samples\n",
      "1152/1152 [==============================] - 0s 197us/sample - loss: 0.1250 - acc: 0.9453 - val_loss: 0.1627 - val_acc: 0.9306\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 171us/sample - loss: 1.2114\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 156us/sample - loss: 1.2017\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 327us/sample - loss: 0.7589 - acc: 0.7031\n",
      "Train on 1152 samples, validate on 288 samples\n",
      "1152/1152 [==============================] - 0s 197us/sample - loss: 0.1220 - acc: 0.9470 - val_loss: 0.1644 - val_acc: 0.9340\n",
      "Epoch 36\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 234us/sample - loss: 1.2825\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 374us/sample - loss: 1.2783\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 203us/sample - loss: 0.6403 - acc: 0.7031\n",
      "Train on 1152 samples, validate on 288 samples\n",
      "1152/1152 [==============================] - 0s 198us/sample - loss: 0.1218 - acc: 0.9470 - val_loss: 0.1618 - val_acc: 0.9306\n",
      "Epoch 37\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 187us/sample - loss: 1.2977\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 234us/sample - loss: 1.2886\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 249us/sample - loss: 0.8949 - acc: 0.6719\n",
      "Train on 1152 samples, validate on 288 samples\n",
      "1152/1152 [==============================] - 0s 195us/sample - loss: 0.1257 - acc: 0.9470 - val_loss: 0.1591 - val_acc: 0.9375\n",
      "Epoch 38\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 187us/sample - loss: 1.1200\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 218us/sample - loss: 1.1145\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 280us/sample - loss: 0.8312 - acc: 0.7188\n",
      "Train on 1152 samples, validate on 288 samples\n",
      "1152/1152 [==============================] - 0s 203us/sample - loss: 0.1292 - acc: 0.9436 - val_loss: 0.1553 - val_acc: 0.9410\n",
      "Epoch 39\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 203us/sample - loss: 1.1814\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 218us/sample - loss: 1.1726\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 296us/sample - loss: 0.6034 - acc: 0.7500\n",
      "Train on 1152 samples, validate on 288 samples\n",
      "1152/1152 [==============================] - 0s 208us/sample - loss: 0.1270 - acc: 0.9427 - val_loss: 0.1576 - val_acc: 0.9375\n",
      "Epoch 40\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 140us/sample - loss: 1.3842\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 187us/sample - loss: 1.3772\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 249us/sample - loss: 0.6264 - acc: 0.7969\n",
      "Train on 1152 samples, validate on 288 samples\n",
      "1152/1152 [==============================] - 0s 365us/sample - loss: 0.1255 - acc: 0.9462 - val_loss: 0.1645 - val_acc: 0.9375\n",
      "Epoch 41\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 327us/sample - loss: 1.2984\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 327us/sample - loss: 1.2980\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 265us/sample - loss: 0.6599 - acc: 0.7656\n",
      "Train on 1152 samples, validate on 288 samples\n",
      "1152/1152 [==============================] - 0s 266us/sample - loss: 0.1252 - acc: 0.9436 - val_loss: 0.1741 - val_acc: 0.9236\n",
      "Epoch 42\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 187us/sample - loss: 1.1370\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 343us/sample - loss: 1.1311\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 312us/sample - loss: 0.8348 - acc: 0.7031\n",
      "Train on 1152 samples, validate on 288 samples\n",
      "1152/1152 [==============================] - 0s 263us/sample - loss: 0.1275 - acc: 0.9358 - val_loss: 0.1576 - val_acc: 0.9375\n",
      "Epoch 43\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 156us/sample - loss: 1.2606\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 218us/sample - loss: 1.2502\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 296us/sample - loss: 0.5552 - acc: 0.8438\n",
      "Train on 1152 samples, validate on 288 samples\n",
      "1152/1152 [==============================] - 0s 243us/sample - loss: 0.1297 - acc: 0.9384 - val_loss: 0.1616 - val_acc: 0.9340\n",
      "Epoch 44\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 234us/sample - loss: 1.2714\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 265us/sample - loss: 1.2696\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 327us/sample - loss: 0.7163 - acc: 0.7188\n",
      "Train on 1152 samples, validate on 288 samples\n",
      "1152/1152 [==============================] - 0s 255us/sample - loss: 0.1348 - acc: 0.9332 - val_loss: 0.1721 - val_acc: 0.9271\n",
      "Epoch 45\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 265us/sample - loss: 1.2136\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 249us/sample - loss: 1.2121\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 343us/sample - loss: 0.5754 - acc: 0.7656\n",
      "Train on 1152 samples, validate on 288 samples\n",
      "1152/1152 [==============================] - 0s 304us/sample - loss: 0.1251 - acc: 0.9418 - val_loss: 0.1620 - val_acc: 0.9375\n",
      "Epoch 46\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 249us/sample - loss: 1.1750\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 296us/sample - loss: 1.1688\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 359us/sample - loss: 0.6115 - acc: 0.7031\n",
      "Train on 1152 samples, validate on 288 samples\n",
      "1152/1152 [==============================] - 0s 255us/sample - loss: 0.1228 - acc: 0.9462 - val_loss: 0.1670 - val_acc: 0.9340\n",
      "Epoch 47\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 499us/sample - loss: 1.3793\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 296us/sample - loss: 1.3761\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 358us/sample - loss: 0.5397 - acc: 0.8125\n",
      "Train on 1152 samples, validate on 288 samples\n",
      "1152/1152 [==============================] - 0s 289us/sample - loss: 0.1227 - acc: 0.9444 - val_loss: 0.1638 - val_acc: 0.9306\n",
      "Epoch 48\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 405us/sample - loss: 1.2496\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 218us/sample - loss: 1.2448\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 265us/sample - loss: 0.6169 - acc: 0.7969\n",
      "Train on 1152 samples, validate on 288 samples\n",
      "1152/1152 [==============================] - 0s 261us/sample - loss: 0.1245 - acc: 0.9418 - val_loss: 0.1587 - val_acc: 0.9375\n",
      "Epoch 49\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 327us/sample - loss: 1.1767\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 234us/sample - loss: 1.1665\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 281us/sample - loss: 0.7743 - acc: 0.6719\n",
      "Train on 1152 samples, validate on 288 samples\n",
      "1152/1152 [==============================] - 0s 216us/sample - loss: 0.1231 - acc: 0.9505 - val_loss: 0.1573 - val_acc: 0.9375\n",
      "Epoch 50\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 187us/sample - loss: 1.1386\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 171us/sample - loss: 1.1452\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 203us/sample - loss: 0.8653 - acc: 0.6719\n",
      "Train on 1152 samples, validate on 288 samples\n",
      "1152/1152 [==============================] - 0s 250us/sample - loss: 0.1249 - acc: 0.9444 - val_loss: 0.1579 - val_acc: 0.9340\n",
      "Epoch 51\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 218us/sample - loss: 1.2166\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 281us/sample - loss: 1.2186\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 234us/sample - loss: 0.7117 - acc: 0.6875\n",
      "Train on 1152 samples, validate on 288 samples\n",
      "1152/1152 [==============================] - 0s 270us/sample - loss: 0.1254 - acc: 0.9436 - val_loss: 0.1648 - val_acc: 0.9410\n",
      "Epoch 52\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 249us/sample - loss: 1.3947\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 218us/sample - loss: 1.3920\n",
      "Fitting discriminator\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64/64 [==============================] - 0s 265us/sample - loss: 0.6449 - acc: 0.7500\n",
      "Train on 1152 samples, validate on 288 samples\n",
      "1152/1152 [==============================] - 0s 329us/sample - loss: 0.1245 - acc: 0.9453 - val_loss: 0.1577 - val_acc: 0.9375\n",
      "Epoch 53\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 249us/sample - loss: 1.3371\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 265us/sample - loss: 1.3357\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 296us/sample - loss: 0.8078 - acc: 0.7500\n",
      "Train on 1152 samples, validate on 288 samples\n",
      "1152/1152 [==============================] - 0s 255us/sample - loss: 0.1276 - acc: 0.9392 - val_loss: 0.1623 - val_acc: 0.9375\n",
      "Epoch 54\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 218us/sample - loss: 1.2651\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 280us/sample - loss: 1.2530\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 312us/sample - loss: 0.6154 - acc: 0.7500\n",
      "Train on 1152 samples, validate on 288 samples\n",
      "1152/1152 [==============================] - 0s 301us/sample - loss: 0.1209 - acc: 0.9505 - val_loss: 0.1630 - val_acc: 0.9340\n",
      "Epoch 55\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 234us/sample - loss: 1.2746\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 390us/sample - loss: 1.2792\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 296us/sample - loss: 0.5539 - acc: 0.7969\n",
      "Train on 1152 samples, validate on 288 samples\n",
      "1152/1152 [==============================] - 0s 311us/sample - loss: 0.1258 - acc: 0.9453 - val_loss: 0.1572 - val_acc: 0.9410\n",
      "Epoch 56\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 234us/sample - loss: 1.2687\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 327us/sample - loss: 1.2554\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 390us/sample - loss: 0.6717 - acc: 0.7656\n",
      "Train on 1152 samples, validate on 288 samples\n",
      "1152/1152 [==============================] - 0s 322us/sample - loss: 0.1242 - acc: 0.9453 - val_loss: 0.1559 - val_acc: 0.9410\n",
      "Epoch 57\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 296us/sample - loss: 1.1775\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 374us/sample - loss: 1.1794\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 265us/sample - loss: 0.6300 - acc: 0.7031\n",
      "Train on 1152 samples, validate on 288 samples\n",
      "1152/1152 [==============================] - 1s 520us/sample - loss: 0.1225 - acc: 0.9488 - val_loss: 0.1546 - val_acc: 0.9444\n",
      "Epoch 58\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 312us/sample - loss: 1.2621\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 234us/sample - loss: 1.2525\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 327us/sample - loss: 0.6787 - acc: 0.7031\n",
      "Train on 1152 samples, validate on 288 samples\n",
      "1152/1152 [==============================] - 0s 256us/sample - loss: 0.1208 - acc: 0.9444 - val_loss: 0.1559 - val_acc: 0.9340\n",
      "Epoch 59\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 249us/sample - loss: 1.3552\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 327us/sample - loss: 1.3538\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 405us/sample - loss: 0.6989 - acc: 0.7656\n",
      "Train on 1152 samples, validate on 288 samples\n",
      "1152/1152 [==============================] - 0s 286us/sample - loss: 0.1254 - acc: 0.9427 - val_loss: 0.1579 - val_acc: 0.9410\n",
      "Epoch 60\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 203us/sample - loss: 1.2780\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 234us/sample - loss: 1.2726\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 281us/sample - loss: 0.6613 - acc: 0.7188\n",
      "Train on 1152 samples, validate on 288 samples\n",
      "1152/1152 [==============================] - 0s 228us/sample - loss: 0.1256 - acc: 0.9401 - val_loss: 0.1603 - val_acc: 0.9340\n",
      "Epoch 61\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 187us/sample - loss: 1.1951\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 265us/sample - loss: 1.1959\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 234us/sample - loss: 0.6404 - acc: 0.7500\n",
      "Train on 1152 samples, validate on 288 samples\n",
      "1152/1152 [==============================] - 0s 224us/sample - loss: 0.1265 - acc: 0.9427 - val_loss: 0.1599 - val_acc: 0.9410\n",
      "Epoch 62\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 249us/sample - loss: 1.2026\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 218us/sample - loss: 1.2000\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 218us/sample - loss: 0.6852 - acc: 0.7188\n",
      "Train on 1152 samples, validate on 288 samples\n",
      "1152/1152 [==============================] - 0s 267us/sample - loss: 0.1226 - acc: 0.9488 - val_loss: 0.1587 - val_acc: 0.9340\n",
      "Epoch 63\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 358us/sample - loss: 1.2110\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 281us/sample - loss: 1.2088\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 280us/sample - loss: 0.6990 - acc: 0.7656\n",
      "Train on 1152 samples, validate on 288 samples\n",
      "1152/1152 [==============================] - 1s 441us/sample - loss: 0.1232 - acc: 0.9479 - val_loss: 0.1591 - val_acc: 0.9340\n",
      "Epoch 64\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 202us/sample - loss: 1.2401\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 234us/sample - loss: 1.2374\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 249us/sample - loss: 0.7165 - acc: 0.6875\n",
      "Train on 1152 samples, validate on 288 samples\n",
      "1152/1152 [==============================] - 0s 212us/sample - loss: 0.1239 - acc: 0.9479 - val_loss: 0.1613 - val_acc: 0.9340\n",
      "Epoch 65\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 171us/sample - loss: 0.9488\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 280us/sample - loss: 0.9471\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 265us/sample - loss: 0.9731 - acc: 0.5625\n",
      "Train on 1152 samples, validate on 288 samples\n",
      "1152/1152 [==============================] - 0s 226us/sample - loss: 0.1242 - acc: 0.9453 - val_loss: 0.1589 - val_acc: 0.9375\n",
      "Epoch 66\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 218us/sample - loss: 1.3474\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 296us/sample - loss: 1.3437\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 421us/sample - loss: 0.4522 - acc: 0.8750\n",
      "Train on 1152 samples, validate on 288 samples\n",
      "1152/1152 [==============================] - 0s 303us/sample - loss: 0.1244 - acc: 0.9470 - val_loss: 0.1566 - val_acc: 0.9340\n",
      "Epoch 67\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 171us/sample - loss: 1.2784\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 249us/sample - loss: 1.2696\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 312us/sample - loss: 0.7484 - acc: 0.6406\n",
      "Train on 1152 samples, validate on 288 samples\n",
      "1152/1152 [==============================] - 0s 203us/sample - loss: 0.1232 - acc: 0.9488 - val_loss: 0.1577 - val_acc: 0.9340\n",
      "Epoch 68\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 249us/sample - loss: 1.2206\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 281us/sample - loss: 1.2215\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 280us/sample - loss: 0.6514 - acc: 0.7344\n",
      "Train on 1152 samples, validate on 288 samples\n",
      "1152/1152 [==============================] - 0s 210us/sample - loss: 0.1219 - acc: 0.9418 - val_loss: 0.1572 - val_acc: 0.9340\n",
      "Epoch 69\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 187us/sample - loss: 1.4648\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 234us/sample - loss: 1.4605\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 171us/sample - loss: 0.8094 - acc: 0.7500\n",
      "Train on 1152 samples, validate on 288 samples\n",
      "1152/1152 [==============================] - 0s 209us/sample - loss: 0.1279 - acc: 0.9436 - val_loss: 0.1610 - val_acc: 0.9306\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 70\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 156us/sample - loss: 1.3258\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 234us/sample - loss: 1.3135\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 249us/sample - loss: 0.7095 - acc: 0.7969\n",
      "Train on 1152 samples, validate on 288 samples\n",
      "1152/1152 [==============================] - 0s 198us/sample - loss: 0.1251 - acc: 0.9418 - val_loss: 0.1746 - val_acc: 0.9097\n",
      "Epoch 71\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 249us/sample - loss: 1.3461\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 280us/sample - loss: 1.3463\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 249us/sample - loss: 0.6643 - acc: 0.7344\n",
      "Train on 1152 samples, validate on 288 samples\n",
      "1152/1152 [==============================] - 0s 186us/sample - loss: 0.1221 - acc: 0.9470 - val_loss: 0.1848 - val_acc: 0.9062\n",
      "Epoch 72\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 156us/sample - loss: 1.2084\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 234us/sample - loss: 1.2004\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 389us/sample - loss: 0.6640 - acc: 0.7969\n",
      "Train on 1152 samples, validate on 288 samples\n",
      "1152/1152 [==============================] - 0s 190us/sample - loss: 0.1400 - acc: 0.9349 - val_loss: 0.1556 - val_acc: 0.9340\n",
      "Epoch 73\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 187us/sample - loss: 1.1429\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 327us/sample - loss: 1.1440\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 452us/sample - loss: 0.7005 - acc: 0.6719\n",
      "Train on 1152 samples, validate on 288 samples\n",
      "1152/1152 [==============================] - 0s 255us/sample - loss: 0.1211 - acc: 0.9497 - val_loss: 0.1636 - val_acc: 0.9271\n",
      "Epoch 74\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 218us/sample - loss: 1.0841\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 296us/sample - loss: 1.0759\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 265us/sample - loss: 0.7436 - acc: 0.6875\n",
      "Train on 1152 samples, validate on 288 samples\n",
      "1152/1152 [==============================] - 0s 188us/sample - loss: 0.1247 - acc: 0.9453 - val_loss: 0.1549 - val_acc: 0.9375\n",
      "Epoch 75\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 203us/sample - loss: 1.2706\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 323us/sample - loss: 1.2670\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 374us/sample - loss: 0.6615 - acc: 0.7500\n",
      "Train on 1152 samples, validate on 288 samples\n",
      "1152/1152 [==============================] - 0s 203us/sample - loss: 0.1228 - acc: 0.9444 - val_loss: 0.1627 - val_acc: 0.9306\n",
      "Epoch 76\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 249us/sample - loss: 1.2933\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 265us/sample - loss: 1.2878\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 343us/sample - loss: 0.5559 - acc: 0.7500\n",
      "Train on 1152 samples, validate on 288 samples\n",
      "1152/1152 [==============================] - 0s 192us/sample - loss: 0.1241 - acc: 0.9427 - val_loss: 0.1636 - val_acc: 0.9306\n",
      "Epoch 77\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 156us/sample - loss: 1.2080\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 203us/sample - loss: 1.2060\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 312us/sample - loss: 0.6082 - acc: 0.7344\n",
      "Train on 1152 samples, validate on 288 samples\n",
      "1152/1152 [==============================] - 0s 188us/sample - loss: 0.1260 - acc: 0.9384 - val_loss: 0.1599 - val_acc: 0.9340\n",
      "Epoch 78\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 203us/sample - loss: 1.3696\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 172us/sample - loss: 1.3627\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 249us/sample - loss: 0.8086 - acc: 0.7656\n",
      "Train on 1152 samples, validate on 288 samples\n",
      "1152/1152 [==============================] - 0s 197us/sample - loss: 0.1254 - acc: 0.9444 - val_loss: 0.1594 - val_acc: 0.9340\n",
      "Epoch 79\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 187us/sample - loss: 1.2146\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 218us/sample - loss: 1.2120\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - ETA: 0s - loss: 0.4727 - acc: 0.750 - 0s 280us/sample - loss: 0.5583 - acc: 0.7812\n",
      "Train on 1152 samples, validate on 288 samples\n",
      "1152/1152 [==============================] - 0s 222us/sample - loss: 0.1228 - acc: 0.9436 - val_loss: 0.1741 - val_acc: 0.9201\n",
      "Epoch 80\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 187us/sample - loss: 1.3967\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 281us/sample - loss: 1.3955\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 358us/sample - loss: 0.7676 - acc: 0.7344\n",
      "Train on 1152 samples, validate on 288 samples\n",
      "1152/1152 [==============================] - 0s 228us/sample - loss: 0.1208 - acc: 0.9531 - val_loss: 0.1578 - val_acc: 0.9375\n",
      "Epoch 81\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 203us/sample - loss: 1.3162\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 234us/sample - loss: 1.3122\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 312us/sample - loss: 0.4726 - acc: 0.8594\n",
      "Train on 1152 samples, validate on 288 samples\n",
      "1152/1152 [==============================] - 0s 377us/sample - loss: 0.1240 - acc: 0.9401 - val_loss: 0.1589 - val_acc: 0.9340\n",
      "Epoch 82\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 187us/sample - loss: 1.3773\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 249us/sample - loss: 1.3733\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 358us/sample - loss: 0.5742 - acc: 0.7656\n",
      "Train on 1152 samples, validate on 288 samples\n",
      "1152/1152 [==============================] - 0s 293us/sample - loss: 0.1304 - acc: 0.9384 - val_loss: 0.1744 - val_acc: 0.9271\n",
      "Epoch 83\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 234us/sample - loss: 1.0631\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 187us/sample - loss: 1.0592\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 265us/sample - loss: 0.9423 - acc: 0.5781\n",
      "Train on 1152 samples, validate on 288 samples\n",
      "1152/1152 [==============================] - 0s 236us/sample - loss: 0.1229 - acc: 0.9470 - val_loss: 0.1656 - val_acc: 0.9340\n",
      "Epoch 84\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 171us/sample - loss: 1.3659\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 218us/sample - loss: 1.3623\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 296us/sample - loss: 0.5820 - acc: 0.8281\n",
      "Train on 1152 samples, validate on 288 samples\n",
      "1152/1152 [==============================] - 0s 215us/sample - loss: 0.1237 - acc: 0.9436 - val_loss: 0.1631 - val_acc: 0.9167\n",
      "Epoch 85\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 171us/sample - loss: 1.2612\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 203us/sample - loss: 1.2568\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 218us/sample - loss: 0.6560 - acc: 0.7344\n",
      "Train on 1152 samples, validate on 288 samples\n",
      "1152/1152 [==============================] - 0s 244us/sample - loss: 0.1220 - acc: 0.9470 - val_loss: 0.1601 - val_acc: 0.9306\n",
      "Epoch 86\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 187us/sample - loss: 1.2823\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 171us/sample - loss: 1.2764\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 249us/sample - loss: 0.7167 - acc: 0.7188\n",
      "Train on 1152 samples, validate on 288 samples\n",
      "1152/1152 [==============================] - 0s 206us/sample - loss: 0.1239 - acc: 0.9401 - val_loss: 0.1587 - val_acc: 0.9306\n",
      "Epoch 87\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 218us/sample - loss: 1.2868\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 249us/sample - loss: 1.2836\n",
      "Fitting discriminator\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64/64 [==============================] - 0s 436us/sample - loss: 0.5121 - acc: 0.7500\n",
      "Train on 1152 samples, validate on 288 samples\n",
      "1152/1152 [==============================] - 0s 318us/sample - loss: 0.1211 - acc: 0.9427 - val_loss: 0.1695 - val_acc: 0.9132\n",
      "Epoch 88\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 250us/sample - loss: 1.0808\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 327us/sample - loss: 1.0786\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 437us/sample - loss: 0.8163 - acc: 0.6875\n",
      "Train on 1152 samples, validate on 288 samples\n",
      "1152/1152 [==============================] - 0s 335us/sample - loss: 0.1244 - acc: 0.9375 - val_loss: 0.1558 - val_acc: 0.9375\n",
      "Epoch 89\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 374us/sample - loss: 1.4350\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 280us/sample - loss: 1.3991\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 374us/sample - loss: 0.6219 - acc: 0.7812\n",
      "Train on 1152 samples, validate on 288 samples\n",
      "1152/1152 [==============================] - 0s 273us/sample - loss: 0.1212 - acc: 0.9479 - val_loss: 0.1591 - val_acc: 0.9340\n",
      "Epoch 90\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 171us/sample - loss: 1.3294\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 296us/sample - loss: 1.3292\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 358us/sample - loss: 0.6355 - acc: 0.6719\n",
      "Train on 1152 samples, validate on 288 samples\n",
      "1152/1152 [==============================] - 0s 351us/sample - loss: 0.1248 - acc: 0.9401 - val_loss: 0.1686 - val_acc: 0.9306\n",
      "Epoch 91\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 281us/sample - loss: 1.0766\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 327us/sample - loss: 1.0754\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 374us/sample - loss: 1.0044 - acc: 0.6250\n",
      "Train on 1152 samples, validate on 288 samples\n",
      "1152/1152 [==============================] - 0s 284us/sample - loss: 0.1272 - acc: 0.9453 - val_loss: 0.1612 - val_acc: 0.9306\n",
      "Epoch 92\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 281us/sample - loss: 1.5349\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 374us/sample - loss: 1.5220\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 327us/sample - loss: 0.4637 - acc: 0.8125\n",
      "Train on 1152 samples, validate on 288 samples\n",
      "1152/1152 [==============================] - 0s 248us/sample - loss: 0.1317 - acc: 0.9418 - val_loss: 0.1557 - val_acc: 0.9306\n",
      "Epoch 93\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 249us/sample - loss: 1.3645\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 249us/sample - loss: 1.3519\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 265us/sample - loss: 0.6193 - acc: 0.7656\n",
      "Train on 1152 samples, validate on 288 samples\n",
      "1152/1152 [==============================] - 0s 202us/sample - loss: 0.1225 - acc: 0.9418 - val_loss: 0.1582 - val_acc: 0.9340\n",
      "Epoch 94\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 187us/sample - loss: 1.3348\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 296us/sample - loss: 1.3461\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 343us/sample - loss: 0.5759 - acc: 0.7344\n",
      "Train on 1152 samples, validate on 288 samples\n",
      "1152/1152 [==============================] - ETA: 0s - loss: 0.1201 - acc: 0.946 - 0s 261us/sample - loss: 0.1208 - acc: 0.9453 - val_loss: 0.1564 - val_acc: 0.9340\n",
      "Epoch 95\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 327us/sample - loss: 1.3699\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 436us/sample - loss: 1.3456\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 468us/sample - loss: 0.7196 - acc: 0.7031\n",
      "Train on 1152 samples, validate on 288 samples\n",
      "1152/1152 [==============================] - 0s 376us/sample - loss: 0.1274 - acc: 0.9436 - val_loss: 0.1532 - val_acc: 0.9375\n",
      "Epoch 96\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 249us/sample - loss: 1.1709\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 265us/sample - loss: 1.1795\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 358us/sample - loss: 0.6843 - acc: 0.6875\n",
      "Train on 1152 samples, validate on 288 samples\n",
      "1152/1152 [==============================] - 0s 272us/sample - loss: 0.1190 - acc: 0.9488 - val_loss: 0.1614 - val_acc: 0.9375\n",
      "Epoch 97\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 218us/sample - loss: 1.2669\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 312us/sample - loss: 1.2606\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 265us/sample - loss: 0.6917 - acc: 0.7188\n",
      "Train on 1152 samples, validate on 288 samples\n",
      "1152/1152 [==============================] - 0s 268us/sample - loss: 0.1200 - acc: 0.9436 - val_loss: 0.1602 - val_acc: 0.9271\n",
      "Epoch 98\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 218us/sample - loss: 1.6264\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 234us/sample - loss: 1.5970\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 265us/sample - loss: 0.4914 - acc: 0.8750\n",
      "Train on 1152 samples, validate on 288 samples\n",
      "1152/1152 [==============================] - 0s 249us/sample - loss: 0.1223 - acc: 0.9462 - val_loss: 0.1630 - val_acc: 0.9340\n",
      "Epoch 99\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 249us/sample - loss: 1.2151\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 265us/sample - loss: 1.2159\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 327us/sample - loss: 0.5759 - acc: 0.8125\n",
      "Train on 1152 samples, validate on 288 samples\n",
      "1152/1152 [==============================] - 0s 285us/sample - loss: 0.1206 - acc: 0.9401 - val_loss: 0.1529 - val_acc: 0.9410\n",
      "Epoch 100\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 203us/sample - loss: 1.3037\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 234us/sample - loss: 1.2988\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 218us/sample - loss: 0.7669 - acc: 0.7188\n",
      "Train on 1152 samples, validate on 288 samples\n",
      "1152/1152 [==============================] - 0s 236us/sample - loss: 0.1217 - acc: 0.9444 - val_loss: 0.1536 - val_acc: 0.9375\n",
      "Epoch 101\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 187us/sample - loss: 1.2862\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 203us/sample - loss: 1.2736\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 358us/sample - loss: 0.5486 - acc: 0.7969\n",
      "Train on 1152 samples, validate on 288 samples\n",
      "1152/1152 [==============================] - 0s 258us/sample - loss: 0.1249 - acc: 0.9375 - val_loss: 0.1534 - val_acc: 0.9375\n",
      "Epoch 102\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 203us/sample - loss: 1.2544\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 218us/sample - loss: 1.2486\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 203us/sample - loss: 0.5535 - acc: 0.7344\n",
      "Train on 1152 samples, validate on 288 samples\n",
      "1152/1152 [==============================] - 0s 246us/sample - loss: 0.1251 - acc: 0.9366 - val_loss: 0.1603 - val_acc: 0.9201\n",
      "Epoch 103\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 218us/sample - loss: 1.2982\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 171us/sample - loss: 1.2952\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 281us/sample - loss: 0.8646 - acc: 0.6562\n",
      "Train on 1152 samples, validate on 288 samples\n",
      "1152/1152 [==============================] - 0s 231us/sample - loss: 0.1228 - acc: 0.9418 - val_loss: 0.1633 - val_acc: 0.9306\n",
      "Epoch 104\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 249us/sample - loss: 1.2362\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 312us/sample - loss: 1.2245\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 253us/sample - loss: 0.6342 - acc: 0.7188\n",
      "Train on 1152 samples, validate on 288 samples\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1152/1152 [==============================] - 0s 226us/sample - loss: 0.1240 - acc: 0.9384 - val_loss: 0.1644 - val_acc: 0.9271\n",
      "Epoch 105\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 249us/sample - loss: 1.2501\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 297us/sample - loss: 1.2454\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 280us/sample - loss: 0.7337 - acc: 0.7031\n",
      "Train on 1152 samples, validate on 288 samples\n",
      "1152/1152 [==============================] - 0s 229us/sample - loss: 0.1234 - acc: 0.9436 - val_loss: 0.1559 - val_acc: 0.9340\n",
      "Epoch 106\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 203us/sample - loss: 1.2279\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 249us/sample - loss: 1.2252\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 296us/sample - loss: 0.5954 - acc: 0.8281\n",
      "Train on 1152 samples, validate on 288 samples\n",
      "1152/1152 [==============================] - 0s 212us/sample - loss: 0.1212 - acc: 0.9418 - val_loss: 0.1600 - val_acc: 0.9201\n",
      "Epoch 107\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 405us/sample - loss: 1.2949\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 343us/sample - loss: 1.2854\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 358us/sample - loss: 0.6512 - acc: 0.7656\n",
      "Train on 1152 samples, validate on 288 samples\n",
      "1152/1152 [==============================] - 0s 195us/sample - loss: 0.1256 - acc: 0.9453 - val_loss: 0.1541 - val_acc: 0.9340\n",
      "Epoch 108\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 218us/sample - loss: 1.1838\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 234us/sample - loss: 1.1814\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 327us/sample - loss: 0.6318 - acc: 0.6719\n",
      "Train on 1152 samples, validate on 288 samples\n",
      "1152/1152 [==============================] - 0s 200us/sample - loss: 0.1215 - acc: 0.9436 - val_loss: 0.1558 - val_acc: 0.9375\n",
      "Epoch 109\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 218us/sample - loss: 1.3475\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 218us/sample - loss: 1.3388\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 296us/sample - loss: 0.6317 - acc: 0.8125\n",
      "Train on 1152 samples, validate on 288 samples\n",
      "1152/1152 [==============================] - 0s 240us/sample - loss: 0.1218 - acc: 0.9479 - val_loss: 0.1547 - val_acc: 0.9375\n",
      "Epoch 110\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 156us/sample - loss: 1.2922\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 218us/sample - loss: 1.2866\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 280us/sample - loss: 0.5682 - acc: 0.7656\n",
      "Train on 1152 samples, validate on 288 samples\n",
      "1152/1152 [==============================] - 0s 198us/sample - loss: 0.1174 - acc: 0.9488 - val_loss: 0.1589 - val_acc: 0.9132\n",
      "Epoch 111\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 203us/sample - loss: 1.3887\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 312us/sample - loss: 1.3843\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 265us/sample - loss: 0.5163 - acc: 0.7656\n",
      "Train on 1152 samples, validate on 288 samples\n",
      "1152/1152 [==============================] - 0s 197us/sample - loss: 0.1233 - acc: 0.9401 - val_loss: 0.1585 - val_acc: 0.9306\n",
      "Epoch 112\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 171us/sample - loss: 1.0563\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 266us/sample - loss: 1.0537\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 358us/sample - loss: 0.6899 - acc: 0.7188\n",
      "Train on 1152 samples, validate on 288 samples\n",
      "1152/1152 [==============================] - 0s 188us/sample - loss: 0.1228 - acc: 0.9418 - val_loss: 0.1605 - val_acc: 0.9340\n",
      "Epoch 113\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 187us/sample - loss: 1.2064\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 343us/sample - loss: 1.2049\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 218us/sample - loss: 0.7086 - acc: 0.7656\n",
      "Train on 1152 samples, validate on 288 samples\n",
      "1152/1152 [==============================] - 0s 222us/sample - loss: 0.1232 - acc: 0.9427 - val_loss: 0.1564 - val_acc: 0.9340\n",
      "Epoch 114\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 187us/sample - loss: 1.2144\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 171us/sample - loss: 1.2081\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 281us/sample - loss: 0.8055 - acc: 0.7031\n",
      "Train on 1152 samples, validate on 288 samples\n",
      "1152/1152 [==============================] - 0s 204us/sample - loss: 0.1228 - acc: 0.9436 - val_loss: 0.1600 - val_acc: 0.9340\n",
      "Epoch 115\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 187us/sample - loss: 1.1846\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 234us/sample - loss: 1.1827\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 362us/sample - loss: 0.6832 - acc: 0.7344\n",
      "Train on 1152 samples, validate on 288 samples\n",
      "1152/1152 [==============================] - 0s 223us/sample - loss: 0.1224 - acc: 0.9418 - val_loss: 0.1557 - val_acc: 0.9375\n",
      "Epoch 116\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 171us/sample - loss: 1.4776\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 234us/sample - loss: 1.4770\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 280us/sample - loss: 0.6124 - acc: 0.7812\n",
      "Train on 1152 samples, validate on 288 samples\n",
      "1152/1152 [==============================] - 0s 210us/sample - loss: 0.1229 - acc: 0.9436 - val_loss: 0.1618 - val_acc: 0.9340\n",
      "Epoch 117\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 156us/sample - loss: 1.3404\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 203us/sample - loss: 1.3363\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 187us/sample - loss: 0.6011 - acc: 0.7656\n",
      "Train on 1152 samples, validate on 288 samples\n",
      "1152/1152 [==============================] - 0s 187us/sample - loss: 0.1242 - acc: 0.9444 - val_loss: 0.1563 - val_acc: 0.9306\n",
      "Epoch 118\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 265us/sample - loss: 1.3664\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 234us/sample - loss: 1.3648\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 171us/sample - loss: 0.6606 - acc: 0.7969\n",
      "Train on 1152 samples, validate on 288 samples\n",
      "1152/1152 [==============================] - 0s 208us/sample - loss: 0.1227 - acc: 0.9444 - val_loss: 0.1527 - val_acc: 0.9340\n",
      "Epoch 119\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 156us/sample - loss: 1.2907\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 249us/sample - loss: 1.2828\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 218us/sample - loss: 0.6877 - acc: 0.7812\n",
      "Train on 1152 samples, validate on 288 samples\n",
      "1152/1152 [==============================] - 0s 206us/sample - loss: 0.1255 - acc: 0.9392 - val_loss: 0.1704 - val_acc: 0.9271\n",
      "Epoch 120\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 171us/sample - loss: 1.2984\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 187us/sample - loss: 1.2957\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 249us/sample - loss: 0.5818 - acc: 0.8125\n",
      "Train on 1152 samples, validate on 288 samples\n",
      "1152/1152 [==============================] - 0s 195us/sample - loss: 0.1266 - acc: 0.9401 - val_loss: 0.1604 - val_acc: 0.9340\n",
      "Epoch 121\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 203us/sample - loss: 1.2341\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 171us/sample - loss: 1.2353\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 374us/sample - loss: 0.6171 - acc: 0.7969\n",
      "Train on 1152 samples, validate on 288 samples\n",
      "1152/1152 [==============================] - 0s 206us/sample - loss: 0.1219 - acc: 0.9410 - val_loss: 0.1644 - val_acc: 0.9201\n",
      "Epoch 122\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 171us/sample - loss: 1.2210\n",
      "Epoch 2/2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64/64 [==============================] - 0s 156us/sample - loss: 1.2019\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 265us/sample - loss: 0.6813 - acc: 0.7500\n",
      "Train on 1152 samples, validate on 288 samples\n",
      "1152/1152 [==============================] - 0s 196us/sample - loss: 0.1226 - acc: 0.9436 - val_loss: 0.1570 - val_acc: 0.9410\n",
      "Epoch 123\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 218us/sample - loss: 1.4985\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 265us/sample - loss: 1.4818\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 390us/sample - loss: 0.5607 - acc: 0.7344\n",
      "Train on 1152 samples, validate on 288 samples\n",
      "1152/1152 [==============================] - 0s 209us/sample - loss: 0.1208 - acc: 0.9427 - val_loss: 0.1533 - val_acc: 0.9375\n",
      "Epoch 124\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 234us/sample - loss: 1.2199\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 296us/sample - loss: 1.2223\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 265us/sample - loss: 0.6864 - acc: 0.7188\n",
      "Train on 1152 samples, validate on 288 samples\n",
      "1152/1152 [==============================] - 0s 192us/sample - loss: 0.1263 - acc: 0.9401 - val_loss: 0.1771 - val_acc: 0.9097\n",
      "Epoch 125\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 265us/sample - loss: 1.0812\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 296us/sample - loss: 1.0739\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 358us/sample - loss: 0.7074 - acc: 0.6875\n",
      "Train on 1152 samples, validate on 288 samples\n",
      "1152/1152 [==============================] - 0s 190us/sample - loss: 0.1279 - acc: 0.9384 - val_loss: 0.1691 - val_acc: 0.9306\n",
      "Epoch 126\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 280us/sample - loss: 1.2767\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 265us/sample - loss: 1.2596\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 312us/sample - loss: 0.6228 - acc: 0.7656\n",
      "Train on 1152 samples, validate on 288 samples\n",
      "1152/1152 [==============================] - 0s 210us/sample - loss: 0.1266 - acc: 0.9410 - val_loss: 0.1553 - val_acc: 0.9375\n",
      "Epoch 127\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 265us/sample - loss: 1.1542\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 281us/sample - loss: 1.1506\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 327us/sample - loss: 0.6846 - acc: 0.7656\n",
      "Train on 1152 samples, validate on 288 samples\n",
      "1152/1152 [==============================] - 0s 246us/sample - loss: 0.1276 - acc: 0.9384 - val_loss: 0.1708 - val_acc: 0.9306\n",
      "Epoch 128\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 265us/sample - loss: 1.2157\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 265us/sample - loss: 1.2115\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 281us/sample - loss: 0.6347 - acc: 0.6719\n",
      "Train on 1152 samples, validate on 288 samples\n",
      "1152/1152 [==============================] - 0s 235us/sample - loss: 0.1238 - acc: 0.9375 - val_loss: 0.1550 - val_acc: 0.9375\n",
      "Epoch 129\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 203us/sample - loss: 1.4023\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 265us/sample - loss: 1.4002\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 296us/sample - loss: 0.4770 - acc: 0.8125\n",
      "Train on 1152 samples, validate on 288 samples\n",
      "1152/1152 [==============================] - 0s 242us/sample - loss: 0.1213 - acc: 0.9462 - val_loss: 0.1572 - val_acc: 0.9410\n",
      "Epoch 130\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 187us/sample - loss: 1.2997\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 249us/sample - loss: 1.2979\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 343us/sample - loss: 0.6850 - acc: 0.7188\n",
      "Train on 1152 samples, validate on 288 samples\n",
      "1152/1152 [==============================] - 0s 253us/sample - loss: 0.1225 - acc: 0.9427 - val_loss: 0.1627 - val_acc: 0.9340\n",
      "Epoch 131\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 203us/sample - loss: 1.3649\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 280us/sample - loss: 1.3603\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 358us/sample - loss: 0.5251 - acc: 0.8281\n",
      "Train on 1152 samples, validate on 288 samples\n",
      "1152/1152 [==============================] - 0s 242us/sample - loss: 0.1265 - acc: 0.9366 - val_loss: 0.1694 - val_acc: 0.9132\n",
      "Epoch 132\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 234us/sample - loss: 1.1702\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 234us/sample - loss: 1.1657\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 234us/sample - loss: 0.6393 - acc: 0.7344\n",
      "Train on 1152 samples, validate on 288 samples\n",
      "1152/1152 [==============================] - 0s 286us/sample - loss: 0.1185 - acc: 0.9427 - val_loss: 0.1600 - val_acc: 0.9271\n",
      "Epoch 133\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 203us/sample - loss: 1.2448\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 249us/sample - loss: 1.2441\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 281us/sample - loss: 0.7408 - acc: 0.6875\n",
      "Train on 1152 samples, validate on 288 samples\n",
      "1152/1152 [==============================] - 0s 246us/sample - loss: 0.1200 - acc: 0.9462 - val_loss: 0.1607 - val_acc: 0.9340\n",
      "Epoch 134\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 218us/sample - loss: 1.4049\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 203us/sample - loss: 1.3960\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 296us/sample - loss: 0.5293 - acc: 0.8125\n",
      "Train on 1152 samples, validate on 288 samples\n",
      "1152/1152 [==============================] - 0s 263us/sample - loss: 0.1222 - acc: 0.9470 - val_loss: 0.1573 - val_acc: 0.9375\n",
      "Epoch 135\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 203us/sample - loss: 1.2024\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 280us/sample - loss: 1.1990\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 234us/sample - loss: 0.8126 - acc: 0.7656\n",
      "Train on 1152 samples, validate on 288 samples\n",
      "1152/1152 [==============================] - 0s 229us/sample - loss: 0.1198 - acc: 0.9453 - val_loss: 0.1578 - val_acc: 0.9340\n",
      "Epoch 136\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 249us/sample - loss: 1.0865\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 265us/sample - loss: 1.0840\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 234us/sample - loss: 0.7125 - acc: 0.6875\n",
      "Train on 1152 samples, validate on 288 samples\n",
      "1152/1152 [==============================] - 0s 226us/sample - loss: 0.1237 - acc: 0.9392 - val_loss: 0.1589 - val_acc: 0.9306\n",
      "Epoch 137\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 234us/sample - loss: 1.3269\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 218us/sample - loss: 1.3217\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 234us/sample - loss: 0.5023 - acc: 0.8125\n",
      "Train on 1152 samples, validate on 288 samples\n",
      "1152/1152 [==============================] - 0s 229us/sample - loss: 0.1202 - acc: 0.9410 - val_loss: 0.1597 - val_acc: 0.9306\n",
      "Epoch 138\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 249us/sample - loss: 1.2885\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 218us/sample - loss: 1.2888\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 234us/sample - loss: 0.6578 - acc: 0.7656\n",
      "Train on 1152 samples, validate on 288 samples\n",
      "1152/1152 [==============================] - 0s 246us/sample - loss: 0.1251 - acc: 0.9418 - val_loss: 0.1532 - val_acc: 0.9375\n",
      "Epoch 139\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 343us/sample - loss: 1.1800\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 187us/sample - loss: 1.1776\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 265us/sample - loss: 0.6969 - acc: 0.7031\n",
      "Train on 1152 samples, validate on 288 samples\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1152/1152 [==============================] - 0s 245us/sample - loss: 0.1234 - acc: 0.9427 - val_loss: 0.1574 - val_acc: 0.9375\n",
      "Epoch 140\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 203us/sample - loss: 1.3537\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 343us/sample - loss: 1.3498\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 358us/sample - loss: 0.6303 - acc: 0.7500\n",
      "Train on 1152 samples, validate on 288 samples\n",
      "1152/1152 [==============================] - 0s 235us/sample - loss: 0.1191 - acc: 0.9427 - val_loss: 0.1577 - val_acc: 0.9375\n",
      "Epoch 141\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 249us/sample - loss: 1.2825\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 249us/sample - loss: 1.2759\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 374us/sample - loss: 0.6554 - acc: 0.7188\n",
      "Train on 1152 samples, validate on 288 samples\n",
      "1152/1152 [==============================] - 0s 216us/sample - loss: 0.1239 - acc: 0.9401 - val_loss: 0.1557 - val_acc: 0.9375\n",
      "Epoch 142\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 296us/sample - loss: 1.1174\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 296us/sample - loss: 1.1113\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 374us/sample - loss: 0.6921 - acc: 0.7500\n",
      "Train on 1152 samples, validate on 288 samples\n",
      "1152/1152 [==============================] - 0s 260us/sample - loss: 0.1236 - acc: 0.9366 - val_loss: 0.1541 - val_acc: 0.9375\n",
      "Epoch 143\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 296us/sample - loss: 1.2585\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 280us/sample - loss: 1.2521\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 343us/sample - loss: 0.7633 - acc: 0.7500\n",
      "Train on 1152 samples, validate on 288 samples\n",
      "1152/1152 [==============================] - 0s 240us/sample - loss: 0.1208 - acc: 0.9479 - val_loss: 0.1545 - val_acc: 0.9375\n",
      "Epoch 144\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 187us/sample - loss: 1.4189\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 265us/sample - loss: 1.4078\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 281us/sample - loss: 0.5072 - acc: 0.7656\n",
      "Train on 1152 samples, validate on 288 samples\n",
      "1152/1152 [==============================] - 0s 195us/sample - loss: 0.1214 - acc: 0.9436 - val_loss: 0.1597 - val_acc: 0.9340\n",
      "Epoch 145\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 218us/sample - loss: 1.3302\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 296us/sample - loss: 1.3302\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 249us/sample - loss: 0.5472 - acc: 0.7344\n",
      "Train on 1152 samples, validate on 288 samples\n",
      "1152/1152 [==============================] - 0s 192us/sample - loss: 0.1192 - acc: 0.9453 - val_loss: 0.1566 - val_acc: 0.9375\n",
      "Epoch 146\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 187us/sample - loss: 1.5354\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 312us/sample - loss: 1.5304\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 296us/sample - loss: 0.5064 - acc: 0.7969\n",
      "Train on 1152 samples, validate on 288 samples\n",
      "1152/1152 [==============================] - 0s 206us/sample - loss: 0.1232 - acc: 0.9375 - val_loss: 0.1544 - val_acc: 0.9340\n",
      "Epoch 147\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 249us/sample - loss: 1.2961\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 296us/sample - loss: 1.2906\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 218us/sample - loss: 0.5481 - acc: 0.8125\n",
      "Train on 1152 samples, validate on 288 samples\n",
      "1152/1152 [==============================] - 0s 191us/sample - loss: 0.1221 - acc: 0.9453 - val_loss: 0.1527 - val_acc: 0.9375\n",
      "Epoch 148\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 171us/sample - loss: 1.3608\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 218us/sample - loss: 1.3327\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 312us/sample - loss: 0.5435 - acc: 0.7656\n",
      "Train on 1152 samples, validate on 288 samples\n",
      "1152/1152 [==============================] - 0s 200us/sample - loss: 0.1272 - acc: 0.9384 - val_loss: 0.1557 - val_acc: 0.9340\n",
      "Epoch 149\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 203us/sample - loss: 1.2000\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 234us/sample - loss: 1.2057\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 202us/sample - loss: 0.6438 - acc: 0.7656\n",
      "Train on 1152 samples, validate on 288 samples\n",
      "1152/1152 [==============================] - 0s 189us/sample - loss: 0.1189 - acc: 0.9453 - val_loss: 0.1518 - val_acc: 0.9410\n",
      "Epoch 150\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 187us/sample - loss: 1.4216\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 203us/sample - loss: 1.3996\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 187us/sample - loss: 0.5195 - acc: 0.8281\n",
      "Train on 1152 samples, validate on 288 samples\n",
      "1152/1152 [==============================] - ETA: 0s - loss: 0.1166 - acc: 0.947 - 0s 203us/sample - loss: 0.1235 - acc: 0.9401 - val_loss: 0.1635 - val_acc: 0.9306\n",
      "Epoch 151\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 171us/sample - loss: 1.3989\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 249us/sample - loss: 1.4047\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 187us/sample - loss: 0.5328 - acc: 0.7344\n",
      "Train on 1152 samples, validate on 288 samples\n",
      "1152/1152 [==============================] - 0s 203us/sample - loss: 0.1258 - acc: 0.9358 - val_loss: 0.1629 - val_acc: 0.9236\n",
      "Epoch 152\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 171us/sample - loss: 1.1268\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 203us/sample - loss: 1.1209\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 218us/sample - loss: 0.6777 - acc: 0.6562\n",
      "Train on 1152 samples, validate on 288 samples\n",
      "1152/1152 [==============================] - 0s 222us/sample - loss: 0.1363 - acc: 0.9332 - val_loss: 0.1585 - val_acc: 0.9201\n",
      "Epoch 153\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 249us/sample - loss: 1.3160\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 265us/sample - loss: 1.3157\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 296us/sample - loss: 0.6137 - acc: 0.6875\n",
      "Train on 1152 samples, validate on 288 samples\n",
      "1152/1152 [==============================] - 0s 227us/sample - loss: 0.1166 - acc: 0.9470 - val_loss: 0.1582 - val_acc: 0.9375\n",
      "Epoch 154\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 156us/sample - loss: 1.0996\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 187us/sample - loss: 1.0954\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 187us/sample - loss: 0.7432 - acc: 0.6875\n",
      "Train on 1152 samples, validate on 288 samples\n",
      "1152/1152 [==============================] - 0s 205us/sample - loss: 0.1188 - acc: 0.9444 - val_loss: 0.1616 - val_acc: 0.9340\n",
      "Epoch 155\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 187us/sample - loss: 1.4080\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 234us/sample - loss: 1.3989\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 218us/sample - loss: 0.5829 - acc: 0.7812\n",
      "Train on 1152 samples, validate on 288 samples\n",
      "1152/1152 [==============================] - 0s 208us/sample - loss: 0.1216 - acc: 0.9410 - val_loss: 0.1606 - val_acc: 0.9340\n",
      "Epoch 156\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 156us/sample - loss: 1.0275\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 171us/sample - loss: 1.0184\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 171us/sample - loss: 0.9122 - acc: 0.6094\n",
      "Train on 1152 samples, validate on 288 samples\n",
      "1152/1152 [==============================] - 0s 208us/sample - loss: 0.1220 - acc: 0.9436 - val_loss: 0.1525 - val_acc: 0.9375\n",
      "Epoch 157\n",
      "Fitting GAN\n",
      "Epoch 1/2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64/64 [==============================] - 0s 156us/sample - loss: 1.4252\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 171us/sample - loss: 1.4207\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 265us/sample - loss: 0.4051 - acc: 0.8438\n",
      "Train on 1152 samples, validate on 288 samples\n",
      "1152/1152 [==============================] - 0s 198us/sample - loss: 0.1205 - acc: 0.9444 - val_loss: 0.1549 - val_acc: 0.9375\n",
      "Epoch 158\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 187us/sample - loss: 1.3673\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 234us/sample - loss: 1.3599\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 281us/sample - loss: 0.6653 - acc: 0.7344\n",
      "Train on 1152 samples, validate on 288 samples\n",
      "1152/1152 [==============================] - 0s 196us/sample - loss: 0.1188 - acc: 0.9470 - val_loss: 0.1537 - val_acc: 0.9375\n",
      "Epoch 159\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 171us/sample - loss: 1.2654\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 202us/sample - loss: 1.2624\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 249us/sample - loss: 0.6004 - acc: 0.7500\n",
      "Train on 1152 samples, validate on 288 samples\n",
      "1152/1152 [==============================] - 0s 199us/sample - loss: 0.1253 - acc: 0.9392 - val_loss: 0.1643 - val_acc: 0.9271\n",
      "Epoch 160\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 171us/sample - loss: 1.2171\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 265us/sample - loss: 1.2178\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 296us/sample - loss: 0.6380 - acc: 0.7656\n",
      "Train on 1152 samples, validate on 288 samples\n",
      "1152/1152 [==============================] - 0s 197us/sample - loss: 0.1281 - acc: 0.9418 - val_loss: 0.1569 - val_acc: 0.9375\n",
      "Epoch 161\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 203us/sample - loss: 1.1655\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 218us/sample - loss: 1.1565\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 281us/sample - loss: 0.7649 - acc: 0.6094\n",
      "Train on 1152 samples, validate on 288 samples\n",
      "1152/1152 [==============================] - 0s 194us/sample - loss: 0.1185 - acc: 0.9470 - val_loss: 0.1552 - val_acc: 0.9375\n",
      "Epoch 162\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 265us/sample - loss: 1.0740\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 203us/sample - loss: 1.0649\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 218us/sample - loss: 0.8633 - acc: 0.6875\n",
      "Train on 1152 samples, validate on 288 samples\n",
      "1152/1152 [==============================] - 0s 187us/sample - loss: 0.1197 - acc: 0.9444 - val_loss: 0.1539 - val_acc: 0.9375\n",
      "Epoch 163\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 241us/sample - loss: 1.1775\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 296us/sample - loss: 1.1708\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 452us/sample - loss: 0.7171 - acc: 0.7344\n",
      "Train on 1152 samples, validate on 288 samples\n",
      "1152/1152 [==============================] - 0s 240us/sample - loss: 0.1192 - acc: 0.9505 - val_loss: 0.1617 - val_acc: 0.9340\n",
      "Epoch 164\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 218us/sample - loss: 1.2503\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 203us/sample - loss: 1.2491\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 218us/sample - loss: 0.6925 - acc: 0.7344\n",
      "Train on 1152 samples, validate on 288 samples\n",
      "1152/1152 [==============================] - 0s 340us/sample - loss: 0.1192 - acc: 0.9462 - val_loss: 0.1573 - val_acc: 0.9340\n",
      "Epoch 165\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 172us/sample - loss: 1.2266\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 296us/sample - loss: 1.2242\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 327us/sample - loss: 0.7000 - acc: 0.7188\n",
      "Train on 1152 samples, validate on 288 samples\n",
      "1152/1152 [==============================] - 0s 206us/sample - loss: 0.1220 - acc: 0.9384 - val_loss: 0.1542 - val_acc: 0.9410\n",
      "Epoch 166\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 187us/sample - loss: 1.1627\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 249us/sample - loss: 1.1600\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 249us/sample - loss: 0.8228 - acc: 0.6562\n",
      "Train on 1152 samples, validate on 288 samples\n",
      "1152/1152 [==============================] - 0s 215us/sample - loss: 0.1242 - acc: 0.9427 - val_loss: 0.1614 - val_acc: 0.9375\n",
      "Epoch 167\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 249us/sample - loss: 1.4901\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 374us/sample - loss: 1.4850\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 327us/sample - loss: 0.6580 - acc: 0.7500\n",
      "Train on 1152 samples, validate on 288 samples\n",
      "1152/1152 [==============================] - 0s 209us/sample - loss: 0.1195 - acc: 0.9479 - val_loss: 0.1545 - val_acc: 0.9340\n",
      "Epoch 168\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 187us/sample - loss: 1.3148\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 203us/sample - loss: 1.3118\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 296us/sample - loss: 0.4710 - acc: 0.8438\n",
      "Train on 1152 samples, validate on 288 samples\n",
      "1152/1152 [==============================] - 0s 216us/sample - loss: 0.1198 - acc: 0.9436 - val_loss: 0.1598 - val_acc: 0.9306\n",
      "Epoch 169\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 156us/sample - loss: 1.1546\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 203us/sample - loss: 1.1459\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 203us/sample - loss: 0.6583 - acc: 0.7188\n",
      "Train on 1152 samples, validate on 288 samples\n",
      "1152/1152 [==============================] - 0s 219us/sample - loss: 0.1228 - acc: 0.9418 - val_loss: 0.1568 - val_acc: 0.9340\n",
      "Epoch 170\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 187us/sample - loss: 1.2281\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 171us/sample - loss: 1.2278\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 203us/sample - loss: 0.7066 - acc: 0.7344\n",
      "Train on 1152 samples, validate on 288 samples\n",
      "1152/1152 [==============================] - 0s 228us/sample - loss: 0.1206 - acc: 0.9462 - val_loss: 0.1579 - val_acc: 0.9340\n",
      "Epoch 171\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 156us/sample - loss: 1.2169\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 405us/sample - loss: 1.2129\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 203us/sample - loss: 0.6594 - acc: 0.7031\n",
      "Train on 1152 samples, validate on 288 samples\n",
      "1152/1152 [==============================] - 0s 217us/sample - loss: 0.1178 - acc: 0.9497 - val_loss: 0.1560 - val_acc: 0.9340\n",
      "Epoch 172\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 171us/sample - loss: 1.2741\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 249us/sample - loss: 1.2601\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 203us/sample - loss: 0.5780 - acc: 0.8281\n",
      "Train on 1152 samples, validate on 288 samples\n",
      "1152/1152 [==============================] - 0s 211us/sample - loss: 0.1246 - acc: 0.9384 - val_loss: 0.1671 - val_acc: 0.9132\n",
      "Epoch 173\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 203us/sample - loss: 1.1953\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 312us/sample - loss: 1.1932\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 280us/sample - loss: 0.6230 - acc: 0.7656\n",
      "Train on 1152 samples, validate on 288 samples\n",
      "1152/1152 [==============================] - 0s 221us/sample - loss: 0.1205 - acc: 0.9462 - val_loss: 0.1623 - val_acc: 0.9236\n",
      "Epoch 174\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 187us/sample - loss: 1.3531\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 249us/sample - loss: 1.3473\n",
      "Fitting discriminator\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64/64 [==============================] - 0s 218us/sample - loss: 0.5246 - acc: 0.7969\n",
      "Train on 1152 samples, validate on 288 samples\n",
      "1152/1152 [==============================] - 0s 190us/sample - loss: 0.1254 - acc: 0.9418 - val_loss: 0.1571 - val_acc: 0.9375\n",
      "Epoch 175\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 249us/sample - loss: 0.9999\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 265us/sample - loss: 0.9947\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 249us/sample - loss: 0.8033 - acc: 0.7188\n",
      "Train on 1152 samples, validate on 288 samples\n",
      "1152/1152 [==============================] - 0s 195us/sample - loss: 0.1247 - acc: 0.9410 - val_loss: 0.1609 - val_acc: 0.9306\n",
      "Epoch 176\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 171us/sample - loss: 1.2052\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 218us/sample - loss: 1.2060\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 281us/sample - loss: 0.7026 - acc: 0.7500\n",
      "Train on 1152 samples, validate on 288 samples\n",
      "1152/1152 [==============================] - 0s 197us/sample - loss: 0.1197 - acc: 0.9479 - val_loss: 0.1648 - val_acc: 0.9306\n",
      "Epoch 177\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 218us/sample - loss: 1.1986\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 249us/sample - loss: 1.1913\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 296us/sample - loss: 0.7997 - acc: 0.7031\n",
      "Train on 1152 samples, validate on 288 samples\n",
      "1152/1152 [==============================] - 0s 189us/sample - loss: 0.1189 - acc: 0.9470 - val_loss: 0.1565 - val_acc: 0.9375\n",
      "Epoch 178\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 156us/sample - loss: 1.1684\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 234us/sample - loss: 1.1671\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 265us/sample - loss: 0.8395 - acc: 0.6875\n",
      "Train on 1152 samples, validate on 288 samples\n",
      "1152/1152 [==============================] - 0s 191us/sample - loss: 0.1186 - acc: 0.9436 - val_loss: 0.1553 - val_acc: 0.9340\n",
      "Epoch 179\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 187us/sample - loss: 1.3210\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 265us/sample - loss: 1.3146\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 312us/sample - loss: 0.5849 - acc: 0.7500\n",
      "Train on 1152 samples, validate on 288 samples\n",
      "1152/1152 [==============================] - 0s 199us/sample - loss: 0.1223 - acc: 0.9436 - val_loss: 0.1665 - val_acc: 0.9306\n",
      "Epoch 180\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 171us/sample - loss: 1.1855\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 218us/sample - loss: 1.1855\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 249us/sample - loss: 0.5815 - acc: 0.7500\n",
      "Train on 1152 samples, validate on 288 samples\n",
      "1152/1152 [==============================] - 0s 195us/sample - loss: 0.1226 - acc: 0.9436 - val_loss: 0.1580 - val_acc: 0.9375\n",
      "Epoch 181\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 203us/sample - loss: 1.3390\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 203us/sample - loss: 1.3349\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 234us/sample - loss: 0.5857 - acc: 0.8281\n",
      "Train on 1152 samples, validate on 288 samples\n",
      "1152/1152 [==============================] - 0s 190us/sample - loss: 0.1240 - acc: 0.9375 - val_loss: 0.1525 - val_acc: 0.9271\n",
      "Epoch 182\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 140us/sample - loss: 1.1979\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 203us/sample - loss: 1.1861\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 281us/sample - loss: 0.6407 - acc: 0.7500\n",
      "Train on 1152 samples, validate on 288 samples\n",
      "1152/1152 [==============================] - 0s 204us/sample - loss: 0.1250 - acc: 0.9375 - val_loss: 0.1520 - val_acc: 0.9375\n",
      "Epoch 183\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 218us/sample - loss: 1.1078\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 296us/sample - loss: 1.1071\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 343us/sample - loss: 0.9161 - acc: 0.5938\n",
      "Train on 1152 samples, validate on 288 samples\n",
      "1152/1152 [==============================] - 0s 261us/sample - loss: 0.1214 - acc: 0.9462 - val_loss: 0.1560 - val_acc: 0.9271\n",
      "Epoch 184\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 234us/sample - loss: 1.2457\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 249us/sample - loss: 1.2473\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 281us/sample - loss: 0.6162 - acc: 0.6875\n",
      "Train on 1152 samples, validate on 288 samples\n",
      "1152/1152 [==============================] - 0s 242us/sample - loss: 0.1203 - acc: 0.9470 - val_loss: 0.1552 - val_acc: 0.9375\n",
      "Epoch 185\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 203us/sample - loss: 1.1248\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 187us/sample - loss: 1.1173\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 280us/sample - loss: 0.7856 - acc: 0.7188\n",
      "Train on 1152 samples, validate on 288 samples\n",
      "1152/1152 [==============================] - 0s 257us/sample - loss: 0.1209 - acc: 0.9401 - val_loss: 0.1523 - val_acc: 0.9375\n",
      "Epoch 186\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 202us/sample - loss: 1.1948\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 280us/sample - loss: 1.1875\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 249us/sample - loss: 0.7213 - acc: 0.7188\n",
      "Train on 1152 samples, validate on 288 samples\n",
      "1152/1152 [==============================] - 0s 234us/sample - loss: 0.1215 - acc: 0.9436 - val_loss: 0.1831 - val_acc: 0.9097\n",
      "Epoch 187\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 187us/sample - loss: 1.3600\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 265us/sample - loss: 1.3590\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 218us/sample - loss: 0.5340 - acc: 0.8125\n",
      "Train on 1152 samples, validate on 288 samples\n",
      "1152/1152 [==============================] - 0s 241us/sample - loss: 0.1390 - acc: 0.9358 - val_loss: 0.1581 - val_acc: 0.9271\n",
      "Epoch 188\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 203us/sample - loss: 1.2285\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 250us/sample - loss: 1.2234\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 405us/sample - loss: 0.5378 - acc: 0.7031\n",
      "Train on 1152 samples, validate on 288 samples\n",
      "1152/1152 [==============================] - 0s 247us/sample - loss: 0.1194 - acc: 0.9453 - val_loss: 0.1552 - val_acc: 0.9340\n",
      "Epoch 189\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 187us/sample - loss: 1.1620\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 187us/sample - loss: 1.1593\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 249us/sample - loss: 0.6465 - acc: 0.7500\n",
      "Train on 1152 samples, validate on 288 samples\n",
      "1152/1152 [==============================] - 0s 203us/sample - loss: 0.1203 - acc: 0.9462 - val_loss: 0.1541 - val_acc: 0.9340\n",
      "Epoch 190\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 156us/sample - loss: 1.1658\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 171us/sample - loss: 1.1615\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 234us/sample - loss: 0.7775 - acc: 0.7188\n",
      "Train on 1152 samples, validate on 288 samples\n",
      "1152/1152 [==============================] - 0s 210us/sample - loss: 0.1270 - acc: 0.9375 - val_loss: 0.1557 - val_acc: 0.9410\n",
      "Epoch 191\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 171us/sample - loss: 1.0556\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 171us/sample - loss: 1.0512\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 218us/sample - loss: 0.8251 - acc: 0.6875\n",
      "Train on 1152 samples, validate on 288 samples\n",
      "1152/1152 [==============================] - 0s 205us/sample - loss: 0.1214 - acc: 0.9462 - val_loss: 0.1575 - val_acc: 0.9340\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 192\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 171us/sample - loss: 1.3220\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 218us/sample - loss: 1.2834\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 327us/sample - loss: 0.5312 - acc: 0.7656\n",
      "Train on 1152 samples, validate on 288 samples\n",
      "1152/1152 [==============================] - 0s 198us/sample - loss: 0.1251 - acc: 0.9392 - val_loss: 0.1558 - val_acc: 0.9375\n",
      "Epoch 193\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 203us/sample - loss: 1.4200\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 296us/sample - loss: 1.4250\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 499us/sample - loss: 0.7227 - acc: 0.7344\n",
      "Train on 1152 samples, validate on 288 samples\n",
      "1152/1152 [==============================] - 0s 242us/sample - loss: 0.1202 - acc: 0.9453 - val_loss: 0.1561 - val_acc: 0.9375\n",
      "Epoch 194\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 193us/sample - loss: 1.2507\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 249us/sample - loss: 1.2372\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 280us/sample - loss: 0.5241 - acc: 0.7812\n",
      "Train on 1152 samples, validate on 288 samples\n",
      "1152/1152 [==============================] - 0s 198us/sample - loss: 0.1214 - acc: 0.9410 - val_loss: 0.1549 - val_acc: 0.9340\n",
      "Epoch 195\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 203us/sample - loss: 1.2388\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 280us/sample - loss: 1.2295\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 312us/sample - loss: 0.5456 - acc: 0.7500\n",
      "Train on 1152 samples, validate on 288 samples\n",
      "1152/1152 [==============================] - 0s 203us/sample - loss: 0.1275 - acc: 0.9358 - val_loss: 0.1605 - val_acc: 0.9201\n",
      "Epoch 196\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 234us/sample - loss: 1.2727\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 280us/sample - loss: 1.2642\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 265us/sample - loss: 0.6167 - acc: 0.7188\n",
      "Train on 1152 samples, validate on 288 samples\n",
      "1152/1152 [==============================] - 0s 203us/sample - loss: 0.1225 - acc: 0.9444 - val_loss: 0.1584 - val_acc: 0.9340\n",
      "Epoch 197\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 234us/sample - loss: 1.2488\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 296us/sample - loss: 1.2509\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 280us/sample - loss: 0.7114 - acc: 0.7344\n",
      "Train on 1152 samples, validate on 288 samples\n",
      "1152/1152 [==============================] - 0s 196us/sample - loss: 0.1212 - acc: 0.9410 - val_loss: 0.1634 - val_acc: 0.9306\n",
      "Epoch 198\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 171us/sample - loss: 1.2871\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 171us/sample - loss: 1.2720\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 281us/sample - loss: 0.6285 - acc: 0.7344\n",
      "Train on 1152 samples, validate on 288 samples\n",
      "1152/1152 [==============================] - 0s 224us/sample - loss: 0.1295 - acc: 0.9358 - val_loss: 0.1569 - val_acc: 0.9306\n",
      "Epoch 199\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 156us/sample - loss: 1.1580\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - ETA: 0s - loss: 1.223 - 0s 249us/sample - loss: 1.1544\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 234us/sample - loss: 0.7878 - acc: 0.7344\n",
      "Train on 1152 samples, validate on 288 samples\n",
      "1152/1152 [==============================] - 0s 211us/sample - loss: 0.1256 - acc: 0.9392 - val_loss: 0.1837 - val_acc: 0.9097\n"
     ]
    }
   ],
   "source": [
    "#gan = define_gan(generator.model, discriminator.model)\n",
    "fit_gan(gan, NewData, 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "N = 128\n",
    "V = generator.predict(TestData.load_random(n_samples=N))\n",
    "Plot('test').picture(V, discriminator.model.predict(V), alpha=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
