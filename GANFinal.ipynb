{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import imageio\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.layers import Dense, Input, Dropout\n",
    "from tensorflow.keras.models import Sequential, Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Misc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# todo: apply to classes\n",
    "def make_trainable(net, val, lr=0.001):\n",
    "    net.model.trainable = val\n",
    "    for l in net.model.layers:\n",
    "        l.trainable = val\n",
    "    net.cmpile(lr)\n",
    "    \n",
    "def define_gan(generator, discriminator):\n",
    "    # make weights in the discriminator not trainable\n",
    "    discriminator.trainable = False\n",
    "    # connect them\n",
    "    model = Sequential()\n",
    "    # add generator\n",
    "    model.add(generator)\n",
    "    # add the discriminator\n",
    "    model.add(discriminator)\n",
    "    # при замене оптимизатора всё слетает ???\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam')\n",
    "    return model\n",
    "\n",
    "def fit_discriminator(discriminator, Data, epochs, lr=0.001):\n",
    "    make_trainable(discriminator, True, lr=lr)\n",
    "    #discriminator.trainable = True\n",
    "    discriminator.fit(Data.x, Data.y, epochs=epochs, plot=True)\n",
    "    \n",
    "# Training GAN\n",
    "def fit_gan(gan, Data, epochs):\n",
    "    p = Plot('GAN_results')\n",
    "\n",
    "    for i in range(epochs):\n",
    "        V = Data.load_random(n_samples=64)\n",
    "        print(\"Epoch %d\" % i)\n",
    "        generated = generator.predict(V)\n",
    "        if i % 10 == 0:\n",
    "            p.add_to_gif(generated, np.ones(V.shape[0]), title='Epoch %d' % i, alpha=1)\n",
    "        #make_trainable(discriminator, False)\n",
    "        print(\"Fitting GAN\")\n",
    "        gan.fit(V, np.ones(V.shape[0]), epochs=2)\n",
    "        #make_trainable(discriminator, True)\n",
    "        print(\"Fitting discriminator\")\n",
    "        discriminator.fit(generated, np.zeros(V.shape[0]), validation_split=None)\n",
    "        discriminator.fit(Data.x, Data.y, validation_split=0.2)\n",
    "    p.save_gif()\n",
    "    gan.save('gan.h5')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data generation class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To generate data\n",
    "class Dataset():\n",
    "    x = None\n",
    "    y = None\n",
    "    W = None\n",
    "    \n",
    "    def __init__(self):\n",
    "        return\n",
    "    \n",
    "    def load_data(self, data_range=10):\n",
    "        dots_x = []\n",
    "        for i in range(data_range*20):\n",
    "            x = random.uniform(-data_range, data_range)\n",
    "            dots_x.append((x, x**2)) # square\n",
    "            for j in range(5):\n",
    "                dots_x.append((x, random.uniform(-data_range, data_range**2))) # less than square\n",
    "                #dots_x.append((x**r, x**(2*r*(1+random.gauss(0.5, 0.25)/20)))) # more than square\n",
    "        dots_x = np.array(dots_x)\n",
    "        #dots_y = np.array([random.uniform(0.75, 1.2) if x[0]**2 == x[1] else random.uniform(0, 0.3) for x in dots_x])\n",
    "        dots_y = np.array([1 if x[0]**2 == x[1] else 0 for x in dots_x])\n",
    "        self.x, self.y = dots_x, dots_y\n",
    "        return dots_x, dots_y\n",
    "    \n",
    "    def load_weights(self, default_weight=0.12):\n",
    "        W = self.y.copy().astype(float)\n",
    "        W[W == 0] = 0.12\n",
    "        self.W = W\n",
    "        return W\n",
    "        \n",
    "    @staticmethod\n",
    "    def load_random(n_dim=5, n_samples=16):\n",
    "        V = np.random.normal(size=(n_samples, n_dim))\n",
    "        return V\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image plotting class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To plot images\n",
    "class Plot:\n",
    "    name = \"\"\n",
    "    images = []\n",
    "    threshold = 0.0\n",
    "    \n",
    "    def __init__(self, name, threshold=0.6):\n",
    "        self.name = name\n",
    "        self.threshold = threshold\n",
    "        self.images = []\n",
    "    \n",
    "    @staticmethod\n",
    "    def parabola_plot(ax, xrange):\n",
    "        x = np.linspace(xrange, 1)\n",
    "        y = x*x\n",
    "        plt.plot(x, y)\n",
    "    \n",
    "    @staticmethod\n",
    "    def dots_plot(ax, dots_x, dots_y, color):\n",
    "        ax.scatter(dots_x, dots_y, color=color, alpha=0.15)\n",
    "        plt.plot()\n",
    "    \n",
    "    def picture(self, dots, predictions, title='', alpha=0.3):\n",
    "        predictions = predictions.reshape(predictions.shape[0])\n",
    "        dots_x = dots.T[0]\n",
    "        fig = plt.figure()\n",
    "        ax1 = fig.add_subplot(111)\n",
    "        ax1.set(title=title)\n",
    "        #ax2 = ax1.twinx()\n",
    "        plt.grid(axis='both')\n",
    "        xrange = (dots_x.min()*1.1, dots_x.max()*1.1)\n",
    "        self.parabola_plot(ax1, xrange)\n",
    "        ax1.scatter(dots.T[0], dots.T[1], c=predictions, cmap='YlOrRd', alpha=alpha)\n",
    "        \n",
    "    def add_to_gif(self, dots_x, predictions, title='', alpha=0.3):\n",
    "        self.picture(dots_x, predictions, title=title, alpha=alpha)\n",
    "        plt.savefig(self.name+'.png')\n",
    "        plt.close()\n",
    "        image = Image.open(self.name+'.png')\n",
    "        ar = np.asarray(image)\n",
    "        self.images.append(ar)\n",
    "        \n",
    "    def save_gif(self):\n",
    "        kargs = { 'duration': 0.2 }\n",
    "        imageio.mimsave(self.name+'.gif', self.images, None, **kargs)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural networks classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classes for neural networks\n",
    "\n",
    "# Generator\n",
    "class Gen:\n",
    "    model = None\n",
    "    \n",
    "    def __init__(self):\n",
    "        model = Sequential([Dense(15, activation='relu', kernel_initializer='he_uniform', input_dim=5),\n",
    "                            Dense(2, activation='linear')\n",
    "        ])\n",
    "        self.model = model\n",
    "        \n",
    "    def predict(self, dots_x):\n",
    "        return self.model.predict(dots_x)\n",
    "    \n",
    "    def cmpile(self):\n",
    "        return\n",
    "    \n",
    "# Discriminator\n",
    "class Dsc:\n",
    "    model = None\n",
    "    \n",
    "    def __init__(self):\n",
    "        model = Sequential([Dense(25, activation='relu', kernel_initializer='he_uniform', input_dim=2),\n",
    "                            Dense(1, activation='sigmoid')\n",
    "        ])\n",
    "        self.model = model\n",
    "    \n",
    "    def cmpile(self, lr=0.0001):\n",
    "        self.model.compile(loss='binary_crossentropy',\n",
    "                           optimizer=tf.keras.optimizers.Adam(lr),\n",
    "                           metrics=['accuracy'])\n",
    "        \n",
    "    def fit(self, dots_x, dots_y, weights=None, epochs=1, validation_split=0.15, plot=False):\n",
    "        if plot:\n",
    "            img = Plot('discriminator_fit')\n",
    "            for i in range(epochs):\n",
    "                print(\"Epoch %d out of %d\" % (i, epochs))\n",
    "                self.model.fit(dots_x, \n",
    "                               dots_y, \n",
    "                               epochs=10, \n",
    "                               sample_weight=weights,\n",
    "                               validation_split=validation_split)\n",
    "                img.add_to_gif(dots_x, self.model.predict(dots_x), title='Epoch %d' % i)\n",
    "            img.save_gif()                        \n",
    "        else:\n",
    "            self.model.fit(dots_x, \n",
    "                           dots_y, \n",
    "                           epochs=epochs, \n",
    "                           sample_weight=weights, \n",
    "                           validation_split=validation_split)\n",
    "    \n",
    "    def save(self, name='discriminator'):\n",
    "        self.model.save(name+'.h5')\n",
    "        \n",
    "# ================= Raw classes, don't work ====================\n",
    "\n",
    "\"\"\"class Gan:\n",
    "    gen = None\n",
    "    dsc = None\n",
    "    model = None\n",
    "    \n",
    "    def __init__(self, gen, dsc, n_dim=5):\n",
    "        make_trainable(dsc, False)\n",
    "        self.gen = gen\n",
    "        self.dsc = dsc\n",
    "        # connect them\n",
    "        model = Sequential()\n",
    "        # add generator\n",
    "        model.add(gen.model)\n",
    "        # add the discriminator\n",
    "        model.add(dsc.model)\n",
    "        self.model = model\n",
    "    \n",
    "    # This method doesn't work\n",
    "    # Presumably because of some optimizer issue\n",
    "    def cmpile(self, lr=0.001):\n",
    "        self.model.compile(loss='binary_crossentropy',\n",
    "                           optimizer=tf.keras.optimizers.Adam(lr),\n",
    "                           metrics = ['accuracy'])\n",
    "        \n",
    "    def fit(self, dots_x, dots_y, epochs=1):\n",
    "        self.model.fit(dots_x, dots_y, epochs=epochs)\n",
    "        \n",
    "class Dummy:\n",
    "    model = None\n",
    "    \n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "        \n",
    "    def cmpile(self, lr=0.0001):\n",
    "        self.model.compile(loss='binary_crossentropy',\n",
    "                           optimizer=tf.keras.optimizers.Adam(lr),\n",
    "                           metrics=['accuracy'])\n",
    "    \n",
    "    # todo: remove hardcode\n",
    "    def fit(self, dots_x, dots_y, weights=None, epochs=1, validation_split=0.15, plot=False):\n",
    "        if plot:\n",
    "            img = Plot('discriminator_fit')\n",
    "            for i in range(epochs//25):\n",
    "                print(\"Epoch %d out of %d\" % (i, epochs))\n",
    "                self.model.fit(dots_x, \n",
    "                               dots_y, \n",
    "                               epochs=25, \n",
    "                               sample_weight=weights)\n",
    "                img.add_to_gif(dots_x, self.model.predict(dots_x), title='Epoch %d' % i*25)\n",
    "            img.save_gif()                        \n",
    "        else:\n",
    "            self.model.fit(dots_x, \n",
    "                           dots_y, \n",
    "                           epochs=epochs, \n",
    "                           sample_weight=weights, \n",
    "                           validation_split=validation_split)\n",
    "    \n",
    "    def save(self, name='discriminator'):\n",
    "        self.model.save(name+'.h5')\n",
    "        \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#discriminator = tf.keras.models.load_model('discriminator.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start Here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W1018 15:01:38.306302 23624 deprecation.py:506] From C:\\Users\\Admin\\.conda\\envs\\neuro\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    }
   ],
   "source": [
    "# Generating data\n",
    "Data = Dataset()\n",
    "Data.load_data()\n",
    "weights = Data.load_weights()\n",
    "\n",
    "# Defining neural networks\n",
    "generator = Gen()\n",
    "discriminator = Dsc()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1018 15:01:38.538683 23624 deprecation.py:323] From C:\\Users\\Admin\\.conda\\envs\\neuro\\lib\\site-packages\\tensorflow\\python\\ops\\nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 out of 10\n",
      "Train on 1020 samples, validate on 180 samples\n",
      "Epoch 1/10\n",
      "1020/1020 [==============================] - 1s 1ms/sample - loss: 4.9631 - acc: 0.7902 - val_loss: 3.0747 - val_acc: 0.8111\n",
      "Epoch 2/10\n",
      "1020/1020 [==============================] - 0s 195us/sample - loss: 2.7648 - acc: 0.7990 - val_loss: 1.3371 - val_acc: 0.8167\n",
      "Epoch 3/10\n",
      "1020/1020 [==============================] - 0s 211us/sample - loss: 0.9008 - acc: 0.7696 - val_loss: 0.4823 - val_acc: 0.7556\n",
      "Epoch 4/10\n",
      "1020/1020 [==============================] - 0s 205us/sample - loss: 0.4940 - acc: 0.7873 - val_loss: 0.4083 - val_acc: 0.8278\n",
      "Epoch 5/10\n",
      "1020/1020 [==============================] - 0s 252us/sample - loss: 0.4443 - acc: 0.8196 - val_loss: 0.3863 - val_acc: 0.8333\n",
      "Epoch 6/10\n",
      "1020/1020 [==============================] - 0s 353us/sample - loss: 0.4287 - acc: 0.8265 - val_loss: 0.4018 - val_acc: 0.8278\n",
      "Epoch 7/10\n",
      "1020/1020 [==============================] - 0s 285us/sample - loss: 0.4223 - acc: 0.8245 - val_loss: 0.3746 - val_acc: 0.8278\n",
      "Epoch 8/10\n",
      "1020/1020 [==============================] - 0s 222us/sample - loss: 0.4190 - acc: 0.8245 - val_loss: 0.3765 - val_acc: 0.8278\n",
      "Epoch 9/10\n",
      "1020/1020 [==============================] - 0s 214us/sample - loss: 0.4217 - acc: 0.8245 - val_loss: 0.3777 - val_acc: 0.8278\n",
      "Epoch 10/10\n",
      "1020/1020 [==============================] - 0s 282us/sample - loss: 0.4181 - acc: 0.8255 - val_loss: 0.3776 - val_acc: 0.8333\n",
      "Epoch 1 out of 10\n",
      "Train on 1020 samples, validate on 180 samples\n",
      "Epoch 1/10\n",
      "1020/1020 [==============================] - 0s 196us/sample - loss: 0.4139 - acc: 0.8284 - val_loss: 0.3702 - val_acc: 0.8333\n",
      "Epoch 2/10\n",
      "1020/1020 [==============================] - 0s 192us/sample - loss: 0.4033 - acc: 0.8324 - val_loss: 0.3724 - val_acc: 0.8333\n",
      "Epoch 3/10\n",
      "1020/1020 [==============================] - 0s 211us/sample - loss: 0.3991 - acc: 0.8333 - val_loss: 0.3743 - val_acc: 0.8333\n",
      "Epoch 4/10\n",
      "1020/1020 [==============================] - 0s 178us/sample - loss: 0.4105 - acc: 0.8333 - val_loss: 0.3693 - val_acc: 0.8333\n",
      "Epoch 5/10\n",
      "1020/1020 [==============================] - 0s 279us/sample - loss: 0.4053 - acc: 0.8353 - val_loss: 0.3771 - val_acc: 0.8333\n",
      "Epoch 6/10\n",
      "1020/1020 [==============================] - 0s 226us/sample - loss: 0.4008 - acc: 0.8353 - val_loss: 0.3746 - val_acc: 0.8389\n",
      "Epoch 7/10\n",
      "1020/1020 [==============================] - 0s 292us/sample - loss: 0.3993 - acc: 0.8353 - val_loss: 0.3914 - val_acc: 0.8389\n",
      "Epoch 8/10\n",
      "1020/1020 [==============================] - 0s 285us/sample - loss: 0.3987 - acc: 0.8363 - val_loss: 0.3705 - val_acc: 0.8389\n",
      "Epoch 9/10\n",
      "1020/1020 [==============================] - 0s 346us/sample - loss: 0.3990 - acc: 0.8363 - val_loss: 0.3942 - val_acc: 0.8389\n",
      "Epoch 10/10\n",
      "1020/1020 [==============================] - 0s 342us/sample - loss: 0.4015 - acc: 0.8363 - val_loss: 0.3721 - val_acc: 0.8389\n",
      "Epoch 2 out of 10\n",
      "Train on 1020 samples, validate on 180 samples\n",
      "Epoch 1/10\n",
      "1020/1020 [==============================] - 0s 211us/sample - loss: 0.4051 - acc: 0.8363 - val_loss: 0.3682 - val_acc: 0.8389\n",
      "Epoch 2/10\n",
      "1020/1020 [==============================] - 0s 260us/sample - loss: 0.3942 - acc: 0.8363 - val_loss: 0.3673 - val_acc: 0.8389\n",
      "Epoch 3/10\n",
      "1020/1020 [==============================] - 0s 227us/sample - loss: 0.3995 - acc: 0.8373 - val_loss: 0.4542 - val_acc: 0.8389\n",
      "Epoch 4/10\n",
      "1020/1020 [==============================] - 0s 277us/sample - loss: 0.4140 - acc: 0.8373 - val_loss: 0.3734 - val_acc: 0.8389\n",
      "Epoch 5/10\n",
      "1020/1020 [==============================] - 0s 346us/sample - loss: 0.3971 - acc: 0.8373 - val_loss: 0.3711 - val_acc: 0.8389\n",
      "Epoch 6/10\n",
      "1020/1020 [==============================] - 0s 282us/sample - loss: 0.3972 - acc: 0.8373 - val_loss: 0.3741 - val_acc: 0.8389\n",
      "Epoch 7/10\n",
      "1020/1020 [==============================] - 0s 278us/sample - loss: 0.4073 - acc: 0.8373 - val_loss: 0.3682 - val_acc: 0.8389\n",
      "Epoch 8/10\n",
      "1020/1020 [==============================] - 0s 232us/sample - loss: 0.4083 - acc: 0.8373 - val_loss: 0.3644 - val_acc: 0.8389\n",
      "Epoch 9/10\n",
      "1020/1020 [==============================] - 0s 270us/sample - loss: 0.3902 - acc: 0.8373 - val_loss: 0.3691 - val_acc: 0.8389\n",
      "Epoch 10/10\n",
      "1020/1020 [==============================] - 0s 237us/sample - loss: 0.3909 - acc: 0.8373 - val_loss: 0.3733 - val_acc: 0.8389\n",
      "Epoch 3 out of 10\n",
      "Train on 1020 samples, validate on 180 samples\n",
      "Epoch 1/10\n",
      "1020/1020 [==============================] - 0s 202us/sample - loss: 0.3953 - acc: 0.8373 - val_loss: 0.3661 - val_acc: 0.8389\n",
      "Epoch 2/10\n",
      "1020/1020 [==============================] - 0s 199us/sample - loss: 0.3863 - acc: 0.8373 - val_loss: 0.3801 - val_acc: 0.8389\n",
      "Epoch 3/10\n",
      "1020/1020 [==============================] - 0s 176us/sample - loss: 0.3949 - acc: 0.8382 - val_loss: 0.3659 - val_acc: 0.8389\n",
      "Epoch 4/10\n",
      "1020/1020 [==============================] - 0s 198us/sample - loss: 0.3879 - acc: 0.8382 - val_loss: 0.3633 - val_acc: 0.8389\n",
      "Epoch 5/10\n",
      "1020/1020 [==============================] - 0s 409us/sample - loss: 0.3853 - acc: 0.8382 - val_loss: 0.3638 - val_acc: 0.8389\n",
      "Epoch 6/10\n",
      "1020/1020 [==============================] - 0s 286us/sample - loss: 0.3855 - acc: 0.8382 - val_loss: 0.3660 - val_acc: 0.8389\n",
      "Epoch 7/10\n",
      "1020/1020 [==============================] - 0s 229us/sample - loss: 0.3796 - acc: 0.8382 - val_loss: 0.3629 - val_acc: 0.8389\n",
      "Epoch 8/10\n",
      "1020/1020 [==============================] - 0s 295us/sample - loss: 0.3853 - acc: 0.8392 - val_loss: 0.3656 - val_acc: 0.8389\n",
      "Epoch 9/10\n",
      "1020/1020 [==============================] - 0s 317us/sample - loss: 0.3822 - acc: 0.8392 - val_loss: 0.3649 - val_acc: 0.8389\n",
      "Epoch 10/10\n",
      "1020/1020 [==============================] - 0s 220us/sample - loss: 0.3833 - acc: 0.8402 - val_loss: 0.3681 - val_acc: 0.8389\n",
      "Epoch 4 out of 10\n",
      "Train on 1020 samples, validate on 180 samples\n",
      "Epoch 1/10\n",
      "1020/1020 [==============================] - 0s 246us/sample - loss: 0.3874 - acc: 0.8382 - val_loss: 0.3605 - val_acc: 0.8444\n",
      "Epoch 2/10\n",
      "1020/1020 [==============================] - 0s 216us/sample - loss: 0.3826 - acc: 0.8382 - val_loss: 0.3609 - val_acc: 0.8444\n",
      "Epoch 3/10\n",
      "1020/1020 [==============================] - 0s 324us/sample - loss: 0.3821 - acc: 0.8412 - val_loss: 0.3596 - val_acc: 0.8556\n",
      "Epoch 4/10\n",
      "1020/1020 [==============================] - 0s 413us/sample - loss: 0.3804 - acc: 0.8471 - val_loss: 0.3712 - val_acc: 0.8500\n",
      "Epoch 5/10\n",
      "1020/1020 [==============================] - 0s 283us/sample - loss: 0.3762 - acc: 0.8490 - val_loss: 0.3750 - val_acc: 0.8500\n",
      "Epoch 6/10\n",
      "1020/1020 [==============================] - 0s 222us/sample - loss: 0.3839 - acc: 0.8510 - val_loss: 0.3691 - val_acc: 0.8500\n",
      "Epoch 7/10\n",
      "1020/1020 [==============================] - 0s 253us/sample - loss: 0.3843 - acc: 0.8520 - val_loss: 0.3588 - val_acc: 0.8556\n",
      "Epoch 8/10\n",
      "1020/1020 [==============================] - 0s 365us/sample - loss: 0.3852 - acc: 0.8520 - val_loss: 0.3609 - val_acc: 0.8611\n",
      "Epoch 9/10\n",
      "1020/1020 [==============================] - 1s 576us/sample - loss: 0.3788 - acc: 0.8510 - val_loss: 0.3525 - val_acc: 0.8611\n",
      "Epoch 10/10\n",
      "1020/1020 [==============================] - 1s 618us/sample - loss: 0.3849 - acc: 0.8529 - val_loss: 0.3537 - val_acc: 0.8611\n",
      "Epoch 5 out of 10\n",
      "Train on 1020 samples, validate on 180 samples\n",
      "Epoch 1/10\n",
      "1020/1020 [==============================] - 0s 330us/sample - loss: 0.3747 - acc: 0.8569 - val_loss: 0.3493 - val_acc: 0.8611\n",
      "Epoch 2/10\n",
      "1020/1020 [==============================] - 0s 433us/sample - loss: 0.3853 - acc: 0.8559 - val_loss: 0.3488 - val_acc: 0.8611\n",
      "Epoch 3/10\n",
      "1020/1020 [==============================] - 0s 399us/sample - loss: 0.3804 - acc: 0.8569 - val_loss: 0.3539 - val_acc: 0.8722\n",
      "Epoch 4/10\n",
      "1020/1020 [==============================] - 0s 345us/sample - loss: 0.3841 - acc: 0.8559 - val_loss: 0.3465 - val_acc: 0.8667\n",
      "Epoch 5/10\n",
      "1020/1020 [==============================] - 0s 332us/sample - loss: 0.3855 - acc: 0.8578 - val_loss: 0.3455 - val_acc: 0.8722\n",
      "Epoch 6/10\n",
      "1020/1020 [==============================] - 0s 431us/sample - loss: 0.3886 - acc: 0.8559 - val_loss: 0.3599 - val_acc: 0.8778\n",
      "Epoch 7/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1020/1020 [==============================] - 0s 410us/sample - loss: 0.3731 - acc: 0.8598 - val_loss: 0.3457 - val_acc: 0.8778\n",
      "Epoch 8/10\n",
      "1020/1020 [==============================] - 0s 259us/sample - loss: 0.3718 - acc: 0.8598 - val_loss: 0.3446 - val_acc: 0.8778\n",
      "Epoch 9/10\n",
      "1020/1020 [==============================] - 0s 232us/sample - loss: 0.3685 - acc: 0.8588 - val_loss: 0.3427 - val_acc: 0.8833\n",
      "Epoch 10/10\n",
      "1020/1020 [==============================] - 0s 198us/sample - loss: 0.3712 - acc: 0.8598 - val_loss: 0.3406 - val_acc: 0.8778\n",
      "Epoch 6 out of 10\n",
      "Train on 1020 samples, validate on 180 samples\n",
      "Epoch 1/10\n",
      "1020/1020 [==============================] - 0s 324us/sample - loss: 0.3741 - acc: 0.8588 - val_loss: 0.3412 - val_acc: 0.8778\n",
      "Epoch 2/10\n",
      "1020/1020 [==============================] - 0s 292us/sample - loss: 0.3713 - acc: 0.8598 - val_loss: 0.3393 - val_acc: 0.8778\n",
      "Epoch 3/10\n",
      "1020/1020 [==============================] - 0s 353us/sample - loss: 0.3664 - acc: 0.8588 - val_loss: 0.3507 - val_acc: 0.8778\n",
      "Epoch 4/10\n",
      "1020/1020 [==============================] - 0s 336us/sample - loss: 0.3735 - acc: 0.8578 - val_loss: 0.3386 - val_acc: 0.8778\n",
      "Epoch 5/10\n",
      "1020/1020 [==============================] - 0s 336us/sample - loss: 0.3724 - acc: 0.8598 - val_loss: 0.3532 - val_acc: 0.8778\n",
      "Epoch 6/10\n",
      "1020/1020 [==============================] - 0s 315us/sample - loss: 0.3700 - acc: 0.8588 - val_loss: 0.3478 - val_acc: 0.8778\n",
      "Epoch 7/10\n",
      "1020/1020 [==============================] - 0s 264us/sample - loss: 0.3700 - acc: 0.8588 - val_loss: 0.3371 - val_acc: 0.8778\n",
      "Epoch 8/10\n",
      "1020/1020 [==============================] - 0s 190us/sample - loss: 0.3680 - acc: 0.8598 - val_loss: 0.3917 - val_acc: 0.8778\n",
      "Epoch 9/10\n",
      "1020/1020 [==============================] - 0s 199us/sample - loss: 0.3650 - acc: 0.8598 - val_loss: 0.3470 - val_acc: 0.8778\n",
      "Epoch 10/10\n",
      "1020/1020 [==============================] - 0s 184us/sample - loss: 0.3746 - acc: 0.8608 - val_loss: 0.3364 - val_acc: 0.8778\n",
      "Epoch 7 out of 10\n",
      "Train on 1020 samples, validate on 180 samples\n",
      "Epoch 1/10\n",
      "1020/1020 [==============================] - 0s 251us/sample - loss: 0.3631 - acc: 0.8598 - val_loss: 0.3445 - val_acc: 0.8778\n",
      "Epoch 2/10\n",
      "1020/1020 [==============================] - 0s 341us/sample - loss: 0.3635 - acc: 0.8578 - val_loss: 0.3720 - val_acc: 0.8833\n",
      "Epoch 3/10\n",
      "1020/1020 [==============================] - 0s 331us/sample - loss: 0.3626 - acc: 0.8598 - val_loss: 0.3391 - val_acc: 0.8833\n",
      "Epoch 4/10\n",
      "1020/1020 [==============================] - 0s 356us/sample - loss: 0.3842 - acc: 0.8608 - val_loss: 0.3565 - val_acc: 0.8833\n",
      "Epoch 5/10\n",
      "1020/1020 [==============================] - 0s 330us/sample - loss: 0.3647 - acc: 0.8608 - val_loss: 0.3442 - val_acc: 0.8778\n",
      "Epoch 6/10\n",
      "1020/1020 [==============================] - 0s 337us/sample - loss: 0.3640 - acc: 0.8608 - val_loss: 0.3418 - val_acc: 0.8778\n",
      "Epoch 7/10\n",
      "1020/1020 [==============================] - 0s 334us/sample - loss: 0.3709 - acc: 0.8618 - val_loss: 0.3444 - val_acc: 0.8778\n",
      "Epoch 8/10\n",
      "1020/1020 [==============================] - 0s 306us/sample - loss: 0.3669 - acc: 0.8608 - val_loss: 0.3437 - val_acc: 0.8833\n",
      "Epoch 9/10\n",
      "1020/1020 [==============================] - 0s 327us/sample - loss: 0.3706 - acc: 0.8578 - val_loss: 0.3315 - val_acc: 0.8778\n",
      "Epoch 10/10\n",
      "1020/1020 [==============================] - 0s 342us/sample - loss: 0.3765 - acc: 0.8618 - val_loss: 0.3338 - val_acc: 0.8778\n",
      "Epoch 8 out of 10\n",
      "Train on 1020 samples, validate on 180 samples\n",
      "Epoch 1/10\n",
      "1020/1020 [==============================] - 0s 177us/sample - loss: 0.3648 - acc: 0.8647 - val_loss: 0.3301 - val_acc: 0.8778\n",
      "Epoch 2/10\n",
      "1020/1020 [==============================] - 0s 299us/sample - loss: 0.3641 - acc: 0.8598 - val_loss: 0.3329 - val_acc: 0.8778\n",
      "Epoch 3/10\n",
      "1020/1020 [==============================] - 0s 279us/sample - loss: 0.3673 - acc: 0.8608 - val_loss: 0.3358 - val_acc: 0.8778\n",
      "Epoch 4/10\n",
      "1020/1020 [==============================] - 0s 354us/sample - loss: 0.3616 - acc: 0.8618 - val_loss: 0.3360 - val_acc: 0.8778\n",
      "Epoch 5/10\n",
      "1020/1020 [==============================] - 0s 340us/sample - loss: 0.3595 - acc: 0.8608 - val_loss: 0.3323 - val_acc: 0.8778\n",
      "Epoch 6/10\n",
      "1020/1020 [==============================] - 0s 325us/sample - loss: 0.3595 - acc: 0.8598 - val_loss: 0.3420 - val_acc: 0.8778\n",
      "Epoch 7/10\n",
      "1020/1020 [==============================] - 0s 352us/sample - loss: 0.3617 - acc: 0.8608 - val_loss: 0.3389 - val_acc: 0.8778\n",
      "Epoch 8/10\n",
      "1020/1020 [==============================] - 0s 353us/sample - loss: 0.3577 - acc: 0.8588 - val_loss: 0.3325 - val_acc: 0.8833\n",
      "Epoch 9/10\n",
      "1020/1020 [==============================] - 0s 398us/sample - loss: 0.3597 - acc: 0.8608 - val_loss: 0.3308 - val_acc: 0.8833\n",
      "Epoch 10/10\n",
      "1020/1020 [==============================] - 0s 397us/sample - loss: 0.3574 - acc: 0.8588 - val_loss: 0.3541 - val_acc: 0.8833\n",
      "Epoch 9 out of 10\n",
      "Train on 1020 samples, validate on 180 samples\n",
      "Epoch 1/10\n",
      "1020/1020 [==============================] - 0s 366us/sample - loss: 0.3726 - acc: 0.8598 - val_loss: 0.3364 - val_acc: 0.8778\n",
      "Epoch 2/10\n",
      "1020/1020 [==============================] - 0s 394us/sample - loss: 0.3889 - acc: 0.8608 - val_loss: 0.3420 - val_acc: 0.8833\n",
      "Epoch 3/10\n",
      "1020/1020 [==============================] - 0s 460us/sample - loss: 0.3583 - acc: 0.8608 - val_loss: 0.3277 - val_acc: 0.8833\n",
      "Epoch 4/10\n",
      "1020/1020 [==============================] - 0s 327us/sample - loss: 0.3554 - acc: 0.8608 - val_loss: 0.3252 - val_acc: 0.8833\n",
      "Epoch 5/10\n",
      "1020/1020 [==============================] - 0s 378us/sample - loss: 0.3634 - acc: 0.8618 - val_loss: 0.3277 - val_acc: 0.8833\n",
      "Epoch 6/10\n",
      "1020/1020 [==============================] - 0s 429us/sample - loss: 0.3530 - acc: 0.8627 - val_loss: 0.3380 - val_acc: 0.8833\n",
      "Epoch 7/10\n",
      "1020/1020 [==============================] - 0s 401us/sample - loss: 0.3585 - acc: 0.8588 - val_loss: 0.3339 - val_acc: 0.8778\n",
      "Epoch 8/10\n",
      "1020/1020 [==============================] - 0s 328us/sample - loss: 0.3615 - acc: 0.8578 - val_loss: 0.3275 - val_acc: 0.8833\n",
      "Epoch 9/10\n",
      "1020/1020 [==============================] - 0s 370us/sample - loss: 0.3540 - acc: 0.8618 - val_loss: 0.3289 - val_acc: 0.8778\n",
      "Epoch 10/10\n",
      "1020/1020 [==============================] - 0s 365us/sample - loss: 0.3516 - acc: 0.8598 - val_loss: 0.3337 - val_acc: 0.8833\n"
     ]
    }
   ],
   "source": [
    "fit_discriminator(discriminator, Data, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "720/720 [==============================] - 0s 97us/sample - loss: 0.4235 - acc: 0.8361\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.4235376834869385, 0.8361111]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TestData = Dataset()\n",
    "TestData.load_data(data_range=6)\n",
    "discriminator.model.evaluate(TestData.x, TestData.y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "Plot('test2').picture(TestData.x, discriminator.model.predict(TestData.x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 7.19725729, 51.80051249],\n",
       "        [ 7.19725729, 32.7513415 ],\n",
       "        [ 7.19725729, 61.88472107],\n",
       "        ...,\n",
       "        [-4.71135514, 80.81500559],\n",
       "        [-4.71135514, 92.3447258 ],\n",
       "        [-4.71135514, 38.70922713]]), array([1, 0, 0, ..., 0, 0, 0]))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NewData = Dataset()\n",
    "NewData.load_data(data_range=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 2ms/sample - loss: 3.1830\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 156us/sample - loss: 3.1092\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1018 15:02:54.782752 23624 training.py:2197] Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 249us/sample - loss: 0.3195 - acc: 0.8594\n",
      "Train on 960 samples, validate on 240 samples\n",
      "960/960 [==============================] - 0s 261us/sample - loss: 0.3695 - acc: 0.8625 - val_loss: 0.3471 - val_acc: 0.8708\n",
      "Epoch 1\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 171us/sample - loss: 3.2484\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 203us/sample - loss: 3.1739\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 296us/sample - loss: 0.2505 - acc: 0.8906\n",
      "Train on 960 samples, validate on 240 samples\n",
      "960/960 [==============================] - 0s 256us/sample - loss: 0.3601 - acc: 0.8615 - val_loss: 0.3450 - val_acc: 0.8708\n",
      "Epoch 2\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 218us/sample - loss: 3.4976\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 265us/sample - loss: 3.4156\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 281us/sample - loss: 0.1996 - acc: 0.9375\n",
      "Train on 960 samples, validate on 240 samples\n",
      "960/960 [==============================] - 0s 296us/sample - loss: 0.3649 - acc: 0.8625 - val_loss: 0.3475 - val_acc: 0.8708\n",
      "Epoch 3\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 296us/sample - loss: 3.5164\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 358us/sample - loss: 3.4306\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 296us/sample - loss: 0.2807 - acc: 0.7969\n",
      "Train on 960 samples, validate on 240 samples\n",
      "960/960 [==============================] - 0s 316us/sample - loss: 0.3577 - acc: 0.8625 - val_loss: 0.3574 - val_acc: 0.8708\n",
      "Epoch 4\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 327us/sample - loss: 3.5868\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 265us/sample - loss: 3.5129\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 327us/sample - loss: 0.3280 - acc: 0.7812\n",
      "Train on 960 samples, validate on 240 samples\n",
      "960/960 [==============================] - 0s 320us/sample - loss: 0.3601 - acc: 0.8625 - val_loss: 0.3487 - val_acc: 0.8708\n",
      "Epoch 5\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - ETA: 0s - loss: 3.475 - 0s 265us/sample - loss: 3.6490\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 327us/sample - loss: 3.5667\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 405us/sample - loss: 0.3127 - acc: 0.7969\n",
      "Train on 960 samples, validate on 240 samples\n",
      "960/960 [==============================] - 0s 340us/sample - loss: 0.3579 - acc: 0.8615 - val_loss: 0.3527 - val_acc: 0.8708\n",
      "Epoch 6\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 234us/sample - loss: 3.0441\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 265us/sample - loss: 2.9702\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 499us/sample - loss: 0.3431 - acc: 0.7812\n",
      "Train on 960 samples, validate on 240 samples\n",
      "960/960 [==============================] - 0s 328us/sample - loss: 0.3535 - acc: 0.8635 - val_loss: 0.3451 - val_acc: 0.8708\n",
      "Epoch 7\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 343us/sample - loss: 3.6516\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 405us/sample - loss: 3.5605\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 390us/sample - loss: 0.2751 - acc: 0.8438\n",
      "Train on 960 samples, validate on 240 samples\n",
      "960/960 [==============================] - 0s 295us/sample - loss: 0.3553 - acc: 0.8635 - val_loss: 0.3471 - val_acc: 0.8708\n",
      "Epoch 8\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 281us/sample - loss: 3.0905\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 327us/sample - loss: 3.0143\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 265us/sample - loss: 0.3097 - acc: 0.7969\n",
      "Train on 960 samples, validate on 240 samples\n",
      "960/960 [==============================] - 0s 266us/sample - loss: 0.3581 - acc: 0.8625 - val_loss: 0.3523 - val_acc: 0.8708\n",
      "Epoch 9\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 156us/sample - loss: 3.2830\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 171us/sample - loss: 3.2026\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 203us/sample - loss: 0.2802 - acc: 0.8438\n",
      "Train on 960 samples, validate on 240 samples\n",
      "960/960 [==============================] - 0s 235us/sample - loss: 0.3690 - acc: 0.8615 - val_loss: 0.3484 - val_acc: 0.8708\n",
      "Epoch 10\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 156us/sample - loss: 2.9083\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 187us/sample - loss: 2.8373\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 265us/sample - loss: 0.3022 - acc: 0.8125\n",
      "Train on 960 samples, validate on 240 samples\n",
      "960/960 [==============================] - 0s 236us/sample - loss: 0.3551 - acc: 0.8625 - val_loss: 0.3477 - val_acc: 0.8708\n",
      "Epoch 11\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 249us/sample - loss: 3.3550\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 171us/sample - loss: 3.2674\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - ETA: 0s - loss: 0.3366 - acc: 0.812 - 0s 280us/sample - loss: 0.2967 - acc: 0.8281\n",
      "Train on 960 samples, validate on 240 samples\n",
      "960/960 [==============================] - 0s 235us/sample - loss: 0.3745 - acc: 0.8656 - val_loss: 0.3475 - val_acc: 0.8708\n",
      "Epoch 12\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 218us/sample - loss: 3.2671\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 234us/sample - loss: 3.1855\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 296us/sample - loss: 0.2938 - acc: 0.8125\n",
      "Train on 960 samples, validate on 240 samples\n",
      "960/960 [==============================] - 0s 217us/sample - loss: 0.3638 - acc: 0.8646 - val_loss: 0.3437 - val_acc: 0.8708\n",
      "Epoch 13\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 218us/sample - loss: 3.1147\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 280us/sample - loss: 3.0247\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 343us/sample - loss: 0.2452 - acc: 0.8594\n",
      "Train on 960 samples, validate on 240 samples\n",
      "960/960 [==============================] - 0s 253us/sample - loss: 0.3653 - acc: 0.8656 - val_loss: 0.3491 - val_acc: 0.8667\n",
      "Epoch 14\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 265us/sample - loss: 2.8290\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 203us/sample - loss: 2.7486\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 234us/sample - loss: 0.3567 - acc: 0.7344\n",
      "Train on 960 samples, validate on 240 samples\n",
      "960/960 [==============================] - 0s 243us/sample - loss: 0.3537 - acc: 0.8656 - val_loss: 0.3414 - val_acc: 0.8667\n",
      "Epoch 15\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 265us/sample - loss: 2.7212\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 187us/sample - loss: 2.6479\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 312us/sample - loss: 0.3168 - acc: 0.8281\n",
      "Train on 960 samples, validate on 240 samples\n",
      "960/960 [==============================] - 0s 234us/sample - loss: 0.3513 - acc: 0.8667 - val_loss: 0.3502 - val_acc: 0.8625\n",
      "Epoch 16\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 249us/sample - loss: 2.2801\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 405us/sample - loss: 2.2171\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 281us/sample - loss: 0.3551 - acc: 0.8125\n",
      "Train on 960 samples, validate on 240 samples\n",
      "960/960 [==============================] - 0s 391us/sample - loss: 0.3500 - acc: 0.8667 - val_loss: 0.3531 - val_acc: 0.8625\n",
      "Epoch 17\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 312us/sample - loss: 2.7510\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 343us/sample - loss: 2.6779\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 249us/sample - loss: 0.2872 - acc: 0.8281\n",
      "Train on 960 samples, validate on 240 samples\n",
      "960/960 [==============================] - 0s 201us/sample - loss: 0.3708 - acc: 0.8573 - val_loss: 0.4166 - val_acc: 0.8625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 203us/sample - loss: 2.7853\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 171us/sample - loss: 2.7079\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 312us/sample - loss: 0.3251 - acc: 0.7969\n",
      "Train on 960 samples, validate on 240 samples\n",
      "960/960 [==============================] - 0s 212us/sample - loss: 0.3593 - acc: 0.8646 - val_loss: 0.3490 - val_acc: 0.8542\n",
      "Epoch 19\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 234us/sample - loss: 2.1336\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 249us/sample - loss: 2.0687\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 296us/sample - loss: 0.3829 - acc: 0.7344\n",
      "Train on 960 samples, validate on 240 samples\n",
      "960/960 [==============================] - 0s 218us/sample - loss: 0.3531 - acc: 0.8656 - val_loss: 0.3481 - val_acc: 0.8542\n",
      "Epoch 20\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 187us/sample - loss: 2.6473\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 343us/sample - loss: 2.5715\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 312us/sample - loss: 0.3216 - acc: 0.7969\n",
      "Train on 960 samples, validate on 240 samples\n",
      "960/960 [==============================] - 0s 232us/sample - loss: 0.3580 - acc: 0.8625 - val_loss: 0.3593 - val_acc: 0.8542\n",
      "Epoch 21\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 265us/sample - loss: 2.5091\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 296us/sample - loss: 2.4364\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 452us/sample - loss: 0.3692 - acc: 0.7812\n",
      "Train on 960 samples, validate on 240 samples\n",
      "960/960 [==============================] - 0s 330us/sample - loss: 0.3486 - acc: 0.8594 - val_loss: 0.3404 - val_acc: 0.8417\n",
      "Epoch 22\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 249us/sample - loss: 1.6739\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 312us/sample - loss: 1.6200\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 203us/sample - loss: 0.4478 - acc: 0.7031\n",
      "Train on 960 samples, validate on 240 samples\n",
      "960/960 [==============================] - 0s 264us/sample - loss: 0.3479 - acc: 0.8625 - val_loss: 0.3500 - val_acc: 0.8500\n",
      "Epoch 23\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 203us/sample - loss: 1.9865\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 296us/sample - loss: 1.9247\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 343us/sample - loss: 0.4216 - acc: 0.7188\n",
      "Train on 960 samples, validate on 240 samples\n",
      "960/960 [==============================] - 0s 193us/sample - loss: 0.3431 - acc: 0.8594 - val_loss: 0.3266 - val_acc: 0.8333\n",
      "Epoch 24\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 187us/sample - loss: 2.0834\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 327us/sample - loss: 2.0232\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 374us/sample - loss: 0.3523 - acc: 0.7969\n",
      "Train on 960 samples, validate on 240 samples\n",
      "960/960 [==============================] - 0s 246us/sample - loss: 0.3279 - acc: 0.8646 - val_loss: 0.3213 - val_acc: 0.8500\n",
      "Epoch 25\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 234us/sample - loss: 1.6358\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 296us/sample - loss: 1.5821\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 296us/sample - loss: 0.4321 - acc: 0.7812\n",
      "Train on 960 samples, validate on 240 samples\n",
      "960/960 [==============================] - 0s 249us/sample - loss: 0.3351 - acc: 0.8573 - val_loss: 0.3148 - val_acc: 0.8333\n",
      "Epoch 26\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 249us/sample - loss: 1.5369\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 296us/sample - loss: 1.4960\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 203us/sample - loss: 0.4479 - acc: 0.7656\n",
      "Train on 960 samples, validate on 240 samples\n",
      "960/960 [==============================] - 0s 246us/sample - loss: 0.3244 - acc: 0.8521 - val_loss: 0.3086 - val_acc: 0.8500\n",
      "Epoch 27\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 218us/sample - loss: 1.7948\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 265us/sample - loss: 1.7451\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 530us/sample - loss: 0.4454 - acc: 0.7031\n",
      "Train on 960 samples, validate on 240 samples\n",
      "960/960 [==============================] - 0s 406us/sample - loss: 0.3221 - acc: 0.8635 - val_loss: 0.3149 - val_acc: 0.8333\n",
      "Epoch 28\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 374us/sample - loss: 1.3495\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 530us/sample - loss: 1.3124\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 405us/sample - loss: 0.4937 - acc: 0.6562\n",
      "Train on 960 samples, validate on 240 samples\n",
      "960/960 [==============================] - 0s 369us/sample - loss: 0.3249 - acc: 0.8531 - val_loss: 0.3152 - val_acc: 0.8417\n",
      "Epoch 29\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 296us/sample - loss: 1.5846\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 358us/sample - loss: 1.5412\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 390us/sample - loss: 0.4329 - acc: 0.7344\n",
      "Train on 960 samples, validate on 240 samples\n",
      "960/960 [==============================] - 0s 266us/sample - loss: 0.3244 - acc: 0.8635 - val_loss: 0.3056 - val_acc: 0.8333\n",
      "Epoch 30\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 171us/sample - loss: 1.5682\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 187us/sample - loss: 1.5231\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 234us/sample - loss: 0.4454 - acc: 0.7344\n",
      "Train on 960 samples, validate on 240 samples\n",
      "960/960 [==============================] - 0s 197us/sample - loss: 0.3180 - acc: 0.8573 - val_loss: 0.3149 - val_acc: 0.8500\n",
      "Epoch 31\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 328us/sample - loss: 1.5489\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 218us/sample - loss: 1.5074\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 281us/sample - loss: 0.4812 - acc: 0.6719\n",
      "Train on 960 samples, validate on 240 samples\n",
      "960/960 [==============================] - 0s 244us/sample - loss: 0.3226 - acc: 0.8521 - val_loss: 0.3013 - val_acc: 0.8375\n",
      "Epoch 32\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 156us/sample - loss: 1.4443\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 218us/sample - loss: 1.4072\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 203us/sample - loss: 0.4520 - acc: 0.7656\n",
      "Train on 960 samples, validate on 240 samples\n",
      "960/960 [==============================] - 0s 226us/sample - loss: 0.3126 - acc: 0.8646 - val_loss: 0.3004 - val_acc: 0.8458\n",
      "Epoch 33\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 203us/sample - loss: 1.3888\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 218us/sample - loss: 1.3530\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 265us/sample - loss: 0.4587 - acc: 0.7344\n",
      "Train on 960 samples, validate on 240 samples\n",
      "960/960 [==============================] - 0s 219us/sample - loss: 0.3156 - acc: 0.8635 - val_loss: 0.2992 - val_acc: 0.8417\n",
      "Epoch 34\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 203us/sample - loss: 1.2216\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 156us/sample - loss: 1.1973\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 249us/sample - loss: 0.5035 - acc: 0.7344\n",
      "Train on 960 samples, validate on 240 samples\n",
      "960/960 [==============================] - 0s 219us/sample - loss: 0.3127 - acc: 0.8573 - val_loss: 0.3113 - val_acc: 0.8583\n",
      "Epoch 35\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 280us/sample - loss: 1.0636\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 203us/sample - loss: 1.0422\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 171us/sample - loss: 0.5145 - acc: 0.6719\n",
      "Train on 960 samples, validate on 240 samples\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "960/960 [==============================] - 0s 217us/sample - loss: 0.3104 - acc: 0.8583 - val_loss: 0.3200 - val_acc: 0.8417\n",
      "Epoch 36\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 234us/sample - loss: 1.1941\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 249us/sample - loss: 1.1704\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 265us/sample - loss: 0.4905 - acc: 0.7969\n",
      "Train on 960 samples, validate on 240 samples\n",
      "960/960 [==============================] - 0s 209us/sample - loss: 0.3159 - acc: 0.8500 - val_loss: 0.2980 - val_acc: 0.8375\n",
      "Epoch 37\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 234us/sample - loss: 1.1681\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 234us/sample - loss: 1.1484\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 234us/sample - loss: 0.4769 - acc: 0.8281\n",
      "Train on 960 samples, validate on 240 samples\n",
      "960/960 [==============================] - 0s 235us/sample - loss: 0.3106 - acc: 0.8615 - val_loss: 0.2967 - val_acc: 0.8375\n",
      "Epoch 38\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 234us/sample - loss: 1.2036\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 234us/sample - loss: 1.1795\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 343us/sample - loss: 0.5208 - acc: 0.7031\n",
      "Train on 960 samples, validate on 240 samples\n",
      "960/960 [==============================] - 0s 216us/sample - loss: 0.3099 - acc: 0.8594 - val_loss: 0.2948 - val_acc: 0.8375\n",
      "Epoch 39\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 171us/sample - loss: 1.1446\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 234us/sample - loss: 1.1237\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 218us/sample - loss: 0.4866 - acc: 0.8750\n",
      "Train on 960 samples, validate on 240 samples\n",
      "960/960 [==============================] - 0s 272us/sample - loss: 0.3184 - acc: 0.8562 - val_loss: 0.2987 - val_acc: 0.8583\n",
      "Epoch 40\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 156us/sample - loss: 1.1099\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 203us/sample - loss: 1.0890\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 202us/sample - loss: 0.5239 - acc: 0.7188\n",
      "Train on 960 samples, validate on 240 samples\n",
      "960/960 [==============================] - 0s 194us/sample - loss: 0.3144 - acc: 0.8667 - val_loss: 0.2971 - val_acc: 0.8542\n",
      "Epoch 41\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 187us/sample - loss: 1.1454\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 218us/sample - loss: 1.1220\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 203us/sample - loss: 0.4744 - acc: 0.8281\n",
      "Train on 960 samples, validate on 240 samples\n",
      "960/960 [==============================] - 0s 215us/sample - loss: 0.3114 - acc: 0.8500 - val_loss: 0.2943 - val_acc: 0.8583\n",
      "Epoch 42\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 156us/sample - loss: 0.9941\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 234us/sample - loss: 0.9785\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 358us/sample - loss: 0.5354 - acc: 0.7969\n",
      "Train on 960 samples, validate on 240 samples\n",
      "960/960 [==============================] - 0s 213us/sample - loss: 0.3108 - acc: 0.8583 - val_loss: 0.2925 - val_acc: 0.8458\n",
      "Epoch 43\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 218us/sample - loss: 1.1654\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 265us/sample - loss: 1.1486\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 296us/sample - loss: 0.4703 - acc: 0.8750\n",
      "Train on 960 samples, validate on 240 samples\n",
      "960/960 [==============================] - 0s 215us/sample - loss: 0.3057 - acc: 0.8573 - val_loss: 0.2929 - val_acc: 0.8542\n",
      "Epoch 44\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 171us/sample - loss: 1.0574\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 249us/sample - loss: 1.0417\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 281us/sample - loss: 0.4932 - acc: 0.9219\n",
      "Train on 960 samples, validate on 240 samples\n",
      "960/960 [==============================] - 0s 310us/sample - loss: 0.3058 - acc: 0.8469 - val_loss: 0.3000 - val_acc: 0.8583\n",
      "Epoch 45\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 405us/sample - loss: 1.0853\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 425us/sample - loss: 1.0683\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 296us/sample - loss: 0.4790 - acc: 0.8906\n",
      "Train on 960 samples, validate on 240 samples\n",
      "960/960 [==============================] - 0s 308us/sample - loss: 0.3075 - acc: 0.8521 - val_loss: 0.2925 - val_acc: 0.8542\n",
      "Epoch 46\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 405us/sample - loss: 0.9476\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 265us/sample - loss: 0.9392\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 311us/sample - loss: 0.5194 - acc: 0.9219\n",
      "Train on 960 samples, validate on 240 samples\n",
      "960/960 [==============================] - 0s 221us/sample - loss: 0.3036 - acc: 0.8552 - val_loss: 0.2915 - val_acc: 0.8458\n",
      "Epoch 47\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 202us/sample - loss: 1.1180\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 234us/sample - loss: 1.1054\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 249us/sample - loss: 0.4532 - acc: 0.9375\n",
      "Train on 960 samples, validate on 240 samples\n",
      "960/960 [==============================] - 0s 264us/sample - loss: 0.3114 - acc: 0.8479 - val_loss: 0.2925 - val_acc: 0.8583\n",
      "Epoch 48\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - ETA: 0s - loss: 0.988 - 0s 265us/sample - loss: 0.9619\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 265us/sample - loss: 0.9567\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 483us/sample - loss: 0.5074 - acc: 0.9531\n",
      "Train on 960 samples, validate on 240 samples\n",
      "960/960 [==============================] - 0s 287us/sample - loss: 0.3098 - acc: 0.8417 - val_loss: 0.2928 - val_acc: 0.8542\n",
      "Epoch 49\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 218us/sample - loss: 1.0761\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 218us/sample - loss: 1.0671\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 187us/sample - loss: 0.4754 - acc: 0.9688\n",
      "Train on 960 samples, validate on 240 samples\n",
      "960/960 [==============================] - 0s 242us/sample - loss: 0.3045 - acc: 0.8521 - val_loss: 0.3064 - val_acc: 0.8542\n",
      "Epoch 50\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 187us/sample - loss: 1.0171\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 218us/sample - loss: 1.0123\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 187us/sample - loss: 0.4774 - acc: 0.9531\n",
      "Train on 960 samples, validate on 240 samples\n",
      "960/960 [==============================] - 0s 232us/sample - loss: 0.3098 - acc: 0.8531 - val_loss: 0.2893 - val_acc: 0.8542\n",
      "Epoch 51\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 218us/sample - loss: 0.9850\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 234us/sample - loss: 0.9797\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 218us/sample - loss: 0.4904 - acc: 0.9375\n",
      "Train on 960 samples, validate on 240 samples\n",
      "960/960 [==============================] - 0s 261us/sample - loss: 0.3031 - acc: 0.8510 - val_loss: 0.2912 - val_acc: 0.8458\n",
      "Epoch 52\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 203us/sample - loss: 0.9625\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 187us/sample - loss: 0.9572\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 265us/sample - loss: 0.5125 - acc: 0.9688\n",
      "Train on 960 samples, validate on 240 samples\n",
      "960/960 [==============================] - 0s 214us/sample - loss: 0.3034 - acc: 0.8490 - val_loss: 0.2971 - val_acc: 0.8625\n",
      "Epoch 53\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 171us/sample - loss: 0.9932\n",
      "Epoch 2/2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64/64 [==============================] - 0s 218us/sample - loss: 0.9894\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 374us/sample - loss: 0.4926 - acc: 0.9844\n",
      "Train on 960 samples, validate on 240 samples\n",
      "960/960 [==============================] - 0s 343us/sample - loss: 0.3014 - acc: 0.8573 - val_loss: 0.2897 - val_acc: 0.8458\n",
      "Epoch 54\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 171us/sample - loss: 0.9797\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 203us/sample - loss: 0.9774\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 249us/sample - loss: 0.4851 - acc: 0.9688\n",
      "Train on 960 samples, validate on 240 samples\n",
      "960/960 [==============================] - 0s 213us/sample - loss: 0.3090 - acc: 0.8490 - val_loss: 0.2912 - val_acc: 0.8583\n",
      "Epoch 55\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 249us/sample - loss: 0.9769\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 452us/sample - loss: 0.9739\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 296us/sample - loss: 0.4919 - acc: 0.9375\n",
      "Train on 960 samples, validate on 240 samples\n",
      "960/960 [==============================] - 0s 204us/sample - loss: 0.2985 - acc: 0.8573 - val_loss: 0.3059 - val_acc: 0.8625\n",
      "Epoch 56\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 234us/sample - loss: 1.0118\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 265us/sample - loss: 1.0067\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 312us/sample - loss: 0.4874 - acc: 1.0000\n",
      "Train on 960 samples, validate on 240 samples\n",
      "960/960 [==============================] - 0s 237us/sample - loss: 0.3045 - acc: 0.8542 - val_loss: 0.2957 - val_acc: 0.8458\n",
      "Epoch 57\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 203us/sample - loss: 1.0139\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 312us/sample - loss: 1.0102\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 343us/sample - loss: 0.4865 - acc: 0.9688\n",
      "Train on 960 samples, validate on 240 samples\n",
      "960/960 [==============================] - 0s 215us/sample - loss: 0.2965 - acc: 0.8604 - val_loss: 0.3151 - val_acc: 0.8458\n",
      "Epoch 58\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 156us/sample - loss: 1.0069\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 218us/sample - loss: 1.0046\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 281us/sample - loss: 0.4724 - acc: 0.9844\n",
      "Train on 960 samples, validate on 240 samples\n",
      "960/960 [==============================] - 0s 284us/sample - loss: 0.3098 - acc: 0.8396 - val_loss: 0.2909 - val_acc: 0.8625\n",
      "Epoch 59\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 234us/sample - loss: 0.9748\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 218us/sample - loss: 0.9728\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 312us/sample - loss: 0.4941 - acc: 0.9844\n",
      "Train on 960 samples, validate on 240 samples\n",
      "960/960 [==============================] - 0s 234us/sample - loss: 0.3041 - acc: 0.8448 - val_loss: 0.2919 - val_acc: 0.8458\n",
      "Epoch 60\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 172us/sample - loss: 0.9991\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 187us/sample - loss: 0.9980\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 359us/sample - loss: 0.4825 - acc: 0.9844\n",
      "Train on 960 samples, validate on 240 samples\n",
      "960/960 [==============================] - 0s 205us/sample - loss: 0.3022 - acc: 0.8552 - val_loss: 0.2925 - val_acc: 0.8500\n",
      "Epoch 61\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 218us/sample - loss: 0.9941\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 249us/sample - loss: 0.9927\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 203us/sample - loss: 0.4719 - acc: 0.9844\n",
      "Train on 960 samples, validate on 240 samples\n",
      "960/960 [==============================] - 0s 210us/sample - loss: 0.3068 - acc: 0.8385 - val_loss: 0.2893 - val_acc: 0.8583\n",
      "Epoch 62\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 140us/sample - loss: 0.9706\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 171us/sample - loss: 0.9688\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 249us/sample - loss: 0.4890 - acc: 0.9531\n",
      "Train on 960 samples, validate on 240 samples\n",
      "960/960 [==============================] - 0s 239us/sample - loss: 0.2905 - acc: 0.8562 - val_loss: 0.2886 - val_acc: 0.8417\n",
      "Epoch 63\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 171us/sample - loss: 1.0135\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 280us/sample - loss: 1.0114\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 218us/sample - loss: 0.4764 - acc: 0.9844\n",
      "Train on 960 samples, validate on 240 samples\n",
      "960/960 [==============================] - 0s 294us/sample - loss: 0.2933 - acc: 0.8521 - val_loss: 0.2888 - val_acc: 0.8458\n",
      "Epoch 64\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 358us/sample - loss: 0.9543\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 281us/sample - loss: 0.9535\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 265us/sample - loss: 0.5001 - acc: 0.9844\n",
      "Train on 960 samples, validate on 240 samples\n",
      "960/960 [==============================] - 0s 215us/sample - loss: 0.2950 - acc: 0.8469 - val_loss: 0.2884 - val_acc: 0.8625\n",
      "Epoch 65\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 218us/sample - loss: 1.0231\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 218us/sample - loss: 1.0220\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 218us/sample - loss: 0.4690 - acc: 1.0000\n",
      "Train on 960 samples, validate on 240 samples\n",
      "960/960 [==============================] - 0s 201us/sample - loss: 0.2968 - acc: 0.8542 - val_loss: 0.2853 - val_acc: 0.8583\n",
      "Epoch 66\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 156us/sample - loss: 1.0265\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 218us/sample - loss: 1.0251\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 171us/sample - loss: 0.4601 - acc: 1.0000\n",
      "Train on 960 samples, validate on 240 samples\n",
      "960/960 [==============================] - 0s 206us/sample - loss: 0.2873 - acc: 0.8469 - val_loss: 0.2964 - val_acc: 0.8583\n",
      "Epoch 67\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 234us/sample - loss: 0.9996\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 187us/sample - loss: 0.9987\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 218us/sample - loss: 0.4784 - acc: 0.9688\n",
      "Train on 960 samples, validate on 240 samples\n",
      "960/960 [==============================] - 0s 209us/sample - loss: 0.2894 - acc: 0.8562 - val_loss: 0.2860 - val_acc: 0.8583\n",
      "Epoch 68\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - ETA: 0s - loss: 0.982 - 0s 218us/sample - loss: 0.9978\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 234us/sample - loss: 0.9972\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 265us/sample - loss: 0.4726 - acc: 1.0000\n",
      "Train on 960 samples, validate on 240 samples\n",
      "960/960 [==============================] - 0s 196us/sample - loss: 0.2957 - acc: 0.8406 - val_loss: 0.3295 - val_acc: 0.8375\n",
      "Epoch 69\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 187us/sample - loss: 1.0056\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 218us/sample - loss: 1.0045\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 203us/sample - loss: 0.4701 - acc: 1.0000\n",
      "Train on 960 samples, validate on 240 samples\n",
      "960/960 [==============================] - 0s 210us/sample - loss: 0.3022 - acc: 0.8479 - val_loss: 0.3287 - val_acc: 0.8417\n",
      "Epoch 70\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 187us/sample - loss: 1.0152\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 187us/sample - loss: 1.0146\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 234us/sample - loss: 0.4622 - acc: 0.9844\n",
      "Train on 960 samples, validate on 240 samples\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "960/960 [==============================] - 0s 235us/sample - loss: 0.3053 - acc: 0.8344 - val_loss: 0.2933 - val_acc: 0.8458\n",
      "Epoch 71\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 296us/sample - loss: 1.0538\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 280us/sample - loss: 1.0533\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 296us/sample - loss: 0.4397 - acc: 1.0000\n",
      "Train on 960 samples, validate on 240 samples\n",
      "960/960 [==============================] - 0s 266us/sample - loss: 0.2810 - acc: 0.8521 - val_loss: 0.2896 - val_acc: 0.8667\n",
      "Epoch 72\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 250us/sample - loss: 1.0307\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 467us/sample - loss: 1.0297\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 327us/sample - loss: 0.4574 - acc: 0.9844\n",
      "Train on 960 samples, validate on 240 samples\n",
      "960/960 [==============================] - 0s 309us/sample - loss: 0.2852 - acc: 0.8510 - val_loss: 0.2817 - val_acc: 0.8458\n",
      "Epoch 73\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 327us/sample - loss: 1.0282\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 623us/sample - loss: 1.0276\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 421us/sample - loss: 0.4543 - acc: 1.0000\n",
      "Train on 960 samples, validate on 240 samples\n",
      "960/960 [==============================] - 0s 273us/sample - loss: 0.2879 - acc: 0.8469 - val_loss: 0.2817 - val_acc: 0.8583\n",
      "Epoch 74\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 203us/sample - loss: 1.0363\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 467us/sample - loss: 1.0354\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 514us/sample - loss: 0.4576 - acc: 1.0000\n",
      "Train on 960 samples, validate on 240 samples\n",
      "960/960 [==============================] - 0s 284us/sample - loss: 0.2859 - acc: 0.8542 - val_loss: 0.2847 - val_acc: 0.8625\n",
      "Epoch 75\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 249us/sample - loss: 1.0583\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 296us/sample - loss: 1.0576\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 296us/sample - loss: 0.4447 - acc: 1.0000\n",
      "Train on 960 samples, validate on 240 samples\n",
      "960/960 [==============================] - 0s 273us/sample - loss: 0.2817 - acc: 0.8573 - val_loss: 0.2884 - val_acc: 0.8542\n",
      "Epoch 76\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 218us/sample - loss: 1.0191\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 343us/sample - loss: 1.0181\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 327us/sample - loss: 0.4592 - acc: 1.0000\n",
      "Train on 960 samples, validate on 240 samples\n",
      "960/960 [==============================] - 0s 298us/sample - loss: 0.3023 - acc: 0.8417 - val_loss: 0.2860 - val_acc: 0.8625\n",
      "Epoch 77\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 265us/sample - loss: 1.0410\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 249us/sample - loss: 1.0400\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 343us/sample - loss: 0.4465 - acc: 1.0000\n",
      "Train on 960 samples, validate on 240 samples\n",
      "960/960 [==============================] - 0s 252us/sample - loss: 0.2781 - acc: 0.8521 - val_loss: 0.2952 - val_acc: 0.8417\n",
      "Epoch 78\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 187us/sample - loss: 1.0393\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 265us/sample - loss: 1.0383\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 265us/sample - loss: 0.4510 - acc: 0.9844\n",
      "Train on 960 samples, validate on 240 samples\n",
      "960/960 [==============================] - 0s 256us/sample - loss: 0.2822 - acc: 0.8458 - val_loss: 0.2836 - val_acc: 0.8500\n",
      "Epoch 79\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 265us/sample - loss: 1.0804\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 405us/sample - loss: 1.0793\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 281us/sample - loss: 0.4258 - acc: 0.9844\n",
      "Train on 960 samples, validate on 240 samples\n",
      "960/960 [==============================] - 0s 249us/sample - loss: 0.2789 - acc: 0.8510 - val_loss: 0.2783 - val_acc: 0.8417\n",
      "Epoch 80\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 187us/sample - loss: 1.0763\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 218us/sample - loss: 1.0753\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 234us/sample - loss: 0.4379 - acc: 1.0000\n",
      "Train on 960 samples, validate on 240 samples\n",
      "960/960 [==============================] - 0s 250us/sample - loss: 0.2781 - acc: 0.8573 - val_loss: 0.3073 - val_acc: 0.8458\n",
      "Epoch 81\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 249us/sample - loss: 1.0206\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 281us/sample - loss: 1.0197\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 218us/sample - loss: 0.4603 - acc: 1.0000\n",
      "Train on 960 samples, validate on 240 samples\n",
      "960/960 [==============================] - 0s 225us/sample - loss: 0.2923 - acc: 0.8438 - val_loss: 0.2849 - val_acc: 0.8542\n",
      "Epoch 82\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 187us/sample - loss: 1.0984\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 265us/sample - loss: 1.0973\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 311us/sample - loss: 0.4238 - acc: 1.0000\n",
      "Train on 960 samples, validate on 240 samples\n",
      "960/960 [==============================] - 0s 246us/sample - loss: 0.2759 - acc: 0.8552 - val_loss: 0.2774 - val_acc: 0.8542\n",
      "Epoch 83\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 187us/sample - loss: 1.0527\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 296us/sample - loss: 1.0520\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 343us/sample - loss: 0.4417 - acc: 0.9844\n",
      "Train on 960 samples, validate on 240 samples\n",
      "960/960 [==============================] - 0s 230us/sample - loss: 0.2787 - acc: 0.8542 - val_loss: 0.2768 - val_acc: 0.8625\n",
      "Epoch 84\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 203us/sample - loss: 1.0835\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 234us/sample - loss: 1.0825\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 265us/sample - loss: 0.4281 - acc: 0.9844\n",
      "Train on 960 samples, validate on 240 samples\n",
      "960/960 [==============================] - 0s 233us/sample - loss: 0.2763 - acc: 0.8479 - val_loss: 0.2798 - val_acc: 0.8500\n",
      "Epoch 85\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 312us/sample - loss: 1.0978\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 249us/sample - loss: 1.0966\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 187us/sample - loss: 0.4254 - acc: 1.0000\n",
      "Train on 960 samples, validate on 240 samples\n",
      "960/960 [==============================] - 0s 234us/sample - loss: 0.2740 - acc: 0.8500 - val_loss: 0.2869 - val_acc: 0.8500\n",
      "Epoch 86\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 171us/sample - loss: 1.0455\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 265us/sample - loss: 1.0447\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 171us/sample - loss: 0.4455 - acc: 1.0000\n",
      "Train on 960 samples, validate on 240 samples\n",
      "960/960 [==============================] - 0s 202us/sample - loss: 0.2828 - acc: 0.8490 - val_loss: 0.2835 - val_acc: 0.8583\n",
      "Epoch 87\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 234us/sample - loss: 1.0483\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 265us/sample - loss: 1.0475\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 187us/sample - loss: 0.4447 - acc: 1.0000\n",
      "Train on 960 samples, validate on 240 samples\n",
      "960/960 [==============================] - 0s 199us/sample - loss: 0.2772 - acc: 0.8396 - val_loss: 0.2748 - val_acc: 0.8625\n",
      "Epoch 88\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 171us/sample - loss: 1.0722\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 250us/sample - loss: 1.0712\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 218us/sample - loss: 0.4321 - acc: 1.0000\n",
      "Train on 960 samples, validate on 240 samples\n",
      "960/960 [==============================] - 0s 191us/sample - loss: 0.2702 - acc: 0.8469 - val_loss: 0.2819 - val_acc: 0.8667\n",
      "Epoch 89\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 249us/sample - loss: 1.0353\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 359us/sample - loss: 1.0344\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 234us/sample - loss: 0.4546 - acc: 1.0000\n",
      "Train on 960 samples, validate on 240 samples\n",
      "960/960 [==============================] - 0s 191us/sample - loss: 0.2922 - acc: 0.8510 - val_loss: 0.2740 - val_acc: 0.8458\n",
      "Epoch 90\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 187us/sample - loss: 1.0774\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 296us/sample - loss: 1.0761\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 312us/sample - loss: 0.4289 - acc: 1.0000\n",
      "Train on 960 samples, validate on 240 samples\n",
      "960/960 [==============================] - 0s 187us/sample - loss: 0.2713 - acc: 0.8542 - val_loss: 0.2856 - val_acc: 0.8458\n",
      "Epoch 91\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 281us/sample - loss: 1.0651\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 483us/sample - loss: 1.0639\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 218us/sample - loss: 0.4352 - acc: 1.0000\n",
      "Train on 960 samples, validate on 240 samples\n",
      "960/960 [==============================] - 0s 205us/sample - loss: 0.2736 - acc: 0.8573 - val_loss: 0.2759 - val_acc: 0.8458\n",
      "Epoch 92\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 218us/sample - loss: 1.0950\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 343us/sample - loss: 1.0940\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 280us/sample - loss: 0.4200 - acc: 1.0000\n",
      "Train on 960 samples, validate on 240 samples\n",
      "960/960 [==============================] - 0s 191us/sample - loss: 0.2723 - acc: 0.8479 - val_loss: 0.2722 - val_acc: 0.8625\n",
      "Epoch 93\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 187us/sample - loss: 1.1079\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - ETA: 0s - loss: 1.078 - 0s 249us/sample - loss: 1.1072\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 296us/sample - loss: 0.4186 - acc: 1.0000\n",
      "Train on 960 samples, validate on 240 samples\n",
      "960/960 [==============================] - 0s 264us/sample - loss: 0.2658 - acc: 0.8521 - val_loss: 0.2723 - val_acc: 0.8625\n",
      "Epoch 94\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 156us/sample - loss: 1.0809\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 249us/sample - loss: 1.0802\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 265us/sample - loss: 0.4321 - acc: 0.9688\n",
      "Train on 960 samples, validate on 240 samples\n",
      "960/960 [==============================] - 0s 185us/sample - loss: 0.2681 - acc: 0.8594 - val_loss: 0.2707 - val_acc: 0.8375\n",
      "Epoch 95\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 156us/sample - loss: 1.0542\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 280us/sample - loss: 1.0535\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 296us/sample - loss: 0.4437 - acc: 1.0000\n",
      "Train on 960 samples, validate on 240 samples\n",
      "960/960 [==============================] - 0s 214us/sample - loss: 0.2685 - acc: 0.8500 - val_loss: 0.2727 - val_acc: 0.8417\n",
      "Epoch 96\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 187us/sample - loss: 1.0883\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 218us/sample - loss: 1.0873\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 202us/sample - loss: 0.4253 - acc: 1.0000\n",
      "Train on 960 samples, validate on 240 samples\n",
      "960/960 [==============================] - 0s 197us/sample - loss: 0.2703 - acc: 0.8479 - val_loss: 0.2781 - val_acc: 0.8458\n",
      "Epoch 97\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 265us/sample - loss: 1.1227\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 218us/sample - loss: 1.1213\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 281us/sample - loss: 0.4106 - acc: 1.0000\n",
      "Train on 960 samples, validate on 240 samples\n",
      "960/960 [==============================] - 0s 209us/sample - loss: 0.2682 - acc: 0.8542 - val_loss: 0.2804 - val_acc: 0.8458\n",
      "Epoch 98\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 187us/sample - loss: 1.0875\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 249us/sample - loss: 1.0867\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 249us/sample - loss: 0.4291 - acc: 1.0000\n",
      "Train on 960 samples, validate on 240 samples\n",
      "960/960 [==============================] - 0s 220us/sample - loss: 0.2845 - acc: 0.8552 - val_loss: 0.2879 - val_acc: 0.8500\n",
      "Epoch 99\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 312us/sample - loss: 1.1026\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 249us/sample - loss: 1.1020\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 234us/sample - loss: 0.4189 - acc: 1.0000\n",
      "Train on 960 samples, validate on 240 samples\n",
      "960/960 [==============================] - 0s 211us/sample - loss: 0.2695 - acc: 0.8552 - val_loss: 0.2689 - val_acc: 0.8542\n",
      "Epoch 100\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 171us/sample - loss: 1.1238\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 218us/sample - loss: 1.1231\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 218us/sample - loss: 0.4054 - acc: 1.0000\n",
      "Train on 960 samples, validate on 240 samples\n",
      "960/960 [==============================] - 0s 207us/sample - loss: 0.2645 - acc: 0.8542 - val_loss: 0.2697 - val_acc: 0.8500\n",
      "Epoch 101\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 249us/sample - loss: 1.0868\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 265us/sample - loss: 1.0860\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 218us/sample - loss: 0.4271 - acc: 1.0000\n",
      "Train on 960 samples, validate on 240 samples\n",
      "960/960 [==============================] - 0s 205us/sample - loss: 0.2727 - acc: 0.8594 - val_loss: 0.2696 - val_acc: 0.8417\n",
      "Epoch 102\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 187us/sample - loss: 1.1160\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 421us/sample - loss: 1.1151\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 250us/sample - loss: 0.4116 - acc: 1.0000\n",
      "Train on 960 samples, validate on 240 samples\n",
      "960/960 [==============================] - 0s 217us/sample - loss: 0.2604 - acc: 0.8573 - val_loss: 0.2775 - val_acc: 0.8458\n",
      "Epoch 103\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 280us/sample - loss: 1.1871\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 171us/sample - loss: 1.1857\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 265us/sample - loss: 0.3896 - acc: 1.0000\n",
      "Train on 960 samples, validate on 240 samples\n",
      "960/960 [==============================] - 0s 232us/sample - loss: 0.2742 - acc: 0.8594 - val_loss: 0.2729 - val_acc: 0.8625\n",
      "Epoch 104\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 171us/sample - loss: 1.0642\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 265us/sample - loss: 1.0632\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 187us/sample - loss: 0.4366 - acc: 1.0000\n",
      "Train on 960 samples, validate on 240 samples\n",
      "960/960 [==============================] - 0s 209us/sample - loss: 0.2618 - acc: 0.8573 - val_loss: 0.2709 - val_acc: 0.8417\n",
      "Epoch 105\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 171us/sample - loss: 1.1177\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 234us/sample - loss: 1.1167\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 296us/sample - loss: 0.4077 - acc: 1.0000\n",
      "Train on 960 samples, validate on 240 samples\n",
      "960/960 [==============================] - 0s 191us/sample - loss: 0.2730 - acc: 0.8448 - val_loss: 0.2705 - val_acc: 0.8542\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 106\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 171us/sample - loss: 1.1386\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 249us/sample - loss: 1.1376\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 296us/sample - loss: 0.4030 - acc: 0.9844\n",
      "Train on 960 samples, validate on 240 samples\n",
      "960/960 [==============================] - 0s 188us/sample - loss: 0.2793 - acc: 0.8510 - val_loss: 0.3023 - val_acc: 0.8417\n",
      "Epoch 107\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 280us/sample - loss: 1.0970\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 296us/sample - loss: 1.0959\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 281us/sample - loss: 0.4156 - acc: 1.0000\n",
      "Train on 960 samples, validate on 240 samples\n",
      "960/960 [==============================] - 0s 185us/sample - loss: 0.2713 - acc: 0.8490 - val_loss: 0.2675 - val_acc: 0.8542\n",
      "Epoch 108\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 218us/sample - loss: 1.0976\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 203us/sample - loss: 1.0960\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 452us/sample - loss: 0.4231 - acc: 1.0000\n",
      "Train on 960 samples, validate on 240 samples\n",
      "960/960 [==============================] - 0s 191us/sample - loss: 0.2655 - acc: 0.8531 - val_loss: 0.2753 - val_acc: 0.8500\n",
      "Epoch 109\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 156us/sample - loss: 1.1254\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 219us/sample - loss: 1.1241\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 374us/sample - loss: 0.4061 - acc: 1.0000\n",
      "Train on 960 samples, validate on 240 samples\n",
      "960/960 [==============================] - 0s 189us/sample - loss: 0.2602 - acc: 0.8521 - val_loss: 0.2698 - val_acc: 0.8458\n",
      "Epoch 110\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 156us/sample - loss: 1.1220\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 265us/sample - loss: 1.1207\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 265us/sample - loss: 0.4107 - acc: 1.0000\n",
      "Train on 960 samples, validate on 240 samples\n",
      "960/960 [==============================] - 0s 197us/sample - loss: 0.2603 - acc: 0.8646 - val_loss: 0.2935 - val_acc: 0.8458\n",
      "Epoch 111\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 296us/sample - loss: 1.1510\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 234us/sample - loss: 1.1502\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 499us/sample - loss: 0.3962 - acc: 1.0000\n",
      "Train on 960 samples, validate on 240 samples\n",
      "960/960 [==============================] - 0s 193us/sample - loss: 0.2708 - acc: 0.8583 - val_loss: 0.2740 - val_acc: 0.8500\n",
      "Epoch 112\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 171us/sample - loss: 1.1803\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 234us/sample - loss: 1.1790\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 250us/sample - loss: 0.3841 - acc: 1.0000\n",
      "Train on 960 samples, validate on 240 samples\n",
      "960/960 [==============================] - 0s 222us/sample - loss: 0.2585 - acc: 0.8521 - val_loss: 0.2694 - val_acc: 0.8375\n",
      "Epoch 113\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 187us/sample - loss: 1.1216\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 203us/sample - loss: 1.1207\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 265us/sample - loss: 0.4075 - acc: 1.0000\n",
      "Train on 960 samples, validate on 240 samples\n",
      "960/960 [==============================] - 0s 287us/sample - loss: 0.2627 - acc: 0.8490 - val_loss: 0.2907 - val_acc: 0.8583\n",
      "Epoch 114\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 234us/sample - loss: 1.0778\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 156us/sample - loss: 1.0766\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 234us/sample - loss: 0.4301 - acc: 1.0000\n",
      "Train on 960 samples, validate on 240 samples\n",
      "960/960 [==============================] - 0s 185us/sample - loss: 0.2718 - acc: 0.8573 - val_loss: 0.2649 - val_acc: 0.8542\n",
      "Epoch 115\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 156us/sample - loss: 1.1087\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 171us/sample - loss: 1.1075\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 265us/sample - loss: 0.4193 - acc: 0.9844\n",
      "Train on 960 samples, validate on 240 samples\n",
      "960/960 [==============================] - 0s 234us/sample - loss: 0.2583 - acc: 0.8604 - val_loss: 0.2687 - val_acc: 0.8375\n",
      "Epoch 116\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 156us/sample - loss: 1.1175\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 250us/sample - loss: 1.1163\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 234us/sample - loss: 0.4092 - acc: 1.0000\n",
      "Train on 960 samples, validate on 240 samples\n",
      "960/960 [==============================] - 0s 191us/sample - loss: 0.2635 - acc: 0.8531 - val_loss: 0.2821 - val_acc: 0.8500\n",
      "Epoch 117\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 140us/sample - loss: 1.1759\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 171us/sample - loss: 1.1748\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 202us/sample - loss: 0.3860 - acc: 1.0000\n",
      "Train on 960 samples, validate on 240 samples\n",
      "960/960 [==============================] - 0s 219us/sample - loss: 0.2667 - acc: 0.8615 - val_loss: 0.2646 - val_acc: 0.8333\n",
      "Epoch 118\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 171us/sample - loss: 1.1449\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 436us/sample - loss: 1.1443\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 203us/sample - loss: 0.3984 - acc: 1.0000\n",
      "Train on 960 samples, validate on 240 samples\n",
      "960/960 [==============================] - 0s 216us/sample - loss: 0.2556 - acc: 0.8531 - val_loss: 0.2648 - val_acc: 0.8500\n",
      "Epoch 119\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 171us/sample - loss: 1.1215\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 304us/sample - loss: 1.1210\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 280us/sample - loss: 0.4089 - acc: 1.0000\n",
      "Train on 960 samples, validate on 240 samples\n",
      "960/960 [==============================] - 0s 216us/sample - loss: 0.2600 - acc: 0.8583 - val_loss: 0.2677 - val_acc: 0.8375\n",
      "Epoch 120\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 171us/sample - loss: 1.1855\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 203us/sample - loss: 1.1846\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 234us/sample - loss: 0.3789 - acc: 1.0000\n",
      "Train on 960 samples, validate on 240 samples\n",
      "960/960 [==============================] - 0s 236us/sample - loss: 0.2559 - acc: 0.8656 - val_loss: 0.2679 - val_acc: 0.8375\n",
      "Epoch 121\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 234us/sample - loss: 1.1408\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 234us/sample - loss: 1.1397\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 234us/sample - loss: 0.3996 - acc: 1.0000\n",
      "Train on 960 samples, validate on 240 samples\n",
      "960/960 [==============================] - 0s 233us/sample - loss: 0.2599 - acc: 0.8521 - val_loss: 0.2630 - val_acc: 0.8417\n",
      "Epoch 122\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 296us/sample - loss: 1.1401\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 265us/sample - loss: 1.1387\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 203us/sample - loss: 0.3999 - acc: 1.0000\n",
      "Train on 960 samples, validate on 240 samples\n",
      "960/960 [==============================] - 0s 236us/sample - loss: 0.2557 - acc: 0.8625 - val_loss: 0.2656 - val_acc: 0.8500\n",
      "Epoch 123\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 249us/sample - loss: 1.1448\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 218us/sample - loss: 1.1446\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 390us/sample - loss: 0.3990 - acc: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 960 samples, validate on 240 samples\n",
      "960/960 [==============================] - 0s 272us/sample - loss: 0.2547 - acc: 0.8552 - val_loss: 0.2623 - val_acc: 0.8417\n",
      "Epoch 124\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 390us/sample - loss: 1.1627\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 265us/sample - loss: 1.1614\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 265us/sample - loss: 0.3915 - acc: 1.0000\n",
      "Train on 960 samples, validate on 240 samples\n",
      "960/960 [==============================] - 0s 231us/sample - loss: 0.2538 - acc: 0.8604 - val_loss: 0.2608 - val_acc: 0.8417\n",
      "Epoch 125\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 203us/sample - loss: 1.1221\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 265us/sample - loss: 1.1202\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 296us/sample - loss: 0.4084 - acc: 1.0000\n",
      "Train on 960 samples, validate on 240 samples\n",
      "960/960 [==============================] - 0s 238us/sample - loss: 0.2574 - acc: 0.8646 - val_loss: 0.2607 - val_acc: 0.8458\n",
      "Epoch 126\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 187us/sample - loss: 1.1240\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 218us/sample - loss: 1.1228\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 343us/sample - loss: 0.4094 - acc: 1.0000\n",
      "Train on 960 samples, validate on 240 samples\n",
      "960/960 [==============================] - 0s 229us/sample - loss: 0.2665 - acc: 0.8646 - val_loss: 0.2641 - val_acc: 0.8542\n",
      "Epoch 127\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 187us/sample - loss: 1.1381\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 327us/sample - loss: 1.1374\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 234us/sample - loss: 0.4006 - acc: 1.0000\n",
      "Train on 960 samples, validate on 240 samples\n",
      "960/960 [==============================] - 0s 206us/sample - loss: 0.2540 - acc: 0.8635 - val_loss: 0.2696 - val_acc: 0.8542\n",
      "Epoch 128\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 358us/sample - loss: 1.1699\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 312us/sample - loss: 1.1682\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 436us/sample - loss: 0.3888 - acc: 1.0000\n",
      "Train on 960 samples, validate on 240 samples\n",
      "960/960 [==============================] - 0s 233us/sample - loss: 0.2489 - acc: 0.8698 - val_loss: 0.2611 - val_acc: 0.8542\n",
      "Epoch 129\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 187us/sample - loss: 1.1353\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 265us/sample - loss: 1.1334\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 249us/sample - loss: 0.4032 - acc: 1.0000\n",
      "Train on 960 samples, validate on 240 samples\n",
      "960/960 [==============================] - 0s 188us/sample - loss: 0.2551 - acc: 0.8583 - val_loss: 0.2634 - val_acc: 0.8542\n",
      "Epoch 130\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 156us/sample - loss: 1.1298\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 280us/sample - loss: 1.1284\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 312us/sample - loss: 0.4036 - acc: 1.0000\n",
      "Train on 960 samples, validate on 240 samples\n",
      "960/960 [==============================] - 0s 212us/sample - loss: 0.2488 - acc: 0.8677 - val_loss: 0.2700 - val_acc: 0.8583\n",
      "Epoch 131\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 156us/sample - loss: 1.1981\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 203us/sample - loss: 1.1967\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 296us/sample - loss: 0.3808 - acc: 1.0000\n",
      "Train on 960 samples, validate on 240 samples\n",
      "960/960 [==============================] - 0s 234us/sample - loss: 0.2545 - acc: 0.8625 - val_loss: 0.2691 - val_acc: 0.8583\n",
      "Epoch 132\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 218us/sample - loss: 1.1335\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 171us/sample - loss: 1.1332\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 327us/sample - loss: 0.4040 - acc: 1.0000\n",
      "Train on 960 samples, validate on 240 samples\n",
      "960/960 [==============================] - 0s 190us/sample - loss: 0.2533 - acc: 0.8646 - val_loss: 0.2624 - val_acc: 0.8583\n",
      "Epoch 133\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 140us/sample - loss: 1.1513\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 171us/sample - loss: 1.1502\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 218us/sample - loss: 0.3951 - acc: 1.0000\n",
      "Train on 960 samples, validate on 240 samples\n",
      "960/960 [==============================] - 0s 270us/sample - loss: 0.2498 - acc: 0.8646 - val_loss: 0.2604 - val_acc: 0.8542\n",
      "Epoch 134\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 203us/sample - loss: 1.1870\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 203us/sample - loss: 1.1857\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 234us/sample - loss: 0.3795 - acc: 1.0000\n",
      "Train on 960 samples, validate on 240 samples\n",
      "960/960 [==============================] - 0s 217us/sample - loss: 0.2474 - acc: 0.8719 - val_loss: 0.2592 - val_acc: 0.8333\n",
      "Epoch 135\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 218us/sample - loss: 1.1416\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 156us/sample - loss: 1.1403\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 171us/sample - loss: 0.3963 - acc: 1.0000\n",
      "Train on 960 samples, validate on 240 samples\n",
      "960/960 [==============================] - 0s 194us/sample - loss: 0.2494 - acc: 0.8667 - val_loss: 0.2582 - val_acc: 0.8417\n",
      "Epoch 136\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 203us/sample - loss: 1.2063\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 234us/sample - loss: 1.2048\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 203us/sample - loss: 0.3680 - acc: 1.0000\n",
      "Train on 960 samples, validate on 240 samples\n",
      "960/960 [==============================] - 0s 222us/sample - loss: 0.2520 - acc: 0.8698 - val_loss: 0.2668 - val_acc: 0.8542\n",
      "Epoch 137\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 187us/sample - loss: 1.1274\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 234us/sample - loss: 1.1260\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 218us/sample - loss: 0.4053 - acc: 1.0000\n",
      "Train on 960 samples, validate on 240 samples\n",
      "960/960 [==============================] - 0s 196us/sample - loss: 0.2512 - acc: 0.8646 - val_loss: 0.2698 - val_acc: 0.8458\n",
      "Epoch 138\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 171us/sample - loss: 1.1909\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 249us/sample - loss: 1.1891\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 234us/sample - loss: 0.3758 - acc: 1.0000\n",
      "Train on 960 samples, validate on 240 samples\n",
      "960/960 [==============================] - 0s 205us/sample - loss: 0.2562 - acc: 0.8719 - val_loss: 0.2583 - val_acc: 0.8375\n",
      "Epoch 139\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 203us/sample - loss: 1.1997\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 202us/sample - loss: 1.1969\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 281us/sample - loss: 0.3707 - acc: 1.0000\n",
      "Train on 960 samples, validate on 240 samples\n",
      "960/960 [==============================] - 0s 218us/sample - loss: 0.2546 - acc: 0.8667 - val_loss: 0.2568 - val_acc: 0.8500\n",
      "Epoch 140\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 171us/sample - loss: 1.1850\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 171us/sample - loss: 1.1836\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 218us/sample - loss: 0.3770 - acc: 1.0000\n",
      "Train on 960 samples, validate on 240 samples\n",
      "960/960 [==============================] - 0s 198us/sample - loss: 0.2476 - acc: 0.8698 - val_loss: 0.2617 - val_acc: 0.8333\n",
      "Epoch 141\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 156us/sample - loss: 1.2480\n",
      "Epoch 2/2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64/64 [==============================] - 0s 156us/sample - loss: 1.2463\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 249us/sample - loss: 0.3539 - acc: 1.0000\n",
      "Train on 960 samples, validate on 240 samples\n",
      "960/960 [==============================] - 0s 188us/sample - loss: 0.2666 - acc: 0.8500 - val_loss: 0.2683 - val_acc: 0.8667\n",
      "Epoch 142\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 234us/sample - loss: 1.1360\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 249us/sample - loss: 1.1341\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 265us/sample - loss: 0.4033 - acc: 1.0000\n",
      "Train on 960 samples, validate on 240 samples\n",
      "960/960 [==============================] - 0s 216us/sample - loss: 0.2488 - acc: 0.8573 - val_loss: 0.2658 - val_acc: 0.8417\n",
      "Epoch 143\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 140us/sample - loss: 1.2494\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 234us/sample - loss: 1.2476\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 280us/sample - loss: 0.3561 - acc: 1.0000\n",
      "Train on 960 samples, validate on 240 samples\n",
      "960/960 [==============================] - 0s 246us/sample - loss: 0.2536 - acc: 0.8708 - val_loss: 0.2572 - val_acc: 0.8625\n",
      "Epoch 144\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 280us/sample - loss: 1.1633\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 281us/sample - loss: 1.1616\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 359us/sample - loss: 0.3893 - acc: 0.9844\n",
      "Train on 960 samples, validate on 240 samples\n",
      "960/960 [==============================] - 0s 218us/sample - loss: 0.2567 - acc: 0.8677 - val_loss: 0.2589 - val_acc: 0.8542\n",
      "Epoch 145\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 156us/sample - loss: 1.1912\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 249us/sample - loss: 1.1888\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 358us/sample - loss: 0.3847 - acc: 1.0000\n",
      "Train on 960 samples, validate on 240 samples\n",
      "960/960 [==============================] - 0s 183us/sample - loss: 0.2547 - acc: 0.8615 - val_loss: 0.2574 - val_acc: 0.8500\n",
      "Epoch 146\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 203us/sample - loss: 1.1937\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 234us/sample - loss: 1.1923\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 249us/sample - loss: 0.3721 - acc: 1.0000\n",
      "Train on 960 samples, validate on 240 samples\n",
      "960/960 [==============================] - 0s 201us/sample - loss: 0.2479 - acc: 0.8635 - val_loss: 0.2756 - val_acc: 0.8667\n",
      "Epoch 147\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 187us/sample - loss: 1.1479\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 187us/sample - loss: 1.1460\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 265us/sample - loss: 0.3966 - acc: 1.0000\n",
      "Train on 960 samples, validate on 240 samples\n",
      "960/960 [==============================] - 0s 209us/sample - loss: 0.2605 - acc: 0.8615 - val_loss: 0.2545 - val_acc: 0.8625\n",
      "Epoch 148\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 140us/sample - loss: 1.1963\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 156us/sample - loss: 1.1932\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 280us/sample - loss: 0.3790 - acc: 1.0000\n",
      "Train on 960 samples, validate on 240 samples\n",
      "960/960 [==============================] - 0s 186us/sample - loss: 0.2535 - acc: 0.8719 - val_loss: 0.2545 - val_acc: 0.8708\n",
      "Epoch 149\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 187us/sample - loss: 1.1991\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 234us/sample - loss: 1.1964\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 249us/sample - loss: 0.3727 - acc: 1.0000\n",
      "Train on 960 samples, validate on 240 samples\n",
      "960/960 [==============================] - 0s 211us/sample - loss: 0.2472 - acc: 0.8708 - val_loss: 0.2737 - val_acc: 0.8542\n",
      "Epoch 150\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 171us/sample - loss: 1.1698\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 218us/sample - loss: 1.1676\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 359us/sample - loss: 0.3857 - acc: 1.0000\n",
      "Train on 960 samples, validate on 240 samples\n",
      "960/960 [==============================] - 0s 185us/sample - loss: 0.2473 - acc: 0.8750 - val_loss: 0.2580 - val_acc: 0.8458\n",
      "Epoch 151\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 171us/sample - loss: 1.1817\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 249us/sample - loss: 1.1796\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 218us/sample - loss: 0.3803 - acc: 1.0000\n",
      "Train on 960 samples, validate on 240 samples\n",
      "960/960 [==============================] - 0s 187us/sample - loss: 0.2525 - acc: 0.8740 - val_loss: 0.2541 - val_acc: 0.8667\n",
      "Epoch 152\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 156us/sample - loss: 1.1689\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 218us/sample - loss: 1.1664\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 296us/sample - loss: 0.3855 - acc: 1.0000\n",
      "Train on 960 samples, validate on 240 samples\n",
      "960/960 [==============================] - 0s 218us/sample - loss: 0.2449 - acc: 0.8635 - val_loss: 0.2528 - val_acc: 0.8583\n",
      "Epoch 153\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 218us/sample - loss: 1.2036\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 234us/sample - loss: 1.2002\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 249us/sample - loss: 0.3692 - acc: 1.0000\n",
      "Train on 960 samples, validate on 240 samples\n",
      "960/960 [==============================] - 0s 267us/sample - loss: 0.2420 - acc: 0.8646 - val_loss: 0.2542 - val_acc: 0.8833\n",
      "Epoch 154\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 203us/sample - loss: 1.1795\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 312us/sample - loss: 1.1767\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 249us/sample - loss: 0.3828 - acc: 1.0000\n",
      "Train on 960 samples, validate on 240 samples\n",
      "960/960 [==============================] - 0s 191us/sample - loss: 0.2414 - acc: 0.8823 - val_loss: 0.2546 - val_acc: 0.8667\n",
      "Epoch 155\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 171us/sample - loss: 1.1993\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 234us/sample - loss: 1.1947\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 265us/sample - loss: 0.3726 - acc: 1.0000\n",
      "Train on 960 samples, validate on 240 samples\n",
      "960/960 [==============================] - 0s 202us/sample - loss: 0.2478 - acc: 0.8667 - val_loss: 0.2533 - val_acc: 0.8583\n",
      "Epoch 156\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 203us/sample - loss: 1.1720\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 218us/sample - loss: 1.1708\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 249us/sample - loss: 0.3830 - acc: 1.0000\n",
      "Train on 960 samples, validate on 240 samples\n",
      "960/960 [==============================] - 0s 195us/sample - loss: 0.2465 - acc: 0.8656 - val_loss: 0.2601 - val_acc: 0.8708\n",
      "Epoch 157\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 171us/sample - loss: 1.1568\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 296us/sample - loss: 1.1543\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 218us/sample - loss: 0.3938 - acc: 1.0000\n",
      "Train on 960 samples, validate on 240 samples\n",
      "960/960 [==============================] - 0s 199us/sample - loss: 0.2447 - acc: 0.8750 - val_loss: 0.2583 - val_acc: 0.8417\n",
      "Epoch 158\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 156us/sample - loss: 1.2241\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 265us/sample - loss: 1.2202\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 203us/sample - loss: 0.3616 - acc: 1.0000\n",
      "Train on 960 samples, validate on 240 samples\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "960/960 [==============================] - 0s 226us/sample - loss: 0.2440 - acc: 0.8719 - val_loss: 0.2562 - val_acc: 0.8667\n",
      "Epoch 159\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 218us/sample - loss: 1.1508\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 343us/sample - loss: 1.1472\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 203us/sample - loss: 0.3948 - acc: 1.0000\n",
      "Train on 960 samples, validate on 240 samples\n",
      "960/960 [==============================] - 0s 173us/sample - loss: 0.2442 - acc: 0.8729 - val_loss: 0.2665 - val_acc: 0.8667\n",
      "Epoch 160\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 140us/sample - loss: 1.1465\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 218us/sample - loss: 1.1440\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 281us/sample - loss: 0.3958 - acc: 1.0000\n",
      "Train on 960 samples, validate on 240 samples\n",
      "960/960 [==============================] - 0s 206us/sample - loss: 0.2431 - acc: 0.8729 - val_loss: 0.2514 - val_acc: 0.8500\n",
      "Epoch 161\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 280us/sample - loss: 1.1389\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 312us/sample - loss: 1.1352\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 203us/sample - loss: 0.3984 - acc: 1.0000\n",
      "Train on 960 samples, validate on 240 samples\n",
      "960/960 [==============================] - 0s 210us/sample - loss: 0.2519 - acc: 0.8719 - val_loss: 0.2526 - val_acc: 0.8625\n",
      "Epoch 162\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 281us/sample - loss: 1.1633\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 312us/sample - loss: 1.1603\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 312us/sample - loss: 0.3900 - acc: 1.0000\n",
      "Train on 960 samples, validate on 240 samples\n",
      "960/960 [==============================] - 0s 183us/sample - loss: 0.2484 - acc: 0.8698 - val_loss: 0.2695 - val_acc: 0.8792\n",
      "Epoch 163\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 234us/sample - loss: 1.1279\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 327us/sample - loss: 1.1249\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 296us/sample - loss: 0.4021 - acc: 1.0000\n",
      "Train on 960 samples, validate on 240 samples\n",
      "960/960 [==============================] - 0s 275us/sample - loss: 0.2562 - acc: 0.8635 - val_loss: 0.2523 - val_acc: 0.8500\n",
      "Epoch 164\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 156us/sample - loss: 1.1896\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 249us/sample - loss: 1.1863\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 280us/sample - loss: 0.3702 - acc: 1.0000\n",
      "Train on 960 samples, validate on 240 samples\n",
      "960/960 [==============================] - 0s 219us/sample - loss: 0.2449 - acc: 0.8760 - val_loss: 0.2596 - val_acc: 0.8667\n",
      "Epoch 165\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 171us/sample - loss: 1.1676\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 234us/sample - loss: 1.1647\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 265us/sample - loss: 0.3829 - acc: 1.0000\n",
      "Train on 960 samples, validate on 240 samples\n",
      "960/960 [==============================] - 0s 234us/sample - loss: 0.2522 - acc: 0.8750 - val_loss: 0.2549 - val_acc: 0.8417\n",
      "Epoch 166\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 218us/sample - loss: 1.1198\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 249us/sample - loss: 1.1176\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 187us/sample - loss: 0.3986 - acc: 1.0000\n",
      "Train on 960 samples, validate on 240 samples\n",
      "960/960 [==============================] - 0s 218us/sample - loss: 0.2489 - acc: 0.8646 - val_loss: 0.2646 - val_acc: 0.8375\n",
      "Epoch 167\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 249us/sample - loss: 1.1616\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 280us/sample - loss: 1.1585\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 265us/sample - loss: 0.3871 - acc: 1.0000\n",
      "Train on 960 samples, validate on 240 samples\n",
      "960/960 [==============================] - 0s 245us/sample - loss: 0.2412 - acc: 0.8760 - val_loss: 0.2516 - val_acc: 0.8542\n",
      "Epoch 168\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 218us/sample - loss: 1.2233\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 327us/sample - loss: 1.2201\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 249us/sample - loss: 0.3611 - acc: 1.0000\n",
      "Train on 960 samples, validate on 240 samples\n",
      "960/960 [==============================] - 0s 234us/sample - loss: 0.2403 - acc: 0.8750 - val_loss: 0.2499 - val_acc: 0.8667\n",
      "Epoch 169\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 203us/sample - loss: 1.1465\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 296us/sample - loss: 1.1444\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 203us/sample - loss: 0.3897 - acc: 1.0000\n",
      "Train on 960 samples, validate on 240 samples\n",
      "960/960 [==============================] - 0s 240us/sample - loss: 0.2447 - acc: 0.8771 - val_loss: 0.2596 - val_acc: 0.8667\n",
      "Epoch 170\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 187us/sample - loss: 1.1531\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 265us/sample - loss: 1.1496\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 249us/sample - loss: 0.3918 - acc: 1.0000\n",
      "Train on 960 samples, validate on 240 samples\n",
      "960/960 [==============================] - 0s 253us/sample - loss: 0.2466 - acc: 0.8760 - val_loss: 0.2517 - val_acc: 0.8708\n",
      "Epoch 171\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 187us/sample - loss: 1.1252\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 265us/sample - loss: 1.1232\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 249us/sample - loss: 0.4003 - acc: 1.0000\n",
      "Train on 960 samples, validate on 240 samples\n",
      "960/960 [==============================] - 0s 232us/sample - loss: 0.2535 - acc: 0.8750 - val_loss: 0.2498 - val_acc: 0.8542\n",
      "Epoch 172\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 234us/sample - loss: 1.1932\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 265us/sample - loss: 1.1891\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 327us/sample - loss: 0.3724 - acc: 1.0000\n",
      "Train on 960 samples, validate on 240 samples\n",
      "960/960 [==============================] - 0s 241us/sample - loss: 0.2383 - acc: 0.8802 - val_loss: 0.2515 - val_acc: 0.8750\n",
      "Epoch 173\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 265us/sample - loss: 1.1617\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 296us/sample - loss: 1.1589\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 530us/sample - loss: 0.3834 - acc: 1.0000\n",
      "Train on 960 samples, validate on 240 samples\n",
      "960/960 [==============================] - 0s 316us/sample - loss: 0.2433 - acc: 0.8802 - val_loss: 0.2543 - val_acc: 0.8583\n",
      "Epoch 174\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 218us/sample - loss: 1.1377\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 265us/sample - loss: 1.1346\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 281us/sample - loss: 0.3977 - acc: 1.0000\n",
      "Train on 960 samples, validate on 240 samples\n",
      "960/960 [==============================] - 0s 252us/sample - loss: 0.2380 - acc: 0.8771 - val_loss: 0.2496 - val_acc: 0.8708\n",
      "Epoch 175\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 249us/sample - loss: 1.1318\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 296us/sample - loss: 1.1294\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 234us/sample - loss: 0.4005 - acc: 1.0000\n",
      "Train on 960 samples, validate on 240 samples\n",
      "960/960 [==============================] - 0s 241us/sample - loss: 0.2394 - acc: 0.8771 - val_loss: 0.2495 - val_acc: 0.8625\n",
      "Epoch 176\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 343us/sample - loss: 1.1488\n",
      "Epoch 2/2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64/64 [==============================] - 0s 249us/sample - loss: 1.1471\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 390us/sample - loss: 0.3884 - acc: 1.0000\n",
      "Train on 960 samples, validate on 240 samples\n",
      "960/960 [==============================] - 0s 259us/sample - loss: 0.2384 - acc: 0.8802 - val_loss: 0.2501 - val_acc: 0.8625\n",
      "Epoch 177\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 312us/sample - loss: 1.1637\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 296us/sample - loss: 1.1615\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 249us/sample - loss: 0.3815 - acc: 1.0000\n",
      "Train on 960 samples, validate on 240 samples\n",
      "960/960 [==============================] - 0s 253us/sample - loss: 0.2441 - acc: 0.8698 - val_loss: 0.2560 - val_acc: 0.8750\n",
      "Epoch 178\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 265us/sample - loss: 1.1725\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 296us/sample - loss: 1.1705\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 327us/sample - loss: 0.3769 - acc: 1.0000\n",
      "Train on 960 samples, validate on 240 samples\n",
      "960/960 [==============================] - 0s 213us/sample - loss: 0.2400 - acc: 0.8771 - val_loss: 0.2525 - val_acc: 0.8583\n",
      "Epoch 179\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 203us/sample - loss: 1.1551\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 296us/sample - loss: 1.1516\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 296us/sample - loss: 0.3851 - acc: 1.0000\n",
      "Train on 960 samples, validate on 240 samples\n",
      "960/960 [==============================] - 0s 232us/sample - loss: 0.2371 - acc: 0.8677 - val_loss: 0.2558 - val_acc: 0.8750\n",
      "Epoch 180\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 140us/sample - loss: 1.1987\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 234us/sample - loss: 1.1959\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 280us/sample - loss: 0.3759 - acc: 1.0000\n",
      "Train on 960 samples, validate on 240 samples\n",
      "960/960 [==============================] - 0s 188us/sample - loss: 0.2479 - acc: 0.8740 - val_loss: 0.2552 - val_acc: 0.8417\n",
      "Epoch 181\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 249us/sample - loss: 1.1905\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 234us/sample - loss: 1.1871\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 249us/sample - loss: 0.3693 - acc: 0.9844\n",
      "Train on 960 samples, validate on 240 samples\n",
      "960/960 [==============================] - 0s 191us/sample - loss: 0.2417 - acc: 0.8719 - val_loss: 0.2572 - val_acc: 0.8667\n",
      "Epoch 182\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 327us/sample - loss: 1.1634\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 358us/sample - loss: 1.1605\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 265us/sample - loss: 0.3820 - acc: 1.0000\n",
      "Train on 960 samples, validate on 240 samples\n",
      "960/960 [==============================] - 0s 183us/sample - loss: 0.2355 - acc: 0.8865 - val_loss: 0.2498 - val_acc: 0.8833\n",
      "Epoch 183\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 171us/sample - loss: 1.1791\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 203us/sample - loss: 1.1767\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 265us/sample - loss: 0.3762 - acc: 1.0000\n",
      "Train on 960 samples, validate on 240 samples\n",
      "960/960 [==============================] - 0s 268us/sample - loss: 0.2435 - acc: 0.8760 - val_loss: 0.2523 - val_acc: 0.8542\n",
      "Epoch 184\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 187us/sample - loss: 1.1600\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 296us/sample - loss: 1.1583\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 249us/sample - loss: 0.3801 - acc: 1.0000\n",
      "Train on 960 samples, validate on 240 samples\n",
      "960/960 [==============================] - 0s 211us/sample - loss: 0.2387 - acc: 0.8760 - val_loss: 0.2654 - val_acc: 0.8625\n",
      "Epoch 185\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 187us/sample - loss: 1.1551\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 249us/sample - loss: 1.1527\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 265us/sample - loss: 0.3883 - acc: 1.0000\n",
      "Train on 960 samples, validate on 240 samples\n",
      "960/960 [==============================] - 0s 189us/sample - loss: 0.2496 - acc: 0.8635 - val_loss: 0.2583 - val_acc: 0.8542\n",
      "Epoch 186\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 187us/sample - loss: 1.1743\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 156us/sample - loss: 1.1716\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 265us/sample - loss: 0.3753 - acc: 1.0000\n",
      "Train on 960 samples, validate on 240 samples\n",
      "960/960 [==============================] - 0s 219us/sample - loss: 0.2492 - acc: 0.8646 - val_loss: 0.2933 - val_acc: 0.8542\n",
      "Epoch 187\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 171us/sample - loss: 1.1901\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 234us/sample - loss: 1.1881\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 249us/sample - loss: 0.3695 - acc: 1.0000\n",
      "Train on 960 samples, validate on 240 samples\n",
      "960/960 [==============================] - 0s 210us/sample - loss: 0.2382 - acc: 0.8781 - val_loss: 0.2469 - val_acc: 0.8750\n",
      "Epoch 188\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 218us/sample - loss: 1.1699\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 265us/sample - loss: 1.1685\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 249us/sample - loss: 0.3760 - acc: 1.0000\n",
      "Train on 960 samples, validate on 240 samples\n",
      "960/960 [==============================] - 0s 184us/sample - loss: 0.2499 - acc: 0.8771 - val_loss: 0.2521 - val_acc: 0.8708\n",
      "Epoch 189\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 265us/sample - loss: 1.1423\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 171us/sample - loss: 1.1379\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 218us/sample - loss: 0.3937 - acc: 1.0000\n",
      "Train on 960 samples, validate on 240 samples\n",
      "960/960 [==============================] - 0s 248us/sample - loss: 0.2517 - acc: 0.8667 - val_loss: 0.2551 - val_acc: 0.8542\n",
      "Epoch 190\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 249us/sample - loss: 1.1621\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 234us/sample - loss: 1.1599\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 218us/sample - loss: 0.3840 - acc: 0.9844\n",
      "Train on 960 samples, validate on 240 samples\n",
      "960/960 [==============================] - 0s 212us/sample - loss: 0.2507 - acc: 0.8750 - val_loss: 0.2530 - val_acc: 0.8542\n",
      "Epoch 191\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 156us/sample - loss: 1.1514\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 265us/sample - loss: 1.1484\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 234us/sample - loss: 0.3850 - acc: 1.0000\n",
      "Train on 960 samples, validate on 240 samples\n",
      "960/960 [==============================] - 0s 222us/sample - loss: 0.2362 - acc: 0.8771 - val_loss: 0.2475 - val_acc: 0.8583\n",
      "Epoch 192\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 171us/sample - loss: 1.1294\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 203us/sample - loss: 1.1256\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 171us/sample - loss: 0.3951 - acc: 1.0000\n",
      "Train on 960 samples, validate on 240 samples\n",
      "960/960 [==============================] - 0s 195us/sample - loss: 0.2320 - acc: 0.8823 - val_loss: 0.2648 - val_acc: 0.8667\n",
      "Epoch 193\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 218us/sample - loss: 1.1222\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 203us/sample - loss: 1.1197\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 686us/sample - loss: 0.4073 - acc: 0.9844\n",
      "Train on 960 samples, validate on 240 samples\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "960/960 [==============================] - 0s 299us/sample - loss: 0.2471 - acc: 0.8646 - val_loss: 0.2471 - val_acc: 0.8708\n",
      "Epoch 194\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 140us/sample - loss: 1.1103\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 203us/sample - loss: 1.1076\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 312us/sample - loss: 0.4111 - acc: 0.9844\n",
      "Train on 960 samples, validate on 240 samples\n",
      "960/960 [==============================] - 0s 213us/sample - loss: 0.2391 - acc: 0.8740 - val_loss: 0.2485 - val_acc: 0.8625\n",
      "Epoch 195\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 140us/sample - loss: 1.1682\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 249us/sample - loss: 1.1644\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 234us/sample - loss: 0.3806 - acc: 0.9844\n",
      "Train on 960 samples, validate on 240 samples\n",
      "960/960 [==============================] - 0s 221us/sample - loss: 0.2367 - acc: 0.8802 - val_loss: 0.2520 - val_acc: 0.8542\n",
      "Epoch 196\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 249us/sample - loss: 1.1674\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 187us/sample - loss: 1.1664\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 280us/sample - loss: 0.3858 - acc: 0.9844\n",
      "Train on 960 samples, validate on 240 samples\n",
      "960/960 [==============================] - 0s 229us/sample - loss: 0.2422 - acc: 0.8719 - val_loss: 0.2628 - val_acc: 0.8542\n",
      "Epoch 197\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 187us/sample - loss: 1.1926\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 234us/sample - loss: 1.1905\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 296us/sample - loss: 0.3796 - acc: 1.0000\n",
      "Train on 960 samples, validate on 240 samples\n",
      "960/960 [==============================] - 0s 190us/sample - loss: 0.2323 - acc: 0.8833 - val_loss: 0.2494 - val_acc: 0.8625\n",
      "Epoch 198\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 187us/sample - loss: 1.1667\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 234us/sample - loss: 1.1614\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 327us/sample - loss: 0.3799 - acc: 0.9844\n",
      "Train on 960 samples, validate on 240 samples\n",
      "960/960 [==============================] - 0s 184us/sample - loss: 0.2389 - acc: 0.8740 - val_loss: 0.2617 - val_acc: 0.8500\n",
      "Epoch 199\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 187us/sample - loss: 1.1999\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 265us/sample - loss: 1.1953\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 234us/sample - loss: 0.3624 - acc: 1.0000\n",
      "Train on 960 samples, validate on 240 samples\n",
      "960/960 [==============================] - 0s 188us/sample - loss: 0.2467 - acc: 0.8771 - val_loss: 0.2457 - val_acc: 0.8792\n",
      "Epoch 200\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 171us/sample - loss: 1.1888\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 218us/sample - loss: 1.1858\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 249us/sample - loss: 0.3770 - acc: 0.9688\n",
      "Train on 960 samples, validate on 240 samples\n",
      "960/960 [==============================] - 0s 196us/sample - loss: 0.2333 - acc: 0.8865 - val_loss: 0.2496 - val_acc: 0.8542\n",
      "Epoch 201\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 187us/sample - loss: 1.1868\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - ETA: 0s - loss: 1.175 - 0s 249us/sample - loss: 1.1798\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 327us/sample - loss: 0.3727 - acc: 1.0000\n",
      "Train on 960 samples, validate on 240 samples\n",
      "960/960 [==============================] - 0s 208us/sample - loss: 0.2345 - acc: 0.8833 - val_loss: 0.2479 - val_acc: 0.8708\n",
      "Epoch 202\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 218us/sample - loss: 1.1968\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 234us/sample - loss: 1.1949\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 218us/sample - loss: 0.3700 - acc: 1.0000\n",
      "Train on 960 samples, validate on 240 samples\n",
      "960/960 [==============================] - 0s 240us/sample - loss: 0.2437 - acc: 0.8740 - val_loss: 0.2541 - val_acc: 0.8542\n",
      "Epoch 203\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 249us/sample - loss: 1.2239\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 281us/sample - loss: 1.2231\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 312us/sample - loss: 0.3526 - acc: 1.0000\n",
      "Train on 960 samples, validate on 240 samples\n",
      "960/960 [==============================] - 0s 214us/sample - loss: 0.2564 - acc: 0.8625 - val_loss: 0.2503 - val_acc: 0.8500\n",
      "Epoch 204\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 218us/sample - loss: 1.2262\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 343us/sample - loss: 1.2244\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 265us/sample - loss: 0.3543 - acc: 1.0000\n",
      "Train on 960 samples, validate on 240 samples\n",
      "960/960 [==============================] - 0s 216us/sample - loss: 0.2460 - acc: 0.8760 - val_loss: 0.2451 - val_acc: 0.8667\n",
      "Epoch 205\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 218us/sample - loss: 1.1647\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 187us/sample - loss: 1.1621\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 249us/sample - loss: 0.3808 - acc: 1.0000\n",
      "Train on 960 samples, validate on 240 samples\n",
      "960/960 [==============================] - 0s 221us/sample - loss: 0.2341 - acc: 0.8771 - val_loss: 0.2459 - val_acc: 0.8708\n",
      "Epoch 206\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 249us/sample - loss: 1.2061\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 265us/sample - loss: 1.2031\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 234us/sample - loss: 0.3613 - acc: 1.0000\n",
      "Train on 960 samples, validate on 240 samples\n",
      "960/960 [==============================] - 0s 220us/sample - loss: 0.2408 - acc: 0.8771 - val_loss: 0.2641 - val_acc: 0.8583\n",
      "Epoch 207\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 171us/sample - loss: 1.1318\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 343us/sample - loss: 1.1278\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 203us/sample - loss: 0.4008 - acc: 0.9844\n",
      "Train on 960 samples, validate on 240 samples\n",
      "960/960 [==============================] - 0s 223us/sample - loss: 0.2432 - acc: 0.8781 - val_loss: 0.2461 - val_acc: 0.8708\n",
      "Epoch 208\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 187us/sample - loss: 1.1703\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 296us/sample - loss: 1.1658\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 156us/sample - loss: 0.3797 - acc: 0.9844\n",
      "Train on 960 samples, validate on 240 samples\n",
      "960/960 [==============================] - 0s 194us/sample - loss: 0.2331 - acc: 0.8833 - val_loss: 0.2448 - val_acc: 0.8667\n",
      "Epoch 209\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 187us/sample - loss: 1.1505\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 234us/sample - loss: 1.1488\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 218us/sample - loss: 0.3883 - acc: 0.9844\n",
      "Train on 960 samples, validate on 240 samples\n",
      "960/960 [==============================] - 0s 212us/sample - loss: 0.2405 - acc: 0.8802 - val_loss: 0.2588 - val_acc: 0.8625\n",
      "Epoch 210\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 171us/sample - loss: 1.1469\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 156us/sample - loss: 1.1459\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 249us/sample - loss: 0.3911 - acc: 1.0000\n",
      "Train on 960 samples, validate on 240 samples\n",
      "960/960 [==============================] - 0s 191us/sample - loss: 0.2373 - acc: 0.8771 - val_loss: 0.2611 - val_acc: 0.8625\n",
      "Epoch 211\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 156us/sample - loss: 1.1897\n",
      "Epoch 2/2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64/64 [==============================] - 0s 156us/sample - loss: 1.1881\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 249us/sample - loss: 0.3738 - acc: 0.9844\n",
      "Train on 960 samples, validate on 240 samples\n",
      "960/960 [==============================] - 0s 206us/sample - loss: 0.2332 - acc: 0.8792 - val_loss: 0.2453 - val_acc: 0.8792\n",
      "Epoch 212\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 234us/sample - loss: 1.1655\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 312us/sample - loss: 1.1636\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 312us/sample - loss: 0.3789 - acc: 1.0000\n",
      "Train on 960 samples, validate on 240 samples\n",
      "960/960 [==============================] - 0s 190us/sample - loss: 0.2340 - acc: 0.8760 - val_loss: 0.2446 - val_acc: 0.8667\n",
      "Epoch 213\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 249us/sample - loss: 1.2211\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 296us/sample - loss: 1.2172\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 312us/sample - loss: 0.3588 - acc: 0.9688\n",
      "Train on 960 samples, validate on 240 samples\n",
      "960/960 [==============================] - 0s 273us/sample - loss: 0.2325 - acc: 0.8865 - val_loss: 0.2598 - val_acc: 0.8625\n",
      "Epoch 214\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 203us/sample - loss: 1.1614\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 234us/sample - loss: 1.1576\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 296us/sample - loss: 0.3919 - acc: 0.9375\n",
      "Train on 960 samples, validate on 240 samples\n",
      "960/960 [==============================] - 0s 201us/sample - loss: 0.2427 - acc: 0.8687 - val_loss: 0.2752 - val_acc: 0.8500\n",
      "Epoch 215\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 296us/sample - loss: 1.2271\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 281us/sample - loss: 1.2255\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 249us/sample - loss: 0.3532 - acc: 1.0000\n",
      "Train on 960 samples, validate on 240 samples\n",
      "960/960 [==============================] - 0s 226us/sample - loss: 0.2430 - acc: 0.8729 - val_loss: 0.2460 - val_acc: 0.8583\n",
      "Epoch 216\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 234us/sample - loss: 1.1703\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 218us/sample - loss: 1.1684\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 202us/sample - loss: 0.3786 - acc: 1.0000\n",
      "Train on 960 samples, validate on 240 samples\n",
      "960/960 [==============================] - 0s 192us/sample - loss: 0.2333 - acc: 0.8771 - val_loss: 0.2827 - val_acc: 0.8625\n",
      "Epoch 217\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 218us/sample - loss: 1.1834\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 312us/sample - loss: 1.1802\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 281us/sample - loss: 0.3770 - acc: 0.9844\n",
      "Train on 960 samples, validate on 240 samples\n",
      "960/960 [==============================] - 0s 195us/sample - loss: 0.2424 - acc: 0.8729 - val_loss: 0.2463 - val_acc: 0.8750\n",
      "Epoch 218\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 249us/sample - loss: 1.1938\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 312us/sample - loss: 1.1928\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 234us/sample - loss: 0.3683 - acc: 0.9844\n",
      "Train on 960 samples, validate on 240 samples\n",
      "960/960 [==============================] - 0s 187us/sample - loss: 0.2387 - acc: 0.8833 - val_loss: 0.2438 - val_acc: 0.8583\n",
      "Epoch 219\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 171us/sample - loss: 1.1662\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 218us/sample - loss: 1.1649\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 249us/sample - loss: 0.3846 - acc: 0.9688\n",
      "Train on 960 samples, validate on 240 samples\n",
      "960/960 [==============================] - 0s 195us/sample - loss: 0.2331 - acc: 0.8719 - val_loss: 0.2463 - val_acc: 0.8667\n",
      "Epoch 220\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 156us/sample - loss: 1.1283\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 171us/sample - loss: 1.1269\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 249us/sample - loss: 0.4056 - acc: 0.9844\n",
      "Train on 960 samples, validate on 240 samples\n",
      "960/960 [==============================] - 0s 209us/sample - loss: 0.2381 - acc: 0.8771 - val_loss: 0.2478 - val_acc: 0.8792\n",
      "Epoch 221\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 265us/sample - loss: 1.2358\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 171us/sample - loss: 1.2336\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 296us/sample - loss: 0.3462 - acc: 1.0000\n",
      "Train on 960 samples, validate on 240 samples\n",
      "960/960 [==============================] - 0s 225us/sample - loss: 0.2438 - acc: 0.8750 - val_loss: 0.2709 - val_acc: 0.8583\n",
      "Epoch 222\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 203us/sample - loss: 1.1853\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 234us/sample - loss: 1.1839\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 249us/sample - loss: 0.3745 - acc: 1.0000\n",
      "Train on 960 samples, validate on 240 samples\n",
      "960/960 [==============================] - 0s 199us/sample - loss: 0.2429 - acc: 0.8698 - val_loss: 0.2547 - val_acc: 0.8708\n",
      "Epoch 223\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 171us/sample - loss: 1.1689\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 187us/sample - loss: 1.1672\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 312us/sample - loss: 0.3842 - acc: 1.0000\n",
      "Train on 960 samples, validate on 240 samples\n",
      "960/960 [==============================] - 0s 316us/sample - loss: 0.2374 - acc: 0.8792 - val_loss: 0.2475 - val_acc: 0.8542\n",
      "Epoch 224\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 312us/sample - loss: 1.1780\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 234us/sample - loss: 1.1764\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 281us/sample - loss: 0.3765 - acc: 0.9844\n",
      "Train on 960 samples, validate on 240 samples\n",
      "960/960 [==============================] - 0s 245us/sample - loss: 0.2351 - acc: 0.8885 - val_loss: 0.2423 - val_acc: 0.8833\n",
      "Epoch 225\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 218us/sample - loss: 1.1825\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 218us/sample - loss: 1.1792\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 327us/sample - loss: 0.3749 - acc: 0.9844\n",
      "Train on 960 samples, validate on 240 samples\n",
      "960/960 [==============================] - 0s 231us/sample - loss: 0.2329 - acc: 0.8865 - val_loss: 0.2488 - val_acc: 0.8583\n",
      "Epoch 226\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 203us/sample - loss: 1.2172\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 280us/sample - loss: 1.2138\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 218us/sample - loss: 0.3677 - acc: 1.0000\n",
      "Train on 960 samples, validate on 240 samples\n",
      "960/960 [==============================] - 0s 214us/sample - loss: 0.2415 - acc: 0.8729 - val_loss: 0.2438 - val_acc: 0.8667\n",
      "Epoch 227\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 234us/sample - loss: 1.1883\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 203us/sample - loss: 1.1882\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 281us/sample - loss: 0.3705 - acc: 0.9844\n",
      "Train on 960 samples, validate on 240 samples\n",
      "960/960 [==============================] - 0s 249us/sample - loss: 0.2419 - acc: 0.8729 - val_loss: 0.2434 - val_acc: 0.8792\n",
      "Epoch 228\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 218us/sample - loss: 1.1898\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 218us/sample - loss: 1.1883\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 249us/sample - loss: 0.3743 - acc: 1.0000\n",
      "Train on 960 samples, validate on 240 samples\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "960/960 [==============================] - 0s 240us/sample - loss: 0.2314 - acc: 0.8771 - val_loss: 0.2437 - val_acc: 0.8667\n",
      "Epoch 229\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 187us/sample - loss: 1.1840\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 234us/sample - loss: 1.1821\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 421us/sample - loss: 0.3780 - acc: 0.9844\n",
      "Train on 960 samples, validate on 240 samples\n",
      "960/960 [==============================] - 0s 255us/sample - loss: 0.2291 - acc: 0.8781 - val_loss: 0.2562 - val_acc: 0.8583\n",
      "Epoch 230\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 203us/sample - loss: 1.2311\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 234us/sample - loss: 1.2285\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 374us/sample - loss: 0.3547 - acc: 1.0000\n",
      "Train on 960 samples, validate on 240 samples\n",
      "960/960 [==============================] - 0s 192us/sample - loss: 0.2331 - acc: 0.8792 - val_loss: 0.2473 - val_acc: 0.8500\n",
      "Epoch 231\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 234us/sample - loss: 1.2026\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 280us/sample - loss: 1.1999\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 343us/sample - loss: 0.3674 - acc: 0.9688\n",
      "Train on 960 samples, validate on 240 samples\n",
      "960/960 [==============================] - 0s 180us/sample - loss: 0.2385 - acc: 0.8708 - val_loss: 0.2447 - val_acc: 0.8583\n",
      "Epoch 232\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 171us/sample - loss: 1.2064\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 218us/sample - loss: 1.2055\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 265us/sample - loss: 0.3640 - acc: 1.0000\n",
      "Train on 960 samples, validate on 240 samples\n",
      "960/960 [==============================] - 0s 199us/sample - loss: 0.2265 - acc: 0.8854 - val_loss: 0.2509 - val_acc: 0.8583\n",
      "Epoch 233\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 280us/sample - loss: 1.2060\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 312us/sample - loss: 1.2045\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 234us/sample - loss: 0.3666 - acc: 1.0000\n",
      "Train on 960 samples, validate on 240 samples\n",
      "960/960 [==============================] - 0s 285us/sample - loss: 0.2276 - acc: 0.8854 - val_loss: 0.2438 - val_acc: 0.8667\n",
      "Epoch 234\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 187us/sample - loss: 1.2391\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 203us/sample - loss: 1.2372\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 249us/sample - loss: 0.3493 - acc: 1.0000\n",
      "Train on 960 samples, validate on 240 samples\n",
      "960/960 [==============================] - 0s 218us/sample - loss: 0.2296 - acc: 0.8896 - val_loss: 0.2425 - val_acc: 0.8708\n",
      "Epoch 235\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 140us/sample - loss: 1.1864\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 234us/sample - loss: 1.1844\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 327us/sample - loss: 0.3739 - acc: 0.9844\n",
      "Train on 960 samples, validate on 240 samples\n",
      "960/960 [==============================] - 0s 217us/sample - loss: 0.2288 - acc: 0.8760 - val_loss: 0.2476 - val_acc: 0.8625\n",
      "Epoch 236\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 187us/sample - loss: 1.2394\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 187us/sample - loss: 1.2372\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 234us/sample - loss: 0.3495 - acc: 1.0000\n",
      "Train on 960 samples, validate on 240 samples\n",
      "960/960 [==============================] - 0s 208us/sample - loss: 0.2484 - acc: 0.8698 - val_loss: 0.2728 - val_acc: 0.8625\n",
      "Epoch 237\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 187us/sample - loss: 1.2093\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 203us/sample - loss: 1.2081\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 296us/sample - loss: 0.3637 - acc: 1.0000\n",
      "Train on 960 samples, validate on 240 samples\n",
      "960/960 [==============================] - 0s 186us/sample - loss: 0.2565 - acc: 0.8604 - val_loss: 0.2512 - val_acc: 0.8667\n",
      "Epoch 238\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 156us/sample - loss: 1.2601\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 265us/sample - loss: 1.2585\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 296us/sample - loss: 0.3434 - acc: 0.9844\n",
      "Train on 960 samples, validate on 240 samples\n",
      "960/960 [==============================] - 0s 218us/sample - loss: 0.2286 - acc: 0.8771 - val_loss: 0.2428 - val_acc: 0.8667\n",
      "Epoch 239\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - ETA: 0s - loss: 1.217 - 0s 203us/sample - loss: 1.2120\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 203us/sample - loss: 1.2102\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 203us/sample - loss: 0.3631 - acc: 1.0000\n",
      "Train on 960 samples, validate on 240 samples\n",
      "960/960 [==============================] - 0s 225us/sample - loss: 0.2313 - acc: 0.8802 - val_loss: 0.2436 - val_acc: 0.8667\n",
      "Epoch 240\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 156us/sample - loss: 1.2508\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 187us/sample - loss: 1.2490\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 280us/sample - loss: 0.3502 - acc: 0.9844\n",
      "Train on 960 samples, validate on 240 samples\n",
      "960/960 [==============================] - 0s 221us/sample - loss: 0.2330 - acc: 0.8833 - val_loss: 0.2418 - val_acc: 0.8750\n",
      "Epoch 241\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 187us/sample - loss: 1.2516\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 249us/sample - loss: 1.2508\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 265us/sample - loss: 0.3432 - acc: 1.0000\n",
      "Train on 960 samples, validate on 240 samples\n",
      "960/960 [==============================] - 0s 223us/sample - loss: 0.2362 - acc: 0.8854 - val_loss: 0.2604 - val_acc: 0.8625\n",
      "Epoch 242\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 203us/sample - loss: 1.2652\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 312us/sample - loss: 1.2629\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 218us/sample - loss: 0.3420 - acc: 1.0000\n",
      "Train on 960 samples, validate on 240 samples\n",
      "960/960 [==============================] - 0s 216us/sample - loss: 0.2273 - acc: 0.8802 - val_loss: 0.2447 - val_acc: 0.8625\n",
      "Epoch 243\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 171us/sample - loss: 1.2626\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 156us/sample - loss: 1.2618\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 234us/sample - loss: 0.3371 - acc: 1.0000\n",
      "Train on 960 samples, validate on 240 samples\n",
      "960/960 [==============================] - 0s 242us/sample - loss: 0.2278 - acc: 0.8875 - val_loss: 0.2431 - val_acc: 0.8583\n",
      "Epoch 244\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 156us/sample - loss: 1.2671\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 234us/sample - loss: 1.2658\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 203us/sample - loss: 0.3424 - acc: 1.0000\n",
      "Train on 960 samples, validate on 240 samples\n",
      "960/960 [==============================] - 0s 197us/sample - loss: 0.2314 - acc: 0.8750 - val_loss: 0.2582 - val_acc: 0.8583\n",
      "Epoch 245\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 187us/sample - loss: 1.2753\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 203us/sample - loss: 1.2717\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 203us/sample - loss: 0.3425 - acc: 0.9844\n",
      "Train on 960 samples, validate on 240 samples\n",
      "960/960 [==============================] - 0s 196us/sample - loss: 0.2318 - acc: 0.8792 - val_loss: 0.2424 - val_acc: 0.8750\n",
      "Epoch 246\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 140us/sample - loss: 1.2700\n",
      "Epoch 2/2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64/64 [==============================] - 0s 171us/sample - loss: 1.2692\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 234us/sample - loss: 0.3371 - acc: 1.0000\n",
      "Train on 960 samples, validate on 240 samples\n",
      "960/960 [==============================] - 0s 210us/sample - loss: 0.2311 - acc: 0.8917 - val_loss: 0.2458 - val_acc: 0.8542\n",
      "Epoch 247\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 156us/sample - loss: 1.2095\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 218us/sample - loss: 1.2077\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 296us/sample - loss: 0.3672 - acc: 1.0000\n",
      "Train on 960 samples, validate on 240 samples\n",
      "960/960 [==============================] - 0s 215us/sample - loss: 0.2368 - acc: 0.8823 - val_loss: 0.2441 - val_acc: 0.8625\n",
      "Epoch 248\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 234us/sample - loss: 1.2717\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 203us/sample - loss: 1.2700\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 327us/sample - loss: 0.3354 - acc: 1.0000\n",
      "Train on 960 samples, validate on 240 samples\n",
      "960/960 [==============================] - 0s 211us/sample - loss: 0.2355 - acc: 0.8646 - val_loss: 0.2428 - val_acc: 0.8667\n",
      "Epoch 249\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 281us/sample - loss: 1.2738\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 249us/sample - loss: 1.2716\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 328us/sample - loss: 0.3378 - acc: 1.0000\n",
      "Train on 960 samples, validate on 240 samples\n",
      "960/960 [==============================] - 0s 218us/sample - loss: 0.2301 - acc: 0.8792 - val_loss: 0.2539 - val_acc: 0.8708\n",
      "Epoch 250\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 187us/sample - loss: 1.2509\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 265us/sample - loss: 1.2495\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 249us/sample - loss: 0.3454 - acc: 1.0000\n",
      "Train on 960 samples, validate on 240 samples\n",
      "960/960 [==============================] - 0s 184us/sample - loss: 0.2312 - acc: 0.8802 - val_loss: 0.2452 - val_acc: 0.8792\n",
      "Epoch 251\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 171us/sample - loss: 1.2963\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 218us/sample - loss: 1.2950\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 265us/sample - loss: 0.3255 - acc: 1.0000\n",
      "Train on 960 samples, validate on 240 samples\n",
      "960/960 [==============================] - 0s 184us/sample - loss: 0.2263 - acc: 0.8917 - val_loss: 0.2475 - val_acc: 0.8750\n",
      "Epoch 252\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 171us/sample - loss: 1.3186\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 218us/sample - loss: 1.3170\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 265us/sample - loss: 0.3157 - acc: 1.0000\n",
      "Train on 960 samples, validate on 240 samples\n",
      "960/960 [==============================] - 0s 192us/sample - loss: 0.2472 - acc: 0.8771 - val_loss: 0.2703 - val_acc: 0.8708\n",
      "Epoch 253\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 171us/sample - loss: 1.2363\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 218us/sample - loss: 1.2352\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 265us/sample - loss: 0.3552 - acc: 0.9844\n",
      "Train on 960 samples, validate on 240 samples\n",
      "960/960 [==============================] - 0s 293us/sample - loss: 0.2429 - acc: 0.8635 - val_loss: 0.2526 - val_acc: 0.8750\n",
      "Epoch 254\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 187us/sample - loss: 1.2683\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 233us/sample - loss: 1.2669\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 265us/sample - loss: 0.3418 - acc: 1.0000\n",
      "Train on 960 samples, validate on 240 samples\n",
      "960/960 [==============================] - 0s 192us/sample - loss: 0.2267 - acc: 0.8854 - val_loss: 0.2407 - val_acc: 0.8792\n",
      "Epoch 255\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 187us/sample - loss: 1.2918\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 203us/sample - loss: 1.2905\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 265us/sample - loss: 0.3268 - acc: 1.0000\n",
      "Train on 960 samples, validate on 240 samples\n",
      "960/960 [==============================] - 0s 217us/sample - loss: 0.2243 - acc: 0.8854 - val_loss: 0.2429 - val_acc: 0.8625\n",
      "Epoch 256\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 218us/sample - loss: 1.2921\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 296us/sample - loss: 1.2906\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 265us/sample - loss: 0.3281 - acc: 1.0000\n",
      "Train on 960 samples, validate on 240 samples\n",
      "960/960 [==============================] - 0s 212us/sample - loss: 0.2390 - acc: 0.8729 - val_loss: 0.2432 - val_acc: 0.8667\n",
      "Epoch 257\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 203us/sample - loss: 1.2639\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 187us/sample - loss: 1.2626\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 280us/sample - loss: 0.3424 - acc: 1.0000\n",
      "Train on 960 samples, validate on 240 samples\n",
      "960/960 [==============================] - 0s 220us/sample - loss: 0.2307 - acc: 0.8833 - val_loss: 0.2450 - val_acc: 0.8708\n",
      "Epoch 258\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 171us/sample - loss: 1.2474\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 249us/sample - loss: 1.2458\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 234us/sample - loss: 0.3454 - acc: 1.0000\n",
      "Train on 960 samples, validate on 240 samples\n",
      "960/960 [==============================] - 0s 194us/sample - loss: 0.2363 - acc: 0.8771 - val_loss: 0.2412 - val_acc: 0.8750\n",
      "Epoch 259\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 187us/sample - loss: 1.2731\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 249us/sample - loss: 1.2721\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 265us/sample - loss: 0.3405 - acc: 1.0000\n",
      "Train on 960 samples, validate on 240 samples\n",
      "960/960 [==============================] - 0s 229us/sample - loss: 0.2256 - acc: 0.8833 - val_loss: 0.2416 - val_acc: 0.8667\n",
      "Epoch 260\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 156us/sample - loss: 1.3084\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 171us/sample - loss: 1.3073\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 249us/sample - loss: 0.3235 - acc: 1.0000\n",
      "Train on 960 samples, validate on 240 samples\n",
      "960/960 [==============================] - 0s 183us/sample - loss: 0.2263 - acc: 0.8802 - val_loss: 0.2447 - val_acc: 0.8750\n",
      "Epoch 261\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 171us/sample - loss: 1.2454\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 265us/sample - loss: 1.2440\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 218us/sample - loss: 0.3441 - acc: 1.0000\n",
      "Train on 960 samples, validate on 240 samples\n",
      "960/960 [==============================] - 0s 218us/sample - loss: 0.2260 - acc: 0.8833 - val_loss: 0.2455 - val_acc: 0.8667\n",
      "Epoch 262\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 234us/sample - loss: 1.2857\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 234us/sample - loss: 1.2833\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 203us/sample - loss: 0.3320 - acc: 1.0000\n",
      "Train on 960 samples, validate on 240 samples\n",
      "960/960 [==============================] - 0s 239us/sample - loss: 0.2252 - acc: 0.8760 - val_loss: 0.2409 - val_acc: 0.8708\n",
      "Epoch 263\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 265us/sample - loss: 1.3169\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 187us/sample - loss: 1.3162\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 327us/sample - loss: 0.3171 - acc: 1.0000\n",
      "Train on 960 samples, validate on 240 samples\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "960/960 [==============================] - 0s 287us/sample - loss: 0.2296 - acc: 0.8875 - val_loss: 0.2445 - val_acc: 0.8750\n",
      "Epoch 264\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 218us/sample - loss: 1.2953\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 296us/sample - loss: 1.2940\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 358us/sample - loss: 0.3245 - acc: 1.0000\n",
      "Train on 960 samples, validate on 240 samples\n",
      "960/960 [==============================] - 0s 248us/sample - loss: 0.2298 - acc: 0.8771 - val_loss: 0.2411 - val_acc: 0.8708\n",
      "Epoch 265\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 296us/sample - loss: 1.3123\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 359us/sample - loss: 1.3116\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 296us/sample - loss: 0.3202 - acc: 1.0000\n",
      "Train on 960 samples, validate on 240 samples\n",
      "960/960 [==============================] - 0s 250us/sample - loss: 0.2314 - acc: 0.8771 - val_loss: 0.2470 - val_acc: 0.8458\n",
      "Epoch 266\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 203us/sample - loss: 1.2788\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 468us/sample - loss: 1.2773\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 343us/sample - loss: 0.3347 - acc: 1.0000\n",
      "Train on 960 samples, validate on 240 samples\n",
      "960/960 [==============================] - 0s 219us/sample - loss: 0.2293 - acc: 0.8771 - val_loss: 0.2512 - val_acc: 0.8583\n",
      "Epoch 267\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 218us/sample - loss: 1.3291\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 265us/sample - loss: 1.3267\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 234us/sample - loss: 0.3130 - acc: 1.0000\n",
      "Train on 960 samples, validate on 240 samples\n",
      "960/960 [==============================] - 0s 244us/sample - loss: 0.2329 - acc: 0.8792 - val_loss: 0.2435 - val_acc: 0.8542\n",
      "Epoch 268\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 218us/sample - loss: 1.2630\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 265us/sample - loss: 1.2627\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 234us/sample - loss: 0.3408 - acc: 1.0000\n",
      "Train on 960 samples, validate on 240 samples\n",
      "960/960 [==============================] - 0s 231us/sample - loss: 0.2273 - acc: 0.8740 - val_loss: 0.2447 - val_acc: 0.8542\n",
      "Epoch 269\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 234us/sample - loss: 1.2397\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 249us/sample - loss: 1.2392\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 280us/sample - loss: 0.3533 - acc: 1.0000\n",
      "Train on 960 samples, validate on 240 samples\n",
      "960/960 [==============================] - 0s 215us/sample - loss: 0.2241 - acc: 0.8750 - val_loss: 0.2407 - val_acc: 0.8625\n",
      "Epoch 270\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 187us/sample - loss: 1.2672\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 296us/sample - loss: 1.2654\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 312us/sample - loss: 0.3386 - acc: 1.0000\n",
      "Train on 960 samples, validate on 240 samples\n",
      "960/960 [==============================] - 0s 234us/sample - loss: 0.2293 - acc: 0.8792 - val_loss: 0.2420 - val_acc: 0.8708\n",
      "Epoch 271\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 309us/sample - loss: 1.2964\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 234us/sample - loss: 1.2948\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 249us/sample - loss: 0.3300 - acc: 1.0000\n",
      "Train on 960 samples, validate on 240 samples\n",
      "960/960 [==============================] - 0s 255us/sample - loss: 0.2226 - acc: 0.8854 - val_loss: 0.2419 - val_acc: 0.8708\n",
      "Epoch 272\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 218us/sample - loss: 1.3374\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 265us/sample - loss: 1.3360\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 421us/sample - loss: 0.3152 - acc: 1.0000\n",
      "Train on 960 samples, validate on 240 samples\n",
      "960/960 [==============================] - 0s 226us/sample - loss: 0.2296 - acc: 0.8833 - val_loss: 0.2732 - val_acc: 0.8667\n",
      "Epoch 273\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 187us/sample - loss: 1.2702\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 296us/sample - loss: 1.2692\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 343us/sample - loss: 0.3398 - acc: 1.0000\n",
      "Train on 960 samples, validate on 240 samples\n",
      "960/960 [==============================] - 0s 251us/sample - loss: 0.2378 - acc: 0.8802 - val_loss: 0.2436 - val_acc: 0.8583\n",
      "Epoch 274\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 187us/sample - loss: 1.2825\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 280us/sample - loss: 1.2811\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 249us/sample - loss: 0.3298 - acc: 1.0000\n",
      "Train on 960 samples, validate on 240 samples\n",
      "960/960 [==============================] - 0s 256us/sample - loss: 0.2269 - acc: 0.8875 - val_loss: 0.2396 - val_acc: 0.8667\n",
      "Epoch 275\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 203us/sample - loss: 1.3027\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 249us/sample - loss: 1.3016\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 265us/sample - loss: 0.3231 - acc: 1.0000\n",
      "Train on 960 samples, validate on 240 samples\n",
      "960/960 [==============================] - 0s 259us/sample - loss: 0.2235 - acc: 0.8896 - val_loss: 0.2476 - val_acc: 0.8500\n",
      "Epoch 276\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 187us/sample - loss: 1.3755\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 249us/sample - loss: 1.3735\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 218us/sample - loss: 0.2986 - acc: 1.0000\n",
      "Train on 960 samples, validate on 240 samples\n",
      "960/960 [==============================] - 0s 237us/sample - loss: 0.2313 - acc: 0.8813 - val_loss: 0.2421 - val_acc: 0.8542\n",
      "Epoch 277\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 203us/sample - loss: 1.3114\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 296us/sample - loss: 1.3097\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 187us/sample - loss: 0.3253 - acc: 1.0000\n",
      "Train on 960 samples, validate on 240 samples\n",
      "960/960 [==============================] - 0s 246us/sample - loss: 0.2488 - acc: 0.8708 - val_loss: 0.2546 - val_acc: 0.8667\n",
      "Epoch 278\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 249us/sample - loss: 1.3584\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 234us/sample - loss: 1.3573\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 296us/sample - loss: 0.3042 - acc: 1.0000\n",
      "Train on 960 samples, validate on 240 samples\n",
      "960/960 [==============================] - 0s 230us/sample - loss: 0.2224 - acc: 0.8823 - val_loss: 0.2389 - val_acc: 0.8708\n",
      "Epoch 279\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 234us/sample - loss: 1.3305\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 234us/sample - loss: 1.3297\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 234us/sample - loss: 0.3129 - acc: 1.0000\n",
      "Train on 960 samples, validate on 240 samples\n",
      "960/960 [==============================] - 0s 235us/sample - loss: 0.2271 - acc: 0.8885 - val_loss: 0.2427 - val_acc: 0.8542\n",
      "Epoch 280\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 187us/sample - loss: 1.3340\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 203us/sample - loss: 1.3330\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 280us/sample - loss: 0.3116 - acc: 1.0000\n",
      "Train on 960 samples, validate on 240 samples\n",
      "960/960 [==============================] - 0s 247us/sample - loss: 0.2219 - acc: 0.8865 - val_loss: 0.2650 - val_acc: 0.8583\n",
      "Epoch 281\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 218us/sample - loss: 1.2923\n",
      "Epoch 2/2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64/64 [==============================] - 0s 187us/sample - loss: 1.2910\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 249us/sample - loss: 0.3295 - acc: 1.0000\n",
      "Train on 960 samples, validate on 240 samples\n",
      "960/960 [==============================] - 0s 209us/sample - loss: 0.2293 - acc: 0.8750 - val_loss: 0.2524 - val_acc: 0.8750\n",
      "Epoch 282\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 156us/sample - loss: 1.3995\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 234us/sample - loss: 1.3987\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 281us/sample - loss: 0.2874 - acc: 1.0000\n",
      "Train on 960 samples, validate on 240 samples\n",
      "960/960 [==============================] - 0s 209us/sample - loss: 0.2311 - acc: 0.8740 - val_loss: 0.2405 - val_acc: 0.8583\n",
      "Epoch 283\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 203us/sample - loss: 1.3267\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 230us/sample - loss: 1.3255\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 421us/sample - loss: 0.3153 - acc: 1.0000\n",
      "Train on 960 samples, validate on 240 samples\n",
      "960/960 [==============================] - 0s 285us/sample - loss: 0.2233 - acc: 0.8844 - val_loss: 0.2434 - val_acc: 0.8708\n",
      "Epoch 284\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 249us/sample - loss: 1.3300\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 249us/sample - loss: 1.3295\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 280us/sample - loss: 0.3156 - acc: 1.0000\n",
      "Train on 960 samples, validate on 240 samples\n",
      "960/960 [==============================] - 0s 190us/sample - loss: 0.2224 - acc: 0.8833 - val_loss: 0.2393 - val_acc: 0.8667\n",
      "Epoch 285\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 156us/sample - loss: 1.3547\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 249us/sample - loss: 1.3537\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 358us/sample - loss: 0.3056 - acc: 1.0000\n",
      "Train on 960 samples, validate on 240 samples\n",
      "960/960 [==============================] - 0s 210us/sample - loss: 0.2218 - acc: 0.8896 - val_loss: 0.2408 - val_acc: 0.8583\n",
      "Epoch 286\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 203us/sample - loss: 1.3552\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 265us/sample - loss: 1.3542\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 280us/sample - loss: 0.3043 - acc: 1.0000\n",
      "Train on 960 samples, validate on 240 samples\n",
      "960/960 [==============================] - 0s 194us/sample - loss: 0.2217 - acc: 0.8927 - val_loss: 0.2418 - val_acc: 0.8667\n",
      "Epoch 287\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 203us/sample - loss: 1.3344\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 218us/sample - loss: 1.3331\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 249us/sample - loss: 0.3089 - acc: 1.0000\n",
      "Train on 960 samples, validate on 240 samples\n",
      "960/960 [==============================] - 0s 203us/sample - loss: 0.2311 - acc: 0.8875 - val_loss: 0.2420 - val_acc: 0.8542\n",
      "Epoch 288\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 203us/sample - loss: 1.2781\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 249us/sample - loss: 1.2768\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 249us/sample - loss: 0.3354 - acc: 1.0000\n",
      "Train on 960 samples, validate on 240 samples\n",
      "960/960 [==============================] - 0s 211us/sample - loss: 0.2238 - acc: 0.8875 - val_loss: 0.2377 - val_acc: 0.8625\n",
      "Epoch 289\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 171us/sample - loss: 1.3005\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 203us/sample - loss: 1.2994\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 234us/sample - loss: 0.3261 - acc: 1.0000\n",
      "Train on 960 samples, validate on 240 samples\n",
      "960/960 [==============================] - 0s 220us/sample - loss: 0.2223 - acc: 0.8844 - val_loss: 0.2479 - val_acc: 0.8583\n",
      "Epoch 290\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 187us/sample - loss: 1.3260\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 280us/sample - loss: 1.3225\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 296us/sample - loss: 0.3265 - acc: 1.0000\n",
      "Train on 960 samples, validate on 240 samples\n",
      "960/960 [==============================] - 0s 226us/sample - loss: 0.2300 - acc: 0.8771 - val_loss: 0.2434 - val_acc: 0.8625\n",
      "Epoch 291\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 203us/sample - loss: 1.3266\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 218us/sample - loss: 1.3234\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 280us/sample - loss: 0.3156 - acc: 1.0000\n",
      "Train on 960 samples, validate on 240 samples\n",
      "960/960 [==============================] - 0s 205us/sample - loss: 0.2223 - acc: 0.8792 - val_loss: 0.2400 - val_acc: 0.8542\n",
      "Epoch 292\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 249us/sample - loss: 1.3100\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 234us/sample - loss: 1.3093\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 249us/sample - loss: 0.3233 - acc: 1.0000\n",
      "Train on 960 samples, validate on 240 samples\n",
      "960/960 [==============================] - 0s 181us/sample - loss: 0.2222 - acc: 0.8854 - val_loss: 0.2372 - val_acc: 0.8625\n",
      "Epoch 293\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 156us/sample - loss: 1.3142\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 171us/sample - loss: 1.3141\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 234us/sample - loss: 0.3228 - acc: 1.0000\n",
      "Train on 960 samples, validate on 240 samples\n",
      "960/960 [==============================] - 0s 287us/sample - loss: 0.2398 - acc: 0.8729 - val_loss: 0.2391 - val_acc: 0.8667\n",
      "Epoch 294\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 249us/sample - loss: 1.3221\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 234us/sample - loss: 1.3213\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 187us/sample - loss: 0.3228 - acc: 1.0000\n",
      "Train on 960 samples, validate on 240 samples\n",
      "960/960 [==============================] - 0s 214us/sample - loss: 0.2259 - acc: 0.8906 - val_loss: 0.2466 - val_acc: 0.8667\n",
      "Epoch 295\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 234us/sample - loss: 1.4184\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 234us/sample - loss: 1.4171\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 218us/sample - loss: 0.2820 - acc: 1.0000\n",
      "Train on 960 samples, validate on 240 samples\n",
      "960/960 [==============================] - 0s 198us/sample - loss: 0.2269 - acc: 0.8813 - val_loss: 0.2392 - val_acc: 0.8667\n",
      "Epoch 296\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 171us/sample - loss: 1.3404\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 187us/sample - loss: 1.3388\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 171us/sample - loss: 0.3124 - acc: 1.0000\n",
      "Train on 960 samples, validate on 240 samples\n",
      "960/960 [==============================] - 0s 205us/sample - loss: 0.2289 - acc: 0.8792 - val_loss: 0.2429 - val_acc: 0.8625\n",
      "Epoch 297\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 203us/sample - loss: 1.3221\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 249us/sample - loss: 1.3205\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 218us/sample - loss: 0.3165 - acc: 1.0000\n",
      "Train on 960 samples, validate on 240 samples\n",
      "960/960 [==============================] - 0s 198us/sample - loss: 0.2200 - acc: 0.8854 - val_loss: 0.2400 - val_acc: 0.8750\n",
      "Epoch 298\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 187us/sample - loss: 1.3430\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 187us/sample - loss: 1.3428\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 187us/sample - loss: 0.3125 - acc: 1.0000\n",
      "Train on 960 samples, validate on 240 samples\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "960/960 [==============================] - 0s 195us/sample - loss: 0.2258 - acc: 0.8781 - val_loss: 0.2371 - val_acc: 0.8750\n",
      "Epoch 299\n",
      "Fitting GAN\n",
      "Epoch 1/2\n",
      "64/64 [==============================] - 0s 156us/sample - loss: 1.3469\n",
      "Epoch 2/2\n",
      "64/64 [==============================] - 0s 234us/sample - loss: 1.3447\n",
      "Fitting discriminator\n",
      "64/64 [==============================] - 0s 265us/sample - loss: 0.3107 - acc: 1.0000\n",
      "Train on 960 samples, validate on 240 samples\n",
      "960/960 [==============================] - 0s 186us/sample - loss: 0.2322 - acc: 0.8771 - val_loss: 0.2517 - val_acc: 0.8625\n"
     ]
    }
   ],
   "source": [
    "gan = define_gan(generator.model, discriminator.model)\n",
    "fit_gan(gan, NewData, 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
