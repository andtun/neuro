{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import imageio\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.layers import Dense, Input\n",
    "from tensorflow.keras.models import Sequential, Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_trainable(net, val):\n",
    "    net.model.trainable = val\n",
    "    for l in net.model.layers:\n",
    "        l.trainable = val\n",
    "    net.cmpile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset():\n",
    "    x = None\n",
    "    y = None\n",
    "    W = None\n",
    "    \n",
    "    def __init__(self):\n",
    "        return\n",
    "    \n",
    "    def load_data(self, data_range=10000):\n",
    "        dots_x = []\n",
    "        for i in range(data_range):\n",
    "            x = random.gauss(0, data_range)\n",
    "            dots_x.append((x, x**2)) # square\n",
    "            dots_x.append((x, random.gauss(x**2, data_range**2.1))) # less than square\n",
    "            #dots_x.append((x**r, x**(2*r*(1+random.gauss(0.5, 0.25)/20)))) # more than square\n",
    "        dots_x = np.array(dots_x)\n",
    "        dots_y = np.array([1 if x[0]**2 == x[1] else 0 for x in dots_x])\n",
    "        self.x, self.y = dots_x, dots_y\n",
    "        return dots_x, dots_y\n",
    "    \n",
    "    def load_weights(self, default_weight=0.12):\n",
    "        W = self.y.copy().astype(float)\n",
    "        W[W == 0] = 0.12\n",
    "        self.W = W\n",
    "        return W\n",
    "        \n",
    "    @staticmethod\n",
    "    def load_random(n_dim=5, n_samples=16):\n",
    "        V = np.random.normal(size=(n_samples, n_dim))\n",
    "        return V\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Plot:\n",
    "    name = \"\"\n",
    "    images = []\n",
    "    threshold = 0.0\n",
    "    \n",
    "    def __init__(self, name, threshold=0.6):\n",
    "        self.name = name\n",
    "        self.threshold = threshold\n",
    "        self.images = []\n",
    "    \n",
    "    @staticmethod\n",
    "    def parabola_plot(ax, xrange):\n",
    "        x = np.linspace(xrange, 1)\n",
    "        y = x*x\n",
    "        plt.plot(x, y)\n",
    "    \n",
    "    @staticmethod\n",
    "    def dots_plot(ax, dots_x, dots_y, color):\n",
    "        ax.scatter(dots_x, dots_y, color=color, alpha=0.15)\n",
    "        plt.plot()\n",
    "    \n",
    "    def picture(self, dots, predictions, title=''):\n",
    "        predictions = predictions.reshape(predictions.shape[0])\n",
    "        dots_x = dots.T[0]\n",
    "        fig = plt.figure()\n",
    "        ax1 = fig.add_subplot(111)\n",
    "        ax1.set(title=title)\n",
    "        #ax2 = ax1.twinx()\n",
    "        plt.grid(axis='both')\n",
    "        xrange = (dots_x.min()*1.1, dots_x.max()*1.1)\n",
    "        self.parabola_plot(ax1, xrange)\n",
    "        right_dots = dots[np.where(predictions >= self.threshold)]\n",
    "        wrong_dots = dots[np.where(predictions < self.threshold)]\n",
    "        #ax1.set_ylim([0, 2e+8])\n",
    "        self.dots_plot(ax1, wrong_dots.T[0], wrong_dots.T[1], color='r')\n",
    "        self.dots_plot(ax1, right_dots.T[0], right_dots.T[1], color='g')\n",
    "        \n",
    "    def add_to_gif(self, dots_x, predictions, title=''):\n",
    "        self.picture(dots_x, predictions, title=title)\n",
    "        plt.savefig(self.name+'.png')\n",
    "        plt.close()\n",
    "        image = Image.open(self.name+'.png')\n",
    "        ar = np.asarray(image)\n",
    "        self.images.append(ar)\n",
    "        \n",
    "    def save_gif(self):\n",
    "        kargs = { 'duration': 0.1 }\n",
    "        imageio.mimsave(self.name+'.gif', self.images, None, **kargs)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Gen:\n",
    "    model = None\n",
    "    \n",
    "    def __init__(self):\n",
    "        model = Sequential([Dense(15, activation='relu', kernel_initializer='he_uniform', input_dim=5),\n",
    "                            Dense(2, activation='linear')\n",
    "        ])\n",
    "        self.model = model\n",
    "        \n",
    "    def predict(self, dots_x):\n",
    "        return self.model.predict(dots_x)\n",
    "    \n",
    "    def cmpile(self):\n",
    "        return\n",
    "    \n",
    "    \n",
    "class Dsc:\n",
    "    model = None\n",
    "    \n",
    "    def __init__(self):\n",
    "        model = Sequential([Dense(25, activation='relu', kernel_initializer='he_uniform', input_dim=2),\n",
    "                            Dense(1, activation='sigmoid')\n",
    "        ])\n",
    "        self.model = model\n",
    "    \n",
    "    def cmpile(self, lr=0.0001):\n",
    "        self.model.compile(loss='binary_crossentropy',\n",
    "                           optimizer=tf.keras.optimizers.Adam(lr),\n",
    "                           metrics=['accuracy'])\n",
    "        \n",
    "    def fit(self, dots_x, dots_y, weights=None, epochs=1, validation_split=0.15, plot=False):\n",
    "        if plot:\n",
    "            img = Plot('discriminator_fit')\n",
    "            for i in range(epochs):\n",
    "                self.model.fit(dots_x, \n",
    "                               dots_y, \n",
    "                               epochs=1, \n",
    "                               sample_weight=weights)\n",
    "                img.add_to_gif(dots_x, self.model.predict(dots_x), title='Epoch %d' % i)\n",
    "                #print(dots_x[15], self.model.predict(dots_x)[15])\n",
    "                img.save_gif()                        \n",
    "        else:\n",
    "            self.model.fit(dots_x, \n",
    "                           dots_y, \n",
    "                           epochs=epochs, \n",
    "                           sample_weight=weights, \n",
    "                           validation_split=validation_split)\n",
    "        \n",
    "# Raw class, doesn't work   \n",
    "class Gan:\n",
    "    gen = None\n",
    "    dsc = None\n",
    "    model = None\n",
    "    \n",
    "    def __init__(self, gen, dsc, n_dim=5):\n",
    "        make_trainable(dsc, False)\n",
    "        self.gen = gen\n",
    "        self.dsc = dsc\n",
    "        # connect them\n",
    "        model = Sequential()\n",
    "        # add generator\n",
    "        model.add(gen.model)\n",
    "        # add the discriminator\n",
    "        model.add(dsc.model)\n",
    "        self.model = model\n",
    "    \n",
    "    def cmpile(self, lr=0.001):\n",
    "        self.model.compile(loss='binary_crossentropy',\n",
    "                           optimizer=tf.keras.optimizers.Adam(lr),\n",
    "                           metrics = ['accuracy'])\n",
    "        \n",
    "    def fit(self, dots_x, dots_y, epochs=1):\n",
    "        self.model.fit(dots_x, dots_y, epochs=epochs)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_gan(generator, discriminator):\n",
    "    # make weights in the discriminator not trainable\n",
    "    discriminator.trainable = False\n",
    "    # connect them\n",
    "    model = Sequential()\n",
    "    # add generator\n",
    "    model.add(generator)\n",
    "    # add the discriminator\n",
    "    model.add(discriminator)\n",
    "    # при замене оптимизатора всё слетает ???\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = Gen()\n",
    "discriminator = Dsc()\n",
    "gan = define_gan(generator.model, discriminator.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data = Dataset()\n",
    "Data.load_data()\n",
    "weights = Data.load_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "20000/20000 [==============================] - 5s 229us/sample - loss: 35450588.2780 - acc: 0.4802\n",
      "20000/20000 [==============================] - 4s 208us/sample - loss: 35803.9394 - acc: 0.5671\n"
     ]
    }
   ],
   "source": [
    "discriminator.cmpile()\n",
    "make_trainable(discriminator, True)\n",
    "print(discriminator.model.trainable)\n",
    "discriminator.fit(Data.x, Data.y, epochs=2, plot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1024/1024 [==============================] - 0s 242us/sample - loss: 0.8007\n",
      "1024/1024 [==============================] - 1s 893us/sample - loss: 1.1555 - acc: 0.8330\n",
      "1024/1024 [==============================] - 0s 225us/sample - loss: 0.7966\n",
      "1024/1024 [==============================] - 1s 883us/sample - loss: 1.1559 - acc: 0.9248\n",
      "1024/1024 [==============================] - 0s 243us/sample - loss: 0.8078\n",
      "1024/1024 [==============================] - 1s 889us/sample - loss: 1.1349 - acc: 0.9824\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 3\n",
    "#gan.compile()\n",
    "discriminator.cmpile()\n",
    "\n",
    "for i in range(n_epochs):\n",
    "    V = Data.load_random(n_samples=1024)\n",
    "    generated = generator.predict(V)\n",
    "    make_trainable(discriminator, False)\n",
    "    gan.fit(V, np.ones(V.shape[0]))\n",
    "    make_trainable(discriminator, True)\n",
    "    discriminator.fit(generated, np.zeros(V.shape[0]), weights=2*np.ones(V.shape[0]), validation_split=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {},
   "outputs": [],
   "source": [
    "V = Data.load_random()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.5381674 , -0.7294682 ],\n",
       "       [-2.823714  ,  2.3865035 ],\n",
       "       [-1.6322343 , -0.60534656],\n",
       "       [-1.4527448 , -0.5131934 ],\n",
       "       [ 1.7400169 , -1.2436492 ],\n",
       "       [-3.2143238 ,  0.8560622 ],\n",
       "       [-2.0015056 , -0.10116366],\n",
       "       [-1.3385688 , -0.6017516 ],\n",
       "       [-0.63379264, -0.40824658],\n",
       "       [-0.36235106, -3.1587038 ],\n",
       "       [ 0.67363346,  0.07549467],\n",
       "       [-0.51835656, -1.2866111 ],\n",
       "       [ 1.292838  , -1.5330855 ],\n",
       "       [ 1.6155298 , -0.34018275],\n",
       "       [-0.41443527,  0.260574  ],\n",
       "       [-0.7371965 , -0.5022781 ]], dtype=float32)"
      ]
     },
     "execution_count": 409,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generator.predict(V)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gan.Dsc.model.trainable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "discriminator.model.trainable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "2 root error(s) found.\n  (0) Invalid argument: You must feed a value for placeholder tensor 'dense_82_input' with dtype float and shape [?,2]\n\t [[{{node dense_82_input}}]]\n\t [[loss_66/mul/_2913]]\n  (1) Invalid argument: You must feed a value for placeholder tensor 'dense_82_input' with dtype float and shape [?,2]\n\t [[{{node dense_82_input}}]]\n0 successful operations.\n0 derived errors ignored.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-181-588ef281f3a1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mgan\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mV\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mones\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m16\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-166-ea51e908182a>\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, dots_x, dots_y, epochs)\u001b[0m\n\u001b[0;32m     67\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     68\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdots_x\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdots_y\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 69\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdots_x\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdots_y\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     70\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\neuro\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    778\u001b[0m           \u001b[0mvalidation_steps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    779\u001b[0m           \u001b[0mvalidation_freq\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidation_freq\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 780\u001b[1;33m           steps_name='steps_per_epoch')\n\u001b[0m\u001b[0;32m    781\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    782\u001b[0m   def evaluate(self,\n",
      "\u001b[1;32m~\\.conda\\envs\\neuro\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[1;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq, mode, validation_in_fit, prepared_feed_values_from_dataset, steps_name, **kwargs)\u001b[0m\n\u001b[0;32m    361\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    362\u001b[0m         \u001b[1;31m# Get outputs.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 363\u001b[1;33m         \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    364\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    365\u001b[0m           \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\neuro\\lib\\site-packages\\tensorflow\\python\\keras\\backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   3290\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3291\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[1;32m-> 3292\u001b[1;33m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[0;32m   3293\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3294\u001b[0m     output_structure = nest.pack_sequence_as(\n",
      "\u001b[1;32m~\\.conda\\envs\\neuro\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1456\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[0;32m   1457\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1458\u001b[1;33m                                                run_metadata_ptr)\n\u001b[0m\u001b[0;32m   1459\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1460\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: 2 root error(s) found.\n  (0) Invalid argument: You must feed a value for placeholder tensor 'dense_82_input' with dtype float and shape [?,2]\n\t [[{{node dense_82_input}}]]\n\t [[loss_66/mul/_2913]]\n  (1) Invalid argument: You must feed a value for placeholder tensor 'dense_82_input' with dtype float and shape [?,2]\n\t [[{{node dense_82_input}}]]\n0 successful operations.\n0 derived errors ignored."
     ]
    }
   ],
   "source": [
    "gan.fit(V, np.ones(16))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'name' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-17ed62720553>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0ma\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mname\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'name' is not defined"
     ]
    }
   ],
   "source": [
    "a = 3\n",
    "name(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8464395312821893"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.gauss(0.5, 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator.model.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gan.Dsc.model.trainable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.43098414, -1.8557093 ],\n",
       "       [-1.416142  ,  0.13706303],\n",
       "       [-0.9289516 , -1.5910852 ],\n",
       "       [-0.60927117, -3.3515854 ],\n",
       "       [ 0.31981492, -0.9599231 ],\n",
       "       [ 0.70434904, -0.33623135],\n",
       "       [ 1.1979504 , -1.7666132 ],\n",
       "       [ 0.33637047, -2.2152154 ],\n",
       "       [-0.55402684, -1.0059581 ],\n",
       "       [ 0.7611686 , -2.1785161 ],\n",
       "       [ 0.17429227, -2.4130015 ],\n",
       "       [ 1.2904017 , -0.8275587 ],\n",
       "       [-1.3589315 , -1.6973226 ],\n",
       "       [-0.9865883 , -1.7392489 ],\n",
       "       [ 0.33242375,  0.28773135],\n",
       "       [ 0.9864638 , -0.82728004]], dtype=float32)"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generator.predict(V)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-9.46154461e-01,  8.42711127e-01,  5.64654642e-01,\n",
       "        -1.61500519e+00,  2.65035287e-01],\n",
       "       [-1.29362045e+00,  1.00340807e-02, -1.61517736e+00,\n",
       "         7.31232946e-04, -6.60969476e-01],\n",
       "       [ 8.73663091e-01, -1.13003419e+00, -1.56780762e+00,\n",
       "         1.72668362e+00, -4.57047344e-01],\n",
       "       [ 2.73782162e+00, -1.68788322e-02, -1.37889423e+00,\n",
       "         3.61923422e-01,  8.68265394e-03],\n",
       "       [ 4.05071014e-01, -1.78001050e-01,  6.90572531e-01,\n",
       "         2.12749241e-01,  1.06033808e+00],\n",
       "       [-4.49625968e-01, -3.24535215e-01,  1.33955713e-01,\n",
       "         1.11888694e+00,  6.98768080e-01],\n",
       "       [ 1.05627802e+00,  1.55713987e-01, -2.57376214e-01,\n",
       "         1.14346600e+00,  6.36171789e-01],\n",
       "       [-2.93742272e-02,  2.15808547e+00,  1.71304648e+00,\n",
       "         8.78535860e-01,  9.64200286e-01],\n",
       "       [-1.35621070e+00,  1.40061897e+00,  7.00649760e-01,\n",
       "         4.09271617e-01,  1.54728200e-02],\n",
       "       [ 9.86079975e-01, -3.52924150e-01, -6.90080659e-01,\n",
       "         2.33588819e+00,  2.63395906e-01],\n",
       "       [-3.16323419e-02,  2.11293773e+00,  1.92426030e+00,\n",
       "         9.94309210e-01,  8.50686147e-01],\n",
       "       [ 2.11058995e-01,  5.14564184e-01,  2.89742891e-01,\n",
       "         5.08564912e-01,  1.56548070e+00],\n",
       "       [ 4.73055334e-01, -1.19002015e+00, -1.57833052e-01,\n",
       "         9.68247498e-01, -1.26470381e+00],\n",
       "       [-1.34502068e+00,  1.22476780e+00,  1.80005665e+00,\n",
       "         5.44467176e-01,  2.76119576e-01],\n",
       "       [-2.42172362e+00,  1.25444144e+00, -5.31616853e-01,\n",
       "         1.15972644e+00,  6.33304500e-01],\n",
       "       [ 9.82657403e-02, -1.76102253e-01,  7.02724207e-01,\n",
       "         5.73267595e-01,  1.79412253e+00]])"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model': <tensorflow.python.keras.engine.sequential.Sequential at 0x24125e4c198>,\n",
       " 'trainable': False}"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gan.Dsc.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': [10496.87605283203], 'acc': [0.5706]}"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "discriminator.model.history.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "discriminator.model.trainable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
