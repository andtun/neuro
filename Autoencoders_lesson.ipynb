{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Autoencoders lesson.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/andtun/neuro/blob/master/Autoencoders_lesson.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X68mLzjZpaiV",
        "colab_type": "text"
      },
      "source": [
        "# Variational autoencoder\n",
        "Autoencoder - архитектура нейросети, которая сначала с помощью Энкодера сжимает изображение в вектор небольшой размерности(он называется скрытым представлением), а затем восстанавливает этот вектор в исходную картинку. Казалось бы, зачем это нужно? Вход и выход этой нейросети - одна и та-же картинка, ничего нового она не создаёт. Однако практика показывает, что скрытое представление картинки позволяет делать очень интересные и красивые вещи - например, гладкую интерполяцию между 2 написанными от руки цифрами. Более того, Autoencoder можно даже обучить очищать изображения от шума.\n",
        "\n",
        "Выражаясь математическим языком, Encoder - это функция, которая отображает входное изображение в пространство размерности latent_size, а Decoder - функция, отображающая латентное представление в пространство изображений. \n",
        "![alt text](http://fastforwardlabs.github.io/blog-images/miriam/imgs_code/vae.4.png)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "k2OI4u7vJmtT",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, UpSampling2D, Dense, Dropout, Input, LeakyReLU, Flatten, Reshape\n",
        "from tensorflow.keras.models import Model,Sequential\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "x_train = (x_train / 255.0).astype(np.float32)\n",
        "x_test = (x_test / 255.0).astype(np.float32)\n",
        "latent_size = 32\n",
        "# Create Encoder\n",
        "def getEncoder(latent_size):\n",
        "  model = Sequential([\n",
        "      Dense(units=128, input_dim=(784)),\n",
        "      LeakyReLU(0.2),\n",
        "      Dense(units=64),\n",
        "      LeakyReLU(0.2),\n",
        "      Dense(units=latent_size, activity_regularizer=tf.keras.regularizers.l1(10e-5))\n",
        "  ])\n",
        "  model.compile(loss='binary_crossentropy', optimizer='adam')\n",
        "  \n",
        "  return model\n",
        "# Create Decoder\n",
        "def getDecoder(latent_size):\n",
        "  # Write your code for Decoder here\n",
        "  return "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u90px5yEajSf",
        "colab_type": "text"
      },
      "source": [
        "# Зачем нужна регуляризация?\n",
        " В общем и целом, для обучения Autoencoder'a достаточно просто задать loss function как MSE от входного и выходного изображения: выход нейросети должен быть таким же, как вход. Однако в таком случае нейросеть будет пытаться разместить все доступные классы картинок(в нашем случае, цифры из датасета MNIST) как можно дальше друг от друга, и функция будет не определена и разрывна во многих областях латентного пространства, что хорошо видно на первой картинке ниже. Это весьма и весьма плохо: например, нам не удасться погенерировать новые картинки, преобразовывая случайную точку из латентного пространства в случайную картинку - именно из-за того, что функция латентного пространства очень во многих областях разрывна.\n",
        "\n",
        " Один из способов решить эту проблему - добавить к loss function небольшое слагаемое, которое будет \"стягивать\" к нулю все представления картинок в латентом пространстве. Это и есть регуляризация - на картинке слагаемое регуляризации выделено желтым.\n",
        " \n",
        " ![alt text](https://miro.medium.com/max/240/1*4MlW1d3xszVAGuXiJ1U6Fg.png)\n",
        " \n",
        " Таким образом, регуляризация играет роль противовеса в loss function Autoencoder'а - она не дает ему просто \"разнести\" представления картинок в латентом пространстве как можно дальше друг от друга, и заставляет строить геометрически осмысленные представления картинок в латентном пространстве, и в результате функция, отображающая картинки в латентное пространство, становится непрерывной."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A4VSiJFJxXPT",
        "colab_type": "text"
      },
      "source": [
        "![alt text](https://www.jeremyjordan.me/content/images/2018/03/Screen-Shot-2018-03-18-at-7.22.24-PM.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "K0xHX4oqbzmo"
      },
      "source": [
        "# Your autoencoder can also be convolutional"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "5g03u1blbwLw",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, UpSampling2D, Dense, Dropout, Input, LeakyReLU, Flatten, Reshape\n",
        "from tensorflow.keras.models import Model,Sequential\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "x_train = (x_train / 255.0).astype(np.float32)\n",
        "x_test = (x_test / 255.0).astype(np.float32)\n",
        "\n",
        "x_train = np.expand_dims(x_train, axis=3)\n",
        "x_test = np.expand_dims(x_test, axis=3)\n",
        "\n",
        "latent_size = 32\n",
        "# Create Encoder\n",
        "def getEncoder(latent_size):\n",
        "  # Write your code for encoder here\n",
        "\n",
        "# Create Decoder\n",
        "def getDecoder(latent_size):\n",
        "  model = Sequential([\n",
        "      Dense(units=32, input_dim=latent_size),\n",
        "      LeakyReLU(0.2),\n",
        "      Dense(units=7*7*64),\n",
        "      Reshape((7, 7, 64), input_shape=(7*7*64,)),\n",
        "      UpSampling2D((2, 2)),\n",
        "      Conv2D(64, (3, 3), padding='same'),\n",
        "      LeakyReLU(0.2),\n",
        "      Conv2D(64, (3, 3), padding='same'),\n",
        "      LeakyReLU(0.2),\n",
        "      UpSampling2D((2, 2)),\n",
        "      Conv2D(32, (3, 3), padding='same'),\n",
        "      LeakyReLU(0.2),\n",
        "      Conv2D(1, (3, 3), activation='sigmoid', padding='same'),\n",
        "  ])\n",
        "  model.compile(loss='binary_crossentropy', optimizer='adam')\n",
        "  \n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ZMuCg2qmT-5T",
        "colab": {}
      },
      "source": [
        "# Merge encoder and decoder into the single model\n",
        "def createVAE(encoder, decoder):\n",
        "    VAE_input = Input(shape=(28, 28, 1)) # Set shape to (28, 28, 1) if autoencoder is convolutional, (784, 1) otherwise\n",
        "    hidden = encoder(VAE_input)\n",
        "    VAE_output= decoder(hidden)\n",
        "    VAE = Model(inputs=VAE_input, outputs=VAE_output)\n",
        "    VAE.compile(loss='mse', optimizer='adam')\n",
        "    \n",
        "    return VAE\n",
        "\n",
        "encoder = getEncoder(latent_size)\n",
        "decoder = getDecoder(latent_size)\n",
        "autoencoder = createVAE(encoder, decoder)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t5EknhcBhNij",
        "colab_type": "text"
      },
      "source": [
        "Теперь, когда мы написали модель, можно запустить обычное обучение: Input'ами нейросети будут картинки из тренировочного датасета, а label'ами - те-же самые входные картинки."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "zJLlQfozUOf1",
        "colab": {}
      },
      "source": [
        "# Train\n",
        "autoencoder.fit(x_train, x_train, batch_size=64, epochs=10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "QzvGlSv5YjTG"
      },
      "source": [
        "Теперь самое время посмотреть, как наша нейросеть научилась восстанавливать картинки! "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "f0DUGatcUtku",
        "colab": {}
      },
      "source": [
        "from matplotlib import pyplot as plt\n",
        "\n",
        "def plot_images(images, title):\n",
        "  fig=plt.figure(figsize=(16, 3))\n",
        "  columns = images.shape[0]\n",
        "  rows = 1\n",
        "  for i in range(columns):\n",
        "    img = np.random.randint(10, size=(10, 10))\n",
        "    fig.add_subplot(rows, columns, i+1)\n",
        "    plt.imshow(images[i], cmap='gray')\n",
        "  fig.suptitle(title)\n",
        "  plt.show()  \n",
        "\n",
        "N_images = 6\n",
        "samples = x_test[np.random.choice(x_test.shape[0], N_images)]\n",
        "reconstructed = autoencoder.predict(samples)\n",
        "plot_images(samples.reshape(-1, 28, 28), title='Original images')\n",
        "plot_images(reconstructed.reshape(-1, 28, 28), title='Reconstructed images')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "FQf_xIbRcijc"
      },
      "source": [
        "# Интерполяция между 2 картинками\n",
        "Интерполяция - это нахождение промежуточных значений между 2 дискретными величинами. В нашем случае, такой дискретной величиной является картинка.\n",
        "Латентное представление, которое Autoencoder выучил при обучении, позволяет посмотреть, какие картинки находятся между 2 другими с геометрической точки зрения."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "0yNPENXvZCUV",
        "colab": {}
      },
      "source": [
        "def interpolation(vec1, vec2, N_inter):\n",
        "  intermediate_values = np.zeros((0, vec1.shape[0]))\n",
        "  for i in range(N_inter):\n",
        "    intermediate = (1-float(i / N_inter))*vec1 + float(i / N_inter)*vec2\n",
        "    intermediate_values = np.append(intermediate_values, intermediate.reshape(1, -1), axis=0)\n",
        "  intermediate_values = np.append(intermediate_values, vec2.reshape(1, -1), axis=0)\n",
        "  return intermediate_values\n",
        "\n",
        "N_inter = 8\n",
        "# Take 2 random images from the test set\n",
        "choice = np.random.choice(x_test.shape[0], 2)\n",
        "samples = x_test[choice]\n",
        "encodings = encoder.predict(samples)\n",
        "\n",
        "vectors = interpolation(encodings[0], encodings[1], N_inter)\n",
        "images = decoder.predict(vectors)\n",
        "plot_images(images.reshape(-1, 28, 28), \"Interpolation of %i into %i\"%(y_test[choice[0]], y_test[choice[1]]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-08LyQu0te_a",
        "colab_type": "text"
      },
      "source": [
        "Если этот файл запущен не на Google Colab, с помощью этого кода можно создать видео, на котором процесс превращения одной цифры в другую будет виден ещё более наглядно."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "RSua0vyadurR",
        "colab": {}
      },
      "source": [
        "import cv2\n",
        "\n",
        "N_inter = 90\n",
        "resize_coeff = 10\n",
        "# Take 2 random images from the test set\n",
        "choice = np.random.choice(x_test.shape[0], 2)\n",
        "samples = x_test[choice]\n",
        "encodings = encoder.predict(samples)\n",
        "\n",
        "vectors = interpolation(encodings[0], encodings[1], N_inter)\n",
        "images = decoder.predict(vectors)\n",
        "\n",
        "size = (images.shape[2]*10, images.shape[1]*10)\n",
        "out = cv2.VideoWriter('interpolation.avi',cv2.VideoWriter_fourcc(*'DIVX'), 30, size, 0)\n",
        "\n",
        "for i in range(len(images)):\n",
        "    img = images[i] / np.max(images[i])\n",
        "    img = (cv2.resize(255*img.reshape(28, 28), size, cv2.INTER_NEAREST))\n",
        "    out.write(img.astype(np.uint8))\n",
        "out.release()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PBTLNGv4trDE",
        "colab_type": "text"
      },
      "source": [
        "# Denoising\n",
        "Другое интересное применение Autoencoder'ов - очищение входной картинки от шумов. Такое принципиально возможно из-за того, что размерность латентного пространства очень мала по сравнению с размерностью входного пространства(в нашем случае - 32 и 784 соответственно) - в нём попросту нет места случайному шуму, но зато есть место для общих закономерностей из входного пространства."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EO07OLzPtbu2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "noise_factor = 0.3\n",
        "\n",
        "# Add some noise to images\n",
        "x_train_noisy = x_train + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=x_train.shape) \n",
        "x_test_noisy = x_test + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=x_test.shape) \n",
        "choice = np.random.choice(x_test.shape[0], 5)\n",
        "\n",
        "# Plot noisy and original images\n",
        "samples = x_train_noisy[choice]\n",
        "plot_images(samples.reshape(-1, 28, 28), \"Training data - noisy\")\n",
        "plot_images(x_train[choice].reshape(-1, 28, 28), \"Training data\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ICEXaTbtbu5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Training\n",
        "autoencoder.fit(x_train_noisy, x_train, batch_size=64, epochs=10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mkleDBlntbu7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "N_images = 6\n",
        "# Select several images from test dataset\n",
        "samples = x_test_noisy[np.random.choice(x_test_noisy.shape[0], N_images)]\n",
        "reconstructed = autoencoder.predict(samples)\n",
        "# Plot inputs and denoised outputs\n",
        "plot_images(samples.reshape(-1, 28, 28), title='Noisy images')\n",
        "plot_images(reconstructed.reshape(-1, 28, 28), title='Denoised by autoencoder')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p6qdtbLZIcCu",
        "colab_type": "text"
      },
      "source": [
        "# Список задач\n",
        "1) Написать Encoder.\n",
        "\n",
        "2) Поэкспериментировать с разными размерами латентного пространства - как его размер будет влиять на качество восстановления изображений, на гладкость интерполяции?\n",
        "\n",
        "3) Попробовать убрать регуляризацию из Encoder'a - изменилось ли качество интерполяции между картинками?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZUCSnpJctbu9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}